[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "XIAO: Big Power, Small Board",
    "section": "",
    "text": "Preface\nFrom the expansive boards of the past, Arduino has come a long way and entered the Seeed Studio XIAO series: thumb-sized yet power-packed, opening a vast horizon for innovation. “XIAO: Big Power, Small Board” dives deep into these capabilities, guiding readers from the basics of Arduino to intricate miniaturized projects. Whether readers want to illuminate an LED or delve into Embedded Machine Learning (TinyML) with XIAO boards and Edge Impulse Studio, this book covers them. Need for prior knowledge? No worries! This book takes a hands-on, project-based approach, ensuring readers grasp the concepts while implementing them. By the end, they will be adept with XIAO and inspired by many user-created projects showcasing the endless possibilities this small board offers."
  },
  {
    "objectID": "Acknowledgements.html",
    "href": "Acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "We want to express our sincere gratitude to Jiamou Yang, Yanming Wen, Mengdu Li, Chunchun Tian, Haixu Liu, Tianrui Wang, and Jianjing Huang for their invaluable technical support and manuscript revisions. This book would not have been possible without their contributions.\nWe extend our deepest gratitude to the entire TinyML4D Academic Network, comprised of distinguished professors, researchers, and professionals. Notable contributions from Marco Zennaro, Brian Plancher, José Alberto Ferreira, Jesus Lopez, Diego Mendez, Shawn Hymel, Dan Situnayake, Pete Warden, and Laurence Moroney have been instrumental in advancing our understanding of Embedded Machine Learning (TinyML).\nSpecial commendation is reserved for Professor Vijay Janapa Reddi of Harvard University. His steadfast belief in the transformative potential of open-source communities, coupled with his invaluable guidance and teachings, has served as a beacon for our efforts from the very beginning.\nAcknowledging these individuals, we pay tribute to the collective wisdom and dedication that have enriched this field and our work.\n\nIllustrative images on the e-book and chapter’s covers generated by OpenAI’s DALL-E via ChatGPT"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "The Seeed Studio XIAO series represents a groundbreaking evolution in the Arduino ecosystem, merging compactness with powerful performance. Understanding and harnessing its capabilities are essential for any enthusiast or professional in electronics and machine learning. With the rapid progression of technology and the increasing demand for smaller, more efficient devices, mastering XIAO and its integration with TinyML is crucial. It presents a new frontier for innovation, allowing the creation of sophisticated projects in spaces previously thought impossible. This topic is paramount as it aligns with the future trajectory of electronics, IoT, and machine learning, making it indispensable for those aiming to stay at the forefront of technological advancements."
  },
  {
    "objectID": "about_book.html#audience",
    "href": "about_book.html#audience",
    "title": "About this Book",
    "section": "Audience",
    "text": "Audience\n The primary audience for “XIAO: Big Power, Small Board” encompasses hobbyists, students, educators, and professionals in electronics and machine learning who want to explore and maximize the potential of compact hardware platforms. Typically, these readers might hold positions as electronics enthusiasts, DIY project creators, electronics educators, or even junior embedded system developers. As they advance in their careers, they might be eyeing roles such as electronics design engineers, IoT developers, or machine learning hardware integrators.\nOur audience possesses a basic understanding of electronics concepts but may have yet to delve deep into Arduino programming or compact hardware design. They likely have encountered standard beginner books on Arduino or general electronics but might have yet to venture into specialized hardware or TinyML. As for skills, they have some hands-on experience with basic electronics or programming but haven’t mastered the intricacies of TinyML or advanced microcontroller functionalities."
  },
  {
    "objectID": "about_book.html#what-readers-will-learn",
    "href": "about_book.html#what-readers-will-learn",
    "title": "About this Book",
    "section": "What readers will learn",
    "text": "What readers will learn\nBy the end of this book, the reader will understand:\n\nThe fundamentals of open-source hardware, focusing on the capabilities of the Seeed Studio XIAO series.\nHow to transition from basic to advanced electronic projects, starting with simple LED controls and advancing to complex applications like telemetry and voice keyword detection.\nThe concepts behind prototype design and its practical implications in product development.\nThe intricacies of integrating various modules like the infrared receiver, ultrasonic distance sensor, and RTC clock with the XIAO platform.\nThe significance and application of Tiny Machine Learning (TinyML), emphasizing its transformative power in hardware like the XIAO nRF52840 Sense and ESP32S3 Sense.\nTechniques to utilize advanced tools such as Edge Impulse Studio for real-world applications like anomaly and object detection and video or sound classification.\n\nThe reader will be able to:\n\nSet up, program, and troubleshoot projects across all XIAO series boards, advancing from basic hardware interactions to intricate project designs.\nConvert abstract ideas into tangible electronic product prototypes, leveraging the insights from the course.\nDesign and implement intermediate-level projects such as a Smart Watch and Air Piano using specialized sensors and modules.\nHarness the power of Wi-Fi and MQTT protocols with XIAO ESP32C3 for cloud communications and data exchange.\nDeploy TinyML on different XIAO boards, executing tasks like image, motion, and sound classification besides anomaly and object detection.\nInnovate and extend project ideas, drawing inspiration from a curated collection of XIAO projects and adapting them for custom needs."
  },
  {
    "objectID": "about_book.html#software-dependencies",
    "href": "about_book.html#software-dependencies",
    "title": "About this Book",
    "section": "Software dependencies",
    "text": "Software dependencies\n\nArduino IDE: Major updates or changes to the Arduino IDE might affect content related to Arduino development and programming in the book.\nSeeed Studio XIAO Libraries: Updates to libraries specific to the XIAO series can influence the projects or example codes provided.\nEdge Impulse Studio: Significant updates or feature changes on this platform would necessitate adjustments in the TinyML chapters.\nMQTT Libraries/Protocols: Any changes related to MQTT libraries or the protocol itself could influence the content of telemetry and commands.\nESP32 Libraries: Updates to libraries used by the XIAO ESP32C3 and ESP32S3 board may impact associated projects or examples."
  },
  {
    "objectID": "about_book.html#book-outline",
    "href": "about_book.html#book-outline",
    "title": "About this Book",
    "section": "Book outline",
    "text": "Book outline\n\nChapter 1: Introduction to Hardware and Programming\n\nIn this chapter, readers start with basic programming on XIAO using Arduino IDE. Through simple example programs, they will learn to control LED lights, buttons, buzzers, and other electronic components, mastering core programming concepts like digital I/O, analog I/O, tone generation, and mapping values. By manually typing out code examples line-by-line, they will develop strong coding habits and grasp programming syntax.\n\nChapter 2: Project Practice for Beginners - Introduction to Prototype Design\n\nIn this chapter, readers will learn the basics of designing prototypes with XIAO through beginner-friendly projects. They will start from an idea and quickly create a verification prototype, focusing more on the practical application of code rather than line-by-line analysis. By leveraging Arduino libraries, community resources, and example programs, they will learn how to find and adapt code snippets to achieve desired effects efficiently. Furthermore, they will explore how to design the physical appearance of prototypes by creatively combining electronic hardware with everyday items. The key outcomes are grasping a project-based approach and developing skills to build simple interactive prototypes.\n\nChapter 3: Intermediate Project Practice—Complex Projects\n\nIn this chapter, readers will advance their prototyping skills by creating sophisticated IoT projects with XIAO. They will implement features like Wi-Fi connectivity, MQTT telemetry, and remote control commands using the XIAO ESP32C3. Through complex builds like an intelligent remote door, smartwatch, and air piano, you will hone programming techniques for wireless communication, cloud integration, and embedded control. Optional blueprints will be provided, but readers are encouraged to explore creative enclosure designs with alternative materials. The key outcomes are mastering intermediate IoT prototyping and preparing for advanced tinyML applications.\n\nChapter 4: Project Practice Advanced - tinyML Application\n\nAmong the XIAO series products, the Seeed Studio XIAO nRF52840 Sense has Bluetooth 5.0 wireless connectivity, low power consumption, and comes with onboard 6-axis IMU and PDM microphone sensors. The XIAO ESP32S3 Sense further integrates a camera, digital microphone, and SD card support. Those features make them powerful tools for TinyML (Embedded Machine Learning) projects. TinyML solves problems in a completely different way from traditional programming methods. This chapter will introduce readers to this cutting-edge field by walking through the entire machine-learning workflow from data collection, training, and testing to deployment and inference using the Edge Impulse Studio tool.\n\nChapter 5: Creative Experiments\n\nSince its launch, the Seeed Studio XIAO series has been widely acclaimed for its compact size, powerful performance, and versatile product range. The maker community has produced a large number of projects created with XIAO. Due to space constraints, we have selected some outstanding projects made with XIAO by our makers. These projects fully demonstrate the powerful functions and wide applications of XIAO. Let us follow the makers’ steps, stimulate creativity, and explore the endless possibilities of XIAO. Readers can draw inspiration from these projects, use imagination, and explore new territories with XIAO."
  },
  {
    "objectID": "chapter_1.html",
    "href": "chapter_1.html",
    "title": "Chapter 1: Introduction to Hardware and Programming",
    "section": "",
    "text": "In this unit, we will enter the world of electronics and programming and explore how to control hardware through code. Starting with the example program, Blink, we will learn how to light up an LED, turn the light on and off through a button, control the sound of a passive buzzer, and so on. In each task, we will master commonly used programming languages, such as digital input/output, analog input/output, tone and map functions, etc., and learn the primary usage of libraries. The programs in this unit are relatively simple. During the learning process, write the program code for each task by hand, develop good habits, and avoid program upload failures due to errors in symbols or unfamiliar rules."
  },
  {
    "objectID": "chapter_1-1.html#arduino-ide-text-editor",
    "href": "chapter_1-1.html#arduino-ide-text-editor",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.1 Arduino IDE Text Editor",
    "text": "1.1.1 Arduino IDE Text Editor\nWe need to program the hardware through the Arduino IDE text editor. If you have not installed the Arduino IDE, go to the download page to install it: 🔗 Software. The Arduino IDE (Integrated Development Environment) is a programming software designed explicitly for Arduino. Through it, we can write and upload different programs for Arduino hardware. When we open the Arduino IDE software, it will create a new file named Sketch, which we can rename.\n\nFor Windows Users\nThe interface of the Arduino IDE is spotless, and can be divided into four parts: menu bar, toolbar, editing area, and debug window.\n\n Menu bar: Includes files, edit, sketch, tools, and help, such as new, save, example programs, select serial port, etc.\n Horizontal toolbar: Contains several commonly used function buttons: verify, upload, debug, board selection, serial plotter, and serial monitor selection.\n Vertical toolbar: Contains shortcuts to the project folder, board manager, library manager, debug, and search.\n Code editing area: This is where you write program code, just as we usually type text in a Word window. Write the program code in this area.\n Serial monitor, output window: On the right side of the horizontal toolbar, you can open or close the serial monitor window.\n\n\nFor MAC Users\nExcept for the location of the menu bar (at the top), which is slightly different from Windows users, all other tools and experiences are the same."
  },
  {
    "objectID": "chapter_1-1.html#adding-seeed-studio-xiao-to-arduino-ide",
    "href": "chapter_1-1.html#adding-seeed-studio-xiao-to-arduino-ide",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.2 Adding Seeed Studio XIAO to Arduino IDE",
    "text": "1.1.2 Adding Seeed Studio XIAO to Arduino IDE\n\n⚠️ Attention\n Due to space limitations, all parts of this course’s program code and hardware connection are based on Seeed Studio XIAO SAMD21. Most of the code in the book can be applied to all products in the Seeed Studio XIAO series. If there are exceptions, they will be additionally marked or explained for applicable hardware. If not marked, they apply to multiple products.\n\nWe must add the Seeed Studio XIAO series products to the Arduino IDE to start our learning journey.\n\nFor Windows users, first, open your Arduino IDE, click “File→Preferences” in the top menu bar, as shown in the figure, and copy the following URL into “Additional Boards Manager URLs.”\nFor Mac users, first, open your Arduino IDE, click “Arduino IDE→Preferences” in the top menu bar, as shown in the figure, and copy the following URL into “Additional Boards Manager URLs.”\nFor Seeed Studio XIAO SAMD21, XIAO nRF52840, and XIAO nRF52840 Sense, copy the link address below: https://files.seeedstudio.com/arduino/package_seeeduino_boards_index.json\nFor Seeed Studio XIAO RP2040, copy the link address below: https://github.com/earlephilhower/arduino-pico/releases/download/global/package_rp2040_index.json\nFor Seeed Studio XIAO ESP32C3, XIAO ESP32S3, copy the link address below: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_dev_index.json\n\n\n\nIf you frequently use multiple different models of XIAO at the same time, you can click on theicon on the right side of the address bar and add all three addresses above to the board manager, as shown in the figure below.\n\n\nNext, click “Tools→Board→Board Manager,” enter the keyword Seeeduino XIAO in the search bar, find Seeed SAMD Boards in the appeared entries, and click INSTALL.\n\n\nWhen the installation starts, you will see an output pop-up window. After the installation is complete, an “INSTALLED” option will appear.\n\n⚠️ Attention\n\nEnter “RP2040” in the search bar to find the installation package for Seeed XIAO RP2040.\nEnter “XIAO nrf52840” to find two installation packages: Seeed nRF52 Boards (for low-power projects) and Seeed nRF52 mbed-enabled Boards (for higher-power TinyML projects).\nEnter “ESP32” to find the installation package for ESP32 by Espressif Systems.\n\n\n\nConnecting Seeed Studio XIAO to Arduino IDE\nConnect XIAO to the computer with a data cable, as shown in the figure below:  \nNext, click on “Tools→Board”, find “Seeeduino XIAO,” and select it, as shown in the figure below.\n\n\n\n⚠️ Attention\nIf your development board is XIAO nRF52840, please select Seeed XIAO nrf52840.  If your development board is XIAO nRF52840 Sense, please select Seeed XIAO nrf52840 Sense.  If your development board is XIAO RP2040, please select Seeed XIAO RP2040.  If your development board is XIAO ESP32C3, please select XIAO_ESP32C3.  If your development board is XIAO ESP32S3, please select XIAO_ESP32S3. \n\nCheck if the port connection is correct; if not, select it manually.\n\nThe serial port on Windows systems is displayed as “COM+number,” as shown in the figure below.\nThe serial port name on Mac or Linux systems is generally /dev/tty.usbmodem+number or /dev/cu.usbmodem+number, as shown in the figure below.\n\nNow, we can start programming XIAO through the software.\n\n⚠️ XIAO ESP32C3 may not be adequately recognized in Arduino IDE 2, and you need to specify the development board and port manually.\n\n\n\n\nWhen ESP32C3 is plugged into a PC with Arduino IDE 2, it may not be able to match the correct development board automatically. As shown in the figure below, the display is not the XIAO ESP32 development board; you need to specify manually. Select ” Other Board & Port…” from the Port drop-down menu. Enter “xiao” in the search bar of the development board, select the XIAO_ESP32C3 development board from the filtered list below, and confirm after selecting the port on the right.\n\n\n\n\nNow you can see that the development board and port are in the correct state.\n\n\n\n\n⚠️ Reset Seeed Studio XIAO\nSometimes when the program upload fails, the Seeed Studio XIAO port may disappear, and we need to perform a reset operation. The reset method will be different for different models of XIAO.\n\n\nReset of Seeed Studio XIAO SAMD21\n\nConnect XIAO SAMD21 to your computer.\nOpen “Blink” in the Arduino IDE sample program and click upload.\nWhile uploading, short circuit the RST pin in the figure once with tweezers or a short wire.\nThe reset is completed when the orange LED flashes and lights up.\n\n\nAs shown in the figure below. .\n\nReset of Seeed Studio XIAO PR2040\n\nConnect Seeed Studio XIAO RP2040 to your computer.\nPress the reset button marked with “R” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, hold down the Boot button marked with “B”, connect the board to your computer while holding down the BOOT button, and then release it to enter the bootloader mode.\n\nReset of Seeed Studio XIAO nRF52840 and Sense version\n\nConnect Seeed Studio XIAO nRF52840 or Sense version to your computer.\nPress the reset button marked with “RST” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, you can quickly click it twice to enter the bootloader mode.\n\nReset of Seeed Studio XIAO ESP32C3\n\nConnect Seeed Studio XIAO ESP32C3 to your computer.\nPress the reset button marked with “R” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, hold down the Boot button marked with “B”, connect the board to your computer while holding down the BOOT button, and then release it to enter the bootloader mode.\n\nReset of Seeed Studio XIAO ESP32S3\n\nConnect Seeed Studio XIAO ESP32S3 to your computer.\nPress the reset button marked with “R” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, hold down the Boot button marked with “B”, connect the board to your computer while holding down the BOOT button, and then release it to enter the bootloader mode.\n\n\nStructure of Arduino Programs\nNow that we have the development board, how can we write programs into it to control its functions? That’s when the Arduino IDE text editor comes in handy. We’ve already introduced the interface functions of Arduino IDE in the introduction, it’s an important tool for writing and uploading programs. Arduino programs consist of two basic functions:\nsetup()  This function is called when the program begins. Use it to initialize variables, pin modes, start using libraries, etc. setup() runs only once each time the Arduino board is powered on or reset.\nloop()  After the program in setup() is executed, the program in loop() begins to execute. The program in loop() runs repeatedly.\n\n\n\nKnowledge window:\n\nThe contents after “/* */” and “//” are comments to help you understand and manage code, the comments will not affect the normal operation of the program;\nWhen writing programs, we need to use “{}” to wrap a set of codes;\nAfter each line of code, use “;” as an end symbol to tell the Arduino editor that this line of code instruction is over.\n\n\n\n\nDigital Signals and I/O Settings\nSimply put, digital signals are signals represented in binary form of 0 and 1. In Arduino, digital signals are represented by high and low levels, high level means digital signal 1, and low level means digital signal 0. Seeed Studio XIAO has 11 digital pins, we can set these pins to perform the function of inputting or outputting digital signals.\n\n\nIn Arduino, you can use functions to set the status and function of pins. Here are the basic steps to set pins through functions:\n\nFirst, determine the pin number of the pin you want to control.\nIn the Arduino code, use the pinMode() function to set the function of the pin, such as input or output. For example, to set the pin to output mode, you can use the following code:\n\nint ledPin = 13; // The pin to be controlled\nvoid setup() {\n    pinMode(ledPin, OUTPUT); // Set the pin to output mode\n}\n\nOnce you have set the pin to output mode, you can use the digitalWrite() function to set the status of the pin, such as setting it to high or low level. For example, to set the pin to high level, you can use the following code:\n\ndigitalWrite(ledPin, HIGH); // Set the pin to high level\n\nIf you set the pin to input mode, you can use the digitalRead() function to read the status of the pin, such as detecting whether it is high or low level. For example, to read the status of the pin and save it to a variable, you can use the following code:\n\nint buttonPin = 2; // The pin to read the status from\nint buttonState = 0; // The variable to save the status\nvoid setup() {\n    pinMode(buttonPin, INPUT); // Set the pin to input mode\n}\nvoid loop() {\n    buttonState = digitalRead(buttonPin); // Read the status of the pin\n}\nBy using functions like pinMode(), digitalWrite(), and digitalRead(), you can easily set and control the status and function of pins in Arduino."
  },
  {
    "objectID": "chapter_1-1.html#task-1-run-blink-to-make-xiaos-led-flash",
    "href": "chapter_1-1.html#task-1-run-blink-to-make-xiaos-led-flash",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.3 Task 1: Run Blink to Make XIAO’s LED Flash",
    "text": "1.1.3 Task 1: Run Blink to Make XIAO’s LED Flash\nJust as “Hello World” is the first section in all programming languages, “Blink” is akin to “Hello World” in Arduino programming. It is the key to our journey in learning Arduino. Arduino provides many example codes to help us get started quickly, and Blink is one of them. We can select “File → Examples → 01.Basics → Blink” in the Arduino window to open the example program Blink.\n\n\nAfter opening the example program, you can see the following code, which implements the effect of LED flashing. You can see that the code has orange and green color prompts, which proves that your input is correct. Pay attention to the difference between uppercase and lowercase.\n\n\n/*\n  Blink\n\n  Turns an LED on for one second, then off for one second, repeatedly.\n\n  Most Arduinos have an on-board LED you can control. On the UNO, MEGA and ZERO\n  it is attached to digital pin 13, on MKR1000 on pin 6. LED_BUILTIN is set to\n  the correct LED pin independent of which board is used.\n  If you want to know what pin the on-board LED is connected to on your Arduino\n  model, check the Technical Specs of your board at:\n  https://www.arduino.cc/en/Main/Products\n\n  modified 8 May 2014\n  by Scott Fitzgerald\n  modified 2 Sep 2016\n  by Arturo Guadalupi\n  modified 8 Sep 2016\n  by Colby Newman\n\n  This example code is in the public domain.\n\n  https://www.arduino.cc/en/Tutorial/BuiltInExamples/Blink\n*/\n\n// the setup function runs once when you press reset or power the board\nvoid setup() {\n  // initialize digital pin LED_BUILTIN as an output.\n  pinMode(LED_BUILTIN, OUTPUT);\n}\n\n// the loop function runs over and over again forever\nvoid loop() {\n  digitalWrite(LED_BUILTIN, HIGH);  // turn the LED on (HIGH is the voltage level)\n  delay(1000);                      // wait for a second\n  digitalWrite(LED_BUILTIN, LOW);   // turn the LED off by making the voltage LOW\n  delay(1000);                      // wait for a second\n}\n\nCode Analysis\n\npinMode(LED_BUILTIN, OUTPUT);\nThe first thing the code does is to initialize LED_BUILTIN as an output pin in the setup() function. Most Arduino series boards default the onboard LED to digital pin 13. The constant LED_BUILTIN connects the onboard LED to pin 13.\n\n\n\ndigitalWrite(LED_BUILTIN, HIGH);\nIn the loop() function, we set the LED_BUILTIN pin to the “on” state, outputting 5V or 3.3V voltage to this pin, which can be represented by HIGH. However, note that all I/O pins on XIAO are 3.3V. Do not input a voltage exceeding 3.3V, or it may damage the CPU.\n\n\ndigitalWrite(LED_BUILTIN, LOW);\nWhat comes on must turn off. This statement sets the LED_BUILTIN pin to the “off” state, outputting 0V voltage to this pin, which can be represented by LOW.\n\n\ndelay(1000);\nThis is a delay statement. It means that the LED can maintain the “on” or “off” state for 1 second, because the parameter in the function is in milliseconds, so 1000 milliseconds is 1 second. After controlling the “on” and “off” statements of the LED, a delay must be added, and the waiting time should be the same to ensure that the LED flashes evenly.\n\n\n\nUpload the Program\nNext, we will learn how to upload the program. Use the data cable in the kit to connect XIAO to the computer, as shown in the figure.\n\n\nChoose the serial port of the development board from the “Tools” bar. For Windows users, it is generally COM3 or a larger number. Select it as shown in the figure below.\nIf several ports are displayed for selection, unplug the data cable, reopen the “Tools” bar, and the port that disappears is the XIAO port. Reconnect the circuit board and then select this serial port. After selecting the board and the serial port, you can see the controller model and corresponding serial port that have been set up in the lower right corner of the IDE interface.\n\n\nIn Mac or Linux systems, the serial port name is generally /dev/tty.usbmodem+number or /dev/cu.usbmodem+number, as shown in the figure below.\n\n\nNext, we can upload the program. Before uploading, we can click the (verify button) to verify whether the program is correct. If “Compilation Completed” is displayed, the program is correct.\n\n\nClick the  (upload button), the debug window will display “Compiling Project→Upload”. When “Upload Completed” is displayed, you can see the effect of the program running on XIAO, as shown in the upload successful prompt window displayed on a Mac computer.\n\n\n\n⚠️ Note\nWhen you start writing code, you will often forget the rules of uppercase and lowercase, punctuation, and make mistakes. Therefore, try to write code by yourself instead of copying and pasting. After the example program is successfully uploaded, try to create a new Sketch and start manually inputting the code."
  },
  {
    "objectID": "chapter_1-1.html#task-2-complete-the-blink-example-by-connecting-an-external-led-to-seeed-xiao-esp32c3-without-led",
    "href": "chapter_1-1.html#task-2-complete-the-blink-example-by-connecting-an-external-led-to-seeed-xiao-esp32c3-without-led",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.4 Task 2: Complete the Blink example by connecting an external LED to Seeed XIAO ESP32C3 without LED",
    "text": "1.1.4 Task 2: Complete the Blink example by connecting an external LED to Seeed XIAO ESP32C3 without LED\nIf the XIAO you have on hand is Seeed XIAO ESP32C3, since it does not have an onboard LED available for users, in order to run the Blink program, you need to first connect an LED to the D10 pin of the board, as shown below:\n\n\n\n⚠️ Note  You must connect a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED to prevent the strong current from burning the LED.\n\nThen copy the following program to the Arduino IDE:\n// Define the LED pin according to the pin diagram\nint led = D10;\n\nvoid setup() {\n    // Initialize the digital pin 'led' as output\n    pinMode(led, OUTPUT);\n}\n\nvoid loop() {\n    digitalWrite(led, HIGH);   // Turn the LED on\n    delay(1000);               // Wait for a second\n    digitalWrite(led, LOW);    // Turn the LED off\n    delay(1000);               // Wait for a second\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L1_Blinks_XIAO_ESP32C3/L1_Blinks_XIAO_ESP32C3.ino\n\n\nCode Analysis \nint led = D10;\nSeeed XIAO ESP32C3 does not have an onboard LED, so we did not preset an LED corresponding pin in the Arduino core. Just now, we connected the LED to the D10 pin, so we need to declare it in the program.\npinMode(led, OUTPUT);\nWe defined led as D10, and this step is to initialize led(D10) as an output pin."
  },
  {
    "objectID": "chapter_1-1.html#extended-exercise",
    "href": "chapter_1-1.html#extended-exercise",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.5 Extended Exercise",
    "text": "1.1.5 Extended Exercise\nRewrite the Blink program: In the example program, the LED is on and off for 1 second each time, so it seems to blink evenly. Try adjusting the waiting time to give the LED different blinking effects.\nHint:\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);\n}\nvoid loop() {\n    digitalWrite(LED_BUILTIN, HIGH);   \n    delay(1000);                     \n    digitalWrite(LED_BUILTIN, LOW);   \n    delay(500);   \n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L1_ll_Blinks_1_en/L1_ll_Blinks_1_en.ino\n\nFor XIAO ESP32C3, we also need to modify the pin definition part of the program:\nint led = D10;\nvoid setup() {\n    pinMode(led, OUTPUT);\n}\nvoid loop() {\n    digitalWrite(led, HIGH);   \n    delay(1000);                     \n    digitalWrite(led, LOW);   \n    delay(500);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L1_ll_blinks_2_en/L1_ll_blinks_2_en.ino"
  },
  {
    "objectID": "chapter_1-2.html#background-knowledge",
    "href": "chapter_1-2.html#background-knowledge",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.1 Background Knowledge",
    "text": "1.2.1 Background Knowledge\nIn the last section, we only used the onboard LED light of the Seeed Studio XIAO without connecting other modules. It could take quite some effort for beginners to use Dupont wires to connect external sensors to a board the size of a thumb and also involve a breadboard. Is there a simpler method?\n\n1.2.1.1 Seeed Studio XIAO Expansion Board\nThe Seeed Studio XIAO Expansion Board, only half the size of Raspberry Pi 4, is powerful and can quickly and easily build prototypes and projects. The board has a variety of peripherals such as OLED, RTC, expandable memory, passive buzzer, RESET/User button, 5V servo/sensor connector, various data interfaces… You can explore the infinite possibilities of Seeed Studio XIAO. The board also supports CircuitPython.  All models in the Seeed Studio XIAO series have uniform specifications and support the Seeed Studio XIAO Grove Shield and Seeed Studio XIAO Expansion Board. The series includes XIAO SAMD21, XIAO RP2040, XIAO nRF52840, XIAO nRF52840 Sense, XIAO ESP32C3 and XIAO ESP32S3. The front and back function interfaces of the XIAO expansion board are shown in the following figure:\n\n\nTo make it easier and quicker to build projects with Seeed Studio XIAO, we equipped it with a powerful expansion board. This board has a wealth of onboard peripherals and can quickly connect to more electronic modules to implement various functions. The expansion board brings out all the pins of XIAO, as shown in the pin diagram below:\n\nIn most cases, the XIAO expansion board is suitable for all Seeed Studio XIAO series products.  When we need to use the XIAO expansion board, we need to connect the XIAO development board to the corresponding position on the expansion board, as shown in the figure below. Connect the pin headers on the XIAO main board to the position circled in yellow on the expansion board. Be sure to align it before pressing down to avoid damaging the pins. After that, we can start working on projects in combination with the expansion board.\n\n\n\n⚠️ Note  Please first plug the Seeed Studio XIAO into the two female headers on the expansion board, and then plug in the Type-C power supply, otherwise it will damage the Seeed Studio XIAO and the expansion board.\n\n\n\n1.2.1.2 Three Basic Structures of Programs\nThe three basic structures of programs are sequential structure, selection structure, and loop structure.  \n\nSequential Structure\nAs the name suggests, the program in a sequential structure is executed in the order of the statements. It is the most basic and simple program structure. As shown in the figure below, the program will first execute the operation in the S1 box, then the operation in the S2 box, and so on.\n\n\n\n\nSelection Structure\nIn a program,sometimes we need to make judgments based on the situation to decide the next step. For instance, the program might need to judge the light value in the current environment. If the light value is high, indicating a bright environment, there’s no need to light up the light. If the light value is low, indicating a dim environment, then it’s necessary to turn on the light. In such cases, we use a selection structure.  As shown in the following figures, the selection structure will judge whether the condition is fulfilled. If “True”, it executes S1; if “False”, it executes S2; or if “True”, it executes S1, if “False”, it exits the selection structure.\n\n\n\nThe if Statement\nThe if statement is the most common selection structure, which executes the following statement when the given expression is true. The if statement has three structural forms as shown in the following example. Simple branch structure: Execute when the condition is fulfilled.\nif (expression) {\n  statement;\n}\nDual branch structure: Execute statement1 when the condition is fulfilled, otherwise execute statement2.\nif (expression) {\n  statement1;\n}\nelse {\n  statement2;\n}\nMulti-branch structure: Use nested if statements to judge different situations.\nif (expression1) {\n  statement1;\n}\nelse if (expression2) {\n  statement2;\n}\nelse if (expression3) {\n  statement3;\n}\n\n\nswitch……case Statement\n When dealing with multiple selection branches, using an “if……else” structure to write a program can be quite lengthy. In this case, it’s much more convenient to use a switch statement. The switch structure compares the expression in parentheses with the constants after case. If they match, it executes the corresponding statement and exits the structure via a break statement. If none match, it runs the statement after default. It’s important to note that the expression in parentheses after switch must be of integer or character type.\n\n\nswitch (expression) {\n  case constant_expression1:\n    statement1;\n    break;\n  case constant_expression2:\n    statement2;\n    break;\n    ……\n  default:\n    statementn;\n    break;\n}\n\n\n\nbreak Statement \nThe break statement can only be used in a switch multi-branch selection structure and loop structures. It is used to terminate the current program structure, allowing the program to jump to subsequent statements for execution.\n\n\n\nLoop Structure \nA loop structure is used when a part of the program needs to be executed repeatedly, based on given judgment conditions to determine whether to continue executing a certain operation or exit the loop. There are three common types of loop statements: \n\nwhile Loop \nThe while loop is a type of “when” loop that executes the statements in the loop body when a certain condition is met.\n\n\n\n\nwhile (expression) {\n  statement;\n}\n\n\ndo……while Loop\nThis is a type of “until” loop. The statement in the loop body is executed once before the expression is evaluated. If the expression is true, the loop continues.\n\n\n\n\ndo {\n  statement;\n} while (expression);\n\n\n\nfor Loop\nThis includes three expressions: Expression1 for initialization, Expression2 for judgment, and Expression3 for increment.\n\n\n\n\nfor (Expression1; Expression2; Expression3) {\n  statement;\n}\nIn addition to the above loop statements, there are control statements, break and continue, in the loop structure used to prematurely end the loop or exit the loop. In this lesson, we just need to understand these program structures. In later courses, we will gradually master them through project examples."
  },
  {
    "objectID": "chapter_1-2.html#task-1-control-the-led-on-the-xiao-using-the-button-on-the-xiao-expansion-board",
    "href": "chapter_1-2.html#task-1-control-the-led-on-the-xiao-using-the-button-on-the-xiao-expansion-board",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.2 Task 1: Control the LED on the XIAO using the button on the XIAO expansion board",
    "text": "1.2.2 Task 1: Control the LED on the XIAO using the button on the XIAO expansion board\n\nAnalysis\nThe effect we want to achieve is that when the button is pressed, the LED lights up; when the button is released, the LED goes off. The program is written in three steps:\n\nDefine pins and create variables.\nInitialize and set pin status.\nRead the button status, implement condition judgment. If the button is pressed, the light is on, otherwise, the light is off.\n\n\n\nVariable\n\nIn a program, a value that can change is called a variable. For example, defining an integer variable i as int i;. We can assign a value to the variable at the same time as we define it, such as int i =0;. Furthermore, depending on the data type, different statements are used to define variables, such as defining a floating point number, float x = 1.9;, and so on. For more details, refer to the Arduino data types and constants documentation https://www.arduino.cc/reference/en/#variables.\n\n\n\nWriting the Program:\nStep 1: Define pins and create variables. The on-board button switch on the XIAO expansion board is D1, so we define it as pin 1 and set a variable for the button status. Note that LED_BUILTIN will set the LED to the correct pin, so we don’t need to manually define it:\nconst int buttonPin = 1;  // The on-board button switch on the XIAO expansion board is D1, which we define as pin 1\n// If you are using XIAO RP2040, please change 1 to D1\nint buttonState = 0;  // buttonState is a variable to store the button status\nStep 2: Set pin status. Set the LED pin to output status and the button pin to input pull-up status. Use INPUT_PULLUP to enable internal pull-up resistors. When the button is not pressed, it returns 1 or HIGH (high level). When the button is pressed, it returns 0 or LOW (low level).\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);// Set the LED pin to output status\n    pinMode(buttonPin, INPUT_PULLUP);// Set the button pin to input status\n}\nStep 3: Continuously read the button status. If the button is pressed, the light is on, otherwise, the light is off. Because the on-board LED of the XIAO is negative logic, when the button is pressed and returns 0, the LED is on; when it returns 1, the LED is off.\nvoid loop() {\n    // Read the button status and store it in the buttonState variable\n    buttonState = digitalRead(buttonPin);  \n    // Check whether the button is pressed, if the button is pressed\n    if (buttonState == HIGH) {\n        // Turn on the LED:\n        digitalWrite(LED_BUILTIN, HIGH);\n    }\n    else {\n        // Turn off the LED:\n        digitalWrite(LED_BUILTIN, LOW);\n    }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L2_Button_XIAO_en/L2_Button_XIAO_en.ino\n\n\n\nUploading the Program\nWe upload the program we wrote to the hardware. First, use the data cable in the kit to connect the XIAO to the computer.\n\n\nNote the position of the buttons on the XIAO extensions used for testing in the figure.  Then click the verify button  to verify the program. If it is correct, click the upload button  to upload the program to the hardware. When the debugging area displays “Done uploading.”, we can press the button to see if the LED lights up.\n\n\n\n⚠️ Note  There are two identical buttons on the expansion board. One is the RESET button near the Type-C interface, and the other is the user-defined button near the lithium battery interface. Test with the one near the lithium battery interface."
  },
  {
    "objectID": "chapter_1-2.html#task-2-use-the-button-on-the-xiao-expansion-board-to-control-the-external-led-on-the-xiao-esp32c3",
    "href": "chapter_1-2.html#task-2-use-the-button-on-the-xiao-expansion-board-to-control-the-external-led-on-the-xiao-esp32c3",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.3 Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3",
    "text": "1.2.3 Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3\nFor the Seeed XIAO ESP32C3, it doesn’t have an on-board LED for users to use. To run the Blink program, you need to first connect an LED to the D10 pin of the board as shown:\n\n\n⚠️ Note  Be sure to add a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED to prevent overcurrent from burning out the LED.\n\nThen copy the following program into the Arduino IDE:\n/*\n * Button controlling external LED of XIA\n\nApologies for the confusion. It seems that there was an issue with quoting text from the document. Let's continue:\n\n#### Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3\nFor the Seeed XIAO ESP32C3, it doesn't have an on-board LED for users to use. To execute the Blink program, you first need to connect an LED to the board's `D10` pin as shown. \n\n&gt; ⚠️ Note: Make sure to add a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED and prevent overcurrent from burning out the LED.\n\nThen, copy the following program into the Arduino IDE:\n```cpp\n/*\n * Button controlling external LED of XIAO ESP32C3\n */\n\nconst int buttonPin = 1;     // The pin number of the button\nint buttonState = 0;    // Variable for reading the button status\nint led = D10;  // Pin number of the LED\n\nvoid setup() {\n  // Initialize the LED pin as an output:\n  pinMode(led, OUTPUT);\n  // Initialize the button pin as an input:\n  pinMode(buttonPin, INPUT_PULLUP);\n}\n\nvoid loop() {\n  // Read the state of the button:\n  buttonState = digitalRead(buttonPin);\n  // Check if the button is pressed. If it is, the button state is HIGH\n  if (buttonState == HIGH) {\n    // Turn the LED on:\n    digitalWrite(led, HIGH);\n  }\n  else {\n    // Turn the LED off:\n    digitalWrite(led, LOW);\n  }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L2_Button_XIAO_ESP32C3_en\n\n\nPowering XIAO with an external battery\nWhen demonstrating the effect, in addition to using a data cable to power the computer, you can also use an external lithium battery. This makes it convenient to move and do projects, as shown in the picture."
  },
  {
    "objectID": "chapter_1-2.html#expanded-exercise",
    "href": "chapter_1-2.html#expanded-exercise",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.4 Expanded Exercise",
    "text": "1.2.4 Expanded Exercise\n\nFlow Chart \nBefore writing the program, you can first draw a flow chart of the program to help organize your thoughts. The common flow chart symbols are as follows:\n\n\nThe button-controlled LED program we implemented in this section is represented by the following flow chart. You can try drawing it yourself."
  },
  {
    "objectID": "chapter_1-3.html#background-knowledge",
    "href": "chapter_1-3.html#background-knowledge",
    "title": "1.3 Transforming XIAO and its Expansion Board into a Morse Code Transmitter",
    "section": "1.3.1 Background Knowledge",
    "text": "1.3.1 Background Knowledge\n\n1.3.1.1 Buzzer\nA buzzer is an integrated electronic sound device that generates sound based on the input of an electrical signal. Buzzers are often installed on electronic products for sound generation. There are two types of buzzers: active (source buzzers) and passive (sourceless buzzers).\n\nActive Buzzers: These buzzers have a simple oscillation circuit inside. When connected to a DC power supply, the buzzer can convert a constant DC into a certain frequency pulse signal, thereby driving the internal aluminum sheet to vibrate and make a sound. Active buzzers can usually only emit some fixed-pitch (frequency) sounds and are widely used in the sound devices of computers, printers, copiers, alarms, electronic toys, car electronics, phones, timers, and other electronic products.\nPassive Buzzers: These buzzers work similarly to loudspeakers. They don’t have an internal oscillator and need to be connected to a changing current signal to work. They usually use different frequency square wave signals for driving. The sound generated by passive buzzers will change according to the change in input signal, and they can output a variety of sounds like speakers, not just emitting a fixed single tone (frequency).\n\n\n\nThe standalone buzzer module is shown in the figure below.\n\n\n\nIn the Seeed Studio XIAO expansion board, there is an onboard passive buzzer connected to pin A3. We can output PWM pulse signals to this pin to control the buzzer.\n\n\n\n\n1.3.1.2 tone() and noTone() Functions\n\ntone()Function\nThe tone()function can generate a fixed frequency PWM signal to drive a passive buzzer to make a sound, and it can define the frequency and duration of the sound.\n\nSyntax:\ntone(pin, frequency);  tone(pin, frequency, duration);\n\n\nParameters:\npin: The pin to which the buzzer is connected (in the Seeed Studio XIAO expansion board, it’s A3).  frequency:The frequency of the sound (unit: Hz), the type allowed is unsigned integer. duration:The duration of the sound (unit: milliseconds, this parameter is optional), the type allowed is unsigned long.\n\n\n\nnoTone() Function\nThis function is used to stop the sound of the buzzer controlled by the tone() function. If there is no sound generated, the function is invalid.\n\nSyntax:\nnoTone(pin);\n\n\nParameters:\npin: The pin to stop the sound.\n\n\n\n\n1.3.1.3 Common Operators\nIn previous studies, we have used some operators. Next, we will learn about common types of operators and their usage methods.\n\nArithmetic Operators: \n\n\n\nOperator\nExplanation\n\n\n\n\n=\nAssignment operator\n\n\n+\nAddition operator\n\n\n-\nSubtraction operator\n\n\n*\nMultiplication operator\n\n\n/\nDivision operator\n\n\n%\nModulus operator\n\n\n\n\n\nComparison Operators:\n\n\n\nOperator\nExplanation\n\n\n\n\n!=\nNot equal to\n\n\n&lt;\nLess than\n\n\n&lt;=\nLess than or equal to\n\n\n==\nEqual to\n\n\n&gt;\nGreater than\n\n\n&gt;=\nGreater than or equal to\n\n\n\n\n\nBoolean Operators:\n\n\n\nOperator\nExplanation\n\n\n\n\n&&\nLogical “and”\n\n\n!\nLogical “not”\n\n\n\n\n\n\n\n\n\nCompound Operators:\n\n\n\nOperator\nExplanation\n\n\n\n\n++\nSelf-increment\n\n\n+=\nCompound addition\n\n\n–\nSelf-decrement\n\n\n-=\nCompound subtraction\n\n\n\nFor detailed explanations, see: https://www.arduino.cc/reference/en/\n\n\n\n1.3.1.4 Morse Code\nMorse code is a method of expressing information in telecommunication, named after the inventor of the telegraph, Samuel Morse.\n\n\nSource of the picture: https://en.wikipedia.org/wiki/Samuel_Morse  The international Morse code encodes the 26 English letters A to Z, some non-English letters, Arabic numbers, and a small number of punctuation marks and prosigns. There is no distinction between upper and lower case letters. Each Morse code symbol consists of a series of dots (·) and dashes (—). The duration of a dot is the basic unit of time measurement in Morse code transmission. The duration of a dash is three times the duration of a dot. After each dot or dash in a character, there is a time when the signal is absent, called a space, equal to the duration of a dot. For example, the standard emergency distress signal SOS is expressed in Morse code as shown in the figure below.\n\n\nIf it’s expressed in sound, it sounds like this.\n\n\nYour browser does not support the audio element. \nAs can be seen, Morse code essentially encodes duration to transmit signals. With such encoding rules, people can present duration in many ways, such as intermittently emitting sounds, intermittently lighting up searchlights, etc., to ultimately achieve the purpose of sending information.\n\n\nSource of the picture:https://en.wikipedia.org/wiki/Morse_code  Morse code was used most when communication was not developed. People used Morse code for long-distance information transmission through radio. The old device below is an early telegraph device, where the operator controls the long and short signals of the telegraph by pressing the circular handle on the right.\n\n\nSource of the picture: https://en.wikipedia.org/wiki/Morse_code  If you are interested in Morse code, you can visit the following website. The website can translate the letters and numbers you enter into Morse code and provide a download of the sound file.  https://morsedecoder.com/"
  },
  {
    "objectID": "chapter_1-3.html#task-1-automatic-broadcasting-of-sos",
    "href": "chapter_1-3.html#task-1-automatic-broadcasting-of-sos",
    "title": "1.3 Transforming XIAO and its Expansion Board into a Morse Code Transmitter",
    "section": "1.3.2 Task 1: Automatic Broadcasting of “SOS”",
    "text": "1.3.2 Task 1: Automatic Broadcasting of “SOS”\n\nAnalysis\nAutomatic broadcasting means that when the control board is started, the onboard buzzer automatically emits the Morse code of “SOS”. The program is written in three steps:\n\nDefine the buzzer pin\nInitialization, setting the state of the buzzer pin\nLoop the buzzer to play the Morse code of “SOS”\n\nLet’s first look at how to reflect the Morse code of “SOS” through the program. If you import the audio file of Morse code into the audio editing software, you can see the waveform of the sound and the duration of each syllable, which is generally divided into long and short sounds. To facilitate understanding and programming, we use a binary way to mark the switch of the buzzer, 1 indicates the buzzer is on, 0 indicates the buzzer is off, and the gray number represents how long the current status needs to last. After a Morse code ends, because it needs to be looped, you need to leave time between the two Morse codes, here it is set to 0.8 seconds.\n\n\nTo emit a short sound, which corresponds to a dot in Morse code, from the buzzer, you can use the following code in Arduino:\ntone(pinBuzzer, 200);\ndelay(100);\nnoTone(pinBuzzer);\ndelay(100);\nIn this code snippet:\n\ntone(pinBuzzer, 200) generates a sound at a frequency of 200 Hz on the buzzer connected to the pinBuzzer pin.\ndelay(100) waits for 100 milliseconds. This is how long the sound lasts.\nnoTone(pinBuzzer) stops the sound on the buzzer.\nThe final delay(100) ensures there’s a pause before the next sound is generated, representing the space between the signals.\n\nThe code you provided is a complete Arduino program for emitting the SOS Morse code signal using a buzzer. Here is the English explanation:\n\nWriting the Program \nStep 1: Define pins and create variables\nint pinBuzzer = 3; // Define the buzzer on pin 3, if you're using XIAO RP2040/XIAO ESP32, change 3 to A3\nStep 2: Set pin state\nvoid setup() {\n    pinMode(pinBuzzer, OUTPUT); // Set the buzzer pin to output state\n}\nStep 3: Loop to play “SOS” Morse code\nvoid loop() {\n    // Emit three short signals:\n    for(int i = 0; i &lt; 3; i++){\n        tone(pinBuzzer, 200);\n        delay(100);\n        noTone(pinBuzzer);\n        delay(100);\n    }\n    delay(200);\n\n    // Emit three long signals:\n    for(int i = 0; i &lt; 3; i++){\n        tone(pinBuzzer, 200);\n        delay(300);\n        noTone(pinBuzzer);\n        delay(100);\n    }\n    delay(200);\n\n    // Emit three short signals again:\n    for(int i = 0; i &lt; 3; i++){\n        tone(pinBuzzer, 200);\n        delay(100);\n        noTone(pinBuzzer);\n        delay(100);\n    }\n    delay(800); // Wait before repeating\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L3_SOS_XIAO_en\n\n\n\nUploading the Program\nTo upload the program to your hardware, connect your XIAO to your computer using the data cable included in the kit. After this, click on the verify button  to check your program. If it passes verification, click on the upload button  to upload the program to your hardware. When the debug area shows “Done uploading.”, you can listen to the Morse code sound. Is it the rhythm you expected?\n\n\nNote the position of the buttons on the XIAO extensions used for testing in the figure."
  },
  {
    "objectID": "chapter_1-3.html#task-2-control-the-buzzer-with-a-button",
    "href": "chapter_1-3.html#task-2-control-the-buzzer-with-a-button",
    "title": "1.3 Transforming XIAO and its Expansion Board into a Morse Code Transmitter",
    "section": "1.3.3 Task 2: Control the buzzer with a button",
    "text": "1.3.3 Task 2: Control the buzzer with a button\nControlling the buzzer with a button to emit Morse code can be done manually. The code logic is simple: use an if statement to determine if the button is pressed. If it is, then the buzzer emits a sound.\n\nAnalysis \nThe program is also written in three steps:\n\nDefine the buzzer and button pins.\nInitialize by setting the state of the buzzer and button pins.\nDetermine whether the button is pressed; if pressed, emit a sound.\n\n\n\nWrite the program: \nStep 1: Define the buzzer and button pins\nconst int buttonPin = 1; // The button is on pin 1, if you are using XIAO RP2040/XIAO ESP32, please change 1 to D1\nint pinBuzzer = 3;// The buzzer is on pin 3, if you are using XIAO RP2040/XIAO ESP32, please change 3 to A3\nStep 2: Set the button and buzzer pin states\nvoid setup() {\n    // Set the buzzer pin as output:\n    pinMode(pinBuzzer, OUTPUT);\n    // Set the button pin as input:\n    pinMode(buttonPin, INPUT_PULLUP);\n}\nStep 3: Check the button state, if the button is pressed, the buzzer sounds. Here, the tone() function is used to control the passive buzzer to make a sound.\nvoid loop() {\n    // buttonState is the button variable, read the button state and store it in the variable:\n    int buttonState = digitalRead(buttonPin);\n\n    // Check if the button is pressed, if the button is pressed:\n    if (buttonState == LOW) {\n        // The buzzer sounds with a frequency of 200, for a duration of 200 milliseconds\n        tone(pinBuzzer, 200, 200);\n    }\n}\n\n⚠️ Note:  There are two identical buttons on the expansion board, one is the RESET button, which is closer to the Type-C interface, and the other is the user-defined button, which is closer to the lithium battery interface. When testing, press the one closer to the lithium battery interface.\n\nThe complete program is as follows:\n/*\n * Button-SOS\n */\nconst int buttonPin = 1; // The button is on pin 1, if you are using XIAO RP2040/XIAO ESP32, please change 1 to D1!\nint pinBuzzer = 3; // The buzzer is on pin 3, if you are using XIAO RP2040/XIAO ESP32, please change 3 to A3!\nvoid setup() {\n  // Set the buzzer pin as output:\n  pinMode(pinBuzzer, OUTPUT);\n  // Set the button pin as input:\n  pinMode(buttonPin, INPUT_PULLUP);\n}\n \nvoid loop() {\n  // buttonState is the button variable, read the button state and store it in the variable:\n  int buttonState = digitalRead(buttonPin);\n \n  // Check if the button is pressed, if the button is pressed:\n  if (buttonState == LOW) {\n    // The buzzer sounds with a frequency of 200, for a duration of 200 milliseconds\n    tone(pinBuzzer, 200, 200);\n  }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L3_ButtonSOS_XIAO_en\n\n\n\nUploading the program\nWe will upload the written program to the hardware. First, connect the XIAO to your computer using the data cable from the kit.\n\n\nNext, click the  (verify button) to validate the program. If there are no errors, click the  (upload button) to upload the program to the hardware. When the debug area shows “Done uploading.”, we can press the button on the XIAO expansion board and test whether the buzzer will sound."
  },
  {
    "objectID": "chapter_1-3.html#extended-exercise",
    "href": "chapter_1-3.html#extended-exercise",
    "title": "1.3 Transforming XIAO and its Expansion Board into a Morse Code Transmitter",
    "section": "1.3.4 Extended Exercise",
    "text": "1.3.4 Extended Exercise\nThe passive buzzer can emit different pitches to form a simple melody. Research how to make Arduino play notes through a search engine. You can open the extended exercise code to experience the effect of playing “Happy Birthday” with the buzzer.\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L3_HappyBirthday_en"
  },
  {
    "objectID": "chapter_1-4.html#background-knowledge",
    "href": "chapter_1-4.html#background-knowledge",
    "title": "1.4 Monitor Knob Value Changes with Serial Monitor",
    "section": "1.4.1 Background Knowledge",
    "text": "1.4.1 Background Knowledge\n\n1.4.1.1 Rotary Potentiometer\nThe rotary potentiometer, although it doesn’t seem common, has a very wide range of uses in household appliances and industrial equipment. For example, the volume knob on the sound system.\n\n\nThe rotary potentiometer can produce an analog output value between 0 and VCC (the voltage of the connected circuit) on its connected pins. By rotating the knob, you can change the output voltage value. The range of the knob’s angle is 300°, and the output value is 0-1023. We can use the rotary potentiometer to control the LED light to show brightness changes, or control the servo to rotate at different angles, etc.\n\n\n\n\n\n1.4.1.2 Analog I/O\nIn the Arduino series of development boards, the pins with “A” in front of the pin number are analog input pins. We can read the analog value on these pins to achieve the effect we want.\n\nAnalog Signal\nIn life, analog signals are everywhere, such as the change in sound, light, temperature, etc., the frequency, amplitude, etc. of the signal can change continuously with time.\n\n\nSo how do we read the analog value of the pin through the development board? The analog input pin has an ADC (analog-to-digital converter), which can convert the external input analog signal into a digital signal that the development board can recognize, thereby achieving the function of reading in analog values, i.e., it can convert a 0-5V voltage signal into an integer value of 0-1023.\n\nanalogRead();\n\nRead the value from the specified analog pin.  Syntax  analogRead(pin);  Parameters  pin:The name of the analog input pin to be read.\n\nanalogWrite();\n\nCorresponding to analog input is analog output. We use the analogWrite() function to achieve this function. It should be noted that when using this function, it is only through a special way to output different voltages to achieve the effect of approximate analog values. This method is called PWM pulse width modulation, so we are writing PWM square waves to the specified pin, not the true analog value.\nSyntax  analogWrite(pin, value);\nParameters  pin:The pin to output PWM, allowed data type: int.  value: Duty cycle, between 0-255, allowed data type: int.\n\nPWM Pulse Width Modulation\nPulse width modulation (PWM) is a way to achieve analog results through digital output. Simply put, you can control the charging current by adjusting the period of PWM and the duty cycle of PWM. As shown in the figure, the voltage is switched back and forth between 0V (low level) and 5V (high level). A switchback is a period. In this period, if the time of high voltage is 25% and the time of low voltage is 75%, the duty cycle is 25%, and the output voltage is 5V.  When we write a few lines of code to control the lighting of LEDs on the development board, or use button switches to control the buzzer, we can directly observe the working status of these external hardware. If it achieves our expected results, we are lucky. But what if it doesn’t? The program compiles without errors, so where is the problem? It would be nice if they could talk. In this section, we will learn how to communicate with the computer, monitor the running status and information of the program and hardware through the serial monitor.   \n\n\n\n\n1.4.1.3 Serial Communication\nWhen we want to communicate with other devices using XIAO, the most common method is serial communication. All Arduino series development boards have this functionality. As we know, computers understand binary data (like 1010). Therefore, among electronic devices, serial communication achieves its function by sending and receiving such data. The key component to implement this function is the USART (Universal Synchronous/Asynchronous Receiver Transmitter). In the Arduino IDE, we can observe the sent and received data through the Serial Monitor, and we need related serial communication functions to implement this feature.\n\n\n\n**Serial.begin()；**\n\nThis function is used to open the serial port and set the data transmission rate.\nSyntax  Serial.begin(speed);\nParameters  Serial: Serial port object.  speed: Baud rate, commonly set to values like 9600, 115200, etc.\n\n**Serial.println();**\n\nSyntax  Serial.println(val);\nParameters  Serial: Serial port object.  val: The value to be printed, which can be of any data type.\nFor example, to print “hello world!!!” to the Serial Monitor, we need to initialize the serial port in the setup() function and output “hello world!!!” through the serial port in the loop() function:\nvoid setup() {\n    Serial.begin(9600); // Initialize the serial port and set the data transmission rate to 9600\n}\nvoid loop() {\n    Serial.println(\"hello world!!!\"); // Output \"hello world!!!\" through the serial port\n}\nReturning to the question at the beginning of this section: when we have written the code and verified it to be correct, but the effect of running the code exceeds expectations or the hardware doesn’t respond at all, where is the problem? At this time, we can use the Serial Monitor to observe the data sent or received by the hardware to make a judgment. For instance, we can control the on-off state of an LED with a button, and we can use the Serial Monitor to check the returned value when the button is pressed to determine whether the button is working properly. Next, we will learn how to use the Serial Monitor to make the hardware “speak”."
  },
  {
    "objectID": "chapter_1-4.html#task-1-use-the-serial-monitor-to-check-if-the-button-is-pressed",
    "href": "chapter_1-4.html#task-1-use-the-serial-monitor-to-check-if-the-button-is-pressed",
    "title": "1.4 Monitor Knob Value Changes with Serial Monitor",
    "section": "1.4.2 Task 1: Use the Serial Monitor to Check if the Button is Pressed",
    "text": "1.4.2 Task 1: Use the Serial Monitor to Check if the Button is Pressed\n\nAnalysis \nRemember controlling the on-off state of an LED with a button? Some of the code can be reused. We only need to read the button on-off setting and button on-off state code, and then add the initialization of the serial port and the data sent to the serial port. The program writing still follows three steps:\n\nDefine button pins and variables.\nInitialize the serial port, set the serial port baud rate, and set the status of the button on-off pin.\nRead the button state and send it to the serial port.\n\n\n\nWrite the program \nStep 1: Define the button pin and variable.\nconst int buttonPin = 1; // Define the button switch as pin 1. If you are using XIAO RP2040/XIAO ESP32, please change 1 to D1\nint buttonState = 0; // Define buttonState as a variable to store the button status\nStep 2: Initialize the serial port, set the baud rate of the serial port, and set the button switch pin status.\nvoid setup() {\n    pinMode(buttonPin, INPUT_PULLUP);  // Set the button pin as input\n    Serial.begin(9600); // Initialize the serial port\n}\nStep 3: Read the button status and send it to the serial port\nvoid loop() {\n    buttonState = digitalRead(buttonPin);  // Read the button status and store it in the buttonState variable\n    Serial.println(buttonState); // Send the button status data to the serial port\n    delay(500);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L4_ReadButton_XIAO_en\n\n\n\nUpload the program:\nWe will upload the written program to the hardware. First, connect the XIAO to the computer with the data cable from the kit.\n\n\nNote the position of the buttons on the XIAO extensions used for testing in the figure.\nClick  (Verify Button) in the Arduino IDE to verify the program. If the verification is correct, click  (Upload Button) to upload the program to XIAO. When the debug area shows “Done uploading.”, open the serial monitor and observe the value changes printed by the serial monitor when the button is pressed and released. What did you find?\n\n\nWhen we press the button on the XIAO expansion board, the serial monitor shows 0, and when we release the button, the serial monitor shows 1."
  },
  {
    "objectID": "chapter_1-4.html#task-2-using-the-serial-monitor-to-view-knob-value-changes",
    "href": "chapter_1-4.html#task-2-using-the-serial-monitor-to-view-knob-value-changes",
    "title": "1.4 Monitor Knob Value Changes with Serial Monitor",
    "section": "1.4.3 Task 2: Using the Serial Monitor to View Knob Value Changes",
    "text": "1.4.3 Task 2: Using the Serial Monitor to View Knob Value Changes\n\nAnalysis: \nIn Task 1, the button switch is a digital input that sends out digital signals 0 and 1, while the knob potentiometer returns an analog signal. We need to read the rotation angle value of the knob potentiometer on pin A0 and send it to the serial port. The program also consists of three steps:\n\nDefine the knob potentiometer pin and variables.\nInitialize the serial port and set the status of the knob potentiometer pin.\nRead and calculate the rotation angle value of the knob potentiometer and send it to the serial port.\n\n\n\nWrite the program \nStep 1: Define the knob potentiometer pin and variables. Here we need to define the voltage value of the ADC (Analog-to-Digital Converter) and the reference voltage of the Grove module interface, because we will calculate the voltage changes in the circuit where the knob switch is connected through these voltage values.\n#define ROTARY_ANGLE_SENSOR A0  // Define the rotary potentiometer interface A0\n#define ADC_REF 3 // ADC reference voltage is 3V\n#define GROVE_VCC 3 // Grove interface reference voltage is 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the knob potentiometer is 300°\nStep 2: Initialize the serial port, set the baud rate of the serial port, and set the status of the knob potentiometer pin.\nvoid setup()\n{\n    Serial.begin(9600);//Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);//Set the rotary potentiometer pin to input state\n}\nStep 3: Read and calculate the rotational angle value of the rotary potentiometer and send it to the serial port. Here, we first need to set the data type of the voltage variable, set the analog value variable of the rotary potentiometer pin, and then calculate the real-time voltage. After calculating the real-time voltage, calculate the rotational angle value of the rotary potentiometer.\nvoid loop()\n{   \n    float voltage;    //Variable voltage is of floating-point type\n    int sensorValue = analogRead(ROTARY_ANGLE_SENSOR);    //Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensorValue*ADC_REF/1023;    //Calculate real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC;    //Calculate the rotation angle of the knob\n    Serial.println(\"The angle between the mark and the starting position:\");    //Print characters at the serial port\n    Serial.println(degrees);    //Print the rotation angle value of the rotary potentiometer at the serial port\n    delay(100);\n}\n\n#define Macro Definition\n#define is a pre-processing command used for macro definitions. In Arduino, we can use #define to name constants. During the compilation of the program, all occurrences of the “macro name” will be replaced with the string in the macro definition, such as #define ledPin 5. During compilation, 5 will replace all uses of ledPin. Syntax: #define constant name constant value. The “#” symbol is mandatory, and there is no need to use the “;” symbol at the end of the sentence.\n\nThe complete code is as follows:\n/*\n * Use the serial monitor to view the knob potentiometer\n */\n#define ROTARY_ANGLE_SENSOR A0//Define the rotary potentiometer interface A0\n#define ADC_REF 3 //ADC reference voltage 3V\n#define GROVE_VCC 3 //Reference voltage 3V\n#define FULL_ANGLE 300 //The maximum rotation angle of the rotary potentiometer is 300°\n \nvoid setup()\n{\n    Serial.begin(9600);//Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);//Set the rotary potentiometer pin as an input\n}\n \nvoid loop()\n{   \n    float voltage;//Variable voltage is of floating-point type\n    int sensorValue = analogRead(ROTARY_ANGLE_SENSOR);//Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensorValue*ADC_REF/1023;//Calculate real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC;//Calculate the rotation angle of the knob\n    Serial.println(\"The angle between the mark and the starting position:\");//Print characters at the serial port\n    Serial.println(degrees);//Print the rotation angle value of the rotary potentiometer at the serial port\n    delay(100);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L4_ReadRotary_XIAO_en\n\n\n\nUpload the program:\nAfter writing the program, since external sensors are used, connect the knob module to the A0 interface using the four-color Grove cable as shown in the image below:\n\n\nAfter connecting, connect the XIAO main control board to your computer using a data cable.\nIn the Arduino IDE, click on the verification button  to verify the program. If it verifies correctly, click the upload button to upload the program to  the hardware. When the debugging area shows “Done uploading.”, you can proceed. Open the serial monitor and rotate the knob potentiometer to observe the data changes displayed in the serial monitor. These changes represent the angle value of the knob."
  },
  {
    "objectID": "chapter_1-4.html#extended-exercise",
    "href": "chapter_1-4.html#extended-exercise",
    "title": "1.4 Monitor Knob Value Changes with Serial Monitor",
    "section": "1.4.4 Extended Exercise",
    "text": "1.4.4 Extended Exercise\nWhile observing the angle value of the knob potentiometer in the serial monitor, we find that the value is constantly jumping and changing. Observing through the numbers alone is not very intuitive. At this time, we can use the serial plotter. With it, we can plot the data that is printed to the Arduino’s serial port in real time. Based on the second task, close the serial monitor and open the “Tools → Serial Plotter” as shown in the image below:\n\n\nThe serial plotter draws the data obtained from the serial port into an XY axis curve chart, where the X-axis represents the change in time and the Y-axis represents the data obtained from the serial port. Through the chart, you can more intuitively see the change in data. Please give it a try."
  },
  {
    "objectID": "chapter_1-5.html#background-knowledge",
    "href": "chapter_1-5.html#background-knowledge",
    "title": "1.5 Controlling LED and Servo with a Knob",
    "section": "1.5.1 Background Knowledge",
    "text": "1.5.1 Background Knowledge\n\n1.5.1.1 Servo and Servo Library\n\nServo \n\n\nA servo, also known as a servo motor, is a DC motor with gears and a feedback system. We can control the servo to rotate to a specific angular position by sending signals to the circuit. This makes it suitable for electronic devices or robots that require precise position control.\n\n\nServo Library servo.h \nWhen we want to control a servo using XIAO or other Arduino development boards, we can use the servo.h library file. It’s one of the Arduino standard libraries, which is convenient to use and also avoids the problem of limited PWM pin quantity. Here are the relevant functions of the servo library:\n\nDeclare the library file  #include &lt;Servo.h&gt;\nCreate the myservo object to control the servo  Servo myservo;\nUse the attach() function to call the signal pin myservo.attach();\nUse the write() function to write the angle to the servo, setting the rotation angle of the shaft myservo.write();\n\nThe servo library does not need to be manually installed. You can open the example program “File → Examples → Servo” and check the two example programs “Knob” and “Sweep” to familiarize yourself with the use of the servo library.\n\n\nIf you can’t find Servo under Examples, you can visit https://github.com/arduino-libraries/Servo and add the Servo example by installing the library.\n\n\n\n1.5.1.2 map() Function\nThe map() function is used to map a number from one range to another. That is, fromLow gets mapped to toLow, and fromHigh gets mapped to toHigh. It’s the simplest form of linear mapping.\nSyntax  map(value, fromLow, fromHigh, toLow, toHigh)\nParameters  value: The number to be mapped.  fromLow: The lower limit of the current range of the value.  fromHigh: The upper limit of the current range of the value.  toLow: The lower limit of the target range of the value.  toHigh: The upper limit of the target range of the value.\nExample: Map val from the range 0-1023 to 0-255.\nvoid setup() {}\nvoid loop() {\n    int val = analogRead(0); // read the value from analog pin A0\n    val = map(val, 0, 1023, 0, 255); // map val to the range 0-255\n    analogWrite(9, val); // output the analog value to pin 9\n}"
  },
  {
    "objectID": "chapter_1-5.html#task-1-using-a-knob-potentiometer-to-control-the-brightness-of-the-onboard-led-on-the-xiao-board",
    "href": "chapter_1-5.html#task-1-using-a-knob-potentiometer-to-control-the-brightness-of-the-onboard-led-on-the-xiao-board",
    "title": "1.5 Controlling LED and Servo with a Knob",
    "section": "1.5.2 Task 1: Using a knob potentiometer to control the brightness of the onboard LED on the XIAO board",
    "text": "1.5.2 Task 1: Using a knob potentiometer to control the brightness of the onboard LED on the XIAO board\n\nAnalysis:\nWhen using a knob potentiometer to control the LED, we need to use the map() function, because the analog value directly output by the knob potentiometer is 0-1023, this value is not the angle value of the knob rotation, we need to calculate the angle value of the knob potentiometer rotation first, then map this value to the brightness range of the LED 0-255 with the map() function. The steps to write the program are as follows:\n\nDefine the knob potentiometer, LED pin.\nInitialize the serial port, set the status of the knob potentiometer and LED pin.\nRead and calculate the rotation angle value of the knob potentiometer, and send it to the serial port.\nMap the angle value of the knob potentiometer to the LED brightness value and store it in the brightness variable, and the LED outputs this variable value.\n\n\n\nWriting the program:\nStep 1: Define the knob potentiometer, LED pin, here we need to define ADC and VCC reference voltage, in order to calculate the angle value of the knob potentiometer.\n#define ROTARY_ANGLE_SENSOR A0 //Define rotary potentiometer interface A0\n#define LEDPIN 13 //Define LED interface 13\n#define ADC_REF 3 //Reference voltage 3V\n#define GROVE_VCC 3 //GROVE reference voltage 3V\n#define FULL_ANGLE 300 //The maximum rotation angle of the rotary potentiometer is 300°\nStep 2: Initialize the serial port, set the status of the knob potentiometer and LED pin.\nvoid setup()\n{\n    Serial.begin(9600); //Initialize serial communication\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT); //Set the rotary potentiometer pin to input\n    pinMode(LEDPIN,OUTPUT); //Set the LED pin to output \n}\nStep 3: Read and calculate the rotation angle value of the knob potentiometer, and send it to the serial port.\nvoid loop()\n{   \n    float voltage; //Variable voltage of type float\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR); //Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value*ADC_REF/1023; //Calculate the real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC; //Calculate the angle of rotation of the knob\n    Serial.println(\"The angle between the mark and the starting position:\"); //Print character on serial monitor\n    Serial.println(degrees); //Print the rotation angle value of the rotary potentiometer on the serial monitor\n    delay(100);\nStep 4: Map the angle value of the knob potentiometer to the LED brightness value and store it in the brightness variable, and the LED outputs this variable value.\n//After Step 3\n    int brightness; //Define brightness variable\n    brightness = map(degrees, 0, FULL_ANGLE, 0, 255); //Map the rotation angle value of the rotary potentiometer to the brightness value of the LED and store it in the brightness variable\n    analogWrite(LEDPIN,brightness); //Output the variable value to the LED\n    delay(500);\n}\nThe final complete code is shown below:\n#define ROTARY_ANGLE_SENSOR A0 //Define rotary potentiometer interface A0\n#define LEDPIN 13 //Define LED interface 13\n#define ADC_REF 3 //Reference voltage 3V\n#define GROVE_VCC 3 //GROVE reference voltage 3V\n#define FULL_ANGLE 300 //The maximum rotation angle of the rotary potentiometer is 300°\n \nvoid setup()\n{\n    Serial.begin(9600); //Initialize serial communication\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT); //Set the rotary potentiometer pin to input\n    pinMode(LEDPIN,OUTPUT); //Set the LED pin to output \n}\n \nvoid loop()\n{   \n    float voltage; //Variable voltage of type float\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR); //Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value*ADC_REF/1023; //Calculate the real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC; //Calculate the angle of rotation of the knob\n    Serial.println(\"The angle between the mark and the starting position:\"); //Print character on serial monitor\n    Serial.println(degrees); //Print the rotation angle value of the rotary potentiometer on the serial monitor\n    delay(100);\n    \n    int brightness; //Define brightness variable\n    brightness = map(degrees, 0, FULL_ANGLE, 0, 255); //Map the rotation angle value of the rotary potentiometer to the brightness value of the LED and store it in the brightness variable\n    analogWrite(LEDPIN,brightness); //Output the variable value to the LED\n    delay(500);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryLed_XIAO_en\n\n\n\nUploading the Program:\nAfter writing the program, connect the rotary potentiometer to the A0 interface using a four-color Grove wire, as shown in the following figure:\n\n\nConnect the XIAO main control board to your computer with a data cable. After connecting, click  (the verify button) in the Arduino IDE to check the program. If there are no errors, click  (the upload button) to upload the program to the hardware. When the debug area shows “Done uploading.”, you can open the serial monitor to observe the rotation angle and LED brightness values as you rotate the potentiometer.\n\n\n\n⚠️ Note  The onboard LED of the XIAO board is used in this example.\n\nIf you need to operate offline, you can connect a lithium battery to the expansion board, as shown in the following figure.\n\n\n\n\nControlling an External LED with a Knob on the XIAO ESP32C3\nThe Seeed XIAO ESP32C3 does not have an onboard LED for users. To run this program, you need to first connect an LED to the D10 pin of the board, as shown below:\n\n\n\n⚠️ Note  Be sure to connect a resistor (about 150Ω) in series with the LED to limit the current passing through the LED and prevent it from being damaged by overcurrent.\n\nNext, copy the following program into the Arduino IDE:\n#define ROTARY_ANGLE_SENSOR A0 // Define rotary potentiometer interface A0\n#define LEDPIN D10 // Define LED light interface 10\n#define ADC_REF 3 // Reference voltage 3V\n#define GROVE_VCC 3 // GROVE reference voltage 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the rotary potentiometer is 300°\n\nvoid setup()\n{\n    Serial.begin(9600); // Initialize serial communication\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT); // Set the rotary potentiometer pin to input mode\n    pinMode(LEDPIN, OUTPUT); // Set the LED light pin to output mode \n}\n\nvoid loop()\n{   \n    float voltage; // Define voltage variable as float\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR); // Read the analog value on the rotary potentiometer pin\n    voltage = (float)sensor_value*ADC_REF/1023; // Calculate real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC; // Calculate the angle of rotation of the knob\n    Serial.println(\"The angle between the mark and the starting position:\"); // Print string to serial port\n    Serial.println(degrees); // Print the rotation angle value of the rotary potentiometer to the serial port\n    delay(100);\n\n    int brightness; // Define brightness variable\n    brightness = map(degrees, 0, FULL_ANGLE, 0, 255); // Map the rotary potentiometer angle value to LED light brightness value and store it in the brightness variable\n    analogWrite(LEDPIN, brightness); // Output brightness value to LED light\n    delay(500);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryLed_XIAO_ESP32C3_en"
  },
  {
    "objectID": "chapter_1-5.html#task-2-control-a-servo-motor-with-a-rotary-potentiometer",
    "href": "chapter_1-5.html#task-2-control-a-servo-motor-with-a-rotary-potentiometer",
    "title": "1.5 Controlling LED and Servo with a Knob",
    "section": "1.5.3 Task 2: Control a Servo Motor with a Rotary Potentiometer",
    "text": "1.5.3 Task 2: Control a Servo Motor with a Rotary Potentiometer\n\nAnalysis\nWhen controlling a servo motor with a rotary potentiometer, we can use the servo.h library and modify our first task slightly. The program can be divided into the following steps:\n\nDeclare the servo library, define the servo rotation angle variable, define the rotary potentiometer pin and voltage.\nInitialize the serial port, set the status of the rotary potentiometer and servo pins.\nRead and calculate the rotation angle value of the rotary potentiometer, send it to the serial port, and drive the servo to rotate according to the angle value change.\n\n\n\nProgram Writing \nStep 1: Declare the servo library, define the servo rotation angle variable, define the rotary potentiometer pin and voltage.\n#include &lt;Servo.h&gt;// Declare the use of the servo library\n#define ROTARY_ANGLE_SENSOR A0 // Define the rotary potentiometer pin as A0\n#define ADC_REF 3 // ADC reference voltage is 3V\n#define GROVE_VCC 3 // GROVE module reference voltage is 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the rotary potentiometer is 300°\nServo myservo;  // Create a myservo object to control the servo\nint pos = 0; // Variable to store the rotation angle of the servo\nStep 2: Initialize the serial port, set the status of the rotary potentiometer and servo pins.\nvoid setup() {\n    Serial.begin(9600);// Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);// Set the rotary potentiometer pin as input\n    myservo.attach(5);  // The myservo signal is transmitted through pin 5, if you are using XIAO RP2040/XIAO ESP32, please modify 5 to D5\n}\nStep 3: Read and calculate the rotation angle value of the rotary potentiometer, send it to the serial port, and drive the servo to rotate according to the angle value change.\nvoid loop() {\n    float voltage;// Set voltage as a floating point\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR);// Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value * ADC_REF / 1023;// Real-time voltage is the read analog value multiplied by the reference voltage divided by 1023\n    float degrees = (voltage * FULL_ANGLE) / GROVE_VCC;// The rotation angle of the knob is the real-time voltage multiplied by the maximum rotation angle of the rotary potentiometer divided by the voltage value of the GROVE module interface\n    Serial.println(\"The angle between the mark and the starting position:\");// Print characters on the serial port\n    Serial.println(degrees);// Print the rotation angle value of the rotary potentiometer on the serial port\n    delay(50);\n    myservo.write(degrees); // Write the rotation angle value of the rotary potentiometer into the servo\n}\nThe final code is as follows:\n#include &lt;Servo.h&gt;// Declare the use of the servo library\n#define ROTARY_ANGLE_SENSOR A0 // Define the rotary potentiometer pin as A0\n#define ADC_REF 3 // ADC reference voltage is 3V\n#define GROVE_VCC 3 // GROVE module reference voltage is 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the rotary potentiometer is 300°\nServo myservo;  // Create a myservo object to control the servo\nint pos = 0; // Variable to store the rotation angle of the servo\n\nvoid setup() {\n    Serial.begin(9600);// Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);// Set the rotary potentiometer pin as input\n    myservo.attach(5);  // The myservo signal is transmitted through pin 5, if you are using XIAO RP2040/XIAO ESP32, please modify 5 to D5\n}\n\nvoid loop() {\n    float voltage;// Set voltage as a floating point\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR);// Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value * ADC_REF / 1023;// Real-time voltage is the read analog value multiplied by the reference voltage divided by 1023\n    float degrees = (voltage * FULL_ANGLE) / GROVE_VCC;// The rotation angle of the knob is the real-time voltage multiplied by the maximum rotation angle of the rotary potentiometer divided by the voltage value of the GROVE module interface\n    Serial.println(\"The angle between the mark and the starting position:\");// Print characters on the serial port\n    Serial.println(degrees);// Print the rotation angle value of the rotary potentiometer on the serial port\n    delay(50);\n    myservo.write(degrees); // Write the rotation angle value of the rotary potentiometer into the servo\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryServo_XIAO_en\n\n\n\n\nUpload Program\nAfter writing the program, first connect the knob potentiometer and the servo to the XIAO expansion board as shown in the figure below. Then, connect the XIAO main control board to the computer with a data cable.\n\n\nAfter the connection, click (the verify button) in the Arduino IDE to verify the program. If the verification is error-free, click  (the upload button) to upload the program to the hardware. When the debugging area shows “Done uploading.”, you can open the serial monitor, rotate the knob potentiometer, and observe the changes in angle value and the movement of the servo. What have you found?\n\n\n\n⚠️ Note  The rotation range of the servo is 0°-180°, so you will see in the serial monitor that when the angle value is greater than 180°, the servo stops rotating."
  },
  {
    "objectID": "chapter_1-5.html#extended-exercise",
    "href": "chapter_1-5.html#extended-exercise",
    "title": "1.5 Controlling LED and Servo with a Knob",
    "section": "1.5.4 Extended Exercise",
    "text": "1.5.4 Extended Exercise\nWe have been using the LED on the XIAO board. If I want to use an external LED and control it with a knob potentiometer to create a breathing light effect, what should I do? The XIAO expansion board brings out two digital-analog Grove interfaces, and there is an A7/D7 interface. We can connect the external LED to this interface, as shown in the figure:\n\n\nAfter the connection, we can slightly modify the program from Task 1, changing #define LEDPIN 13 to #define LEDPIN 7. Upload the modified program and see if it can achieve our desired effect.\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryLed_ledmodule_en"
  },
  {
    "objectID": "chapter_1-6.html#background-knowledge",
    "href": "chapter_1-6.html#background-knowledge",
    "title": "1.6 Displaying “Hello World” on OLED",
    "section": "1.6.1 Background Knowledge",
    "text": "1.6.1 Background Knowledge\n\n1.6.1.1 OLED Display\nOLED, also known as Organic Light Emitting Diode, has advantages such as self-luminous, low power consumption, fast response speed, high resolution, light weight, etc. Its application field is very wide. The XIAO expansion board integrates a 0.96 inch 128x64 pixel OLED display, which can be used directly without wiring. During project production, we can display time, temperature and humidity, and other sensor return values through the OLED display, and we can also directly display letters, numbers, graphics, and even patterns, achieving visual interactive effects.\n\n\n\n\n\n1.6.1.2 How to Download and Install the U8g2_Arduino Library\nA library is a collection of program codes, which encapsulates some commonly used functions into a file for users to call. When we use OLED displays, temperature and humidity sensors, etc., we need to use the corresponding libraries. Where can these libraries be downloaded and how to install them? We will explain using the U8g2_Arduino library file of the OLED display as an example. Enter the website link 🔗 https://github.com/olikraus/u8g2_arduino to enter the GitHub page, click Code→Download ZIP to download the resource package to the local, as shown in the figure below.\n\n\nAfter the download is complete, open the Arduino IDE, click Sketch→Include Library→Add .ZIP Library, and select the ZIP file you just downloaded.\n\n\nIf the library is installed correctly, you can see the prompt information for successful library installation in the output window.\n\n\n1.6.1.3 U8g2 Library for OLED\n\n\nU8g2 is a monochrome graphics library for embedded devices, which supports various types of OLED displays, making it easy for us to write programs to achieve the desired effects. The U8g2 library also includes the U8x8 library, and the two libraries have different functions:\n\nU8g2\nIncludes all graphic procedures (line/box/circle drawing); Supports various fonts, (almost) no restrictions on font height; Some memory in the microcontroller is needed to display.\n\n\nU8x8\nOnly supports text (character) output; Only allows each character to use a fixed-size font (8x8 pixels); Writes directly to the display, no buffer is needed in the microcontroller. Simply put, when we want the OLED display to display various fonts, graphics, patterns, and present visual content more flexibly, we can use the U8g2 library; when we want to display characters more directly, with no font requirements, just to display sensor values, time, etc., we can use the U8x8 library, which is more efficient. We can find many example programs in “File→Examples→U8g2”, and familiarize ourselves with the use of the library through the example programs.\n\n\nNext, we will display characters and draw circles using two libraries respectively."
  },
  {
    "objectID": "chapter_1-6.html#task-1-display-hello-world-on-the-oled-of-the-xiao-expansion-board",
    "href": "chapter_1-6.html#task-1-display-hello-world-on-the-oled-of-the-xiao-expansion-board",
    "title": "1.6 Displaying “Hello World” on OLED",
    "section": "1.6.2 Task 1: Display Hello World! on the OLED of the XIAO expansion board",
    "text": "1.6.2 Task 1: Display Hello World! on the OLED of the XIAO expansion board\n\n⚠️ Note Before starting to write a program for the OLED of the XIAO expansion board, make sure the Arduino IDE has loaded the U8g2_Arduino library file. The loading method can be referred to the description in the “How to Download and Install Arduino Library” section of this lesson.\n\n\nAnalysis\nIf you just want to display “Hello World!” on the OLED, you can directly write characters with the U8x8 library. The steps are as follows:\n\nDeclare the library file, set the constructor, and the constructor defines the display type, controller, RAM buffer size, and communication protocol.\nInitialize the display.\nSet the display font, set the print starting position, and output “Hello World!”.\n\n\n\nWrite the program \nStep 1: Declare the library file, set the constructor, and the constructor defines the display type, controller, RAM buffer size, and communication protocol.\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;//Use U8x8 library file\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);\n//Set the constructor, define the display type, controller, RAM buffer size, and communication protocol, generally determine according to the used display model\nStep 2: Initialize the display. After declaring the library file in the previous step, you can use the functions in the library to set the OLED display.\nvoid setup(void) {\n    u8x8.begin();//Initialize u8x8 library\n    u8x8.setFlipMode(1);//Flip the display 180 degrees, generally numbers 0 and 1\n}\nStep 3: Set the display font (there are various fonts to choose from in the u8x8 library, we can refer to https://github.com/olikraus/u8g2/wiki/fntlist8x8 to choose), set the print starting position, and output “Hello World!”.\nvoid loop(void) {\n    u8x8.setFont(u8x8_font_chroma48medium8_r);//Define u8x8 font\n    u8x8.setCursor(0, 0);//Set the position of the drawing cursor\n    u8x8.print(\"Hello World!\");//Draw content on OLED: Hello World！\n}\nThe complete program is as follows:\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;//Use U8x8 library file\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);\n//Set the constructor, define the display type, controller, RAM buffer size, and communication protocol, generally determine according to the used display model\n\nvoid setup(void) {\n    u8x8.begin();//Initialize u8x8 library\n    u8x8.setFlipMode(1);//Flip the display 180 degrees, generally numbers 0 and 1\n}\n\nvoid loop(void) {\n    u8x8.setFont(u8x8_font_chroma48medium8_r);//Define u8x8 font\n    u8x8.setCursor(0, 0);//Set the position of the drawing cursor\n    u8x8.print(\"Hello World!\");//Draw content on OLED: Hello World！\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L6_HelloWorld_XIAO_en\n\n\n\nProgram Upload:\nAfter the program is written, we connect the XIAO main control board to the computer interface using a data cable, as shown in the image below:\n\n\nClick “Upload” to transfer the program to the main control board. Once the upload is complete, check if the OLED display shows “Hello World!”."
  },
  {
    "objectID": "chapter_1-6.html#task-2-draw-a-circle-on-the-oled-display",
    "href": "chapter_1-6.html#task-2-draw-a-circle-on-the-oled-display",
    "title": "1.6 Displaying “Hello World” on OLED",
    "section": "1.6.3 Task 2: Draw a Circle on the OLED Display",
    "text": "1.6.3 Task 2: Draw a Circle on the OLED Display\n\nAnalysis\nTo draw a circle on the OLED display, we need to use the U8g2 library. Programming involves four steps:\n\nDeclare the U8g2 library file, determine whether to use SPI or I2C protocol, and set up the constructor to connect to the OLED display.\nThe draw() function uses the u8g2.drawCircle function to draw a circle on the OLED.\nInitialize the U8g2 library.\nIn the loop() function, call related functions to draw images on the OLED.\n\n\n\nProgram Writing \nStep 1: Declare the U8g2 library file, determine whether to use SPI or I2C protocol, and set up the constructor to connect to the OLED display.\n#include&lt;Arduino.h&gt;\n#include&lt;U8g2lib.h&gt;//Use U8g2 library\n\n// Determine whether to use SPI or I2C protocol\n#ifdef U8X8_HAVE_HW_SPI\n#include&lt;SPI.h&gt;\n#endif\n#ifdef U8X8_HAVE_HW_I2C\n#include&lt;Wire.h&gt;\n#endif\n\nU8G2_SSD1306_128X64_NONAME_F_HW_I2C u8g2(U8G2_R0, /* reset=*/ U8X8_PIN_NONE);\n// Set up the constructor, define display type, controller, RAM buffer size, and communication protocol\nStep 2: The draw()function uses the u8g2.drawCircle function to draw a circle on the OLED. The u8g2.drawCircle(x0,y0,rad,opt) function parameters are as follows:\n\nx0,y0: The position of the center of the circle.\nrad: Defines the size of the circle, with the diameter of the circle being 2*rad+1.\nopt: Choose a part or all of the circle.\n\nvoid draw(void) { \n    u8g2.drawCircle(20, 25, 10, U8G2_DRAW_ALL);// Draw a full circle with a diameter of 21 at coordinates (20, 25)\n}\nStep 3: Initialize the U8g2 library.\nvoid setup(void) {\n    u8g2.begin();// Initialize the library\n}\nStep 4: In the loop() function, call related functions to draw images on the OLED. Use the firstPage and nextPage functions to cycle through image content. They need to be used together, as shown in the program below:\nvoid loop(void) {\n    // Cycle through image display\n    u8g2.firstPage();\n    do {\n        draw();// Use draw function\n    } while( u8g2.nextPage() );\n\n    delay(1000);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L6_DrawCircle_XIAO_en\n\n\n\nUploading the Program\nAfter writing the program, connect the XIAO main control board to the computer using a data cable, as shown below:\n\n\nOnce connected, click on the “Upload” button to upload the program to the hardware. When the debugging area displays “Upload Successful”, check if the OLED display screen has shown a circular pattern."
  },
  {
    "objectID": "chapter_1-6.html#extended-exercise",
    "href": "chapter_1-6.html#extended-exercise",
    "title": "1.6 Displaying “Hello World” on OLED",
    "section": "1.6.4 Extended Exercise",
    "text": "1.6.4 Extended Exercise\nTry drawing some more complex patterns."
  },
  {
    "objectID": "chapter_2.html",
    "href": "chapter_2.html",
    "title": "Chapter 2: Project Practice for Beginners - Introduction to Prototype Design",
    "section": "",
    "text": "This unit will delve into project practice with a few classic projects as case studies. We will learn how to create a quick verification prototype starting from an idea. Instead of analyzing code line by line as we’ve done previously, we will only explain critical steps in this unit. The focus will be more on the practical application of code. Arduino’s libraries and example programs are abundant, as are community resources.\nWhen working on a project, we should be adept at finding these resources, referring to example programs, and adjusting the code according to our needs to achieve the desired effects more quickly. Furthermore, this unit will begin to cover how to design appearances based on the effects achieved by the program. We will start by repurposing items around us, combining these items with electronic hardware to quickly form prototype works."
  },
  {
    "objectID": "chapter_2-1.html#cultivating-the-maker-mindset",
    "href": "chapter_2-1.html#cultivating-the-maker-mindset",
    "title": "2.1 Introduction to Product Prototype Design",
    "section": "2.1.1 Cultivating the Maker Mindset",
    "text": "2.1.1 Cultivating the Maker Mindset\nBecoming an excellent maker is not just about learning hardware modules and programming knowledge, but also consciously cultivating some habits.\n\n\nDale Dougherty, the founder of Make: magazine, gave some advice on cultivating the maker mindset in his welcome speech at Maker Camp (refer to 🔗 https://makercamp.com/get-started).\n\nKeep it playful\nPlay opens us to creative ideas and new experiences. While we play, we engage our bodies and our mind, and we often engage with others. While we play, learning feels natural and we can take risks to do things we didn’t know we can do.\nBe Curious\nAsk questions – who, what, why, and how. How are things around you made? Who makes them and where are they made?\nGet physical\nUse your sense to experience the physical world all around you. What are the differences between the natural world and the built world?\nFind a favorite tool\nTools exist for all kinds of applications. Given an area you’re interested such as bicycles or music, what are some of the tools, both physical and digital, that you might want to learn to use? Choose a new tool and share it with us.\nDo something you’ve never done before\nSometimes we decide that we’re not good at something and we never try to do it. Part of the DIY spirit is to try something you’ve never tried before, even if you’re not particularly good at it. Think of it as an experiment. See if you like it. Try cooking or gardening or playing a musical instrument. Or try to fix something that’s broken. Share this new skill.\nMake something\nYou might design something that solves a problem — it could be a problem for you or a problem for others. You might build something that’s interactive such as a play toy, or a toy car or plane. Paper airplane launchers are popular, as are rockets.\n\n\nWhat are the benefits of engaging young people in making?\nHere are the five key competencies that we identified as outcomes for young people who participate in Start Making!\n\n\n\nIdentify as a creator or maker. Young people develop positive attitudes toward creating hands-on projects. \nDevelop confidence in creative expression. Young people feel capable of bringing their ideas to life by designing, experimenting, iterating, and persisting through failures. \nAcquire technical tool literacy. Young people become familiar with a variety of tools and technologies that they can use to make projects. \nBecome aware of STEAM. Young people become aware of ideas and concepts that bridge science, technology, engineering, art, and math and demonstrate curiosity to learn more. \nLearn collaboration and networking skills. Young people actively engage in collaborating and helping others.\n\nStart Making! A Guide to Engaging Young People in Maker Activities By Danielle Martin and Alisha Panjwani edited by Natalie Rusk\n\n\nWhat are the attributes of a maker? What is a maker mindset?\n\nMakers are curious. They are explorers. They pursue projects that they personally find interesting.\nMakers are playful. They often work on projects that show a sense of whimsy.\nMakers are willing to take on risk. They aren’t afraid to try things that haven’t been done before.\nMakers take on responsibility. They enjoy taking on projects that can help others.\nMakers are persistent. They don’t give up easily.\nMakers are resourceful. They look for materials and inspiration in unlikely places.\nMakers share—their knowledge, their tools, and their support.\nMakers are optimistic. They believe that they can make a difference in the world.\n\nMaking Makers: Kids, Tools and the Future of Innovation By AnnMarie Thomas"
  },
  {
    "objectID": "chapter_2-1.html#enlightening-on-product-prototype-design",
    "href": "chapter_2-1.html#enlightening-on-product-prototype-design",
    "title": "2.1 Introduction to Product Prototype Design",
    "section": "2.1.2 Enlightening on Product Prototype Design",
    "text": "2.1.2 Enlightening on Product Prototype Design\n\nAuthor Introduction:\n\n\nWen Yanming, a post-90s female, graduated from the Chinese University of Hong Kong and South China University of Technology, with a master’s degree in law. She is a hardware product manager, an inventor, an entrepreneur, with over a decade of technology practice and maker experience.\n\n\n2.1.2.1 Basic Process of Product Prototype Design\n From idea to product prototype and then to the product, this is a process that every product must go through. A product prototype allows us to quickly verify ideas, functionality, and product feasibility in a cost-effective way, providing the basis for product testing, optimization, and iterative updates. Behind every successful product we see, there may have been countless iterations of product prototypes. Therefore, creating a good product prototype is an essential process and solid foundation for a successful product.  The prototypes needed for different types of products and different stages of the product are not the same. When we mention a product prototype, it may refer to a conceptual prototype, a functional prototype, a small batch production prototype, a factory hand model, etc. It should be noted that for electronic hardware products, the discussion here is mainly about product prototypes for product concepts and functional implementation.  Generally speaking, the design of a functional product prototype mainly includes the following processes:\n\n1. Identify and Clarify the Problem to be Solved\nEinstein once said: “Posing a problem is often more important than solving a problem.” Every product must exist to solve a certain problem or to provide some benefit to people. Therefore, identifying and clarifying the problem to be solved is a prerequisite for clarifying product design needs and proceeding with product design.  It is important to note that just because we have identified a problem does not mean we truly understand and accurately define this problem. For example, over 100 years ago, when Henry Ford, the founder of Ford Motor Company, went around asking customers what kind of transportation they needed, almost everyone’s answer was, “I want a faster horse.” But do people really just need a faster horse? If Mr. Ford had defined the problem based on this, we might not have had faster and more comfortable cars so quickly.\n\n\n\n\n2. Demand Analysis and Product Definition\nOnce the problem is clearly defined, we can extract unmet needs from it. Like the example above, the problem at that time was actually how to get to the destination faster, so the corresponding need was “a faster mode of transportation,” not “a faster horse.” Therefore, we need to be good at digging deeper from the problems we discover to find the real needs. Demand analysis generally requires an analysis of the user population and use scenarios, from which to derive the functions needed to solve the problem, that is, to clarify: for whom, in what scenarios, to achieve what functions, to gain what benefits.\n\n\nThere are many types of needs: true user needs, superficial needs, urgent needs, ordinary needs, high-frequency needs, low-frequency needs, and so on. All of these need to be analyzed in light of the actual situation, which can then inform the correct definition of the product based on these needs.  Every product ultimately needs to be commercialized to realize its maximum value. Therefore, when designing a product for the market, we also need to conduct a series of market analyses, including market size, sales expectations, profit analysis, payback period, input-output ratio analysis, and so on.\n\n\n3. Hardware Selection and Assembly\nFor the design of electronic products, once the needs are defined, we need to find hardware that can implement these functional needs. When choosing hardware, the elements that generally need to be considered include: feasibility, level of need satisfaction, cost, volume, weight, performance, lifespan, appearance, etc. One of the most important abilities of an excellent product designer is to take into account various factors based on the product definition and needs, balance these factors, and make trade-offs. Often, there is no single correct answer.  Generally speaking, when we build a prototype, the first thing we should consider is creating a minimum viable product (MVP). Its function is to use the least resources to quickly verify the product and quickly improve and iterate.\n\n\n\n\n4. Software Development and Functional Implementation\nMany experienced software development engineers will draw a functional implementation flowchart before software development. They will draw a functional implementation flowchart according to the functions to be implemented. This can help clarify the software design thinking, check the function logic, facilitate the identification of leaks and deficiencies, and refer to it at any time during programming, ensuring they have a clear understanding. Therefore, regardless of the complexity of software function development, it is recommended that everyone develop a good habit of drawing a functional implementation flowchart first. It can be a simple hand-drawn sketch, or a professional software like Visio, Axure can be used to draw it.\n\n\n\n\n When developing software, try to be efficient and concise. Take full advantage of the benefits of the open-source community and learn to use existing hardware and software resources more effectively. For example, many pieces of hardware or applications already have many ready-made open-source libraries and routines. During development, you can refer to these, comply with the corresponding open-source agreements to use related resources, and avoid wasting time reinventing the wheel.\n\n\n5. Prototype Testing and Optimization\nAfter the prototype is made, we need to test it to verify its functional implementation and whether it meets the original design needs. This process should involve as many target users as possible to collect their feedback. In this way, we can better discover the defects in the product prototype, make remedial measures and improvements, update and iterate the design, and finally make a design scheme that meets user needs, laying a solid foundation for formal product design.\n\n\n\n2.1.2.2 Product Prototype Practice - “One Meter Distance Alarm” Prototype\n\n\nNext, let’s take the prototype manufacturing process of the “One Meter Distance Alarm” as an example to experience the product prototype design process.\n\n1. Identifying and Defining the Problem to be Solved\nAt the beginning of 2020, the COVID-19 pandemic broke out globally, the situation was very severe. To prevent the virus from spreading through droplets and close-range airborne contact, governments and health departments around the world urged everyone to reduce gatherings and maintain social distancing of at least one meter whenever possible. However, it is not easy for everyone to constantly remember this and maintain an accurate social distance of more than one meter. For children, they often forget to maintain distance because they are playing happily, or they have no concept of how far they should keep their distance. When going out, there are also some strangers who, due to a lack of epidemic prevention awareness, unconsciously come close to us, and we need to find a polite way to remind them.  Therefore, we have derived a question from life: How can we constantly remind people to maintain a social distance of more than one meter?\n\n\n2. Needs Analysis and Product Definition\nWith the problem defined, let’s analyze the core needs that this problem triggers: an epidemic prevention reminder device for public use that sends out reminders when others enter within one meter, thus encouraging everyone to consciously maintain a one meter social distance.  Thinking further about the core needs, what kind of reminder should this be? We can think of the electronic products we usually use, what kind of reminders do they have? They are nothing more than sounds, lights, vibrations, screen text prompts, etc. Considering that the reminder needs to be timely, direct, and obvious, it’s not easy to see the screen clearly at a distance of about one meter, and the volume will be larger and the cost higher after adding a screen, so we do not consider adding a screen. The remaining options are sound, light, and vibration. We can continue to balance and choose the necessary reminder method according to the cost, volume, and appearance. There is no single answer here. So, based on the needs analysis process, we tentatively define the product as: a device that emits light and vibrates to remind when it detects someone entering within a one meter distance.\n\n\n3. Hardware Selection and Assembly\nWith the product defined, we can decompose the core functional requirements:\n\nDetect when a person enters within a one-meter distance \nAlert self and others \nSmall size, easy to carry\n\nSo, what kind of hardware should be used to implement these respectively? In the process of product prototype implementation, we usually choose open-source hardware with low cost, complete information, and many routines to implement hardware functions. After comprehensively considering the cost, function realization, assembly difficulty, volume, software development resources, and other elements, I have chosen the following hardware:\n\n\n\n\n\n\n\n\nFunctional Requirements\nHardware Product\nFunction Introduction\n\n\n\n\nMain Board\nSeeeduino XIAO（SAMD21）\nThis is a mini-main control board developed by Seed Technology based on SAMD21. The volume is very mini, only 20x17.5mm, the size of a thumb, the interface is rich, the performance is strong, very suitable for the development of various small volume devices.\n\n\nExpansion Board\n  Seeed Studio Grove Base for XIAO\nGrove Shield for Seeed Studio XIAO is a plug-and-play Grove extension board for Seeed Studio XIAO series. With the on-board battery management chip and battery bonding pad, you could easily power your Seeed Studio XIAO with lithium battery and recharge it. 8 Grove connectors onboard includes two Grove I2C and one UART. It acts as a bridge for Seeed Studio XIAO and Seeed’s Grove system. Flash SPI bonding pad allows you add Flash to Seeed Studio XIAO to expand its memory space, providing Seeed Studio XIAO with more possibilities.\n\n\nDistance Detection\n  Grove - Time of Flight Distance Sensor（ToF）\nThere are many sensors to detect distance, most of which measure through ultrasound, infrared, lasers, etc. Among them, the Grove Time of Flight Distance Sensor is a new generation of ToF laser ranging module based on VL53L0X, which can provide accurate distance measurement up to 2 meters. The small size and high precision of this module made it my first choice.\n\n\nLight Alarm\n  Grove - Circular LED\nA Grove - Circular LED with a circle of LEDs can light up a white light. It is aesthetically pleasing and provides a larger, more noticeable light reminder compared to a single LED.\n\n\nVibration Alarm\n  Grove - Vibration Motor\nA Grove module with a built-in vibration motor. It can be used plug-and-play, and it’s convenient to generate continuous or intermittent vibration reminders by controlling the digital signal.\n\n\nPower Supply\n  3.7V lithium battery (401119)\nA mini-sized 3.7V lithium battery commonly used for Bluetooth headset power supply. The model is 401119, which represents the thickness, width, and length of the battery as 4mm, 11mm, and 19mm respectively. After welding this size lithium battery to the lithium battery pad on the Grove expansion board, it can be placed directly in the gap between the Seeeduino XIAO and the Grove expansion board, making the product more tidy and beautiful.\n\n\nWriting\n Grove universal connection cable (5cm)\nThe Grove universal connector is a standard connector for the Grove system. It can be used conveniently plug-and-play, without soldering and considering the line sequence. The Grove line connects various sensors and actuators to the expansion board, making the project building as simple as building blocks and saving a lot of time. The 5cm short line is very suitable for space-compact product prototypes.\n\n\n\nThe module connection is as follows, as depicted in the image:\n\n\nThe chosen hardware modules have a great structural design, which can be directly used to build the distance alarm’s form factor, saving time in making a shell. Thus, the production method is quite simple: all that’s needed is to connect each piece of hardware to the appropriate interface, arrange their respective positions, and then bond them together with hot melt adhesive. This quickly completes the hardware connection and form factor building of a one-meter distance alarm. The completed hardware product is as follows:\n\n\n\n\n\n\n4. Software Development and Function Implementation\nBefore officially writing the program, I planned the functions and logic that the software needs to implement and drew the following functional implementation flow chart using Visio:\n\n\n\n\n Because Seeeduino XIAO supports Arduino IDE, I chose to program in the Arduino IDE. Most of the hardware provided by Seed Technology is open source, and they offer excellent documentation support for their products. Thus, during the programming process, I found the corresponding open-source hardware Wiki on the Seeedstudio official website, downloaded the relevant library files (note: library files are a collection of specific functionalities provided by developers that can be used by simply calling them, without having to rewrite the code), and referred to the example routines of the used modules. I completed the program swiftly.\nAfter the program was written and compiled successfully, I connected the Seeeduino XIAO to the computer via a Type-C connection and downloaded the written code to the Seeeduino XIAO through the Arduino IDE. Once the code was successfully uploaded, the prototype was completed.\n\n\n\n\n5. Prototype Testing and Optimization\n\n\n\n\n\n\n\n\nAfter completing the prototype, it was time for testing. First, I needed to test whether the prototype implemented the basic functionality, i.e., whether it would sound and light an alarm when a person was detected within a one-meter range. Then, I had to use it in an actual scenario to see if the user experience was good enough. If it could meet the product’s requirements and definition satisfactorily, the product prototype could be deemed successful, and the next step in product development could be initiated. Of course, if issues were found during testing, adjustments and improvements were required, followed by retesting. This process is repeated until the product prototype meets the requirements, and the final scheme is determined.\nFinishing the prototype is just the first step in making a successful product. The birth of each product requires a lot of effort, continual trial and error, and adjustment to achieve the best results. The final success of a product, in addition to meeting user needs, also needs to withstand many market tests. This requires students, when beginning to learn to make products, to always maintain the spirit of a craftsman, while also keeping a keen sense for the market, and learning knowledge beyond the product itself. There is a long way to go, and I hope everyone can stick to their original intentions, keep exploring, and ultimately make successful products.\nThe source code of the program is as follows:\n#include &lt;Grove_LED_Bar.h&gt;\n#include \"Seeed_vl53l0x.h\"\n\nconst int Buzzer = 8;//Vibration motor connected to D8\nGrove_LED_Bar bar(0, 1, 0, LED_CIRCULAR_24);  //Grove-LED ring connected to D0 \nSeeed_vl53l0x VL53L0X;  //Grove-tof distance sensor connected to IIC (D4/D5)\n\n#if defined(ARDUINO_SAMD_VARIANT_COMPLIANCE) && defined(SerialUSB)\n#define SERIAL SerialUSB\n#else\n#define SERIAL Serial\n#endif\n\n\nvoid setup() {\n    bar.begin();\n\n    pinMode(Buzzer, OUTPUT);\n    digitalWrite(Buzzer, LOW);   // turn the Buzzer on (HIGH is the voltage level)\n    // Turn off all LEDs\n    bar.setBits(0x0);            \n\n    VL53L0X_Error Status = VL53L0X_ERROR_NONE;\n    SERIAL.begin(115200);\n    Status = VL53L0X.VL53L0X_common_init();\n    if (VL53L0X_ERROR_NONE != Status) {\n        SERIAL.println(\"Starting VL53L0X measurement failed!\");\n        VL53L0X.print_pal_error(Status);\n        while (1);\n    }\n\n    VL53L0X.VL53L0X_long_distance_ranging_init();\n\n    if (VL53L0X_ERROR_NONE != Status) {\n        SERIAL.println(\"Starting VL53L0X measurement failed!\");\n        VL53L0X.print_pal_error(Status);\n        while (1);\n    }\n\n}\n\nvoid loop() {\n\n    VL53L0X_RangingMeasurementData_t RangingMeasurementData;\n    VL53L0X_Error Status = VL53L0X_ERROR_NONE;\n\n    memset(&RangingMeasurementData, 0, sizeof(VL53L0X_RangingMeasurementData_t));\n    Status = VL53L0X.PerformSingleRangingMeasurement(&RangingMeasurementData);\n    if (VL53L0X_ERROR_NONE == Status) {\n        if (RangingMeasurementData.RangeMilliMeter &gt;= 2000) {\n            SERIAL.println(\"Out of range!!\");\n            digitalWrite(Buzzer, LOW);   // turn the Buzzer off (LOW is the voltage level)\n\n            // Turn off all LEDs\n            bar.setBits(0x0);\n\n        } \n        else if (RangingMeasurementData.RangeMilliMeter &lt;= 1000) {\n            digitalWrite(Buzzer, HIGH);   // turn the Buzzer on (HIGH is the voltage level)\n            // Turn on all LEDs\n            bar.setBits(0b111111111111111111111111);\n\n            SERIAL.print(\"Distance:\");\n            SERIAL.print(RangingMeasurementData.RangeMilliMeter);\n            SERIAL.println(\" mm\");\n        } \n        else {    \n            digitalWrite(Buzzer, LOW);   // turn the Buzzer off (LOW is the voltage level)\n\n            // Turn off all LEDs\n            bar.setBits(0x0);\n\n            SERIAL.print(\"Distance:\");\n            SERIAL.print(RangingMeasurementData.RangeMilliMeter);\n            SERIAL.println(\" mm\");\n        }\n\n    }\n    else {\n        SERIAL.print(\"Measurement failed!! Status code =\");\n        SERIAL.println(Status);\n        digitalWrite(Buzzer, LOW);   // turn the Buzzer off (LOW is the voltage level)\n\n        // Turn off all LEDs\n        bar.setBits(0x0);\n    }\n\n    delay(250);   \n\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L7_tof_XIAO_en"
  },
  {
    "objectID": "chapter_2-2.html#background-knowledge",
    "href": "chapter_2-2.html#background-knowledge",
    "title": "2.2 Smart Hygrometer and Thermometer",
    "section": "2.2.1 Background Knowledge",
    "text": "2.2.1 Background Knowledge\n\n2.2.1.1 Temperature\nTemperature is closely tied to our daily lives; it informs what clothes we wear before stepping out, and ensures the food or drink we consume is not too hot or too cold. When you step outside your home, you can sense the cold or heat, but to quantify exactly how cold or hot it is, we use “temperature”.\nTemperature is a physical quantity that indicates the degree of coldness or hotness of an object. The high and low temperature of an object is a macroscopic phenomenon that reflects the intensity of thermal motion of the molecules that make up the object at the microscopic level. Hence, the temperature is a manifestation of the intensity of thermal motion of a large number of molecules that constitute an object. The faster the molecular motion, the higher the temperature, and the hotter the object; the slower the molecular motion, the lower the temperature, and the colder the object.\nTo measure temperature accurately, we need to establish a temperature unit standard and design corresponding temperature measurement tools.\n\n\n\nTemperature Scale \nThe unit standard for temperature is known as the temperature scale. Throughout the development of science, a variety of temperature scales have been devised, but their core methodology is the same: by stipulating the temperature values of certain phenomena or things, all other temperatures can be calibrated. Common temperature scales include Fahrenheit, Celsius, and Kelvin. Only five countries, including the United States and a few other English-speaking countries, still use the Fahrenheit scale. The vast majority of the world, including China, uses the Celsius scale. In research fields, scientists prefer to use the Kelvin scale.\n\nIn the Fahrenheit scale, under standard atmospheric pressure, the temperature at which water begins to freeze is set at 32 degrees Fahrenheit and the temperature at which water boils is 212 degrees Fahrenheit. The scale is divided into 180 equal parts between these two points, with each part being one degree Fahrenheit, denoted as 1℉. In the Fahrenheit scale, normal human body temperature is around 98℉.\nIn the Celsius scale, under standard atmospheric pressure, the temperature at which water begins to freeze is set at 0 degrees Celsius and the temperature at which water boils is 100 degrees Celsius. The scale is divided into 100 equal parts between these two points, with each part being one degree Celsius, denoted as 1℃. In the Celsius scale, normal human body temperature is around 36.5℃.\nThe Kelvin scale is established on the basis of absolute zero. Scientists found that there is a minimum temperature in the universe, -273.15℃, which cannot be reached but only asymptotically approached. This minimum temperature was designated as absolute zero, and set as 0 Kelvin, denoted as 0K. The temperature at which water begins to freeze under standard atmospheric pressure is set at 273.15K, and the temperature at which water boils is 373.15K. In the Kelvin scale, normal human body temperature is around 309.7K.\n\n\n\n\n2.2.1.2 Thermometer\nA thermometer is a tool for measuring temperature. Since temperature is not a physical quantity that can be seen directly, the measurement of temperature requires the assistance of physical phenomena directly related to temperature. For instance, in ancient China, there is a record of ‘lustrous pure blue flame,’ which is measured by observing the color of the flame.\nAnother example is the infrared thermometer, as shown in the image to the right, which measures temperature through the radiation differences of objects at different temperatures. Humans, like other organisms, also radiate infrared energy around them. This energy typically has a wavelength of 9-13μm and falls within the near-infrared band of 0.76-100μm. Since light within this wavelength range is not absorbed by air, the surface temperature of the human body can be accurately measured by simply measuring the infrared energy radiated by the human body. The human body infrared temperature sensor is designed and manufactured based on this principle.\n\n\nFurthermore, the phenomenon of thermal expansion and contraction is often used in temperature measurement. Commonly seen thermometers and body thermometers are based on the principle of measuring temperature by the expansion and contraction of a liquid when heated or cooled. The image below shows a commonly used alcohol thermometer that measures temperature by the property of alcohol’s expansion and contraction with temperature. The winter daytime temperature displayed in the image is -17°C.\n\n\n\n\n2.2.1.3 Humidity\nHumidity is a physical quantity that indicates the degree of dryness in the atmosphere. Under a certain temperature, the less water vapor a certain volume of air contains, the drier the air; the more water vapor, the more humid the air. The dryness or wetness of air is called “humidity.” Weather forecasts typically report humidity values in terms of relative humidity, which is a percentage obtained by comparing the actual amount of water vapor in the air to the maximum amount of water vapor the air can hold at the same temperature.\n\n\n\n\n2.2.1.4 Temperature and Humidity Sensor —— Grove Temperature and Humidity Sensor V2.0 (DHT20)\nAs the name implies, a temperature and humidity sensor is a sensor that can detect the temperature and humidity in the environment. There are many types of temperature and humidity sensors, and the one we chose is Grove Temperature and Humidity Sensor V2.0 (DHT20). This is a low-power, high-precision, and high-stability product with a fully calibrated digital I2C interface and a temperature measurement range of -40~80°C. Temperature and humidity sensors have a wide range of applications in the fields of agriculture, environmental protection, and home life.\n\n\n\n⚠️ Grove - Temperature and Humidity Sensor (DHT11)  \nIf you are using the Grove DHT11 version of the temperature and humidity sensor (with a blue sensor case), please refer to this version’s Wiki document. DHT11 is a temperature and humidity sensor that outputs calibrated digital signals. The biggest difference between it and DHT20 is their communication method: DHT11 uses a single-bus digital signal, while DHT20 uses an I2C signal."
  },
  {
    "objectID": "chapter_2-2.html#task-1-reading-temperature-and-humidity-values-in-the-serial-monitor-based-on-the-dht20-model",
    "href": "chapter_2-2.html#task-1-reading-temperature-and-humidity-values-in-the-serial-monitor-based-on-the-dht20-model",
    "title": "2.2 Smart Hygrometer and Thermometer",
    "section": "2.2.2 Task 1: Reading Temperature and Humidity Values in the Serial Monitor (Based on the DHT20 model)",
    "text": "2.2.2 Task 1: Reading Temperature and Humidity Values in the Serial Monitor (Based on the DHT20 model)\n\nAdding the Grove_Temperature_And_Humidity_Sensor Library File\nBefore starting to program the Grove Temperature and Humidity Sensor with the Arduino IDE, it is necessary to add the necessary library files for the sensor. Type the library file address in the browser address bar: 🔗 https://github.com/Seeed-Studio/Grove_Temperature_And_Humidity_Sensor, enter the GitHub page, and click Code→Download ZIP to download the resource package Grove_Temperature_And_Humidity_Sensor-master.zip to your local machine, as shown in the image below.\n\n\nAdd the resource package Grove_Temperature_And_Humidity_Sensor-master.zip downloaded in the previous step in the menu bar’s Sketch→Include Library→Add .ZIP Library, until you see a prompt indicating the successful loading of the library.\n\n\nOpening the “DHTtester” Example\nOnce the library file has been successfully added, the DHT library can be used. The “DHTtester” example can be opened through the following path: File→Examples→Grove Temperature And Humidity Sensor→DHTtester.\n\n⚠️ Note If the DHTtester example is not found in the menu after installing the library files, it can be viewed by closing and reopening the Arduino IDE.\n\nAfter opening the example program, we can see a program like the one shown below. This program reads the temperature and relative humidity in the environment and displays real-time data in the serial monitor. Part of the example program’s code needs to be modified.\n// Example testing sketch for various DHT humidity/temperature sensors\n// Written by ladyada, public domain\n\n#include \"DHT.h\"\n\n// Uncomment whatever type you're using!\n//#define DHTTYPE DHT11   // DHT 11\n#define DHTTYPE DHT22   // DHT 22  (AM2302)\n//#define DHTTYPE DHT21   // DHT 21 (AM2301)\n//#define DHTTYPE DHT10   // DHT 10\n//#define DHTTYPE DHT20   // DHT 20\n\n/*Notice: The DHT10 and DHT20 is different from other DHT* sensor ,it uses i2c interface rather than one wire*/\n/*So it doesn't require a pin.*/\n#define DHTPIN 2     // what pin we're connected to（DHT10 and DHT20 don't need define it）\nDHT dht(DHTPIN, DHTTYPE);   //   DHT11 DHT21 DHT22\n//DHT dht(DHTTYPE);         //   DHT10 DHT20 don't need to define Pin\n\n// Connect pin 1 (on the left) of the sensor to +5V\n// Connect pin 2 of the sensor to whatever your DHTPIN is\n// Connect pin 4 (on the right) of the sensor to GROUND\n// Connect a 10K resistor from pin 2 (data) to pin 1 (power) of the sensor\n\n\n#if defined(ARDUINO_ARCH_AVR)\n    #define debug  Serial\n\n#elif defined(ARDUINO_ARCH_SAMD) ||  defined(ARDUINO_ARCH_SAM)\n    #define debug  SerialUSB\n#else\n    #define debug  Serial\n#endif\n\nvoid setup() {\n\n    debug.begin(115200);\n    debug.println(\"DHTxx test!\");\n    Wire.begin();\n\n    /*if using WIO link,must pull up the power pin.*/\n    // pinMode(PIN_GROVE_POWER, OUTPUT);\n    // digitalWrite(PIN_GROVE_POWER, 1);\n\n    dht.begin();\n}\n\nvoid loop() {\n    float temp_hum_val[2] = {0};\n    // Reading temperature or humidity takes about 250 milliseconds!\n    // Sensor readings may also be up to 2 seconds 'old' (its a very slow sensor)\n\n\n    if (!dht.readTempAndHumidity(temp_hum_val)) {\n        debug.print(\"Humidity: \");\n        debug.print(temp_hum_val[0]);\n        debug.print(\" %\\t\");\n        debug.print(\"Temperature: \");\n        debug.print(temp_hum_val[1]);\n        debug.println(\" *C\");\n    } else {\n        debug.println(\"Failed to get temprature and humidity value.\");\n    }\n\n    delay(1500);\n}\nPay attention to the document’s comments. The program above provides several types of temperature and humidity sensor models (DHT22 is set as default), but we need the DHT20. So, uncomment the part for DHT20 and delete the definitions for other unneeded sensor models. DHT10 and DHT20 do not require pin definitions, so the revised code after modification is as follows:\n#include \"DHT.h\"\n#define DHTTYPE DHT20   // DHT 20\nDHT dht(DHTTYPE); \n#if defined(ARDUINO_ARCH_AVR)\n#define debug  Serial\n\n#elif defined(ARDUINO_ARCH_SAMD) ||  defined(ARDUINO_ARCH_SAM)\n#define debug  Serial\n#else\n#define debug  Serial\n#endif\n\nvoid setup() {\n    debug.begin(115200);\n    debug.println(\"DHTxx test!\");\n    Wire.begin();\n    dht.begin();\n}\n\nvoid loop() {\n    float temp_hum_val[2] = {0};\n    if (!dht.readTempAndHumidity(temp_hum_val)) {\n        debug.print(\"Humidity: \");\n        debug.print(temp_hum_val[0]);\n        debug.print(\" %\\t\");\n        debug.print(\"Temperature: \");\n        debug.print(temp_hum_val[1]);\n        debug.println(\" *C\");\n    } else {\n        debug.println(\"Failed to get temprature and humidity value.\");\n    }\n\n    delay(1500);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_DHTtester_DHT20_XIAO_en\n\nAfter modifying the code, first connect the temperature and humidity sensor to the I2C interface of the XIAO expansion board, as shown below. Then connect the XIAO development board to your computer, upload the modified example program to XIAO in the Arduino IDE, and open the serial monitor in Arduino IDE. You will now be able to see the values of temperature and humidity. Try placing the sensor in different environments to observe if the temperature and humidity values change.\n\n\n\n\n\n\nIt appears the temperature and humidity sensor is functioning correctly.\n\n\nReading Temperature and Humidity Values in the Serial Monitor (Based on the DHT11 Sensor) \nIf you are using the Grove DHT11 Temperature and Humidity Sensor with a blue casing, parts of the program code need to be modified as follows:  #define DHTPIN 0 needs to be modified according to the actual pin number the sensor is connected to.  #define DHTTYPE DHT11 should be set because there are different models of temperature and humidity sensors, and you need to choose the correct one, i.e., DHT11.  The example code after modification is shown below:\n#include \"DHT.h\"\n#define DHTTYPE DHT11   // DHT 11\n#define DHTPIN 0 \nDHT dht(DHTPIN, DHTTYPE); \n\n#if defined(ARDUINO_ARCH_AVR)\n    #define debug  Serial\n\n#elif defined(ARDUINO_ARCH_SAMD) ||  defined(ARDUINO_ARCH_SAM)\n    #define debug  SerialUSB\n#else\n    #define debug  Serial\n#endif\n\nvoid setup() {\n    debug.begin(115200);\n    debug.println(\"DHTxx test!\");\n    Wire.begin();\n    dht.begin();\n}\n\nvoid loop() {\n    float temp_hum_val[2] = {0};\n    if (!dht.readTempAndHumidity(temp_hum_val)) {\n        debug.print(\"Humidity: \");\n        debug.print(temp_hum_val[0]);\n        debug.print(\" %\\t\");\n        debug.print(\"Temperature: \");\n        debug.print(temp_hum_val[1]);\n        debug.println(\" *C\");\n    } else {\n        debug.println(\"Failed to get temprature and humidity value.\");\n    }\n\n    delay(1500);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_DHTtrster_DHT11_XIAO_en\n\nAfter modifying the code, first connect the temperature and humidity sensor to the A0 port of the XIAO expansion board, as shown in the figure below. Then, connect the XIAO development board to the computer, upload the modified example program to XIAO in the Arduino IDE, and open the serial monitor in the Arduino IDE to see the values of temperature and humidity. You can place the temperature and humidity sensor in different environments to see if the temperature and humidity values will change."
  },
  {
    "objectID": "chapter_2-2.html#project-creation-smart-temperature-and-humidity-meter",
    "href": "chapter_2-2.html#project-creation-smart-temperature-and-humidity-meter",
    "title": "2.2 Smart Hygrometer and Thermometer",
    "section": "2.2.3 Project Creation: Smart Temperature and Humidity Meter",
    "text": "2.2.3 Project Creation: Smart Temperature and Humidity Meter\n\nProject Description\nWe are going to make a portable mini temperature and humidity detector that detects temperature and humidity values through a temperature and humidity sensor and displays the values on the OLED display of the XIAO expansion board. However, it is not rich enough to have only the display function. We can add a buzzer alarm function. When the detected temperature and humidity exceed a certain range, an alarm will be sounded as a reminder. The value range can be adjusted according to different application scenarios. For example, in a home life scenario, set a comfortable temperature and humidity range based on human feelings; or use it in plant planting places, set the temperature and humidity value range based on suitable plant growth, exceed the alarm, and remind people to adjust.\n\n\nProgram Writing\nReferencing the example program above, one of the effects we want to achieve is to display the temperature and humidity values on the OLED display of the XIAO expansion board. The code for reading the temperature and humidity sensor detection values can be reused by just changing the display medium. In combination with Section 1.6, we have learned how to display characters on the OLED, so we just need to add an if…else condition judgment statement to judge the temperature and humidity values. The program writing idea is as follows:\n\nDeclare the DHT.h library, U8x8 library, etc., and connect the buzzer pin as a reminder to sound the device.\nInitialize the library file, define the buzzer pin state.\nDefine temperature and humidity variables to store readings and display them on the OLED screen, add logical judgment, and implement buzzer alarm.\n\nTo facilitate understanding and implementation, we divide the program implementation into two tasks:\n\nDetect temperature and humidity and display them on the OLED screen of the XIAO expansion board.\nAdd alarm function.\n\n\nTask 1: Use the Grove DHT20 sensor to detect temperature and humidity and display them on the OLED screen of the XIAO expansion board \nStep 1: Headers, declare the library files to be called.\n#include \"DHT.h\"    //Use DHT library\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;    //Use u8x8 library\n#define DHTTYPE DHT20\nDHT dht(DHTTYPE);   //DHT20 does not need to define pins\n\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);  //Setup constructor to connect to OLED screen\nStep 2: Initialize the DHT library and the u8x8 library.\nvoid setup() { \n    Wire.begin();   //Initialize wire library, and join I2C network\n    dht.begin();    //DHT starts working\n    u8x8.begin();   //u8x8 starts working\n    u8x8.setPowerSave(0);  //Turn off power saving mode, 1 is on, and nothing can be seen on the screen after power saving mode is on\n    u8x8.setFlipMode(1);\n}\nStep 3: Define temperature and humidity variables to store readings, read temperature and humidity values and display them on the OLED screen. Pay attention to the coordinate positions of temperature and humidity display.\nvoid loop() { \n    float temp, humi;   //Set the variables temp and humi to floating point type, representing temperature and humidity respectively\n    temp = dht.readTemperature();   //Read temperature value and store it in temp\n    humi = dht.readHumidity();  //Read humidity value and store it in humi\n    u8x8.setFont(u8x8_font_chroma48medium8_r);  //Set display font\n    u8x8.setCursor(0, 33);  //Set the position of the drawing cursor (0,33)\n    u8x8.print(\"Temp:\");    //Display Temp at the position (0,33)\n    u8x8.print(temp);   //Display real-time temperature value\n    u8x8.print(\"C\");    //Display the unit \"C\" of temperature\n    u8x8.setCursor(0,50);\n    u8x8.print(\"Humidity:\");\n    u8x8.print(humi);\n    u8x8.print(\"%\");\n    u8x8.refreshDisplay();\n    delay(200);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_dht20_tem_humi_XIAO_en\n\nStep 4: Connect the hardware, upload the program Connect the temperature and humidity sensor to the I2C interface of the XIAO expansion board, as shown in the figure:\n\n\nUse the data cable to connect XIAO to the computer, click the “upload” button in the Arduino IDE, and upload the program to the hardware. When the debugging area shows “upload successful”, you can observe whether the temperature and humidity values are displayed on the OLED screen, and you can hold the black part of the sensor with your palm to observe whether the values change.\n\n\nTask 2: Add an alarm function\nStep 1: Add alarm function code. The alarm function requires a buzzer to be integrated into the circuit, which can be facilitated using the on-board buzzer of the XIAO expansion board. The program needs to set the buzzer pin state, add a part for condition judgment - when the temperature exceeds a certain value or the humidity falls below a certain value, the buzzer will sound an alarm. Here, a logical expression needs to be written using the “&&” logical operator “and”.\n\nBoolean Operators\n\n&&: Logical AND, represents “and”,if (expression1 && expression2), only when all expressions in the parentheses are true will it execute the statements in if {}. \n||: Logical OR, represents “or”,if (expression1 || expression2), if either of the expressions are satisfied, the entire expression is true, and the statements in if {} are executed. \n!: Logical NOT, represents “not”, if (!expression1), only when the value of expression1 in the parentheses is false will it execute the statements in if {}. \n\nUsage example:  When the temperature exceeds 30 or the humidity falls below 40, satisfying either condition will make the buzzer sound an alarm.\n\nif (temp &gt; 30 || humi &lt; 40) {\n    tone(buzzerPin, 200, 200);\n}\nThe added part of the program mainly sets the buzzer and makes decisions based on temperature and humidity, controlling the buzzer to make a sound.\n// Part of the program, will not run\nint buzzerPin = A3; // Connects the buzzer to pin A3\n\nvoid setup() {\n    pinMode(buzzerPin , OUTPUT); // Sets the buzzer pin as output\n}\n\nvoid loop() {\n    float temp, humi;\n    temp = dht.readTemperature();\n    humi = dht.readHumidity();\n    if (temp &gt; 30 || humi &lt; 40) {  // When the temperature exceeds 30 or the humidity falls below 40, satisfying either condition will make the buzzer sound an alarm.\n        tone(buzzerPin, 200, 200);\n    }\nAdd the above code to the corresponding location of the Task 1 program to realize all functions. The complete program is shown below:\n#include \"DHT.h\" // Use DHT library\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt; // Use u8x8 library\n#define DHTTYPE DHT20\nDHT dht(DHTTYPE); // DHT20 does not require pin definition\nint buzzerPin = A3;\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE); // Set constructor to connect OLED display\n\nvoid setup() { \n    pinMode(buzzerPin , OUTPUT); // Set buzzer pin to output mode\n    Wire.begin(); // Initialize Wire library and join to I2C network\n    dht.begin(); // DHT begins operation\n    u8x8.begin(); // u8x8 begins operation\n    u8x8.setPowerSave(0);  // Disable power save mode, 1 is enable. After enabling power save mode, nothing will be seen on the screen\n    u8x8.setFlipMode(1);\n}\n\nvoid loop() { \n    float temp, humi; // Set variables temp and humi to floating point type, representing temperature and humidity respectively\n    temp = dht.readTemperature(); // Read temperature value and store it in temp\n    humi = dht.readHumidity(); // Read humidity value and store it in humi\n    if (temp &gt; 30 || humi &lt; 40) {  // When the temperature is above 30 or the humidity is below 40, if either condition is met, the buzzer will sound an alarm\n        tone(buzzerPin, 200, 200);\n    }\n\n    u8x8.setFont(u8x8_font_chroma48medium8_r); // Set display font\n    u8x8.setCursor(0, 33); // Set the position of the drawing cursor (0,33)\n    u8x8.print(\"Temp:\"); // Display \"Temp:\" at the position (0,33)\n    u8x8.print(temp); // Then display the real-time temperature value\n    u8x8.print(\"C\"); // Then display the unit of temperature \"C\"\n    u8x8.setCursor(0,50);\n    u8x8.print(\"Humidity:\");\n    u8x8.print(humi);\n    u8x8.print(\"%\");\n    u8x8.refreshDisplay();\n    delay(200);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_dht20_alarm_XIAO_en\n\nStep 2: Upload the program.\nAfter writing the program, connect the XIAO main control board to the computer using a data cable, as shown in the image below:\n\n\nAfter connection, click the “Verify” button to check the program. If the verification is successful, click the “Upload” button to upload the program to the hardware. When the debugging area shows “Upload Successful”, it is complete. To verify whether the alarm function runs smoothly, tightly grip the temperature and humidity sensor with your hand, observe the value change on the OLED display, and listen for the buzzer alarm when the temperature exceeds 30℃.\n\n\n\n\nTask 2-2: Use Grove DHT11 sensor to display temperature and humidity on the XIAO extension board’s OLED and add an alarm function.\nFor the Grove DHT11 sensor with a blue casing, the program is shown below:\n#include \"DHT.h\"//Use DHT library\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;//Use u8x8 library\n#define DHTPIN 0 \n#define DHTTYPE DHT11//Specify using DHT11\nDHT dht(DHTPIN, DHTTYPE); \nint buzzerPin = A3;\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);//Set constructor to connect OLED display\n\nvoid setup() { \n  pinMode(buzzerPin , OUTPUT);//Set buzzer pin to output mode\n  Wire.begin();//Initialize wire library and join to I2C network\n  dht.begin();//DHT begins operation\n  u8x8.begin();//u8x8 begins operation\n  u8x8.setPowerSave(0);  //Disable power save mode, 1 is enable. After enabling power save mode, nothing will be seen on the screen\n  u8x8.setFlipMode(1);\n}\n\nvoid loop() { \n  float temp, humi;//Set variables temp and humi to floating point type, representing temperature and humidity respectively\n  temp = dht.readTemperature();//Read temperature value and store it in temp\n  humi = dht.readHumidity();//Read humidity value and store it in humi\n  if (temp &gt; 30 || humi &lt; 40) {  //When the temperature is above 30 or the humidity is below 40, if either condition is met, the buzzer will sound an alarm\n  tone(buzzerPin, 200, 200);\n  }\n\n  u8x8.setFont(u8x8_font_chroma48medium8_r);//Set display font\n  u8x8.setCursor(0, 33);//Set the position of the drawing cursor (0,33)\n  u8x8.print(\"Temp:\");//Display \"Temp:\" at the position (0,33)\n  u8x8.print(temp);//Then display the real-time temperature value\n  u8x8.print(\"C\");//Then display the unit of temperature \"C\"\n  u8x8.setCursor(0,50);\n  u8x8.print(\"Humidity:\");\n  u8x8.print(humi);\n  u8x8.print(\"%\");\n  u8x8.refreshDisplay();\n  delay(200);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_dht11_alarm_XIAO_en"
  },
  {
    "objectID": "chapter_2-2.html#appearance-design",
    "href": "chapter_2-2.html#appearance-design",
    "title": "2.2 Smart Hygrometer and Thermometer",
    "section": "2.2.4 Appearance Design",
    "text": "2.2.4 Appearance Design\nStarting from this section, we will add the part of appearance design, beginning to explore the complete prototype product manufacturing. Initially, we can try to draw design sketches and make a simple modification with the materials at hand. Returning to the smart temperature and humidity meter in this section, please design the appearance of the prototype work based on the product characteristics and functions.\n\n\n\n\n\n\n\nProduct Name\nSmart Temperature and Humidity Meter\n\n\n\n\nProduct Features\nSmall, portable, high sensitivity.\n\n\nProduct Functions\nReal-time display of temperature and humidity values, and emits an alarm when temperature and humidity values exceed the comfortable range.\n\n\nProduct Appearance\n(For example, made into a pendant to hang on the backpack that is carried around, stick on the tissue storage box in the bedroom, etc.)\n\n\n\n\nCase reference"
  },
  {
    "objectID": "chapter_2-3.html#background-knowledge",
    "href": "chapter_2-3.html#background-knowledge",
    "title": "2.3 Surprise Gift Box Based on Light Sensor",
    "section": "2.3.1 Background Knowledge",
    "text": "2.3.1 Background Knowledge\n\n2.3.1.1 Light Sensor\nLight sensors can detect the light intensity in the surrounding environment and convert the detected light energy into electrical energy. Light sensors are divided into types such as photoresistive, photodiode, and photoelectric transistor. Here, we will simply introduce two commonly used light sensors, photoresistive and photodiode.\nPhotoresistive Type  Firstly, the photoresistive type, its module will integrate a photoresistor, as shown below. The photoresistor is extremely sensitive to light, any light visible to our eyes can cause its reaction. High-intensity light will cause the resistance value to decrease, and low-intensity light will cause the resistance value to increase. By adjusting the resistance value in the circuit through the light intensity, it can control other devices, such as controlling the LED light on and off.\n\n\nPhotodiode Type  Photodiodes, also known as photoelectric sensors or photodetectors, when a beam of light hits the diode, the electrons in the tube will quickly scatter to form electron holes, thereby causing current to flow. The stronger the light, the stronger the current. Since the current generated by the photodiode is proportional to the intensity of light, it is very beneficial for light detection that requires a rapid change in light response. The light sensor we are going to use in this lesson is of this type.\n\n\nTalking about the uses of light sensors, we can build a light-controlled switch through a light sensor, such as controlling the light on and off through a light sensor, turning off the light during the day, and turning on the light at night. The main purpose of the light control device is to save energy, improve efficiency through intelligent automation, the most common in life is probably the light control light, light control desk lamp, light control street lamp, highway tunnel lighting, etc., bringing convenience to our life and also contributing to environmental protection and energy conservation.\n\n\n2.3.1.2 RGB LED Strip\n\n\nThe project in this class is paired with an RGB LED strip. The strip integrates multiple color-adjustable light beads. Compared with a single LED, it can achieve more lighting effects and cool visual impacts, making it ideal for creating surprises. RGB LED strips come in various styles and models. The one we are going to use is the Grove - WS2813 RGB LED Strip, 30-bead model. We can control the RGB LED strip to achieve a rich lighting effect through programming, and build more interesting lighting projects."
  },
  {
    "objectID": "chapter_2-3.html#task-1-light-up-rgb-led-strip-to-get-started-with-rgb-led-strips-start-by-installing-and-understanding-its-library.",
    "href": "chapter_2-3.html#task-1-light-up-rgb-led-strip-to-get-started-with-rgb-led-strips-start-by-installing-and-understanding-its-library.",
    "title": "2.3 Surprise Gift Box Based on Light Sensor",
    "section": "2.3.2 Task 1: Light up RGB LED Strip To get started with RGB LED strips, start by installing and understanding its library.",
    "text": "2.3.2 Task 1: Light up RGB LED Strip To get started with RGB LED strips, start by installing and understanding its library.\n\nAdd the Adafruit_NeoPixel Library \nBefore starting to program the RGB LED strip with the Arduino IDE, you need to add the necessary library files. Enter the library file address 🔗 https://github.com/adafruit/Adafruit_NeoPixel in the browser address bar, enter the GitHub page, click Code→Download ZIP to download the resource package Adafruit_NeoPixel-master.zip to your local machine.\n\n\nNext, add the resource package Adafruit_NeoPixel-master.zip downloaded in the previous step via the menu bar Sketch→Include Library→Add .ZIP Library until you see the library loaded successfully.\n\n\nOpen the Simple Example \nYou can open the simple example through the following path: File → Examples → Adafruit NeoPixel → simple. Once the example program is opened, we can see the following program:\n// NeoPixel Ring simple sketch (c) 2013 Shae Erisson\n// Released under the GPLv3 license to match the rest of the\n// Adafruit NeoPixel library\n\n#include &lt;Adafruit_NeoPixel.h&gt;\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; // Required for 16 MHz Adafruit Trinket\n#endif\n\n// Which pin on the Arduino is connected to the NeoPixels?\n#define PIN        6 // On Trinket or Gemma, suggest changing this to 1\n\n// How many NeoPixels are attached to the Arduino?\n#define NUMPIXELS 16 // Popular NeoPixel ring size\n\n// When setting up the NeoPixel library, we tell it how many pixels,\n// and which pin to use to send signals. Note that for older NeoPixel\n// strips you might need to change the third parameter -- see the\n// strandtest example for more information on possible values.\nAdafruit_NeoPixel pixels(NUMPIXELS, PIN, NEO_GRB + NEO_KHZ800);\n\n#define DELAYVAL 500 // Time (in milliseconds) to pause between pixels\n\nvoid setup() {\n    // These lines are specifically to support the Adafruit Trinket 5V 16 MHz.\n    // Any other board, you can remove this part (but no harm leaving it):\n    #if defined(__AVR_ATtiny85__) && (F_CPU == 16000000)\n    clock_prescale_set(clock_div_1);\n    #endif\n    // END of Trinket-specific code.\n\n    pixels.begin(); // INITIALIZE NeoPixel strip object (REQUIRED)\n}\n\nvoid loop() {\n    pixels.clear(); // Set all pixel colors to 'off'\n\n    // The first NeoPixel in a strand is #0, second is 1, all the way up\n    // to the count of pixels minus one.\n    for(int i=0; i&lt;NUMPIXELS; i++) { // For each pixel...\n\n        // pixels.Color() takes RGB values, from 0,0,0 up to 255,255,255\n        // Here we're using a moderately bright green color:\n        pixels.setPixelColor(i, pixels.Color(0, 150, 0));\n\n        pixels.show();   // Send the updated pixel colors to the hardware.\n\n        delay(DELAYVAL); // Pause before next pass through loop\n    }\n}\nThis program allows the strip to light up 30 beads (green light) in sequence. This is a simple light strip example, and we need to modify some parameters:\n#define PIN 0, you need to modify the pin connected to the light strip according to the actual situation. It is connected to the A0 interface of the XIAO expansion board, so it is PIN 0.  #define NUMPIXELS 30, defines the number of LEDs in the light strip. Since the light strip has different models and the number of integrated beads is different, we use a light strip with 30 beads, so it is NUMPIXELS 30.\nAfter modifying the parameters, you can remove the English comments for a clearer view of the code. It occupies a large amount of space.\n#include &lt;Adafruit_NeoPixel.h&gt; // Header file, declaring the library\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n\n#define PIN 0 // The light strip is connected to pin 0. If you are using XIAO RP2040, please change 0 to A0\n#define NUMPIXELS 30 // The number of LED lights on the light strip\nAdafruit_NeoPixel pixels(NUMPIXELS, PIN, NEO_GRB + NEO_KHZ800); // Create a new light strip object, define data mode\n#define DELAYVAL 500 // The interval time for each light to light up\n\nvoid setup() {\n    #if defined(__AVR_ATtiny85__) && (F_CPU == 16000000)\n    clock_prescale_set(clock_div_1);\n    #endif\n    pixels.begin(); // The light strip is ready to output data\n}\n\nvoid loop() {\n    pixels.clear(); // All beads on the light strip are turned off\n    for(int i=0; i&lt;NUMPIXELS; i++) { \n        pixels.setPixelColor(i, pixels.Color(0, 150, 0)); // Light up the beads in sequence, the color is green\n        pixels.show(); // Display the light strip\n        delay(DELAYVAL); \n    }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L9_NeoPixel30_simple_XIAO_en\n\nIn the code above, pixels.Color(0,150,0) is a function to set the color of the LED light strip. The numbers in the parentheses represent the three primary colors (red, green, blue) respectively. If it is (0,150,0), it means that the brightness of red is 0, the brightness of green is 150, and the brightness of blue is 0. The entire light strip will show a green effect. The larger the number, the brighter it will be, with a maximum of 255. Next, connect the light strip to the A0/D0 interface of the XIAO expansion board, as shown in the following figure:\n\n\nConnect the XIAO main board to the computer with a data cable, and upload the program to the main board. After the upload is successful, observe the effect of the light strip.\nThe light strip can change color, flicker, and present various lighting effects such as breathing. We can refer to the sample program in the library: File → Example → Adafruit NeoPixel → buttoncycler. This sample program switches different lighting effects on the light strip through buttons. We can find the code for various lighting effects in it, such as flickering, rainbow lights, chasing, etc."
  },
  {
    "objectID": "chapter_2-3.html#project-making-surprise-gift-box",
    "href": "chapter_2-3.html#project-making-surprise-gift-box",
    "title": "2.3 Surprise Gift Box Based on Light Sensor",
    "section": "2.3.3 Project Making: Surprise Gift Box",
    "text": "2.3.3 Project Making: Surprise Gift Box\n\nProject Description\nThe program for the surprise gift box wants to realize: Use a light sensor to control the on and off of the RGB LED light strip, just like a light-controlled lamp, but the effect is opposite. When the value detected by the light sensor is less than a fixed value, that is, it is in a dim environment, the RGB LED light strip is off. When the value detected by the light sensor is greater than a fixed value, that is, in a bright environment, the RGB LED light strip lights up the rainbow light.\n\n\nProgram Writing\nThe program writing idea is as follows:\n\nDeclare the files to be called, create a new light strip object, define the sensor pin and the number of LEDs on the light strip.\nInitialize the light strip and set the light sensor pin mode.\nRead the light value. If the light value is greater than 100, the light strip will present a rainbow and breathing light effect. Otherwise, the light strip will turn off.\n\nThe program is completed in two tasks:\n\nTask 1: Make the Light Strip Present Rainbow and Breathing Light Effect\nStep 1: Declare the files to be called, declare the light strip object, and define the pin and the number of LEDs on the light strip.\n#include &lt;Adafruit_NeoPixel.h&gt; // Header file, declaring the library\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n\n#define PIXEL_PIN 0 // The light strip is connected to pin A0. If you are using XIAO RP2040, please change 0 to A0\n#define PIXEL_COUNT 30 // The number of LED lights on the light strip\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800);\n// Declare a new light strip object and define the data mode\nStep 2: Initialize the light strip.\nvoid setup() {\n    strip.begin(); // Initialize the light strip, the light strip is ready to output data\n}\nStep 3: The light strip presents a rainbow and breathing light effect. This part uses the for() function to present the breathing effect. For example, for( i = 0; i&lt;5; i ++ ){} means that the initial value of i is 0, when i is less than 5, the statement in the loop body {} is run, each time the loop is run, i is incremented by 1. This loop will run 5 times.\nvoid loop() {\n    strip.clear();// Turn off all the lights on the light strip\n    rainbow(10);// The light strip displays a rainbow light effect. The number in the parenthesis represents the speed of the rainbow light circulation. The smaller the number, the faster the circulation speed\n}\n// The following is the code for the rainbow light effect, presenting the breathing light effect. This code can be found in the example program buttoncycler\nvoid rainbow(int wait) {\n    for(long firstPixelHue = 0; firstPixelHue &lt; 3*65536; firstPixelHue += 256) {\n        for(int i=0; i&lt;strip.numPixels(); i++) { \n            int pixelHue = firstPixelHue + (i * 65536L / strip.numPixels());\n            strip.setPixelColor(i, strip.gamma32(strip.ColorHSV(pixelHue)));\n        }\n        strip.show(); // The light strip presents a light effect\n        delay(wait);  // Delay\n    }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L9_Rainbow_XIAO_en\n\nStep 4: Connect the hardware and upload the program. First, connect the RGB LED light strip to the A0/D0 interface of the XIAO expansion board, as shown in the figure:\n\n\nUse a data cable to connect XIAO to the computer, click the “Upload” button, and upload the program to the hardware. When the debugging area shows “Upload successful”, you can observe the light effect of the light strip.\n\n\n\n\nTask 2: Adding Light Control Switch Function\nStep 1: Add code.\nThe added function is mainly to read the light value detected by the light sensor, and use the if…else… statement to judge the light value. When it is greater than 100 (this value can be adjusted according to the actual environment), the RGB LED light strip will show a rainbow breathing light effect.  Part of the program added:\n// This is an added part of the program, it cannot run directly\n#define LIGHT_PIN 7// Define the light sensor connected to A7. If you are using XIAO RP2040, please change 7 to A3. If you are using XIAO BLE, please change 7 to 5\n#define PIXEL_PIN 0// Define light strip. If you are using XIAO RP2040, please change 0 to A0\nint readValue = 0;// Define the variable readValue to store the light value\nvoid setup() { \n    pinMode(LIGHT_PIN , INPUT); // Set the pin of the light sensor as input status\n}\nvoid loop() {\n    readValue = analogRead(A7);// Read the analog value of the A7 pin light and store it in the readValue variable. If you are using XIAO RP2040, please change A7 to A3. If you are using XIAO BLE, please change A7 to A5\n    if(readValue &gt; 500){ // Condition judgment, if the light value is greater than 500, then the light strip presents a rainbow light effect, otherwise, the light strip is turned off\n        rainbow(10);\n    }else {\n        strip.clear();  \n        strip.show(); \n    }\n}\nWe add the entered statement to the corresponding position of Task 1’s program. See the complete program:\n#include &lt;Adafruit_NeoPixel.h&gt;// Header file, declare library\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n#define LIGHT_PIN 7// Define the light sensor connected to A7. If you are using XIAO RP2040, please change 7 to A3. If you are using XIAO BLE, please change 7 to 5\n#define PIXEL_PIN 0 // The light strip is connected to the A0 pin. If you are using XIAO RP2040, please change 0 to A0\n#define PIXEL_COUNT 30 // The number of LEDs on the light strip\nint readValue = 0;// Define variable readValue to store light values\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800);\n// Declare the light strip object and define the data mode\nvoid setup() {\n  strip.begin(); // Initialize the light strip and prepare the light strip to output data\n  pinMode(LIGHT_PIN , INPUT); // Set the pin of the light sensor to input state\n}\nvoid loop() {\n  strip.clear();// Turn off all the beads on the light strip\n  rainbow(10);// The light strip shows a rainbow light effect. The number in the parentheses represents the speed of the rainbow light rotation. The smaller the number, the faster the rotation speed\n  readValue = analogRead(A7);// Read the analog value of the light on the A7 pin and store it in the readValue variable. If you are using XIAO RP2040, please change A7 to A3. If you are using XIAO BLE, please change A7 to A5\n    if(readValue &gt; 500){ // Conditional judgment, if the light value is greater than 500, then the light strip presents a rainbow light effect, otherwise, the light strip is turned off\n        rainbow(10);\n    }else {\n        strip.clear();  \n        strip.show(); \n    }\n}\n// The following is the code for the rainbow light effect, presenting the breathing light effect, this code can be found in the sample program buttoncycler\nvoid rainbow(int wait) {\n  for(long firstPixelHue = 0; firstPixelHue &lt; 3*65536; firstPixelHue += 256) {\n    for(int i=0; i&lt;strip.numPixels(); i++) { \n      int pixelHue = firstPixelHue + (i * 65536L / strip.numPixels());\n      strip.setPixelColor(i, strip.gamma32(strip.ColorHSV(pixelHue)));\n    }\n    strip.show(); // The light strip presents a light effect\n    delay(wait);  // Delay\n  }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L9_StripLight_XIAO_en\n\nStep 2: Connect the hardware and upload the program. First, connect the RGB LED light strip to the A0 interface of the XIAO expansion board, and connect the light sensor to the A7 interface, as shown in the figure below:\n\n\n\n⚠️ Note  If you are using XIAO BLE, please connect the light sensor to the I2C interface of the XIAO expansion board.  If you are using XIAO RP2040, due to the limited number of pins exposed, you need to connect the SIG pin of the light sensor and the A3 pin of XIAO RP2040 with Dupont wires on your own.\n\nNext, connect XIAO to your computer with a data cable, click the “Upload” button in the Arduino IDE to upload the program to the hardware. When the debugging area shows “Upload successful”, you can cover the light sensor with your hand, then release the light sensor, and observe the changes in the light strip. Note that because it takes a certain amount of time for the light strip to display light effects, the light strip will not turn off immediately when you cover the light sensor."
  },
  {
    "objectID": "chapter_2-3.html#exterior-design",
    "href": "chapter_2-3.html#exterior-design",
    "title": "2.3 Surprise Gift Box Based on Light Sensor",
    "section": "2.3.4 Exterior Design",
    "text": "2.3.4 Exterior Design\nCombining the program design of the surprise gift box, when the light sensor is in a dim environment, the RGB LED light strip is off, and when the light sensor is in a bright environment, the RGB LED light strip lights up with rainbow lights. We can imagine that the electronic part is placed in a closed box, which can match the function implemented by the program and can also meet the positioning of the gift. Of course, you can also have other designs.\n\n\n\n\n\n\n\nProduct Name\nSurprise Gift Box\n\n\n\n\nProduct Features\nCool light effects, photocontrol, surprise, birthday\n\n\nProduct Functions\nControl the lighting of the RGB LED light strip with a light sensor\n\n\nProduct Appearance\n\n\n\n\n\nCase reference"
  },
  {
    "objectID": "chapter_2-4.html#background-knowledge",
    "href": "chapter_2-4.html#background-knowledge",
    "title": "2.4 Rhythmic Dance with a Triaxial Accelerometer",
    "section": "2.4.1 Background Knowledge",
    "text": "2.4.1 Background Knowledge\n\n2.4.1.1 Triaxial Accelerometer\nAs people pay more and more attention to their health, an increasing number of people are starting to wear wristbands, pedometers, or use smartphones to record their steps, which has become a lifestyle habit for many. So how exactly does a pedometer work? The answer lies in a tiny chip called a triaxial accelerometer which is usually found in modern phones or wristbands and is the key component in step counting. An accelerometer is a sensor capable of measuring acceleration. It usually consists of a mass, a damper, an elastic element, a sensitive element, and an adjustment circuit. During acceleration, the sensor measures the inertial force applied to the mass, and uses Newton’s second law to determine acceleration. Depending on the different sensitive elements of the sensor, common accelerometers include capacitive, inductive, strain, piezoresistive, piezoelectric, and others.\n\n\nThe capacitive accelerometer, based on the principle of capacitance, is a common type of accelerometer and is indispensable in certain fields, such as safety airbags, mobile devices like phones, etc. Capacitive accelerometers employ Micro-Electro-Mechanical Systems (MEMS) technology, which makes them very economical when mass-produced, thus ensuring low cost.\n\nApplications of Accelerometers \nAccelerometers can help robots understand their environment. Are they climbing a hill? Or going downhill, or have they fallen? For balance cars or drones, accelerometers can help them maintain balance. In addition to everyday areas like smartphones and health wristbands, accelerometers have also found wide application in other fields.\n\nAccelerometers in seismic probe design: Seismic detectors are special sensors used for geological exploration and engineering measurements. They are sensors that convert ground vibration into electrical signals, turning ground movement caused by seismic waves into electrical signals, which are then converted into binary data through an analog/digital converter, organized, stored, and processed.\n\n\n\n\nMonitoring high-voltage line dancing: Currently, domestic monitoring of line dancing mainly adopts two main technical schemes: video image acquisition and motion acceleration measurement. The former requires high reliability and stability of video equipment under high-temperature, high-humidity, severe cold, dense fog, dust storms, and other weather conditions, and the effects of the video images taken will also be affected. Hence, it can only serve as auxiliary monitoring means and cannot quantitatively analyze line motion parameters. Using an accelerometer to monitor line dancing allows for quantitative analysis of the up-and-down vibration and left-right swing of transmission lines at a certain point, but it can only measure the amplitude and frequency of line linear motion and not accurately measure complex circular motion.\n\n\n\n\nAutomotive Safety: Accelerometers are mainly used in automotive safety airbags, anti-lock braking systems, traction control systems, and other safety features. In safety applications, the rapid response of the accelerometer is crucial. It must be quickly determined when a safety airbag should deploy, so the accelerometer must respond instantly. A sensor design that can quickly reach a stable state rather than continuing to vibrate can shorten the device’s response time.\n\n\n\n\nDrones: Accelerometers are also key components of drone control, positioning, and stability.\n\n\n\n\nGame Control: Accelerometers can detect changes in the tilt angles up, down, left, and right, so it becomes straightforward to control the directions of objects in games by tilting handheld devices forward and backward. Many new game console controllers and VR device controllers incorporate accelerometers.\n\n\n\n\nImage Auto-flip: Accelerometers detect the rotation movements and directions of handheld devices, making the displayed images upright.\n\n\n\n\nCompensation for GPS Navigation System Blind Spots: GPS systems determine an object’s location by receiving signals from three satellites distributed at 120 degrees. In special circumstances and terrains, like tunnels, dense buildings, jungle areas, GPS signals may weaken or even be completely lost, creating blind spots. By adding an accelerometer and using inertial navigation we previously mentioned, we can measure system dead zones. By integrating the accelerometer once, we change it into the speed change per unit time, thereby measuring the movement of an object in the dead zone.\n\n\n\n\nPedometer Function: Accelerometers can detect AC signals and object vibrations. When people walk, they produce regular vibrations, and the accelerometer can detect the zero crossing of the vibrations, thereby calculating the number of steps walked or run, and thus calculating the displacement moved by the person. Using certain formulas, we can also calculate the calories burned.\n\n\n\n\nImage Stabilization and Shooting Stabilizers: The image stabilization function uses an accelerometer to detect the vibration/swing amplitude of handheld devices, and when the vibration/swing amplitude is too large, it locks the camera shutter to ensure the images taken are always clear. The shooting stabilizer uses an accelerometer to maintain the stability of the entire device.\n\n\n\n\nHard Drive Protection: By detecting the state of free fall with an accelerometer, necessary protection can be implemented for hard drives. It is well known that when a hard drive is reading data, the gap between the read/write head and the platter is minuscule, and even minor external vibrations can have severe consequences for the hard drive, leading to data loss. By using an accelerometer, the state of free fall can be detected. When the state of free fall is detected, the read/write head is reset to reduce the extent of hard drive damage.\n\n\n\n\n\nGrove Three-Axis Accelerometer \nIn our kit, we have a three-axis accelerometer module - Grove Three-Axis Accelerometer Module. This tiny, incredible three-axis accelerometer supports I2C, SPI, and ADC GPIO interfaces, which means you can choose any way to connect to your development board. Additionally, the accelerometer can also monitor the surrounding temperature to adjust for errors caused by it."
  },
  {
    "objectID": "chapter_2-4.html#task1-reading-values-from-the-xyz-axes-of-the-three-axis-accelerometer",
    "href": "chapter_2-4.html#task1-reading-values-from-the-xyz-axes-of-the-three-axis-accelerometer",
    "title": "2.4 Rhythmic Dance with a Triaxial Accelerometer",
    "section": "2.4.2 Task1: Reading Values from the XYZ Axes of the Three-Axis Accelerometer",
    "text": "2.4.2 Task1: Reading Values from the XYZ Axes of the Three-Axis Accelerometer\nThe key to using a three-axis accelerometer for project creation is learning how to read the values of the X, Y, Z axes of the accelerometer.\n\nAdd the Seeed_Arduino_LIS3DHTR Library\nBefore starting to program the Grove Three-Axis Accelerometer with the Arduino IDE, it is necessary to add the required library for the sensor. Enter the library address 🔗 https://github.com/Seeed-Studio/Seeed_Arduino_LIS3DHTR/ in the browser address bar, enter the GitHub page, click Code→Download ZIP to download the resource package Seeed_Arduino_LIS3DHTR-master.zip to local, as shown in the figure below.\n\n\nAdd the previously downloaded resource package Seeed_Arduino_LIS3DHTR-master.zip through Sketch→Include Library→Add .ZIP Library in the menu bar, until you see a library load successful prompt.\n\n\nOpen the Sample File\nSimilarly, you can refer to the library file and open the LIS3DHTR_IIC sample through the following path: File→Examples→Grove-3-Axis-Digital-Accelerometer-2g-to-16g-LIS3DHTR→LIS3DHTR_IIC.\n// This example use I2C.\n#include \"LIS3DHTR.h\"\n#include &lt;Wire.h&gt;\nLIS3DHTR&lt;TwoWire&gt; LIS; //IIC\n#define WIRE Wire\n\nvoid setup()\n{\n  Serial.begin(115200);\n  while (!Serial)\n  {\n  };\n  LIS.begin(WIRE); //IIC init dafault :0x18\n  //LIS.begin(WIRE, 0x19); //IIC init\n  LIS.openTemp();  //If ADC3 is used, the temperature detection needs to be turned off.\n  //  LIS.closeTemp();//default\n  delay(100);\n  //  LIS.setFullScaleRange(LIS3DHTR_RANGE_2G);\n  //  LIS.setFullScaleRange(LIS3DHTR_RANGE_4G);\n  //  LIS.setFullScaleRange(LIS3DHTR_RANGE_8G);\n  //  LIS.setFullScaleRange(LIS3DHTR_RANGE_16G);\n  //  LIS.setOutputDataRate(LIS3DHTR_DATARATE_1HZ);\n  //  LIS.setOutputDataRate(LIS3DHTR_DATARATE_10HZ);\n  //  LIS.setOutputDataRate(LIS3DHTR_DATARATE_25HZ);\n  LIS.setOutputDataRate(LIS3DHTR_DATARATE_50HZ);\n  //  LIS.setOutputDataRate(LIS3DHTR_DATARATE_100HZ);\n  //  LIS.setOutputDataRate(LIS3DHTR_DATARATE_200HZ);\n  //  LIS.setOutputDataRate(LIS3DHTR_DATARATE_1_6KHZ);\n  //  LIS.setOutputDataRate(LIS3DHTR_DATARATE_5KHZ);\n  LIS.setHighSolution(true); //High solution enable\n}\nvoid loop()\n{\n  if (!LIS)\n  {\n    Serial.println(\"LIS3DHTR didn't connect.\");\n    while (1)\n      ;\n    return;\n  }\n  //3 axis\n  //  Serial.print(\"x:\"); Serial.print(LIS.getAccelerationX()); Serial.print(\"  \");\n  //  Serial.print(\"y:\"); Serial.print(LIS.getAccelerationY()); Serial.print(\"  \");\n  //  Serial.print(\"z:\"); Serial.println(LIS.getAccelerationZ());\n  //ADC\n  //    Serial.print(\"adc1:\"); Serial.println(LIS.readbitADC1());\n  //    Serial.print(\"adc2:\"); Serial.println(LIS.readbitADC2());\n  //    Serial.print(\"adc3:\"); Serial.println(LIS.readbitADC3());\n\n  //temperature\n  Serial.print(\"temp:\");\n  Serial.println(LIS.getTemperature());\n  delay(500);\n}\nThe sample program can read the values of the X, Y, Z axes of the three-axis accelerometer and output through the serial monitor. The sample program provides us with different setting choices using the “//” comment method, but you need to manually select the required parts, as follows:  LIS.begin(WIRE): initializes the default values, you can choose between 0×18 and 0×19, we need to choose LIS.begin(WIRE,0×19);.  LIS.setOutputDataRate(LIS3DHTR_DATARATE_50HZ): The accelerometer’s output rate has multiple choices, choose 50Hz. The three-axis accelerometer can also monitor the ambient temperature, we temporarily do not need to delete the related code, the complete program is as follows:\n// This example shows the 3-axis acceleration.\n#include \"LIS3DHTR.h\" // Declare library\n#include &lt;Wire.h&gt;\nLIS3DHTR&lt;TwoWire&gt; LIS; \n#define WIRE Wire // Initialize the module above using hardware I2C\n\nvoid setup()\n{\n    Serial.begin(9600);\n    while (!Serial) { }; // If you can't open the serial monitor, the code will stop here\n    LIS.begin(WIRE, 0x19); // Initialize I2C with default value\n    delay(100);\n    LIS.setOutputDataRate(LIS3DHTR_DATARATE_50HZ); // Set the accelerometer's output rate to 50Hz.\n}\nvoid loop()\n{\n    if (!LIS) {\n        Serial.println(\"LIS3DHTR didn't connect.\");\n        while (1);\n        return;\n    }\n    // Read the values of the X, Y, Z axes from the sensor, and display them on the serial monitor\n    Serial.print(\"x:\"); Serial.print(LIS.getAccelerationX()); Serial.print(\"  \");\n    Serial.print(\"y:\"); Serial.print(LIS.getAccelerationY()); Serial.print(\"  \");\n    Serial.print(\"z:\"); Serial.println(LIS.getAccelerationZ());\n    delay(500);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L10_LIS3DHTR_IIC_XIAO_en\n\nNext, connect the three-axis accelerometer to the I2C interface. There are two I2C interfaces on the XIAO expansion board, as shown in the picture below:\n\n\n\n\nMonitor Data Changes via Serial Monitor \nConnect XIAO to your computer with a data cable, upload the program, wait for the program to upload successfully, then open the serial monitor. Move the three-axis accelerometer in the X, Y, Z axis direction and observe the changes in the readings.\n\n\n\n\nMonitor Data Changes with Serial Plotter \nThe numerical way of presenting the changes in the accelerometer’s 3-axis values is not very intuitive. You can open the serial plotter, as shown in the picture below."
  },
  {
    "objectID": "chapter_2-4.html#project-production-rhythmic-dance",
    "href": "chapter_2-4.html#project-production-rhythmic-dance",
    "title": "2.4 Rhythmic Dance with a Triaxial Accelerometer",
    "section": "2.4.3 Project Production: Rhythmic Dance",
    "text": "2.4.3 Project Production: Rhythmic Dance\n\nProject Description\nWe can add an RGB LED strip in the project to achieve cool light effects changes. The three-axis accelerometer is used to detect movement, and different light effects are triggered based on different values on the X, Y, Z axes of the accelerometer.\n\n\nProgram Writing\nTo control the RGB LED strip to change the light effects via the three-axis accelerometer, follow these steps:\n\nDeclare the library files that need to be invoked, define the strip pin and LED quantity.\nInitialize the three-axis accelerometer and the strip.\nSet the light effect of the strip to red, green and blue flashing, set the conditional judgment, and control the change by different value intervals on the X, Y, Z axis of the three-axis accelerometer.\n\n\n\nTask: Control RGB LED Strip to Change Light Effects via Three-Axis Accelerometer\nStep 1: Declare the library files that need to be invoked, define the strip pin and the number of LEDs.\n#include \"LIS3DHTR.h\" // Declare the library file of the three-axis accelerometer\n#include &lt;Adafruit_NeoPixel.h&gt; // Declare the strip's library file\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n// Below are to initialize the module using software I2C or hardware I2C\n#ifdef SOFTWAREWIRE\n#include &lt;SoftwareWire.h&gt;\nSoftwareWire myWire(3, 2);\nLIS3DHTR&lt;SoftwareWire&gt; LIS; \n#define WIRE myWire\n#else\n#include &lt;Wire.h&gt;\nLIS3DHTR&lt;TwoWire&gt; LIS;    \n#define WIRE Wire\n#endif\n\n#define PIXEL_PIN 0 // Define the pin of the strip, if you use XIAO RP2040/XIAO ESP32, please modify 0 to A0\n#define PIXEL_COUNT 30 // Define the number of LEDs in the strip as 30\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800); // Declare the strip object, set the data type\nStep 2: Initialize the three-axis accelerometer and the strip. Here, you need to initialize the accelerometer and set the rate to 50HZ.\nvoid setup() { \n    Serial.begin(9600); // Initialize the serial monitor\n    while (!Serial) {}; // If the serial monitor isn't opened, the code will stop here, so please open the serial monitor\n    LIS.begin(WIRE, 0x19); // Initialize I2C\n    delay(100);\n    LIS.setOutputDataRate(LIS3DHTR_DATARATE_50HZ); // Set the accelerometer's output rate to 50Hz\n    strip.begin(); // Start the strip\n    strip.show(); // Display the strip\n}\nStep 3: Set the light effects to flash in red, green, and blue, respectively. Conditionals are used to change the color of the light strip according to the varying readings on the X, Y, and Z axes of the 3-axis accelerometer. These readings can be viewed via the serial monitor. By observing the change in values when the accelerometer is moved along the X, Y, and Z axes, we can determine the appropriate settings for the light strip. Since the readings may sometimes be negative, we take the absolute value of the readings. The abs() function can be used to get the absolute value, for example, abs(LIS.getAccelerationX()) would give the absolute value of the reading on the X-axis.\nvoid loop() {\n    if (!LIS) {  // Check if the 3-axis accelerometer is connected properly\n        Serial.println(\"LIS3DHTR didn't connect.\");\n        while (1);\n        return;\n    }\n\n    if ((abs(LIS.getAccelerationX()) &gt; 0.2)) {\n        theaterChase(strip.Color(127, 0, 0), 50); // The light strip turns red\n    }\n    if ((abs(LIS.getAccelerationY()) &gt; 0.2)) {\n        theaterChase(strip.Color(0, 127, 0), 50); // The light strip turns green\n    }\n    if ((abs(LIS.getAccelerationZ()) &gt; 1.0)) {\n        theaterChase(strip.Color(0, 0, 127), 50); // The light strip turns blue\n    }\n    else\n    {\n        strip.clear(); \n        strip.show();\n    }\n\n    // Read the values of the X, Y, and Z axes from the sensor and display them on the serial monitor\n    Serial.print(\"x:\"); Serial.print(LIS.getAccelerationX()); Serial.print(\"  \");\n    Serial.print(\"y:\"); Serial.print(LIS.getAccelerationY()); Serial.print(\"  \");\n    Serial.print(\"z:\"); Serial.println(LIS.getAccelerationZ());\n\n    delay(500);\n}\n// Set theaterChase for flashing light effects\nvoid theaterChase(uint32_t color, int wait) {\n    for(int a=0; a&lt;10; a++) {  \n        for(int b=0; b&lt;3; b++) { \n            strip.clear();   \n            for(int c=b; c&lt;strip.numPixels(); c += 3) {\n                strip.setPixelColor(c, color);\n            }\n            strip.show(); \n            delay(wait);\n        }\n    }\n}\nComplete program as follows:\n#include \"LIS3DHTR.h\"// Declare the library file for the 3-axis accelerometer\n#include &lt;Adafruit_NeoPixel.h&gt;// Declare the library file for the light strip\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n// The following is to initialize the module using software I2C or hardware I2C\n#ifdef SOFTWAREWIRE\n#include &lt;SoftwareWire.h&gt;\nSoftwareWire myWire(3, 2);\nLIS3DHTR&lt;SoftwareWire&gt; LIS; \n#define WIRE myWire\n#else\n#include &lt;Wire.h&gt;\nLIS3DHTR&lt;TwoWire&gt; LIS;    \n#define WIRE Wire\n#endif\n\n#define PIXEL_PIN 0 // Define the pin of the light strip, if you are using XIAO RP2040/XIAO ESP32, please change 0 to A0\n#define PIXEL_COUNT 30 // Define the number of LEDs on the light strip as 30\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800); // Declare the light strip object and set the data type\n\nvoid setup() { \n    Serial.begin(9600); // Initialize the serial monitor\n    while (!Serial) {};// If you do not open the serial monitor, the code will stop here, so please open the serial monitor\n    LIS.begin(WIRE, 0x19); // IIC initialization\n    delay(100);\n    LIS.setOutputDataRate(LIS3DHTR_DATARATE_50HZ); // Set the output rate of the accelerometer to 50Hz\n    strip.begin(); // The light strip starts working\n    strip.show(); // The light strip displays\n}\nvoid loop() {\n    if (!LIS) {  // Check if the 3-axis accelerometer is connected correctly\n        Serial.println(\"LIS3DHTR didn't connect.\");\n        while (1);\n        return;\n    }\n\n    if ((abs(LIS.getAccelerationX()) &gt; 0.2)) {\n        theaterChase(strip.Color(127, 0, 0), 50); // The light strip turns red\n    }\n    if ((abs(LIS.getAccelerationY()) &gt; 0.2)) {\n        theaterChase(strip.Color(0, 127, 0), 50); // The light strip turns green\n    }\n    if ((abs(LIS.getAccelerationZ()) &gt; 1.0)) {\n        theaterChase(strip.Color(0, 0, 127), 50); // The light strip turns blue\n    }\n    else\n    {\n        strip.clear(); \n        strip.show();\n    }\n\n    // Read the values of the X, Y, and Z axes from the sensor and display them on the serial monitor\n    Serial.print(\"x:\"); Serial.print(LIS.getAccelerationX()); Serial.print(\"  \");\n    Serial.print(\"y:\"); Serial.print(LIS.getAccelerationY()); Serial.print(\"  \");\n    Serial.print(\"z:\"); Serial.println(LIS.getAccelerationZ());\n\n    delay(500);\n}\n// Set theaterChase for flashing light effects\nvoid theaterChase(uint32_t color, int wait) {\n    for(int a=0; a&lt;10; a++) {  \n        for(int b=0; b&lt;3; b++) { \n            strip.clear();   \n            for(int c=b; c&lt;strip.numPixels(); c += 3) {\n                strip.setPixelColor(c, color);\n            }\n            strip.show(); \n            delay(wait);\n        }\n    }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L10_MovementRGBLED_XIAO_en\n\nStep 4: Connect the hardware and upload the program. First, connect the RGB LED light strip to the A0/D0 interface of the XIAO expansion board, and the three-axis accelerometer to the I2C interface, as shown in the figure:\n\n\nUse a data cable to connect XIAO to your computer, click the “Upload” button in Arduino IDE, and upload the program to the hardware. Once the debugging area shows “Upload Successful”, you can open the serial monitor and try swinging the three-axis accelerometer left, right, up, and down to feel the light effect changes of the light strip."
  },
  {
    "objectID": "chapter_2-4.html#exterior-design",
    "href": "chapter_2-4.html#exterior-design",
    "title": "2.4 Rhythmic Dance with a Triaxial Accelerometer",
    "section": "2.4.4 Exterior Design",
    "text": "2.4.4 Exterior Design\nImagine how cool it would be if there were lights flashing with your dance steps as you passionately swing your arms. That’s where the inspiration for Rhythm Dance comes from. It can be combined with clothes or accessories to create a wearable style.\n\n\n\n\n\n\n\nProduct Name\nRhythm Dance\n\n\n\n\nProduct Features\nWearable, Cool light effects, Posture detection\n\n\nProduct Functions\nRGB LED light strip displays different light effects based on the values detected by the three-axis accelerometer\n\n\nProduct Appearance\n(For example: The waterproof layer on the outside of the RGB LED light strip can be removed, and it can be sewn together with clothes or a belt, etc.)\n\n\n\n\nReference for the case"
  },
  {
    "objectID": "chapter_3.html",
    "href": "chapter_3.html",
    "title": "Chapter 3: Intermediate Project Practice - Complex Projects",
    "section": "",
    "text": "In this unit, we will delve into more intricate and comprehensive projects, striving towards mature works in terms of program implementation and design of appearance structure. These include miniaturized smart homes, wearable electronic devices, interactive electronic instruments, Wi-Fi connectivity, and applications enabled by XIAO ESP32C3 or telemetry and command via the MQTT protocol. We will provide the laser-cut design blueprints for the first three cases for your reference. Of course, you’re not limited to these examples; you could use other, more accessible materials, such as corrugated cardboard or cardstock, for crafting. Feel free to unleash your creativity and design the work you wish to present!"
  },
  {
    "objectID": "chapter_3-1.html#background-knowledge",
    "href": "chapter_3-1.html#background-knowledge",
    "title": "3.1 Smart Remote Control Door",
    "section": "3.1.1 Background Knowledge",
    "text": "3.1.1 Background Knowledge\n\n3.1.1.1 Infrared Receivers and Transmitters\nAn infrared receiver is used to receive infrared signals, and is also used for remote control detection. The infrared receiver has an infrared detector for picking up the infrared light emitted by the infrared transmitter. The Grove - IR Infrared Receiver Module has a range of 10 meters; signals cannot be received beyond this effective range. Generally, the infrared receiver and infrared transmitter work together.\n\n\nGrove - IR Infrared Receiver Module\n\n\nAn infrared transmitter is a type of remote control device with a remote control function. It emits light through an infrared emission tube within a certain range, thereby achieving control signal functions. The remote controls we use to control TVs, air conditioners, and car doors in daily life are infrared transmitters. Common infrared transmitters include modular ones like the Grove - Infrared Emitter Module, as well as regular remote controls, each with corresponding usage scenarios and methods. For our smart remote control door, we will be using an infrared remote control.\n\n\nGrove - Infrared Emitter Infrared Transmitter Module\n\n\nGrove - Infrared Emitter Infrared Transmitter Module\n\n To explain simply, the principle of infrared transmission and reception is that the infrared transmitter inputs the signal, amplifies it, and sends it through the infrared transmission tube. The infrared receiver then receives this infrared signal, amplifies it and converts it back to an electrical signal, thereby realizing infrared control."
  },
  {
    "objectID": "chapter_3-1.html#task-1-reading-remote-control-key-codes",
    "href": "chapter_3-1.html#task-1-reading-remote-control-key-codes",
    "title": "3.1 Smart Remote Control Door",
    "section": "3.1.2 Task 1: Reading Remote Control Key Codes",
    "text": "3.1.2 Task 1: Reading Remote Control Key Codes\n\nAdding the Arduino-IRremote Library File\nBefore we begin programming the Grove - IR Infrared Receiver with the Arduino IDE, we need to add the necessary library files. Enter the library file address 🔗 https://github.com/Arduino-IRremote/Arduino-IRremote in your browser address bar, go to the GitHub page, and click Code→Download ZIP to download the resource package Arduino-IRremote-master.zip to your local machine, as shown in the image below:\n\n\nAdd the resource package Arduino-IRremote-master.zip you just downloaded through Sketch→Include Library→Add .ZIP Library in the Arduino IDE menu bar until you see a message indicating successful library loading.\n\n\nOpen the Example File \nIf you want to control other devices through the infrared remote control, such as pressing the left key on the mini infrared remote control to rotate the servo to the left, or pressing the right key to rotate the servo to the right, you first need to know what kind of code each key on the remote control will emit. This way, you can set it through the program. But how do you read the codes of different keys on the remote control? You can use the IRremote library and open the IRrecvDemo example via the following path: **File→Examples→IRremote→ReceiveDemo**. This example program can read the key codes of the remote control, but some parameters need to be modified:  **int RECV_PIN = 7**, change the number according to the hardware connection pin. We have connected the infrared receiver to pin 7. Next, we select useful code. We only need to define the header file and the part that reads the remote control key codes. After reducing, the program is as follows:\n#include &lt;Arduino.h&gt;\n#include &lt;IRremote.h&gt;\n\nconst byte IR_RECEIVE_PIN=7; // The infrared receiver is connected to pin 7. If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0\n\nvoid setup() {\n    Serial.begin(115200);\n    Serial.println(F(\"Enabling IRin\"));\n    IrReceiver.begin(IR_RECEIVE_PIN,ENABLE_LED_FEEDBACK); // Start infrared decoding\n    Serial.print(F(\"Ready to receive IR signals at pin \"));\n    Serial.println(IR_RECEIVE_PIN);\n    delay(1000);\n}\n\nvoid loop() {\n    if (IrReceiver.decode()) // Decode successfully, receive a set of infrared signals\n   {\n      Serial.println(IrReceiver.decodedIRData.command, HEX); // Output infrared decoding result (hexadecimal)\n      Serial.println(IrReceiver.decodedIRData.command); // Output infrared decoding result (octal)\n      IrReceiver.resume(); // Receive the next set of values\n   }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L11_IRrecvDemo_en\n\nThe infrared receiver module is connected to the port 7, as shown in the following figure:\n\n\n\n⚠️ Note:  If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0.\n\nAfter the code is uploaded, open the serial monitor, aim the remote control at the black component of the infrared receiver at a close distance, press any key, and observe the characters output by the serial monitor. The hexadecimal code appears in the first line, and the octal code appears in the second line. The two lines form one group, representing one key. Please note that if you press the key for too long, “FFFFFFFF” will appear, and this line of code and the numeric code below are invalid.\n\n\n\n⚠️ Note: Different remote controls may give different values."
  },
  {
    "objectID": "chapter_3-1.html#project-creation-smart-remote-door",
    "href": "chapter_3-1.html#project-creation-smart-remote-door",
    "title": "3.1 Smart Remote Control Door",
    "section": "3.1.3 Project Creation: Smart Remote Door",
    "text": "3.1.3 Project Creation: Smart Remote Door\n\nProject Description\nHow can we recreate a smart remote control door? With a remote control and an infrared receiver, the next step is to control the opening and closing of the door. Recall how the remote control doors in our life work? When the remote control is pressed, the door slowly opens. When it opens to a certain angle, it slowly closes. We can use a servo to control the rotation of the door. When closing the door, the servo rotates from 90° to 0°. When opening the door, the servo rotates from 0° to 90°. By transmitting the signals to open and close the door with a remote control, we can implement the function of a smart remote control door.\n\n\nProgram Writing\nTo control the rotation of the servo with an infrared remote control, you need to follow these steps:\n\nDeclare the IRremote library and Serve library to be called, and define variables.\nInitialize the library files, initialize the servo.\nRead the infrared decoding result and control the rotation of the servo according to the instructions to the left and right.\n\n\n\nTask 2: Control the Rotation of the Servo with an Infrared Remote Control\nStep 1: Declare the IRremote library and Serve library to be called, and define variables.\n#include &lt;IRremote.h&gt;\n#include &lt;Servo.h&gt;\n\nServo myservo; // Create a servo object myservo to control the servo\nint RECV_PIN = 7; // The infrared receiver is connected to pin 7. If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0\nIRrecv irrecv(RECV_PIN); // Define an IRrecv object to receive infrared signals\ndecode_results results; // Decoding results are placed in results\n\nint pos = 90; // Define pos as 90°\nStep 2: Initialize the library files, initialize the servo.\nvoid setup()\n{\n    Serial.begin(9600);\n    Serial.println(\"Enabling IRin\");  \n    irrecv.enableIRIn(); \n    myservo.attach(5); // Connect the servo on pin 5 to myservo. If you are using XIAO RP2040/XIAO ESP32, please change 5 to D5\n}\nStep 3: Read the infrared decoding result and control the rotation of the servo according to the instructions to the left and right. If you have questions about the program, you can refer to the comment section.\n\n⚠️ Note: In the example, the infrared signal value of the right key 16761405, and the infrared signal value of the left key 16712445, need to be replaced by the values obtained from the “Read Remote Control Key Code” example using the remote control in your hand. Otherwise, there will be no response after pressing the key.\n\nvoid loop() {\n    if (irrecv.decode(&results)) {  // If decoding is successful, a set of infrared signals is received\n        if (results.value == 16761405) {  // If the received signal is 16761405 (right key)\n            for (pos; pos &lt;= 89; pos += 1) { // Then the servo is incremented from 0° to 90° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);\n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {  \n                    irrecv.resume();\n                    if (results.value == 16712445)  \n                        break;\n                }\n            }\n        }\n\n        if (results.value == 16712445) {    // If the received signal is 16712445 (left key)\n            for (pos; pos &gt;= 1; pos -= 1) { // Then the servo is decremented from 90° to 0° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);                       \n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {\n                    irrecv.resume();\n                    if (results.value == 16761405)\n                        break;\n                }\n            }\n        }\n        // Display hexadecimal and octal codes in the serial port\n        Serial.println(pos);\n        Serial.println(results.value, HEX);\n        Serial.println(results.value);\n        irrecv.resume();                    \n\n    }\n    delay(100);\n}\nComplete program details:\n#include &lt;IRremote.h&gt;\n#include &lt;Servo.h&gt;\n\nServo myservo; // Create a servo object myservo to control the servo\nint RECV_PIN = 7; // The infrared receiver is connected to pin 7. If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0\nIRrecv irrecv(RECV_PIN); // Define an IRrecv object to receive infrared signals\ndecode_results results; // Decoding results are placed in results\n\nint pos = 90; // Define pos as 90°\n\nvoid setup()\n{\n    Serial.begin(9600);\n    Serial.println(\"Enabling IRin\");  \n    irrecv.enableIRIn(); \n    myservo.attach(5); // Connect the servo on pin 5 to myservo. If you are using XIAO RP2040/XIAO ESP32, please change 5 to D5\n}\n\n// Note: Left 16712445 Right 16761405, please replace with the key values read from your own remote control\nvoid loop() {\n    if (irrecv.decode(&results)) {  // If decoding is successful, a set of infrared signals is received\n        if (results.value == 16761405) {  // If the received signal is 16761405 (right key)\n            for (pos; pos &lt;= 89; pos += 1) { // Then the servo is incremented from 0° to 90° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);\n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {  \n                    irrecv.resume();\n                    if (results.value == 16712445)  \n                        break;\n                }\n            }\n        }\n\n        if (results.value == 16712445) {    // If the received signal is 16712445 (left key)\n            for (pos; pos &gt;= 1; pos -= 1) { // Then the servo is decremented from 90° to 0° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);                       \n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {\n                    irrecv.resume();\n                    if (results.value == 16761405)\n                        break;\n                }\n            }\n        }\n        // Display hexadecimal and octal codes in the serial port\n        Serial.println(pos);\n        Serial.println(results.value, HEX);\n        Serial.println(results.value);\n        irrecv.resume();                    \n\n    }\n    delay(100);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L11_IR_Servo_ino_XIAO_en\n\nStep 4: Connect the hardware and upload the program. First, connect the infrared receiving module to the 7th interface of the XIAO expansion board, and connect the servo to the I2C interface, as shown in the figure below:\n\n\n\n⚠️ Note:  If you are using XIAO RP2040, please connect the infrared receiving module to the A0 interface.\n\nConnect XIAO to the computer with a data cable, click the “Upload” button, upload the program to the hardware, and when the debug area shows “Upload Successful”, open the serial monitor, aim the remote control at the infrared receiver, press the “Left” key and the “Right” key, observe the rotation of the servo, and check the encoding information output by the serial monitor."
  },
  {
    "objectID": "chapter_3-1.html#exterior-design",
    "href": "chapter_3-1.html#exterior-design",
    "title": "3.1 Smart Remote Control Door",
    "section": "3.1.4 Exterior Design",
    "text": "3.1.4 Exterior Design\nIn this unit, we need to implement a more complete project, combining the functions implemented by the program, the modules, and the appearance of the structure to form a prototype. Going back to the smart remote control door project, we need to control the rotation of the servo through the remote control, simulate the opening and closing of the door. When making the appearance, we need to focus on the following issues:\n\nHow to combine the servo and the door panel to make the rotation of the servo drive the rotation of the door panel.\nThe infrared receiver should be exposed in a conspicuous position, without any cover.\nWhether the main control, expansion board, and connecting wires are covered to keep the appearance neat.\nHow to make the work stand steadily.\n\nThe figure below provides an appearance case, which is laser cut from basswood, and provides cutting files for reference. If you can use drawing software, you can process and design it yourself. If you don’t have a laser cutting machine, you can also use corrugated paper, cardstock, non-woven fabric, and other handmade materials to make it, which tests your hands-on ability more.\n\n\nDownload files for use with a laser cutter 🔗  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/dxf/XIAO_ADR.dxf."
  },
  {
    "objectID": "chapter_3-2.html#background-knowledge",
    "href": "chapter_3-2.html#background-knowledge",
    "title": "3.2 Smart Watch",
    "section": "3.2.1 Background Knowledge",
    "text": "3.2.1 Background Knowledge\n\n3.2.1.1 RTC Clock\nRTC stands for Real_Time Clock, which is an integrated circuit used to display time, also called an RTC clock chip. RTCs are widely used, and we can find RTC in almost any electronic device. In the XIAO expansion board, there is an RTC clock chip, as shown in the following figure. We can display the date and time on the OLED display on the expansion board, and it can be powered by a button battery or lithium battery. Even if we disconnect, it can continue to track time. When we reconnect the power supply, we will find that the time is still moving. With the RTC clock, we can make timed reminder devices, such as timed watering, timed pet feeding, and so on.\n\n\nPosition of the RTC clock chip on the XIAO expansion board\n\n\nGrove also has an RTC module: Grove - DS1307 RTC (Real Time Clock) for Arduino, as shown in the figure below.  \n\nGrove RTC Module"
  },
  {
    "objectID": "chapter_3-2.html#task-1-displaying-rtc-clock-in-the-serial-monitor",
    "href": "chapter_3-2.html#task-1-displaying-rtc-clock-in-the-serial-monitor",
    "title": "3.2 Smart Watch",
    "section": "3.2.2 Task 1: Displaying RTC Clock in the Serial Monitor",
    "text": "3.2.2 Task 1: Displaying RTC Clock in the Serial Monitor\n\nAdding PCF8563-Arduino-Library Library\nBefore starting to program the RTC on the XIAO expansion board with Arduino IDE, you need to add the necessary library files. Enter the library file address 🔗 https://github.com/Bill2462/PCF8563-Arduino-Library in the browser address bar, go to the GitHub page, click Code→Download ZIP to download the resource package PCF8563-Arduino-Library-master.zip to the local, as shown in the figure below.\n\n\nAdd the previously downloaded resource package PCF8563-Arduino-Library-master.zip in Sketch→Include Library→Add .ZIP Library in the menu bar until you see the library loading success prompt.\n\n\nOpening the Sample File\nCreating an RTC clock can’t be without the powerful library file. Open the simple example through the following path: File→Examples→PCF8563→simple. This example program can display the RCT clock through the serial monitor. After opening the example program, we only need to modify the current date and start time:\n#include &lt;PCF8563.h&gt; //Declare library file\nPCF8563 pcf;//Define variable pcf\n\nvoid setup() {\n    Serial.begin(9600);\n    pcf.init();//Initialize the clock\n    pcf.stopClock();//Stop the clock\n\n    //Set the current date and time. After setting, it will start timing from this moment\n\n    pcf.setYear(23);//Year\n    pcf.setMonth(05);//Month\n    pcf.setDay(29);//Day\n    pcf.setHour(16);//Hour\n    pcf.setMinut(10);//Minute\n    pcf.setSecond(0);//Second\n\n    pcf.startClock();//Clock starts timing\n}\n\nvoid loop() {\n    Time nowTime = pcf.getTime();//Get time\n\n    //Print the current date and time on the serial monitor\n    Serial.print(nowTime.day);\n    Serial.print(\"/\");\n    Serial.print(nowTime.month);\n    Serial.print(\"/\");\n    Serial.print(\"20\"); // Manually input the set year\n    Serial.print(nowTime.year);\n    Serial.print(\"/\");\n    Serial.print(nowTime.hour);\n    Serial.print(\":\");\n    Serial.print(nowTime.minute);\n    Serial.print(\":\");\n    Serial.println(nowTime.second);\n    delay(1000);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L12_RTC_simple_XIAO_en\n\nWithout connecting other electronic modules, you can click the upload program button. After the code is uploaded, open the serial monitor, and you will be able to see the time."
  },
  {
    "objectID": "chapter_3-2.html#project-making-smart-watch",
    "href": "chapter_3-2.html#project-making-smart-watch",
    "title": "3.2 Smart Watch",
    "section": "3.2.3 Project Making: Smart Watch",
    "text": "3.2.3 Project Making: Smart Watch\n\nProject Description\nIn this section, we are going to make a smart watch that can display the date, time, temperature, and humidity in real time. To display the date and time, we just need XIAO and the expansion board. To display the temperature and humidity, we need to add a temperature and humidity sensor.\n\n\nProgramming\nThe program consists of the following steps:\n\nDeclare the necessary libraries and define variables.\nInitialize the libraries, and set the current time.\nRead temperature and humidity variables, get the current time, and display the temperature, humidity, and date/time on the OLED screen.\n\n\n⚠️ Note\n\nBefore starting to program for the OLED of the XIAO expansion board, make sure that the U8g2_Arduino library has been loaded into the Arduino IDE. The loading method can be referred to the instructions in the “How to Download and Install Arduino Libraries” section of Section 1.1.\nBefore starting to program for the Grove temperature and humidity sensor, make sure that the Arduino IDE has loaded the Grove_Temperature_And_Humidity_Sensor library. The loading method can be referred to the instructions in the “Adding the Grove_Temperature_And_Humidity_Sensor Library” section of Section 2.2.\n\n\n\nTask 2: Display the current time and temperature/humidity values on the OLED display of the XIAO expansion board (based on the DHT20 sensor)\nStep 1: Declare the necessary libraries and define variables.\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt; //use u8x8 library\n#include &lt;PCF8563.h&gt; //RTC library\nPCF8563 pcf; //define variable pcf\n#include &lt;Wire.h&gt;\n#include \"DHT.h\" //DHT library\n#define DHTTYPE DHT20 //The type of the temperature and humidity sensor is DHT20\nDHT dht(DHTTYPE);\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE); //OLED's constructor, set data type, connect OLED display\nStep 2: Initialize the libraries, and set the current time.\nvoid setup() {\n    Serial.begin(9600);\n    u8x8.begin(); //u8x8 starts working\n    u8x8.setFlipMode(1);\n    Wire.begin();\n    pcf.init(); //Initialize the clock\n    pcf.stopClock(); //Stop the clock\n    //Set the current time and date:\n    pcf.setYear(23);\n    pcf.setMonth(05);\n    pcf.setDay(29);\n    pcf.setHour(18);\n    pcf.setMinut(53);\n    pcf.setSecond(0);\n    pcf.startClock(); //The clock starts timing\n}\nStep 3: Read temperature and humidity variables, get the current time, and display the temperature, humidity, and date/time on the OLED screen.\nvoid loop() {\n    float temp, humi; //Define temperature and humidity variables\n    temp = dht.readTemperature(); //Read the temperature value\n    humi = dht.readHumidity(); //Read the humidity value\n    Time nowTime = pcf.getTime(); //Get the time\n    u8x8.setFont(u8x8_font_chroma48medium8_r); //u8x8 font\n\n    //Display the current date, time, temperature, and humidity at different coordinates on the OLED screen.\n    u8x8.setCursor(0, 0);\n    u8x8.print(nowTime.day);\n    u8x8.print(\"/\");\n    u8x8.print(nowTime.month);\n    u8x8.print(\"/\");\n    u8x8.print(\"20\");\n    u8x8.print(nowTime.year);\n    u8x8.setCursor(0, 1);\n    u8x8.print(nowTime.hour);\n    u8x8.print(\":\");\n    u8x8.print(nowTime.minute);\n    u8x8.print(\":\");\n    u8x8.println(nowTime.second);\n    delay(1000);\n    u8x8.setCursor(0, 2);\n    u8x8.print(\"Temp:\");\n    u8x8.print(temp);\n    u8x8.print(\"C\");\n    u8x8.setCursor(0,3);\n    u8x8.print(\"Humidity:\");\n    u8x8.print(humi);\n    u8x8.print(\"%\");\n    u8x8.refreshDisplay();\n    delay(200);\n}\nFor the complete program, please refer to:\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt; //use u8x8 library\n#include &lt;PCF8563.h&gt; //RTC library\nPCF8563 pcf; //define variable pcf\n#include &lt;Wire.h&gt;\n#include \"DHT.h\" //DHT library\n#define DHTTYPE DHT20 //The type of the temperature and humidity sensor is DHT20\nDHT dht(DHTTYPE);\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE); //OLED's constructor, set data type, connect OLED display\n\nvoid setup() {\n    Serial.begin(9600);\n    u8x8.begin(); //u8x8 starts working\n    u8x8.setFlipMode(1);\n    Wire.begin();\n    pcf.init(); //Initialize the clock\n    pcf.stopClock(); //Stop the clock\n    //Set the current time and date:\n    pcf.setYear(23);\n    pcf.setMonth(05);\n    pcf.setDay(29);\n    pcf.setHour(18);\n    pcf.setMinut(53);\n    pcf.setSecond(0);\n    pcf.startClock(); //The clock starts timing\n}\nvoid loop() {\n    float temp, humi; //Define temperature and humidity variables\n    temp = dht.readTemperature(); //Read the temperature value\n    humi = dht.readHumidity(); //Read the humidity value\n    Time nowTime = pcf.getTime(); //Get the time\n    u8x8.setFont(u8x8_font_chroma48medium8_r); //u8x8 font\n\n    //Display the current date, time, temperature, and humidity at different coordinates on the OLED screen.\n    u8x8.setCursor(0, 0);\n    u8x8.print(nowTime.day);\n    u8x8.print(\"/\");\n    u8x8.print(nowTime.month);\n    u8x8.print(\"/\");\n    u8x8.print(\"20\");\n    u8x8.print(nowTime.year);\n    u8x8.setCursor(0, 1);\n    u8x8.print(nowTime.hour);\n    u8x8.print(\":\");\n    u8x8.print(nowTime.minute);\n    u8x8.print(\":\");\n    u8x8.println(nowTime.second);\n    delay(1000);\n    u8x8.setCursor(0, 2);\n    u8x8.print(\"Temp:\");\n    u8x8.print(temp);\n    u8x8.print(\"C\");\n    u8x8.setCursor(0,3);\n    u8x8.print(\"Humidity:\");\n    u8x8.print(humi);\n    u8x8.print(\"%\");\n    u8x8.refreshDisplay();\n    delay(200);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L12_SmartWatch_DHT20_XIAO_en\n\nStep 4: Connect the hardware and upload the program. First, connect the DHT20 temperature and humidity sensor to the I2C interface of the XIAO expansion board, and connect the XIAO to the computer with a data cable, as shown in the picture:\n\n\nClick the “Upload” button in the Arduino IDE to upload the program to the hardware. When the debugging area shows “Upload successful”, observe whether the OLED display correctly outputs the current time and starts timing, as well as the real-time temperature and humidity.\n\n\n\n\nTask 3: Display the current time and temperature and humidity values on the OLED display of the XIAO expansion board (based on the DHT11 sensor)\nIf you are using the Grove DHT11 temperature and humidity sensor with a blue casing, part of the program code needs to be modified as follows:  #define DHTPIN 0, this needs to be modified according to the actual pin number to which the temperature and humidity sensor is connected.  #define DHTTYPE DHT11, since there are different models of temperature and humidity sensors, you need to select the correct model — DHT11. The modified example code is as follows:\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;\n#include &lt;PCF8563.h&gt;\nPCF8563 pcf;\n#include &lt;Wire.h&gt;\n#include \"DHT.h\" \n#define DHTPIN 0  \n#define DHTTYPE DHT11 \nDHT dht(DHTPIN, DHTTYPE);\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);\n//U8X8_SSD1306_128X64_NONAME_SW_I2C u8x8(/* clock=*/ SCL, /* data=*/ SDA, /* reset=*/ U8X8_PIN_NONE);   // OLEDs without Reset of the Display\n \nvoid setup() {\n  Serial.begin(115200);\n  u8x8.begin();\n  u8x8.setFlipMode(1);\n  Wire.begin();\n  pcf.init(); //initialize the clock\n  pcf.stopClock(); //stop the clock\n  pcf.setYear(23); //set year\n  pcf.setMonth(05); //set month\n  pcf.setDay(29); //set date\n  pcf.setHour(18); //set hour\n  pcf.setMinut(53); //set minute\n  pcf.setSecond(0); //set second\n  pcf.startClock(); //start the clock\n}\n \nvoid loop() {\n  float temp, humi;\n  temp = dht.readTemperature();\n  humi = dht.readHumidity();\n  Time nowTime = pcf.getTime(); //get current time\n  u8x8.setFont(u8x8_font_chroma48medium8_r);   // choose a suitable font\n \n  u8x8.setCursor(0, 0);\n  u8x8.print(nowTime.day);\n  u8x8.print(\"/\");\n  u8x8.print(nowTime.month);\n  u8x8.print(\"/\");\n  u8x8.print(\"20\");\n  u8x8.print(nowTime.year);\n  u8x8.setCursor(0, 1);\n  u8x8.print(nowTime.hour);\n  u8x8.print(\":\");\n  u8x8.print(nowTime.minute);\n  u8x8.print(\":\");\n  u8x8.println(nowTime.second);\n  delay(1000);\n  u8x8.setCursor(0, 2);\n  u8x8.print(\"Temp:\");\n  u8x8.print(temp);\n  u8x8.print(\"C\");\n  u8x8.setCursor(0,3);\n  u8x8.print(\"Humidity:\");\n  u8x8.print(humi);\n  u8x8.print(\"%\");\n  u8x8.refreshDisplay();\n  delay(200);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L12_SmartWatch_DHT11_XIAO_en\n\n\nAfter modifying the code, first connect the DHT11 temperature and humidity sensor to the A0 interface of the XIAO expansion board, as shown in the image below.\n\n\nThen connect the XIAO development board to your computer, upload the modified sample program to the XIAO via Arduino IDE, and you should be able to see the time, temperature, and humidity readings on the OLED of the XIAO expansion board. You can place the temperature and humidity sensor in different environments to observe changes in temperature and humidity readings."
  },
  {
    "objectID": "chapter_3-2.html#exterior-design",
    "href": "chapter_3-2.html#exterior-design",
    "title": "3.2 Smart Watch",
    "section": "3.2.4 Exterior Design",
    "text": "3.2.4 Exterior Design\nGiven its compact size, XIAO is especially suitable for creating wearable devices. The expansion board incorporates an RTC chip, a buzzer, and an OLED display screen, which means you can create a variety of applications even without adding other modules. In this section, we have made a smart watch using the on-board OLED display, RTC chip, and an external temperature and humidity sensor. When creating the appearance, we only need to consider wearability, organization of modules and connecting wires, and the exposure of the OLED display screen. As shown below, we provide a wearable watch style and the laser cutting files for it. With just a simple installation, your wearable device is ready.\n\n\nDownload files for laser cutting machine 🔗  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/dxf/XIAO_X_watch.dxf."
  },
  {
    "objectID": "chapter_3-3.html#background-knowledge",
    "href": "chapter_3-3.html#background-knowledge",
    "title": "3.3 Air Piano",
    "section": "3.3.1 Background Knowledge",
    "text": "3.3.1 Background Knowledge\n\n3.3.1.1 Grove Ultrasonic Distance Sensor\n\n\n\n\nThe Grove Ultrasonic Distance Sensor is a non-contact distance measurement module. Thanks to its strong directivity, the ultrasonic waves it emits can travel long distances in a medium. The calculations are simple and it is easy to control, so it’s often used for distance measurements. When the ultrasonic distance sensor works, the transmitter emits ultrasonic waves in a certain direction. When the waves hit an obstacle, they reflect back. The ultrasonic receiver stops timing as soon as it receives the reflected waves. The actual distance from the emission point to the obstacle is calculated based on the time difference between emission and reception, much like bat echolocation. The application range of ultrasonic waves is becoming broader, commonly seen in reverse radar systems, intelligent guidance systems, robot obstacle avoidance systems, medical ultrasound examinations, and more.\n\n⚠️ Note  The Grove Ultrasonic Distance Sensor module is not included in the Seeed Studio XIAO Starter Kit!"
  },
  {
    "objectID": "chapter_3-3.html#task-1-reading-the-grove-ultrasonic-distance-sensor-value",
    "href": "chapter_3-3.html#task-1-reading-the-grove-ultrasonic-distance-sensor-value",
    "title": "3.3 Air Piano",
    "section": "3.3.2 Task 1: Reading the Grove Ultrasonic Distance Sensor Value",
    "text": "3.3.2 Task 1: Reading the Grove Ultrasonic Distance Sensor Value\n\nAdding the Seeed_Arduino_UltrasonicRanger Library\nBefore starting to program the Grove Ultrasonic Distance Sensor with Arduino IDE, it’s necessary to add the essential library for the sensor. Type the library address 🔗 https://github.com/Seeed-Studio/Seeed_Arduino_UltrasonicRanger into the browser address bar, enter the GitHub page, click Code→Download ZIP to download the resource package Seeed_Arduino_UltrasonicRanger-master.zip to your local drive, as shown below.\n\n\nAdd the downloaded resource package Seeed_Arduino_UltrasonicRanger-master.zip to the Sketch→Include Library→Add .ZIP Library from the menu bar until you see a successful library loading prompt.\n\n\nOpening the Example File\nAfter successfully installing the library, a new item Grove Ultrasonic Ranger will be added to the Arduino’s File→Examples list. Open the UltrasonicDisplayOnTerm sample program from it. This program can display the value of the ultrasonic distance sensor on the Serial Monitor. Modify Ultrasonic ultrasonic(7); in the sample program to Ultrasonic ultrasonic(0); (the ultrasonic distance sensor will be connected to the A0 port of the XIAO expansion board).\n\n\nOpen the modified sample file through the following path, 🔗  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L13_UltrasonicDisplayOnTerm_XIAO_en.\n#include \"Ultrasonic.h\"//declare the library file\nUltrasonic ultrasonic(0);//define variables, connect pins. If you're using XIAO RP2040/XIAO ESP32, please change 0 to D0\nvoid setup() {\n    Serial.begin(9600);\n}\nvoid loop() {\n    long RangeInInches;//define a long integer variable named RangeInInches\n    long RangeInCentimeters;//define a long integer variable named RangeInCentimeters\n\n    Serial.println(\"The distance to obstacles in front is: \");\n    RangeInInches = ultrasonic.MeasureInInches();//read the distance value (inches) measured by the ultrasonic distance sensor and store it in the variable RangeInInches\n    Serial.print(RangeInInches);//serial print value\n    Serial.println(\" inch\");\n    delay(250);\n\n    RangeInCentimeters = ultrasonic.MeasureInCentimeters(); //read the distance value (centimeters) measured by the ultrasonic distance sensor and store it in the variable RangeInCentimeters\n    Serial.print(RangeInCentimeters);//serial print value\n    Serial.println(\" cm\");\n    delay(250);\n}\nThe ultrasonic distance sensor is connected to the A0 interface, as shown in the figure below:\n\n\nAfter uploading the code, open the Serial Monitor. Place your hand or a card at any position in front of the ultrasonic distance sensor and observe the change in the values output by the Serial Monitor."
  },
  {
    "objectID": "chapter_3-3.html#project-production-ultrasonic-air-harp",
    "href": "chapter_3-3.html#project-production-ultrasonic-air-harp",
    "title": "3.3 Air Piano",
    "section": "3.3.3 Project Production: Ultrasonic Air Harp",
    "text": "3.3.3 Project Production: Ultrasonic Air Harp\n\nProject Description\nThe working principle of the air harp is to measure the distance from the module to the palm of your hand through the ultrasonic distance sensor. Depending on the distance, the buzzer emits different musical notes. We have already learned how to measure distance and read values through the ultrasonic distance sensor with the sample program. Next, we just need to define different musical notes for the corresponding distances. As shown in the figure below: According to the width of the palm, one musical note corresponds to a unit of 2cm, and the performance starts from 4cm. “Do, Re, Mi, Fa, Sol, La, Xi, Do” respectively correspond to 4cm, 6cm, 8cm, 10cm, 12cm, 14cm, 16cm, 18cm… and so on.\n\n\n\n\nWriting the Program\nThe implementation of the air harp program requires the following steps:\n\nDeclare the library file, define different notes and buzzer pins.\nInitialization, setting the status of the buzzer pin.\nRead the distance (cm) measured by the ultrasonic distance sensor, and make a condition judgment to set different distances to emit different notes.\n\n\nUsing the tone() Function to Play Melody\n When we want to control the buzzer to play notes or songs through the program, we need to set the frequency value of each note ourselves. If a song has many notes, it’s too troublesome to adjust one by one, and it tests our music theory knowledge and pitch. Is there a simpler method? Of course! When defining notes, we can refer to the tone() function written on the Arduino website 🔗 https://www.arduino.cc/en/Tutorial/BuiltInExamples/toneMelody, this function defines the corresponding frequency of different notes through pitches.h, which is convenient for us to use the tone() function to set the notes emitted by the buzzer. The code of pitches.h is shown below:\n\n/*\n* pitches.h\n*/\n\n#define NOTE_B0  31\n#define NOTE_C1  33\n#define NOTE_CS1 35\n#define NOTE_D1  37\n#define NOTE_DS1 39\n#define NOTE_E1  41\n#define NOTE_F1  44\n#define NOTE_FS1 46\n#define NOTE_G1  49\n#define NOTE_GS1 52\n#define NOTE_A1  55\n#define NOTE_AS1 58\n#define NOTE_B1  62\n#define NOTE_C2  65\n#define NOTE_CS2 69\n#define NOTE_D2  73\n#define NOTE_DS2 78\n#define NOTE_E2  82\n#define NOTE_F2  87\n#define NOTE_FS2 93\n#define NOTE_G2  98\n#define NOTE_GS2 104\n#define NOTE_A2  110\n#define NOTE_AS2 117\n#define NOTE_B2  123\n#define NOTE_C3  131\n#define NOTE_CS3 139\n#define NOTE_D3  147\n#define NOTE_DS3 156\n#define NOTE_E3  165\n#define NOTE_F3  175\n#define NOTE_FS3 185\n#define NOTE_G3  196\n#define NOTE_GS3 208\n#define NOTE_A3  220\n#define NOTE_AS3 233\n#define NOTE_B3  247\n#define NOTE_C4  262\n#define NOTE_CS4 277\n#define NOTE_D4  294\n#define NOTE_DS4 311\n#define NOTE_E4  330\n#define NOTE_F4  349\n#define NOTE_FS4 370\n#define NOTE_G4  392\n#define NOTE_GS4 415\n#define NOTE_A4  440\n#define NOTE_AS4 466\n#define NOTE_B4  494\n#define NOTE_C5  523\n#define NOTE_CS5 554\n#define NOTE_D5  587\n#define NOTE_DS5 622\n#define NOTE_E5  659\n#define NOTE_F5  698\n#define NOTE_FS5 740\n#define NOTE_G5  784\n#define NOTE_GS5 831\n#define NOTE_A5  880\n#define NOTE_AS5 932\n#define NOTE_B5  988\n#define NOTE_C6  1047\n#define NOTE_CS6 1109\n#define NOTE_D6  1175\n#define NOTE_DS6 1245\n#define NOTE_E6  1319\n#define NOTE_F6  1397\n#define NOTE_FS6 1480\n#define NOTE_G6  1568\n#define NOTE_GS6 1661\n#define NOTE_A6  1760\n#define NOTE_AS6 1865\n#define NOTE_B6  1976\n#define NOTE_C7  2093\n#define NOTE_CS7 2217\n#define NOTE_D7  2349\n#define NOTE_DS7 2489\n#define NOTE_E7  2637\n#define NOTE_F7  2794\n#define NOTE_FS7 2960\n#define NOTE_G7  3136\n#define NOTE_GS7 3322\n#define NOTE_A7  3520\n#define NOTE_AS7 3729\n#define NOTE_B7  3951\n#define NOTE_C8  4186\n#define NOTE_CS8 4435\n#define NOTE_D8  4699\n#define NOTE_DS8 4978\n\n\nTask 2: Ultrasonic Air Harp\nStep 1: Declare the library file, define different notes and buzzer pins. The main notes we use are “Do Re Mi Fa Sol La Xi Do”, corresponding to “C5 D5 E5 F5 G5 A5 B5 C6”. You can only define the notes you need to avoid the program looking too lengthy.\n#include \"Ultrasonic.h\"//declare the library file\nUltrasonic ultrasonic(0);//define the ultrasonic object and connect the ultrasonic wave to the A0 interface. If you're using XIAO RP2040, please change 0 to D0\nint buzzerPin = 3;//The buzzer is connected to the A3 interface, if you're using XIAO RP2040, please change 3 to A3\n\n#define NOTE_C5  523\n#define NOTE_CS5 554\n#define NOTE_D5  587\n#define NOTE_DS5 622\n#define NOTE_E5  659\n#define NOTE_F5  698\n#define NOTE_FS5 740\n#define NOTE_G5  784\n#define NOTE_GS5 831\n#define NOTE_A5  880\n#define NOTE_AS5 932\n#define NOTE_B5  988\n#define NOTE_C6  1047\nStep 2: Initialize the baud rate and set the buzzer pin status.\nvoid setup()\n{\n    Serial.begin(9600);\n    pinMode(buzzerPin,OUTPUT);\n}\nStep 3: Read the distance (cm) measured by the ultrasonic distance sensor and make a condition judgment to set different distances to emit different notes. Since the setting of the air harp is that different distances trigger different notes, and this distance is a long integer value, so we need to use the long() function to define the value returned by the ultrasonic wave. For example, (long)RangeInCentimeters== 4, that is, the distance value returned by the ultrasonic wave is 4. Corresponding to the buzzer emitting different notes, use the tone() function, for example, tone(3,NOTE_C5,100), that is, the buzzer on pin 3, emits NOTE_C5 (Do) note, lasts for 100 milliseconds.\nvoid loop()\n{\n    // Read the distance value detected by the ultrasonic distance sensor, in centimeters, and print it on the serial monitor\n    long RangeInCentimeters;\n    RangeInCentimeters = ultrasonic.MeasureInCentimeters(); \n    Serial.print(RangeInCentimeters);\n    Serial.println(\" cm\");\n    delay(250);\n    // Using an if statement for conditional judgment, when the distance is 4, 6, 8, 10, 12, 14, 16, 18, it corresponds to C5, D5, E5, F5, G5, A5, B5, C6\n    if (((long)RangeInCentimeters== 4)) {  //Do\n        tone(3,NOTE_C5,100);   \n    }\n    if (((long) RangeInCentimeters== 6)) { //Re\n        tone(3,NOTE_D5,100);    \n    }\n    if (((long) RangeInCentimeters== 8)) { //Mi\n        tone(3,NOTE_E5,100);  \n    }\n    if (((long) RangeInCentimeters== 10)) {  //Fa\n        tone(3,NOTE_F5,100);\n    }\n    if (((long) RangeInCentimeters== 12)) {  //Sol\n        tone(3,NOTE_G5,100);\n    }\n    if (((long) RangeInCentimeters== 14)) {  //La\n        tone(3,NOTE_A5,100);\n    }\n    if (((long) RangeInCentimeters== 16)) { //Xi\n        tone(3,NOTE_B5,100);\n    }\n    if (((long) RangeInCentimeters== 18)) {  //Do\n        tone(3,NOTE_C6,100);\n    }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L13_UltrasonicPiano_XIAO_en\n\nStep 4: Connect the hardware and upload the program. Connect the ultrasonic distance sensor to the A0 interface of the XIAO expansion board as shown below:\n\n\nUse the data cable to connect XIAO to the computer, click the “Upload” button, upload the program to the hardware, when the debugging area shows “Upload Successful”, open the serial monitor, and start playing with your palm."
  },
  {
    "objectID": "chapter_3-3.html#exterior-design",
    "href": "chapter_3-3.html#exterior-design",
    "title": "3.3 Air Piano",
    "section": "3.3.4 Exterior Design",
    "text": "3.3.4 Exterior Design\nThe inspiration for the air harp comes from the piano, with a note every 2 cm also designed according to the style of the piano keys. In the process of creating the appearance, we can cut a harp surface from a basswood board, and fix the ultrasonic range sensor at the left end of the harp. We also provide laser cutting files for reference, which can be easily assembled, as shown in the picture:\n\n\nDownload the files suitable for the laser cutting machine 🔗  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/dxf/XIAO_Air_Piano.dxf."
  },
  {
    "objectID": "chapter_3-4.html#background-knowledge",
    "href": "chapter_3-4.html#background-knowledge",
    "title": "3.4 Implementing Wi-Fi Connection and Applications with XIAO ESP32C3",
    "section": "3.4.1 Background Knowledge",
    "text": "3.4.1 Background Knowledge\n\n3.4.1.1 OSI Reference Model (Network Seven-Layer Model)\nOSI (Open System Interconnect) is commonly known as the OSI reference model or network seven-layer structure, which is the network interconnect model researched by the ISO organization in 1985. This architectural standard defines the seven-layer framework (physical layer, data link layer, network layer, transport layer, session layer, presentation layer, and application layer) for network interconnection. For ease of understanding, the following diagram uses a logistics transportation process to correspond to each layer of the OSI model.\n\n\nThe following knowledge will use the concepts of these layers.\n\n\n3.4.1.2 ICMP (Internet Control Message Protocol) and ping Command\nICMP (Internet Control Message Protocol) is a sub-protocol of the TCP/IP protocol suite. It is used to transmit control messages between IP hosts and routers. Control messages refer to messages about the network itself, such as whether the network is available, whether the host is reachable, whether the route is available, etc. Although these control messages do not transmit user data, they play an important role in the transmission of user data.\n\n🎓 Learn more: visit the Wikipedia entry on ICMP.\n\nWe often use the ICMP protocol in the network, such as the Ping command (available in both Linux and Windows) we often use to check whether the network is available. This Ping process is actually the working process of the ICMP protocol. ping can test the connection speed between two devices and accurately report the time it takes for a packet to reach its destination and return to the sender’s device. Although ping does not provide data about routing or hops, it is still a useful metric for measuring latency between two devices. Below we will learn how to implement ping requests on XIAO ESP32C3.  Before starting this attempt, we need to learn how to connect XIAO ESP32C3 with your Wi-Fi."
  },
  {
    "objectID": "chapter_3-4.html#task-1-using-wi-fi-network-on-xiao-esp32c3",
    "href": "chapter_3-4.html#task-1-using-wi-fi-network-on-xiao-esp32c3",
    "title": "3.4 Implementing Wi-Fi Connection and Applications with XIAO ESP32C3",
    "section": "3.4.2 Task 1: Using Wi-Fi Network on XIAO ESP32C3",
    "text": "3.4.2 Task 1: Using Wi-Fi Network on XIAO ESP32C3\nXIAO ESP32C3 supports Wi-Fi connections with IEEE 802.11b/g/n. The following will introduce the basic knowledge of using Wi-Fi on this board.\n\n⚠️ Note: Be careful when attempting to use the XIAO ESP32C3 development board as a hotspot (access point). Overheating issues may occur and lead to burns.\n\n\nHardware Setup: Connect an Antenna to the XIAO ESP32C3 and Connect it to Your Computer\nStep 1. Connect the provided Wi-Fi/Bluetooth antenna to the IPEX connector on the development board.\n\n\n\n\n\nStep 2. Connect the XIAO ESP32C3 to your computer via a USB Type-C data cable.\n\n\n\n\nSoftware Setup: Add the ESP32 Board Package to the Arduino IDE \nStep 1. Open the Arduino IDE preferences to add the Board Manager URL.\n\nFor Windows users, first open your Arduino IDE, click on “File→Preferences” in the top menu bar, and copy the following URL into “Additional Board Manager URLs”.\nFor Mac users, first open your Arduino IDE, click on “Arduino IDE→Preferences” in the top menu bar, and copy the following URL into “Additional Board Manager URLs”.\n\nFor Seeed Studio XIAO ESP32C3, copy the link below:  https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_dev_index.json  to the Board Manager URL bar and confirm, as shown in the figure below.\n\n\nStep 2. In the Arduino IDE menu, click “Tools→Board→Board Manager”, type “esp32” into the search bar, find the latest version of ESP32 Arduino in the resulting entries, and click “Install”. When the installation starts, you will see an output pop-up. Once the installation is complete, the “Installed” option will appear.\nStep 3. Select the Board.\nNavigate to “Tools &gt; Board &gt; ESP32 Arduino” and select “XIAO_ESP32C3”. The list will be a bit long, and you will need to scroll down to find it, as shown in the figure below.\n\n\nStep 4. Add Port.\nCheck if the port connection is correct in the Arudino IDE. If not, you need to manually select.\n\nFor Windows systems, the serial port is displayed as “COM+number”, as shown in the figure below.\n\n\n\n\nOn Mac or Linux systems, the port name is typically /dev/tty.usbmodem+number or /dev/cu.usbmodem+number, as shown in the figure below.\n\n\n\n\n\nScanning Nearby Wi-Fi Networks (STA Mode) \nIn this example, we will use the XIAO ESP32C3 to scan for available Wi-Fi networks in the area. The development board in this example will be configured in STA mode.\nStep 1. Copy and paste the code below into the Arduino IDE.\n#include \"WiFi.h\"\n \nvoid setup()\n{\n    Serial.begin(115200);\n \n    // Set WiFi to station mode and disconnect from an AP if it was previously connected\n    WiFi.mode(WIFI_STA);\n    WiFi.disconnect();\n    delay(100);\n \n    Serial.println(\"Setup done\");\n}\n \nvoid loop()\n{\n    Serial.println(\"scan start\");\n \n    // WiFi.scanNetworks will return the number of networks found\n    int n = WiFi.scanNetworks();\n    Serial.println(\"scan done\");\n    if (n == 0) {\n        Serial.println(\"no networks found\");\n    } else {\n        Serial.print(n);\n        Serial.println(\" networks found\");\n        for (int i = 0; i &lt; n; ++i) {\n            // Print SSID and RSSI for each network found\n            Serial.print(i + 1);\n            Serial.print(\": \");\n            Serial.print(WiFi.SSID(i));\n            Serial.print(\" (\");\n            Serial.print(WiFi.RSSI(i));\n            Serial.print(\")\");\n            Serial.println((WiFi.encryptionType(i) == WIFI_AUTH_OPEN)?\" \":\"*\");\n            delay(10);\n        }\n    }\n    Serial.println(\"\");\n \n    // Wait a bit before scanning again\n    delay(5000);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_Scanwifi_XIAO_en\n\nStep 2. Upload the code and open the serial monitor to start scanning for Wi-Fi networks, as shown in the figure below.\n\n\n\n\nConnecting to a Wi-Fi Network\nIn this example, we will use the XIAO ESP32C3 to connect to your Wi-Fi network.\nStep 1. Copy and paste the code below into the Arduino IDE.\n#include &lt;WiFi.h&gt;\n \nconst char* ssid     = \"your-ssid\";\nconst char* password = \"your-password\";   \n \nvoid setup()\n{\n    Serial.begin(115200);\n    delay(10);\n \n    // We start by connecting to a WiFi network\n \n    Serial.println();\n    Serial.println();\n    Serial.print(\"Connecting to \");\n    Serial.println(ssid);\n \n    WiFi.begin(ssid, password);\n \n    while (WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n \n    Serial.println(\"\");\n    Serial.println(\"WiFi connected\");\n    Serial.println(\"IP address: \");\n    Serial.println(WiFi.localIP());\n}  \nvoid loop()\n{\n  }\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_Connectwifi_XIAO_en\n\nThen, replace your-ssid in the code with the name of your Wi-Fi network, and replace your-password in the code with the password for your Wi-Fi network.\nStep 2. Upload the code and open the serial monitor to check whether the development board is connected to the Wi-Fi network, as shown in the figure below.\n\n\n\n🎓 Learn more: You can read the Wiki documentation for more about using the XIAO ESP32C3."
  },
  {
    "objectID": "chapter_3-4.html#task-2-ping-a-specified-website",
    "href": "chapter_3-4.html#task-2-ping-a-specified-website",
    "title": "3.4 Implementing Wi-Fi Connection and Applications with XIAO ESP32C3",
    "section": "3.4.3 Task 2: Ping a Specified Website",
    "text": "3.4.3 Task 2: Ping a Specified Website\nWith the knowledge above, we can now learn how to use the XIAO ESP32C3 to ping a specified website.\nStep 1. Download and install the ESP32Ping library. Enter the URL 🔗 https://github.com/marian-craciunescu/ESP32Ping to go to the GitHub page, click on Code→Download ZIP to download the resource pack to your local machine, as shown in the figure below.\n\n\nAfter downloading, open the Arduino IDE, click on Sketch→Include Library→Add .ZIP Library, and choose the ZIP file you just downloaded.\n\n\nStep 2. Copy and paste the code below into the Arduino IDE. This code sets the test website to www.seeedstudio.com. Remember to replace your-ssid in the code with your Wi-Fi network name and your-password in the code with your Wi-Fi password.\n////////////////////////////////////////////////////////////////////////////////\n// IDE:\n//   Arduino 2.0.3\n// Platform:\n//   esp32 2.0.4 - https://github.com/espressif/arduino-esp32\n// Board:\n//   XIAO_ESP32C3\n// Libraries:\n//   ESP32Ping 1.6 - https://github.com/marian-craciunescu/ESP32Ping\n\n////////////////////////////////////////////////////////////////////////////////\n// Includes\n\n#include &lt;WiFi.h&gt;\n#include &lt;ESP32Ping.h&gt;\n\nstatic constexpr unsigned long INTERVAL = 3000; // [msec.]\n\nstatic const char WIFI_SSID[] = \"your-ssid\";\nstatic const char WIFI_PASSPHRASE[] = \"your-password\";\n\nstatic const char SERVER[] = \"www.google.com\";\n\nvoid setup()\n{\n    Serial.begin(115200);\n    delay(1000);\n    Serial.println();\n    Serial.println();\n\n    Serial.println(\"WIFI: Start.\");\n    WiFi.mode(WIFI_STA);\n    if (WIFI_SSID[0] != '\\0')\n    {\n        WiFi.begin(WIFI_SSID, WIFI_PASSPHRASE);\n    }\n    else\n    {\n        WiFi.begin();\n    }\n}\n\nvoid loop()\n{\n    static int count = 0;\n\n    const bool wifiStatus = WiFi.status() == WL_CONNECTED;\n    const int wifiRssi = WiFi.RSSI();\n\n    const bool pingResult = !wifiStatus ? false : Ping.ping(SERVER, 1);\n    const float pingTime = !pingResult ? 0.f : Ping.averageTime();\n\n    Serial.print(count);\n    Serial.print('\\t');\n    Serial.print(wifiStatus ? 1 : 0);\n    Serial.print('\\t');\n    Serial.print(wifiRssi);\n    Serial.print('\\t');\n    Serial.print(pingResult ? 1 : 0);\n    Serial.print('\\t');\n    Serial.println(pingTime);\n    count++;\n\n    delay(INTERVAL);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_Ping_XIAO_en\n\nStep 3. Upload the code and open the serial monitor to check the ping results, as shown in the figure below."
  },
  {
    "objectID": "chapter_3-4.html#project-creation-using-xiao-esp32c3-to-make-http-get-and-http-post-requests",
    "href": "chapter_3-4.html#project-creation-using-xiao-esp32c3-to-make-http-get-and-http-post-requests",
    "title": "3.4 Implementing Wi-Fi Connection and Applications with XIAO ESP32C3",
    "section": "3.4.4 Project Creation: Using XIAO ESP32C3 to Make HTTP GET and HTTP POST Requests",
    "text": "3.4.4 Project Creation: Using XIAO ESP32C3 to Make HTTP GET and HTTP POST Requests\n\n3.4.4.1 Introduction to HTTP Protocol\nHTTP stands for HyperText Transfer Protocol. It’s an application-layer protocol for distributed, collaborative, and hypermedia information systems. HTTP is the most widely used network transmission protocol on the Internet, and all WWW files must comply with this standard.  HTTP is designed for communication between Web browsers and Web servers, but it can also be used for other purposes. HTTP is a protocol that uses TCP/IP to transmit data (such as HTML files, image files, query results, etc.).  Despite its wide use, HTTP has significant security flaws, mainly its plain text data transmission and lack of message integrity checks. These are exactly the two most critical security aspects in emerging applications like online payment, online trading, Internet of Things, etc. Browsers like Google Chrome, Internet Explorer, and Firefox issue warnings about insecure connections when visiting websites with mixed content composed of encrypted and unencrypted content using HTTP.\n\n\n3.4.4.2 Introduction to HTTPS Protocol\nHTTPS stands for HyperText Transfer Protocol Secure. It’s a protocol for secure communication over a computer network. HTTPS communicates via HTTP but uses SSL/TLS to encrypt packets. The main purpose of HTTPS is to authenticate the website server’s identity and protect the privacy and integrity of the exchanged data.\n\n\n\n\n3.4.4.3 HTTP Request Methods\nAccording to the HTTP standard, HTTP requests can use multiple request methods.  HTTP1.0 defined three request methods: GET, POST, and HEAD.  HTTP1.1 added six new request methods: OPTIONS, PUT, PATCH, DELETE, TRACE, and CONNECT.\n\n\n\n\n\n\n\n\nNo.\nMethod\nDescription\n\n\n\n\n1\nGET\nRequests specified page information and returns the entity body.\n\n\n2\nHEAD\nSimilar to a GET request, but the response returned doesn’t contain specific content, used to obtain headers.\n\n\n3\nPOST\nSubmits data for processing to a specified resource (e.g., submits a form or uploads a file). The data is included in the request body. POST requests may result in the creation of a new resource and/or the modification of an existing resource.\n\n\n4\nPUT\nThe data sent from the client to the server replaces the content of a specified document.\n\n\n5\nDELETE\nRequests the server to delete a specified page.\n\n\n6\nCONNECT\nReserved in HTTP/1.1 for proxy servers that can switch the connection to a pipe mode.\n\n\n7\nOPTIONS\nAllows the client to view the server’s capabilities.\n\n\n8\nTRACE\nEchoes the request received by the server, mainly used for testing or diagnosis.\n\n\n9\nPATCH\nIt’s a supplement to the PUT method, used to partially update a known resource.\n\n\n\nWe’ve already learned how to connect to a Wi-Fi network using XIAO ESP32C3. Now, let’s try some more complex operations based on the network. The following sections will introduce how to use XIAO ESP32C3 to send HTTP GET and HTTP POST requests.\n\n\n3.4.4.4 Task 3: Using XIAO ESP32C3 to Send an HTTP GET Request\nTo send an HTTP GET request, a corresponding backend server that supports the request is required. For convenient testing, we can set up a backend server on our own PC, allowing XIAO ESP32C3 to send an HTTP GET request to the PC through the local Wi-Fi connection.\nThere are many ways to set up a backend service. In this case, we’ll use the popular Python web framework — FastAPI to set up the backend server. To learn more about this tool, visit its official documentation.\n\nSetting Up a Backend Server with FastAPI \nHere is the Python server code.\nfrom typing import Union\nfrom pydantic import BaseModel\nfrom fastapi import FastAPI\nimport datetime\n\napp = FastAPI()\nitems = {}\n\nclass Sensor_Item(BaseModel):\n    name: str\n    value: float\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    items[\"sensor\"] = {\"name\": \"Sensor\",\"Value\":0}\n\n@app.get(\"/items/{item_id}\")\nasync def read_items(item_id: str):\n\n    return items[item_id],datetime.datetime.now()\n\n@app.post(\"/sensor/\")\nasync def update_sensor(si: Sensor_Item):\n    items[\"sensor\"][\"Value\"] = si.value\n    return si\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\nThis code snippet, implemented using the Python FastAPI framework, can return the latest information of the Sensor stored on the backend server when we use a get request on http://domain/items/sensor. When we use post to send data to http://domain/sensor/, it can modify and record the latest Sensor value. The operation steps are as follows:\nStep 1. Create a python file named main.py locally, copy and paste the code above into main.py. Then, on your PC, open the terminal and execute the following commands to install FastAPI.\n\npip install fastapi\npip install \"uvicorn[standard]\"\nStep 2. Execute the following command to start the backend service and local monitoring.\nuvicorn main:app --reload --host 0.0.0.0\n\n⚠️ Note:  When running the command above, make sure the terminal is currently in the directory where main:app resides. If there is a prompt during running:\n\nERROR:    [Errno 48] Address already in use\n\nThis means the current address is already occupied and there is an address conflict. You can specify a specific port as shown in the command below.\n\nuvicorn main:app --reload --host 0.0.0.0 --port 1234\n\nIf the [Errno 48] error still appears, you can modify the port number after port.\n\nThe prompt information after the command is successfully run is as follows\nINFO:     Will watch for changes in these directories: ['']\nINFO:     Uvicorn running on http://0.0.0.0:1234 (Press CTRL+C to quit)\nINFO:     Started reloader process [53850] using WatchFiles\nINFO:     Started server process [53852]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nThe backend server for testing is now running normally.\n\n\nUsing XIAO ESP32C3 to Send an HTTP GET Request \nNext, we’ll perform a request test on XIAO ESP32C3.  The GET method should only be used for reading data, and should not be used in operations that generate “side effects”. GET requests directly issued by browsers can only be triggered by a URL. If you want to carry some parameters outside of the URL in GET, you can only rely on the querystring (query string) attached to the URL.\nStep 1: Copy and paste the following code into the Arduino IDE. This code sets the tested serverName to http://192.168.1.2/items/sensor. The 192.168.1.2 needs to be replaced with the IP address of your PC acting as the backend server. To get the IP address of your PC, Windows users can enter the ipconfig command in the command line window, and Mac users can enter the ifconfig command in the terminal window. Remember to change your-ssid in the code to your Wi-Fi network name and your-password to the corresponding Wi-Fi password.\n#include \"WiFi.h\"\n#include &lt;HTTPClient.h&gt;\n\nconst char* ssid = \"your-ssid\";\nconst char* password = \"your-password\";\nString serverName = \"http://192.168.1.2/items/sensor\";\nunsigned long lastTime = 0;\nunsigned long timerDelay = 5000;\n\nvoid setup()\n{\n    Serial.begin(115200); \n\n    WiFi.begin(ssid, password);\n    Serial.println(\"Connecting\");\n    while(WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\");\n    Serial.print(\"Connected to WiFi network with IP Address: \");\n    Serial.println(WiFi.localIP());\n\n    Serial.println(\"Timer set to 5 seconds (timerDelay variable), it will take 5 seconds before publishing the first reading.\");\n\n    Serial.println(\"Setup done\");\n}\n\nvoid loop()\n{\n    if ((millis() - lastTime) &gt; timerDelay) {\n        //Check WiFi connection status\n        if(WiFi.status()== WL_CONNECTED){\n            HTTPClient http;\n\n            String serverPath = serverName ;\n\n            http.begin(serverPath.c_str());\n\n            int httpResponseCode = http.GET();\n\n            if (httpResponseCode&gt;0) {\n                Serial.print(\"HTTP Response code: \");\n                Serial.println(httpResponseCode);\n                String payload = http.getString();\n                Serial.println(payload);\n            }\n            else {\n                Serial.print(\"Error code: \");\n                Serial.println(httpResponseCode);\n            }\n\n            http.end();\n        }\n        else {\n            Serial.println(\"WiFi Disconnected\");\n        }\n        lastTime = millis();\n    }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_HTTPget_XIAO_en\n\n\n⚠️ Note:  We need to change the serverName in the Arduino code to the IP address of the host running the backend service. The XIAO ESP32C3 needs to be on the same local area network as it. If the local area network IP of the backend server (in this example, your PC) is 192.168.1.2, then the GET request interface is http://192.168.1.2/items/sensor, and other interfaces are similar. If you specified a port when running the backend service and local monitoring, the GET request interface would be http://192.168.1.2:1234/items/sensor.\n\nStep 2: Upload the code to XIAO ESP32C3 in the Arduino IDE. After the upload is successful, open the serial monitor to check the result returned by our backend server after the GET is issued, as shown in the figure below.\n\n\nThe prompt HTTP Response code: 200 means the request has been successful, and our XIAO ESP32C3 has successfully gotten data from the server.\n\n\n\n3.4.4.5 Task 4: Using XIAO ESP32C3 to Send an HTTP POST Request\nSubmit data to a specified resource and request the server to process it (for example, submit a form or upload a file). The data is included in the request body. This request may create new resources or modify existing resources, or both. Each time it is submitted, the form data is encoded into the body of the HTTP request by the browser. The body of a POST request issued by a browser mainly has two formats, one is application/x-www-form-urlencoded used to transmit simple data, roughly in the format of key1=value1&key2=value2. The other is for transmitting files and will use the multipart/form-data format. The latter is adopted because the encoding method of application/x-www-form-urlencoded is very inefficient for binary data like files.  Next, we will submit experimental data to the backend server built on our machine in a manner similar to submitting a form, and verify whether the backend server has received the data.\nStep 1: Before starting this example, make sure that the backend server built with FastAPI in the previous step is running normally. If not, please refer to the above instructions to start the server program.\nStep 2: Copy and paste the following code into the Arduino IDE. This code sets the tested serverName to http://192.168.1.2/sensor/. The 192.168.1.2 needs to be replaced with the IP address of your PC acting as the backend server. Remember to change your-ssid in the code to your Wi-Fi network name and your-password to the corresponding Wi-Fi password.\n#include &lt;WiFi.h&gt;\n#include &lt;HTTPClient.h&gt;\n\nconst char* ssid = \"your-ssid\";\nconst char* password = \"your-password\";\n\nconst char* serverName = \"https://192.168.1.2/sensor/\";\n\nunsigned long lastTime = 0;\nunsigned long timerDelay = 5000;\n\nvoid setup() {\n  Serial.begin(115200);\n\n  WiFi.begin(ssid, password);\n  Serial.println(\"Connecting\");\n  while(WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n  Serial.println(\"\");\n  Serial.print(\"Connected to WiFi network with IP Address: \");\n  Serial.println(WiFi.localIP());\n \n  Serial.println(\"Timer set to 5 seconds (timerDelay variable), it will take 5 seconds before publishing the first reading.\");\n}\n\nvoid loop() {\n  //Send an HTTP POST request every 10 minutes\n  if ((millis() - lastTime) &gt; timerDelay) {\n    //Check WiFi connection status\n    if(WiFi.status()== WL_CONNECTED){\n      WiFiClient client;\n      HTTPClient http;\n    \n\n      http.begin(client, serverName);\n\n      http.addHeader(\"Content-Type\", \"application/json\");\n      int httpResponseCode = http.POST(\"{\\\"name\\\":\\\"sensor\\\",\\\"value\\\":\\\"123\\\"}\");\n     \n      Serial.print(\"HTTP Response code: \");\n      Serial.println(httpResponseCode);\n        \n      // Free resources\n      http.end();\n    }\n    else {\n      Serial.println(\"WiFi Disconnected\");\n    }\n    lastTime = millis();\n  }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_HTTPpost_XIAO_en\n\nStep 2: Upload the code to XIAO ESP32C3 using the Arduino IDE. After a successful upload, open the Serial Monitor to examine the result returned by our backend server in response to the GET request. The image below illustrates the process.\n\n\nThe message **HTTP Response code: 200** signifies a successful request. On your local PC, open a browser and navigate to **http://192.168.1.2/items/sensor** (please replace the IP address according to your actual PC’s IP address, and if a port has been set, append a colon followed by the designated port number after the IP address). You should now see the most recent data sent by the XIAO ESP32C3. Since XIAO sends data every 5 seconds, you can always view the most recent data received by the backend server by refreshing the current page (the timestamp of the data will change).\n\n\nWe have now successfully sent data from XIAO ESP32C3 to the local backend server."
  },
  {
    "objectID": "chapter_3-5.html#background-knowledge",
    "href": "chapter_3-5.html#background-knowledge",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.1 Background Knowledge",
    "text": "3.5.1 Background Knowledge\n\n3.5.1.1 IoT (Internet of Things)\nThe “I” in IoT stands for Internet—cloud connectivity and services that enable many of the functions of IoT devices, from gathering sensor measurements linked to devices, to sending messages to control actuators. IoT devices typically connect to a single IoT cloud service using standard communication protocols, and this service is tightly integrated with the rest of your IoT application, from AI services making intelligent decisions around data, to web applications for control or reporting.\n\n🎓 Data collected from sensors and sent to the cloud is called telemetry.\n\nIoT devices can also receive information from the cloud. This information typically consists of commands—instructions to perform internal actions (such as rebooting or updating firmware) or to actuate (e.g., turning on a light).\n\n\n3.5.1.2 Communication Protocols\nThere are many popular communication protocols that IoT devices use to communicate with the internet. The most popular are based around the publishing/subscribing of messages through some agent: IoT devices connect to the agent, publish telemetry data and subscribe to commands. Cloud services also connect to the agent, subscribe to all telemetry information, and publish commands to specific devices or groups of devices, as shown in the figure below.\n\n\nMQTT is the most popular communication protocol for IoT devices and will be covered in this section. Other protocols include AMQP and HTTP/HTTPS, which we introduced in the previous section.\n\n\n3.5.1.3 Message Queuing Telemetry Transport (MQTT) \nMQTT is short for Message Queuing Telemetry Transport. It is a messaging protocol based on the publish/subscribe paradigm under the ISO standard: ISO/IEC PRF 20922. It can be seen as a “bridge for data delivery”. It operates on top of the TCP/IP protocol stack and is a publish/subscribe type messaging protocol designed for remote devices with poor hardware performance and poor network conditions. It is a lightweight, open standard messaging transport protocol that can send messages between devices. Originally designed in 1999 for monitoring oil pipelines, it was published as an open standard by IBM 15 years later.\nThe biggest advantage of MQTT is that it provides a real-time and reliable messaging service for connecting remote devices with minimal code and limited bandwidth. As a low-overhead, low-bandwidth consumption instant communication protocol, it is widely used in IoT, small devices, mobile applications, and so on.\nMQTT has one broker and multiple clients. All clients connect to the broker, which then routes messages to the relevant clients. Messages are routed using named topics, not sent directly to a single client. Clients can publish to a topic, and any client subscribed to that topic will receive the message.\n\n\n\n✅ Do some research. If you have a large number of IoT devices, how can you ensure that your MQTT broker can handle all messages?\n\n\nSome Open Source MQTT Brokers\nWhile we can set up our own MQTT broker if circumstances allow, you might not be ready to delve into server and application setup yet. If you’re just learning, you can start with some open source MQTT brokers.\n\nEclipse Mosquitto 🔗 https://www.mosquitto.org/\nThis is an open source MQTT broker. Instead of dealing with the complexities of setting up an MQTT broker as part of this task, this test broker is publicly available at test.mosquitto.org and doesn’t require account setup. It’s a great tool for testing MQTT clients and servers.\n\n\n\n\nshiftr.io\nAn IoT platform for interconnected projects, quickly connect hardware and software with its cloud service and desktop applications. The platform also provides a clear view of all connections, topics, and messages in the network through real-time charts. The shiftr.io broker supports MQTT and HTTP for publishing, subscribing, and retrieving messages, and the platform supports free accounts, enough for us to learn and use. They also provide a public server at public.cloud.shiftr.io with username public on ports 1883 (MQTT) and 8883 (MQTTS). The animated view of connected services and data being exchanged on the public server is very cool, as shown in the image below.\n\n\n\n\nHiveMQ\nHiveMQ is a cloud-based MQTT platform, offering scalable, secure, and reliable IoT communication services. HiveMQ can help enterprises and developers quickly build and manage IoT applications, supporting millions of devices and messages."
  },
  {
    "objectID": "chapter_3-5.html#task-1-connect-the-xiao-esp32c3-to-the-mqtt-broker",
    "href": "chapter_3-5.html#task-1-connect-the-xiao-esp32c3-to-the-mqtt-broker",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.2 Task 1: Connect the XIAO ESP32C3 to the MQTT Broker",
    "text": "3.5.2 Task 1: Connect the XIAO ESP32C3 to the MQTT Broker\nThe first step to adding internet control to your smart temperature and humidity meter is to connect the XIAO ESP32C3 to an MQTT broker.  In this part of the section, you’ll connect your smart temperature and humidity meter from Section 2.2 to the internet, enabling it to provide telemetry and be remotely controlled. Later in this section, your device will send a telemetry message via MQTT to a public MQTT broker, which will be received by some server code you’ll write. This code will check the temperature and humidity values, and send a command message to the device, telling it to turn a buzzer on or off.\n\n\nOne real-world use of this setup would be in a large indoor space with many temperature and humidity sensors, such as a farm. Before deciding to turn on air conditioning, data can be gathered from multiple temperature and humidity sensors. If only one sensor reading exceeds the threshold, but other sensor readings are normal, this can prevent the entire air conditioning system from being turned on.\n✅ Can you think of other situations where an evaluation of data from multiple sensors is required before issuing a command?\n\n💁 Remember, this test broker is public and unsecure, and anyone can listen in on what you’re publishing, so it should not be used for any data that needs to be kept confidential.\n\nFollow the related steps below to connect your device to the MQTT broker we introduced earlier: public.cloud.shiftr.io.\n\nAdd the arduino-mqtt library \nBefore you start programming the XIAO ESP32C3 with the Arduino IDE, you need to add the necessary libraries. Type the library URL 🔗 https://github.com/256dpi/arduino-mqtt into your browser’s address bar to go to the GitHub page. Click on Code→Download ZIP to download the resource pack arduino-mqtt-master.zip to your local machine, as shown in the image below.\n\n\nFrom the menu bar, select Sketch→Include Library→Add .ZIP Library to add the resource pack arduino-mqtt-master.zip you downloaded in the previous step. Continue until you see a message indicating successful library loading.\n\n\nRun the ESP32 MQTT example \nAfter the library is loaded successfully, open the “ESP32DevelopmentBoard” example in the Arduino IDE through the following path: File→Examples→MQTT→ESP32DevelopmentBoard, as shown in the image below.\n\n\nAfter the example program is opened, you can see the program as shown below. Then change the ssid in the code to your Wi-Fi network name, and change the pass in the code to the corresponding Wi-Fi password for your Wi-Fi network.\n// This example uses an ESP32 Development Board\n// to connect to shiftr.io.\n//\n// You can check on your device after a successful\n// connection here: https://www.shiftr.io/try.\n//\n// by Joël Gähwiler\n// https://github.com/256dpi/arduino-mqtt\n\n#include &lt;WiFi.h&gt;\n#include &lt;MQTT.h&gt;\n\nconst char ssid[] = \"ssid\";\nconst char pass[] = \"pass\";\n\nWiFiClient net;\nMQTTClient client;\n\nunsigned long lastMillis = 0;\n\nvoid connect() {\n  Serial.print(\"checking wifi...\");\n  while (WiFi.status() != WL_CONNECTED) {\n    Serial.print(\".\");\n    delay(1000);\n  }\n\n  Serial.print(\"\\nconnecting...\");\n  while (!client.connect(\"arduino\", \"public\", \"public\")) {\n    Serial.print(\".\");\n    delay(1000);\n  }\n\n  Serial.println(\"\\nconnected!\");\n\n  client.subscribe(\"/hello\");\n  // client.unsubscribe(\"/hello\");\n}\n\nvoid messageReceived(String &topic, String &payload) {\n  Serial.println(\"incoming: \" + topic + \" - \" + payload);\n\n  // Note: Do not use the client in the callback to publish, subscribe or\n  // unsubscribe as it may cause deadlocks when other things arrive while\n  // sending and receiving acknowledgments. Instead, change a global variable,\n  // or push to a queue and handle it in the loop after calling `client.loop()`.\n}\n\nvoid setup() {\n  Serial.begin(115200);\n  WiFi.begin(ssid, pass);\n\n  // Note: Local domain names (e.g. \"Computer.local\" on OSX) are not supported\n  // by Arduino. You need to set the IP address directly.\n  client.begin(\"public.cloud.shiftr.io\", net);\n  client.onMessage(messageReceived);\n\n  connect();\n}\n\nvoid loop() {\n  client.loop();\n  delay(10);  // &lt;- fixes some issues with WiFi stability\n\n  if (!client.connected()) {\n    connect();\n  }\n\n  // publish a message roughly every second.\n  if (millis() - lastMillis &gt; 1000) {\n    lastMillis = millis();\n    client.publish(\"/hello\", \"world\");\n  }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L15_ESP32DevelopmentBoard_XIAO_en\n\nRun the example and check the serial monitor for: connected!. If you see a connected client and flowing messages in the live chart, your XIAO is continuously sending data to this public MQTT broker!\n\n\nYou can see the messages you sent by accessing public.cloud.shiftr.io in your browser. However, because this is a public broker, your device will quickly get lost in the crowd.\n\n\n\n💁 Keep in mind, this test broker is public and insecure. Anyone can listen to what you’re publishing, so it should not be used for anything requiring confidentiality."
  },
  {
    "objectID": "chapter_3-5.html#deep-dive-into-mqtt",
    "href": "chapter_3-5.html#deep-dive-into-mqtt",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.3 Deep Dive into MQTT",
    "text": "3.5.3 Deep Dive into MQTT\nTopics can have a hierarchy, and clients can use wildcards to subscribe to different levels of different hierarchies. For example: you can send temperature telemetry to the /telemetry/temperature topic, humidity data to the /telemetry/humidity topic, and then subscribe to the /telemetry/* topic in your cloud application to receive both temperature and humidity telemetry. When messages are sent, a Quality of Service (QoS) can be specified which determines the guarantee of message delivery.\n\nAt most once: The message is sent only once, and no additional steps are taken by the client and the broker to confirm delivery (Fire and Forget).\nAt least once: The message is retried by the sender until it receives an acknowledgment (Acknowledged delivery).\nExactly once: A two-level handshake is performed by the sender and receiver to ensure that only one copy of the message is received (Assured delivery).\n\n\n✅ In what scenarios might you need to deliver messages on a Fire and Forget basis? \n\nAlthough MQTT (Message Queuing Telemetry Transport) has “Message Queuing” in its name (the first two letters of MQTT), it does not actually support message queues. This means that if a client disconnects and then reconnects, it will not receive messages that were sent while it was disconnected, except for those messages that it had already begun processing using the QoS process. A retain flag can be set on a message. If this flag is set, the MQTT broker will store the last message sent on a topic with this flag, and will send it to any clients who subsequently subscribe to that topic. This way, clients always receive the latest message.  MQTT also supports a keep-alive feature to check if the connection is still online during long intervals between messages. MQTT connections can be public, or encrypted and protected using usernames, passwords, or certificates.\n\n💁 MQTT communicates over TCP/IP, the same underlying network protocol as HTTP, but on a different port. You can also communicate with web applications running in a browser over MQTT on websockets, or in situations where firewalls or other network rules block standard MQTT connections."
  },
  {
    "objectID": "chapter_3-5.html#telemetry",
    "href": "chapter_3-5.html#telemetry",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.4 Telemetry",
    "text": "3.5.4 Telemetry\nThe word “telemetry” comes from Greek roots meaning “remote measurement”. Telemetry refers to the act of collecting data from sensors and sending it to the cloud.\n\n💁 One of the earliest telemetry devices was invented in France in 1874, sending real-time weather and snow depth data from Mont Blanc to Paris. As there was no wireless technology at the time, it used a physical wire.\n\nLet’s go back to the smart thermostat example from Section 1.1.\n\n\nSmart Thermostat System Architecture\n\nThe thermostat has temperature sensors to collect telemetry data. It likely has a built-in temperature sensor and may connect to multiple external temperature sensors via wireless protocols such as Low Energy Bluetooth (BLE).\nAn example of the telemetry data it sends could be:\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nAC_Temperature\n18°C\nThe temperature measured by the thermostat’s built-in temperature sensor\n\n\nLiving_Room_Temperature\n19°C\nThe temperature measured by a remote temperature sensor named livingroom , indicating the room it is in\n\n\nBedroom_Temperature\n21°C\nThe temperature measured by a remote temperature sensor named bedroom , indicating the room it is in\n\n\n\nThen, the cloud service can use this telemetry data to decide what commands to send to control cooling or heating."
  },
  {
    "objectID": "chapter_3-5.html#task-2-sending-telemetry-information-from-xiao-to-mqtt-broker",
    "href": "chapter_3-5.html#task-2-sending-telemetry-information-from-xiao-to-mqtt-broker",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.5 Task 2: Sending Telemetry Information from XIAO to MQTT Broker",
    "text": "3.5.5 Task 2: Sending Telemetry Information from XIAO to MQTT Broker\nThe next part of adding internet control to your smart hygrothermograph is sending the temperature and humidity telemetry data to the telemetry topic of the MQTT broker. Replace the XIAO of your smart hygrothermograph device from Section 2.2 with the XIAO ESP32C3, as shown in the image below.\n\n\nLoad the following program into the Arduino IDE to test sending telemetry data from your device to the MQTT broker. Note that in this example, we’re trying a different MQTT broker than in Task 1: broker.hivemq.com, and we’ve set XIAO_ESP32C3_Telemetry/ as the subscription name.\n////////////////////////////////////////////////////////////////////////////////\n// IDE:\n//   Arduino 2.0.0\n// Platform:\n//   esp32 2.0.5 - https://github.com/espressif/arduino-esp32\n// Board:\n//   XIAO_ESP32C3\n// Libraries:\n//   MQTT 2.5.0 - https://github.com/knolleary/pubsubclient\n//   ArduinoJson 6.19.4 - https://github.com/bblanchon/ArduinoJson\n\n////////////////////////////////////////////////////////////////////////////////\n// Includes\n\n#include &lt;WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include &lt;Wire.h&gt;\n#include \"DHT.h\"\n#define DHTTYPE DHT20   \nDHT dht(DHTTYPE); \n\nconst char* ssid = \"ssid\";\nconst char* password = \"pass\";\n\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\nlong lastMsg = 0;\nchar msg[50];\nint value = 0;\n\nfloat temperature = 0;\nfloat humidity = 0;\n\nvoid setup() {\n  Serial.begin(115200);\n  setup_wifi();\n  client.setServer(mqtt_server, 1883);\n  Wire.begin();\n  dht.begin();\n}\n\nvoid setup_wifi() {\n  delay(10);\n  // We start by connecting to a WiFi network\n  Serial.println();\n  Serial.print(\"Connecting to \");\n  Serial.println(ssid);\n\n  WiFi.begin(ssid, password);\n\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n  Serial.println(\"\");\n  Serial.println(\"WiFi connected\");\n  Serial.println(\"IP address: \");\n  Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n  // Loop until we're reconnected\n  while (!client.connected()) {\n    Serial.print(\"Attempting MQTT connection...\");\n    // Attempt to connect\n    if (client.connect(\"XIAO_ESP32\")) {\n      Serial.println(\"connected\");\n      // Subscribe\n      client.subscribe(\"XIAO_ESP32/LEDOUTPUT\");\n    } else {\n      Serial.print(\"failed, rc=\");\n      Serial.print(client.state());\n      Serial.println(\" try again in 5 seconds\");\n      // Wait 5 seconds before retrying\n      delay(5000);\n    }\n  }\n}\n\nvoid loop() {\n    \n  if (!client.connected()) {\n    reconnect();\n  }\n  client.loop();\n\n  long now = millis();\n  float temp_hum_val[2] = {0};\n  if (now - lastMsg &gt; 5000) {\n    lastMsg = now;\n\n    dht.readTempAndHumidity(temp_hum_val);\n    temperature = temp_hum_val[1];   \n  \n    char tempString[8];\n    dtostrf(temperature, 1, 2, tempString);\n    Serial.print(\"Temperature: \");\n    Serial.println(tempString);\n    client.publish(\"XIAO_ESP32C3_Telemetry/Temperaturedataread\", tempString);\n\n    humidity = temp_hum_val[0];\n    \n    char humString[8];\n    dtostrf(humidity, 1, 2, humString);\n    Serial.print(\"Humidity: \");\n    Serial.println(humString);\n    client.publish(\"XIAO_ESP32_Telemetry/Humiditydataread\", humString);\n  }\n\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L15_MQTTTelemetry_XIAO_en\n\nBecause this example relies on the PubSubClient.h library, if you try to compile it directly, you will encounter the error “PubSubClient.h: No such file or directory”. To resolve this issue, follow the steps below to install the library.\n\nOpen the Arduino IDE.\nGo to “Sketch” -&gt; “Include Library” -&gt; “Manage Libraries”.\nIn the Library Manager, type “PubSubClient” in the search bar.\nLook for the “PubSubClient” library by Nick O’Leary and click on it.\nClick the “Install” button to install the library.\n\nThen modify the ssid in the code to your Wi-Fi network name and pass to your Wi-Fi password corresponding to your Wi-Fi network name.  After successfully uploading the program, open the serial monitor. If all goes well, you will see the device start sending temperature and humidity data, as shown in the image below.\n\n\nHow can you see the sensor data from another platform? There are many ways, such as MQTT X. After downloading and installing the software suitable for your PC system, the interface is as shown in the image below.\n\n\nClicking the + New Connection button will bring you to the connection creation window, as shown in the image below. Fill in XIAO-DHT20 in the Name box as the connection name. The Host is broker.hivemq.com that we set in the program, no other settings are needed, click Connect in the upper right corner.\n\n\nCreate a new subscription, showing all the information under XIAO_ESP32C3_Telemetry/, as shown in the image below.\n\n\nNow, we can see the telemetry data sent from XIAO ESP32C3, as shown in the image below.\n\n\n\nHow often should telemetry be sent?\nOne question that needs careful consideration with telemetry is: how often should you measure and send data? The answer is — it depends on the needs of the device being monitored and the task at hand. If you measure frequently, you can indeed respond to changes in the measurements more quickly, but this would cause your device to consume more power, more bandwidth, generate more data, and require more cloud resources to handle. You need to strike a balance between measuring often enough but not too often.\nFor a thermostat, measuring every few minutes might be enough because the temperature isn’t likely to change frequently. If you only measure once a day, then you might be heating your house for nighttime temperatures on a sunny day, and if you measure every second, you’d have thousands of unnecessary repeated temperature measurements which will eat up users’ internet speed and bandwidth (which is a problem for people with limited bandwidth plans), and also consume more power, which is a problem for devices like remote sensors that rely on battery power, and further increase the cost of cloud computing resources to process and store them.\nIf you’re monitoring data around a machine in a factory that might cause catastrophic damage and millions in lost revenue if it fails, then measuring multiple times a second may be necessary. Wasting bandwidth is better than missing telemetry data that could signal the need to stop and repair before a machine fails.\n\n💁 In this situation, you could consider first using an edge device to handle the telemetry data to reduce dependence on the internet.\n\n\n\nLosing connection\nInternet connections can be unreliable, and it’s common to lose signal. In this case, what should an IoT device do? Should it lose data, or should it store data until the connection is restored? Again, the answer is — it depends on the device being monitored.\nFor a thermostat, data is likely lost once a new temperature measurement has been made. If the current temperature is 19°C, the heating system doesn’t care that the temperature 20 minutes ago was 20.5°C; it’s the current temperature that dictates whether the heat should be turned on or off.\nFor some machines, you may want to retain this data, especially if it’s being used to look for trends. Some machine learning models can identify anomalies in data streams by looking at a defined time period (e.g., the last hour). This is often used for predictive maintenance, looking for signs that something might be about to fail so you can repair or replace it before disaster strikes. You may want every point of telemetry from a machine sent so it can be used for anomaly detection, so once an IoT device can reconnect, it will send all the telemetry data generated during the internet outage.\nIoT device designers should also consider whether an IoT device can operate during an internet outage or if it loses signal due to location. If a smart thermostat is unable to send telemetry data to the cloud due to an internet outage, it should be able to make some limited decisions to control heating.\n\n\n  This Ferrari became a brick when someone tried to update it in an underground car park… but there was no cell signal there.\n\nFor MQTT handling connection interruptions, if necessary, the device and server code will need to be responsible for ensuring message delivery, for example, requiring all sent messages to be replied to by an additional message on the reply topic, and if not, to manually queue them for later resending."
  },
  {
    "objectID": "chapter_3-5.html#commands",
    "href": "chapter_3-5.html#commands",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.6 Commands",
    "text": "3.5.6 Commands\nCommands are messages sent by the cloud to a device instructing it to do something. Most often, this involves providing some output via an actuator, but it could be an instruction to the device itself, such as to reboot, or to collect additional telemetry data and send it as a response to the command.\n\n \nA thermostat could receive a command from the cloud to turn on the heat. Based on the telemetry data from all sensors, if the cloud service has decided that the heat should be turned on, then it sends the appropriate command."
  },
  {
    "objectID": "chapter_3-5.html#task-3-send-commands-to-xiao-via-mqtt-broker",
    "href": "chapter_3-5.html#task-3-send-commands-to-xiao-via-mqtt-broker",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.7 Task 3: Send Commands to XIAO via MQTT Broker",
    "text": "3.5.7 Task 3: Send Commands to XIAO via MQTT Broker\nHaving mastered telemetry, the next step is to send commands to IoT devices via an MQTT broker. In this task, we will try to use a computer with MQTT broker, often called a host computer, to send specific characters and let the Wi-Fi connected XIAO ESP32C3 control a buzzer attached to an expansion board to emit a warning sound.\nIn the Arduino IDE, load the following program to test sending specific characters (first character is ‘0’) from the MQTT broker to activate the buzzer. We use the MQTT broker: broker.hivemq.com in this example.\n////////////////////////////////////////////////////////////////////////////////\n// IDE:\n//   Arduino 2.0.0\n// Platform:\n//   esp32 2.0.5 - https://github.com/espressif/arduino-esp32\n// Board:\n//   XIAO_ESP32C3\n// Libraries:\n//   MQTT 2.5.0 - https://github.com/knolleary/pubsubclient\n//   ArduinoJson 6.19.4 - https://github.com/bblanchon/ArduinoJson\n//  https://github.com/Seeed-Studio/Seeed_Arduino_MultiGas\n\n\n////////////////////////////////////////////////////////////////////////////////\n// Includes\n\n\n#include &lt;WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include &lt;Wire.h&gt;\n\n\nconst char* ssid = \"ssid\";\nconst char* password = \"pass\";\n\n\nconst char* mqtt_server = \"broker.hivemq.com\";\n\n\nWiFiClient espClient;\nPubSubClient client(espClient);\nlong lastMsg = 0;\nchar msg[50];\nint value = 0;\n\n\nint speakerPin = A3;\n\n\nvoid setup_wifi() {\n  delay(10);\n  // We start by connecting to a WiFi network\n  Serial.println();\n  Serial.print(\"Connecting to \");\n  Serial.println(ssid);\n\n\n  WiFi.begin(ssid, password);\n\n\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n\n  Serial.println(\"\");\n  Serial.println(\"WiFi connected\");\n  Serial.println(\"IP address: \");\n  Serial.println(WiFi.localIP());\n}\n\n\nvoid callback(char* topic, byte* payload, unsigned int length) {\n  Serial.print(\"Message arrived [\");\n  Serial.print(topic);\n  Serial.print(\"] \");\n  for (int i=0;i&lt;length;i++) {\n    Serial.print((char)payload[i]);\n  }\n  if((char)payload[0]=='0'){\n    Serial.print(\"  RUN\");\n    digitalWrite(speakerPin, HIGH);\n    delay(2000);\n    digitalWrite(speakerPin, LOW);\n    delay(100);  \n  }\n  Serial.println();\n}\n\n\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(speakerPin, OUTPUT);\n  setup_wifi();\n  client.setServer(mqtt_server, 1883);\n  client.subscribe(\"XIAO_ESP32/Recieve\");\n  client.setCallback(callback);\n}\n\n\nvoid reconnect() {\n  // Loop until we're reconnected\n  while (!client.connected()) {\n    Serial.print(\"Attempting MQTT connection...\");\n    // Attempt to connect\n    if (client.connect(\"XIAO_ESP32\")) {\n      Serial.println(\"connected\");\n      // Subscribe\n      \n    } else {\n      Serial.print(\"failed, rc=\");\n      Serial.print(client.state());\n      Serial.println(\" try again in 5 seconds\");\n      // Wait 5 seconds before retrying\n      delay(5000);\n    }\n  }\n}\n\n\nvoid loop() {\n    \n  if (!client.connected()) {\n    reconnect();\n    client.subscribe(\"XIAO_ESP32/Recieve\");\n  }\n  client.loop();\n\n\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L15_MQTTCommand_XIAO_en\n\nThen modify the ssid in the code to your Wi-Fi network name, and modify the pass in the code to the Wi-Fi password corresponding to your Wi-Fi network name.  The logic of the program execution is explained as follows:\nclient.setServer(mqtt_server, 1883);\nclient.subscribe(\"XIAO_ESP32/Recieve\");\nclient.setCallback(callback);\nDuring the setup stage, the connection between XIAO and the MQTT server is initialized, and the topic subscription settings and callback functions are set. Here we subscribe to the topic XIAO_ESP32/Recieve as an example. When we send a message to this topic from the host computer, the corresponding callback function callback will be executed:\nvoid callback(char* topic, byte* payload, unsigned int length) {\n  Serial.print(\"Message arrived [\");\n  Serial.print(topic);\n  Serial.print(\"] \");\n  for (int i=0;i&lt;length;i++) {\n    Serial.print((char)payload[i]);\n  }\n  if((char)payload[0]=='0'){\n    Serial.print(\"  RUN\");\n    digitalWrite(speakerPin, HIGH);\n    delay(2000);\n    digitalWrite(speakerPin, LOW);\n    delay(100);  \n  }\n  Serial.println();\n}\nHere it will first print out the received message, then extract the character at position 0. When the character at position 0, which is the first character, is0, it satisfies the condition for the if statement to perform an action. Here we connect the XIAO ESP32C3 and the expansion board together. When the condition is met, the buzzer on the expansion board will change its level briefly and beep for 2 seconds, while sending the prompt messageRUN to the serial port.\nIn the process of development and testing by readers, you can also try to integrate the receive and send functions of MQTT, and send messages to specific topics in the callback function, so that the sender can ensure that XIAO has received the message.\nOn the host computer, we use MQTT X to test. Open MQTT X, the interface is as shown in the following figure.\n\n\nClick the + New Connection button to enter the connection creation window, as shown in the following figure. Fill in the Name box with XIAO-MQTT-Recieve as the connection name. Host is the broker.hivemq.com we set in the program, and nothing else needs to be set. Click Connect at the top right corner. The interface after successful connection is as shown in the following figure.\n\n\nNow we can publish messages to the specified topic, which is the topic XIAO_ESP32/Recieve we subscribed to on XIAO. Then we enter 00 in the input box of XIAO_ESP32/Recieve at the lower right corner of the interface, and then click the send button  in the lower right corner.\n\n\nAt this time, in the serial monitor on the PC side, you can see the prompt message received from XIAO, as shown in the following figure, and prompt RUN, the buzzer will sound for 2 seconds, indicating that the message has been received.\n\n\nNow, we have successfully driven the buzzer on the expansion board connected to the Wi-Fi connected XIAO ESP32C3 through the instruction sent by the PC side.  The action of the buzzer can be replaced with the control of any peripheral to achieve the desired function.\n\nLost connection\nIf a cloud service needs to send a command to an offline IoT device, what should it do? Again, the answer depends on the situation. If the latest command overwrites the previous one, the previous command may be ignored. If the cloud service sends a command to turn on the heating, and then sends another command to turn off the heating, then the turn-on command can be ignored and does not need to be resent.  If the commands need to be processed in order, such as first moving the robot arm up and then closing the gripper, then they need to be sent in order once the connection is restored.\n\n✅ How can device or server code ensure that commands are always sent and processed in order through MQTT if needed?\n\n\nUsing XIAO’s Bluetooth function\nXIAO nRF52840, XIAO nRF52840 Sense, XIAO ESP32C3 all support Bluetooth function, you can refer to the related Wiki documents to learn how to use the Bluetooth function.\n\nBluetooth Usage on Seeed Studio XIAO ESP32C3\nBluetooth Usage (Seeed nRF52 Boards Library)\nBluetooth Usage (Seeed nrf52 mbed-enabled Boards Library)"
  },
  {
    "objectID": "chapter_4.html",
    "href": "chapter_4.html",
    "title": "Chapter 4: Project Practice Advanced - TinyML Applications",
    "section": "",
    "text": "Among the XIAO series products, the Seeed Studio XIAO nRF52840 Sense has Bluetooth 5.0 wireless connectivity, low power consumption, and onboard 6-axis IMU and PDM microphone sensors. Besides, the XIAO ESP32S3 Sense further integrates PSRAM, a camera, a digital microphone, and SD card support.\n\nThose characteristics make those devices powerful tools for TinyML (Tiny Machine Learning) projects.\n\nTinyML solves problems in a completely different way from traditional programming methods. This chapter will introduce you to this cutting-edge field by walking through the entire TinyML workflow, from data collection, pre-processing, model definition, training, testing, and deployment to allow actual inference on the physical world."
  },
  {
    "objectID": "chapter_4-1.html#common-terms",
    "href": "chapter_4-1.html#common-terms",
    "title": "4.1 Understanding TinyML and Edge Impulse Studio",
    "section": "4.1.1 Common Terms",
    "text": "4.1.1 Common Terms\nIn addition to TinyML, we often hear conceptually similar terms such as edge computing, edge AI, embedded machine learning, etc. So, before learning TinyML, you need to understand these terms and their meanings.\n\n4.1.1.1 Embedded Systems\nAn embedded system is a computer used only to solve a few particular problems and is challenging to change. The term “embedded” means that it is built into the system. It is a permanent part of the more extensive system. It usually doesn’t look like a computer; in most cases, it doesn’t have a keyboard, monitor, or mouse. But like any computer, it has a processor, software, input, and output.\nEmbedded systems are computers controlling various physical and electronic devices, and now they are almost everywhere. From the Bluetooth headphones you use, home audio-visual equipment, game consoles, air conditioners, sweeping robots, rice cookers, and washing machines to the control units of electric vehicles to communication equipment, factory equipment, medical equipment, office places, and even military equipment, almost any electrically driven device has the presence of embedded systems. Embedded software is the software running on them, and the following figures show some scenes where you can see embedded systems.\n\nEmbedded systems can be large or small, as small as the microcontroller controlling the digital watch and as large as the embedded computer in the autonomous car. Unlike general-purpose computers such as laptops or smartphones, embedded systems usually perform a specific specialized task.\n\n🔍 Do some research:  Look around you, what devices might have embedded systems in them?\n\nThe size and complexity of embedded systems vary, but they all contain three basic components:\n\nHardware: These systems use microprocessors and microcontrollers as their hardware. Microprocessors are similar to microcontrollers because they are both related to CPUs (central processing units), and CPUs are combined with other essential computer parts (such as storage chips and digital signal processors (DSPs)). Microcontrollers integrate all these parts into a single chip.\nFirmware and Software: The complexity of the system software differs from industrial-grade microcontrollers and embedded IoT systems, on the other hand, they usually run relatively basic software, using very little memory.\nReal-Time Operating System (RTOS): These systems, especially the more minor, often do not include these operation systems. By supervising software during program execution and establishing standards, RTOS determines how the system operates.\n\nEmbedded systems are often also constrained by their deployment environment. For example, many embedded systems need to run on battery power. Hence, their design needs to consider energy efficiency metrics - perhaps memory is limited, or the clock speed is extremely slow.\nThe challenge for engineers programming for embedded systems is often implementing functional requirements within these limited hardware and environmental resource constraints. You must consider hardware resource constraints when learning to build your TinyML project model for XIAO later.\n\n\n4.1.1.2 Edge Computing and Internet of Things (IoT)\nThe concept of “Edge” is relative to the “Center.” In the early days, computers like the ENIAC (Electronic Numerical Integrator and Computer), built in 1945, were massive, weighing nearly 30 tons and occupying 170 square meters.\n\n\nStaff programming the ENIAC\n\n\nAt this stage, computational tasks were centralized on the core machine. These large computers evolved into “minicomputers,” typically consisting of a central host and multiple terminals connected to the host. Multiple users could issue computational instructions through the terminals, but most of the computation still occurred on the central host. As time passed, the terminals became more complex and took over more and more functions of the central computer.\n\n\nThe processor manual cover for the minicomputer pdp11/70, showing the host and connected terminals.\n\n It wasn’t until the advent of personal computers that computation truly expanded to the “edge.” The rapid development of personal computers also led to the decline of those massive machines, and the scale of human computation quickly tilted towards the “edge.”\n\n\nThe 70s Wang computer, once a world leader in market share. (Personal computer Wang 2200 PCS II. It is located in the Belgrade Museum of Technology.)\n\n The emergence and development of the Internet led to a large concentration of servers to provide a variety of data storage and computational services, search engines, streaming video, online games, social networks, etc. The highly centralized cloud computing era had arrived, and many internet service providers owned massive data center rooms.\n\n\nGoogle’s data center located on the outskirts of Pryor, Oklahoma, USA\n\n\nIn theory, all our computing services can be completed in the cloud. But these cloud-based services are useless in many areas without internet connections or when the internet goes down.\nThe computers we use for work and entertainment are just some devices connected to these cloud services. As of 2021, there were as many as 12.2 billion connected devices worldwide, and we call this network of devices IoT (Internet of Things). It includes everything you can and can’t think of, such as mobile phones, smart speakers, connected security cameras, cars, containers, pet trackers, industrial sensors, etc.\nThese devices are embedded systems containing microprocessors running software written by embedded software engineers. We can also call them edge devices because they are located at the edge of the network. Computation performed on edge devices is known as Edge Computing. The following illustration expresses the relationship between the cloud and edge devices.\n\n\nDevices at the network edge can communicate with the cloud, edge infrastructure, and each other. Edge applications typically span multiple locations on this map. For example, data may be sent from an IoT device equipped with sensors to a local edge server for processing.\n\n\n4.1.1.3 Artificial Intelligence (AI)\nArtificial Intelligence (AI) is a vast concept and is difficult to define. In a vague sense, it’s about making things possess human-like intelligence and thinking abilities. But even the definition of intelligence itself is disputed, and this is a cutting-edge field with many unknowns, which readers are welcome to explore on their own. For the convenience of understanding the following concepts, this book provides a relatively narrow definition of AI: an artificial system capable of making wise decisions based on specific inputs.\n\n\n4.1.1.4 Machine Learning (ML)\nMachine Learning (ML) primarily aims to design and analyze algorithms that allow computers to “learn” automatically. ML algorithms are a class of algorithms that automatically analyze and learn patterns from data and use these patterns to predict unknown data.\nTake a typical example of machine learning—continuous motion recognition. In Section 2.4, we learned about the triaxial accelerometer. The image below shows a Wio Terminal with an embedded triaxial accelerometer and screen. We can use it to record accelerometer data for several different movements: waving (wave), flipping (flip), and idling (idle).\n\n\nLooking at the data generated from these different movements, you can find a method for the machine to recognize these motion patterns. The traditional way involves manually analyzing and checking the data, identifying specific logical rules for different movements through mathematical analysis, and then writing a recognition program to perform the desired action based on these rules. Sounds complicated, doesn’t it?\nFortunately, we now have machine learning methods. Training and testing these data will yield an algorithm, and the device only needs to run this algorithm to automatically complete our desired “inference” process and deliver results. From the current state of machine learning development, this method is exceptionally proficient in handling complex data scenarios. We will learn more about this process in subsequent sections.\n\n\n4.1.1.5 Edge AI\nAs the term suggests, Edge AI combines edge devices and artificial intelligence. The development of Edge AI stems from the pursuit of lower system power consumption and higher efficiency. For example, popular smartwatches or fitness bands often have built-in accelerometers that generate hundreds of readings per second—a large volume of data—and continuous data reading is required to recognize movement states. If the recognition of movements is performed in the cloud, the smartwatch would need to consume a lot of energy to send data to the cloud, and there would usually be a delay in receiving the result. This makes the entire computational process uneconomical—high energy consumption and latency. This latency can also prevent us from effectively using data for real-time feedback.\nEdge AI solves this problem by recognizing movements on the smartwatch or band itself. This allows for quick results without relying on the cloud. If necessary data needs to be uploaded to the cloud, there’s no need to send a large amount of sensor data; instead, just the essential motion recognition results are sent, significantly reducing communication volume and consuming less electric power.\n\n\n4.1.1.6 Embedded Machine Learning\nEmbedded Machine Learning is the art and science of running machine learning models on embedded systems. When we talk about embedded machine learning, we typically refer to machine learning inference—the process of taking input and making a prediction (for example, guessing motion status based on accelerometer data). The training part is typically still performed on traditional computers.\nFurthermore, embedded systems usually have limited memory. This challenges running many machine learning models, which often have high demands for read-only memory (storing the model) and RAM (handling intermediate results generated during inference). They often need more computing capability as well. Many machine learning models are quite compute-intensive, which can also pose problems.\n\n\n4.1.1.7 Tiny Machine Learning (TinyML)\nTinyML involves implementing the inference process of machine learning on the most restricted embedded hardware, such as Micro Processor Units (MCUs), Digital Signal Processors (DSPs), and Field Programmable Gate Arrays (FPGAs).\nThe image below helps to understand the relationship between these terms better."
  },
  {
    "objectID": "chapter_4-1.html#advantages-and-operation-of-edge-ai",
    "href": "chapter_4-1.html#advantages-and-operation-of-edge-ai",
    "title": "4.1 Understanding TinyML and Edge Impulse Studio",
    "section": "4.1.2 Advantages and Operation of Edge AI",
    "text": "4.1.2 Advantages and Operation of Edge AI\nFor many years, the Internet of Things (IoT) has been referred to as “machine-to-machine” (M2M). It involves connecting sensors and various computing devices for process automation control and has been widely adopted in industrial machinery and processes.\nMachine learning offers the ability to make further progress in automation by introducing models that can make predictions or decisions without human intervention. Due to the complexity of many machine learning algorithms, the traditional integration of IoT and ML involves sending raw sensor data to a central server, which performs the necessary inference computations to generate predictions.\n\n\nThis configuration might be acceptable for low volumes of raw data and complex models. However, several potential problems have emerged:\n\nTransmitting extensive sensor data (like images) can consume a lot of network bandwidth.\nData transmission also requires power.\nSensors must continuously connect to the server to provide near real-time machine learning computation.\n\nGiven these challenges and the rapid development of machine learning, Edge AI has begun to emerge. Jeff Bier, founder of Edge AI and Vision Alliance, outlined five factors that push artificial intelligence to the edge in his article What’s Driving AI and Vision to the Edge —BLERP, which stands for Bandwidth, Latency, Economics, Reliability, and Privacy.\n\nBandwidth: If you have a commercial greenhouse, workshop, or mall with hundreds of cameras, it’s impossible to send this information to the cloud for processing—the data would choke any type of internet connection you have. You simply need to process it locally.\nLatency: The latency here refers to the time between the system receiving sensor input and making a response. Consider autonomous vehicles: if a pedestrian suddenly appears at a crosswalk, the car’s computer might only have a few hundred milliseconds to decide. There’s not enough time to send the image to the cloud and await a response.\nEconomics: Cloud computing and communication are getting better and cheaper, but they still cost money—possibly a lot of money, especially regarding video data. Edge computing reduces the amount of data that must be sent to the cloud and the computation workload once it arrives, significantly reducing costs.\nReliability: Think of a home security system with facial recognition—even if there’s an internet outage, you still want it to allow your family members to enter. Local processing makes this possible and gives the system more robust fault tolerance.\nPrivacy: The rapid development of edge audio and video sensors has caused severe privacy issues, and sending this information to the cloud dramatically increases these concerns. The more information that can be processed locally, the less potential for abuse—what happens on the edge stays on the edge.\n\nIn most cases, training a machine learning model involves a three-step process of Model ➡️ Training ➡️ Inference, where obtaining the model requires more intensive computation than executing inference.\n\nModel: A mathematical formula trying to generalize information from a given dataset.\nTraining: The process of automatically updating the parameters from data within a model. This model “learns” to make conclusions and generalize about the data.\nInference: Providing new, unseen data to a trained model to make predictions, decisions, or classifications.\n\nThus, under normal circumstances, we would rely on powerful server clusters to train new models, constructing datasets from raw data collected on-site (images, sensor data, etc.) and using this dataset to train our machine learning models.\n\n⚠️ Note:  In some cases, we can train on the device side. However, this is generally unfeasible due to the memory and processing limitations of such edge devices.\n\nOnce we have a trained model, which is just a mathematical model (in the form of a software library), we can deploy it to our intelligent sensors or other edge devices. We can use this model to write firmware or software to collect new raw sensor readings, perform inferences, and take actions based on these inference results, as shown in the figure below. These actions could be self-driving cars, moving robotic arms, or sending notifications to users about engine failures. Since inference is performed locally on the edge device, the device does not need to maintain a network connection (the optional connection is shown as a dotted line in the chart)."
  },
  {
    "objectID": "chapter_4-1.html#applications-of-edge-ai",
    "href": "chapter_4-1.html#applications-of-edge-ai",
    "title": "4.1 Understanding TinyML and Edge Impulse Studio",
    "section": "4.1.3 Applications of Edge AI",
    "text": "4.1.3 Applications of Edge AI\nRunning machine learning models on edge devices without staying connected to a more powerful computer opens up possibilities for various automated tools and more intelligent IoT systems. Here are a few examples of edge AI enabling innovation in multiple industries.\n\n\nBenjamin Cabé used TinyML technology to create an artificial nose that  distinguishes between various distinct smells.\n\n\nEnvironmental Protection\n\nSmart grid monitoring to detect faults in power lines early\nWildlife tracking and behavior research\nForest fire detection and early warning\n\n\n\nAgriculture\n\nPrecision weeding, fertilization, pesticide application, or irrigation\nAutomatic recognition of irrigation needs\nAutomatic recognition of crop status and disease/insect infestation conditions\n\n\n\nSmart Buildings\n\nMonitoring of intrusions and recognition of abnormal states\nAir conditioning systems that adapt based on the number of people in a room\n\n\n\nHealth and Sports\n\nWearable devices that track sleep and exercise conditions\nPortable medical devices\nGesture recognition\n\n\n\nHuman-Machine Interaction\n\nVoice activation word detection\nGesture and device motion recognition for auxiliary control\n\n\n\nIndustry\n\nAutomatic safety helmet detection\nMachine, equipment, and facility condition monitoring\nProduction line defect detection\nPosition and motion state detection\n\nThe computational power typically required to perform machine learning inference at the edge is often more significant than simply polling sensors and transmitting raw data. However, locally, achieving such computations requires less power than sending raw data to a remote server.\nThe following table provides some suggestions on the type of hardware needed to perform machine learning inference at the edge, depending on the required application.\n[Source: https://docs.edgeimpulse.com/docs/concepts/what-is-edge-machine-learning]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXIAO for this kind of task\n\n\n\n\n\n\n\n\nLow-End MCU\nHigh-End MCU\nNPU (Neural Network Processor)\nMPU (Microprocessor)\nGPU (Graphics Processor)\n\n\n\nTask\nSensor Fusion Classification\nAudio Classification\nImage Classification\nComplex Images or Sound and simple Videos\nVideo Classification\n\n\n\nMemory\n18KB\n50KB\n256KB\n1MB+\n1GB+\n\n\n\nSensors\n✅\n✅\n✅\n✅\n✅\n\n\n\nAudio\n\n✅\n✅\n✅\n✅\n\n\n\nImages\n\n\n✅\n✅\n✅\n\n\n\nVideos\n\n\n\n✅\n✅\n\n\n\n\n\n\n\n\n\n\n\n\nXIAO\nnRF52840 Sense\nnRF52840 & ESP32S3 Sense\nESP32S3 Sense\nESP32S3 Sense\n—————–\n\n\n\n\nEmbedded hardware is also rapidly evolving, and it’s expected that the contents of this table will change soon."
  },
  {
    "objectID": "chapter_4-1.html#introduction-to-edge-impulse-studio",
    "href": "chapter_4-1.html#introduction-to-edge-impulse-studio",
    "title": "4.1 Understanding TinyML and Edge Impulse Studio",
    "section": "4.1.4 Introduction to Edge Impulse Studio",
    "text": "4.1.4 Introduction to Edge Impulse Studio\nEdge Impulse was founded by Zach Shelby and Jan Jongboom in 2019. It is the leading edge device machine learning development platform. This platform allows developers to create and optimize solutions with real-world data, making the process of building, deploying, and scaling embedded ML applications more accessible and faster than ever before.\n\n\nLogo of Edge Impulse.\n\n\nYou can visit Edge Impulse’s official website for more information about this tool and check the official documentation for a basic explanation.\nIn the following sections, we will learn to achieve continuous motion recognition with the on-board 6-axis accelerometer of the XIAO nRF52840 Sense shown below and voice keyword wake-up functionality using the on-board PDM microphone.\n\n\nSeeed Studio XIAO nRF52840 Sense\n\n\nComputer Vision applications such as Image Classification and Object Detection will also be implemented using the camera of the XIAO ESP32S3 Sense shown below.\n\n\nSeeed Studio XIAO ESP32S3 Sense"
  },
  {
    "objectID": "chapter_4-2.html#things-used-in-this-project",
    "href": "chapter_4-2.html#things-used-in-this-project",
    "title": "4.2 Anomaly Detection & Motion Classification",
    "section": "4.2.1 Things used in this project",
    "text": "4.2.1 Things used in this project\n\nHardware components\n\nSeeed Studio XIAO nRF52840 Sense × 1\n\n\n\n\n\n\nSoftware apps and online services\n\n Arduino IDE\n\n\n\n\n Edge Impulse Studio"
  },
  {
    "objectID": "chapter_4-2.html#introduction",
    "href": "chapter_4-2.html#introduction",
    "title": "4.2 Anomaly Detection & Motion Classification",
    "section": "4.2.2 Introduction",
    "text": "4.2.2 Introduction\nAs you learned in the previous section, microcontrollers (MCUs) are very cheap electronic components, usually with just a few kilobytes of RAM, designed to use tiny amounts of energy. They can be found in almost any consumer, medical, automotive, and industrial device. Over 40 billion microcontrollers will be sold this year, and there are probably hundreds of billions in service nowadays. However, these devices get little attention because they’re often only used to replace the functionality of older electro-mechanical systems in cars, washing machines, or remote controls. More recently, with the Internet of Things (IoT) era, a significant part of those MCUs is generating “quintillions” of data that, in its majority, is not used due to the high cost and complexity (bandwidth and latency) of data transmission.\nOn the other hand, in recent decades, we have seen a lot of development in Machine Learning models trained with vast amounts of data in very powerful and power-hungry mainframes. And what is happening today is that due to those developments, it is now possible to take noisy signals like images, audio, or accelerometers and extract meaning from them by using Machine Learning algorithms such as Neural Networks.\nAnd what is more important is that we can run these algorithms on microcontrollers and sensors themselves using very little power, interpreting much more of those sensor data that we are currently ignoring. This is TinyML, a new technology that enables machine intelligence right next to the physical world.\n\nTinyML can have many exciting applications for the benefit of society at large.\n\nThis section will explore TinyML, running on a robust and tiny device, the Seed XIAO nRF52840 Sense（also called XIAO BLE Sense）."
  },
  {
    "objectID": "chapter_4-2.html#xiao-nrf52840-sense",
    "href": "chapter_4-2.html#xiao-nrf52840-sense",
    "title": "4.2 Anomaly Detection & Motion Classification",
    "section": "4.2.3 XIAO nRF52840 Sense",
    "text": "4.2.3 XIAO nRF52840 Sense\n\n\n\nMainFeatures\n\nBluetooth 5.0 with onboard antenna\nCPU: Nordic nRF52840, ARM® Cortex®-M4 32-bit processor with FPU, 64 MHz\nUltra-Low Power: Standby power consumption is less than 5μA\nBattery charging chip: Supports lithium battery charge and discharge management\n2 MB flash\n256 KB RAM\nPDM microphone\n6-axis LSM6DS3TR-C IMU\nUltra Small Size: 20 x 17.5mm, XIAO series classic form-factor for wearable devices\nRich interfaces: 1xUART, 1xI2C, 1xSPI, 1xNFC, 1xSWD, 11xGPIO(PWM), 6xADC\nSingle-sided components, surface mounting design\n\n\n\n4.2.3.1 Connecting the XIAO nRF52840 Sense with Arduino IDE\nThe simple way to test and use this device is using the Arduino IDE. Once you have the IDE installed on your machine, navigate to File &gt; Preferences, and fill in “Additional Boards Manager URLs” with the URL below: https://files.seeedstudio.com/arduino/package_seeeduino_boards_index.json\n\n\nNow, navigate to Tools→Board→Board Manager in the top menu, and type in the filter keyword seeed nrf52 in the search box.\nYou will see two installation packages: Seeed nRF52 Boards and Seeed nRF52 mbed-enabled Boards, the differences between these two packages are as follows:\n\nSeeed nRF52 Boards: Friendly for Bluetooth and low-power compatibility, suitable for Bluetooth and low power applications.\nSeeed nRF52 mbed-enabled Boards: Friendly for TinyML support, suitable for making TinyML or Bluetooth-related projects, but not suitable for applications with high low-power requirements.\n\nBecause we will develop a TinyML project, we chose the latest version of the Seeed nRF52 mbed-enabled Boards package. Install it and wait until you see a successful installation prompt in the output window.\n\n\nNow, you can access this device from your Arduino IDE by selecting the development board and serial port, as shown in the figure below.\n\n\nYour development board is now ready to run code on it. Let’s start with Blink - lighting up the LED. Note that the board does not have a regular LED like most Arduino boards. Instead, you will find an RGB LED that can be activated with “reverse logic” (you should apply LOW to activate each of the three separate LEDs). Test your RGB LED with the following code:\nvoid setup() {\n\n  // initialize serial.\n  Serial.begin(115200);\n  while (!Serial);\n  Serial.println(\"Serial Started\");\n  \n  // Pins for the built-in RGB LEDs on the Arduino Nano 33 BLE Sense\n  pinMode(LEDR, OUTPUT);\n  pinMode(LEDG, OUTPUT);\n  pinMode(LEDB, OUTPUT);\n\n  // Note: The RGB LEDs are ON when the pin is LOW and off when HIGH.\n  digitalWrite(LEDR, HIGH);\n  digitalWrite(LEDG, HIGH);\n  digitalWrite(LEDB, HIGH);\n  \n}\n\nvoid loop() {\n  digitalWrite(LEDR, LOW); \n  Serial.println(\"LED RED ON\");\n  delay(1000);              \n  digitalWrite(LEDR, HIGH);    \n  Serial.println(\"LED RED OFF\");\n  delay(1000);     \n\n  digitalWrite(LEDG, LOW); \n  Serial.println(\"LED GREEN ON\"); \n  delay(1000);              \n  digitalWrite(LEDG, HIGH);  \n  Serial.println(\"LED GREEN OFF\");  \n  delay(1000);  \n\n  digitalWrite(LEDB, LOW); \n  Serial.println(\"LED BLUE ON\");  \n  delay(1000);     \n  digitalWrite(LEDB, HIGH);   \n  Serial.println(\"LED BLUE OFF\");   \n  delay(1000);  \n}\n\nGet this code online 🔗  https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/tree/main/Seeed_Xiao_Sense_bilnk_RGB\n\nHere is the result:\n\n\n\n\n4.2.3.2 Testing the Microphone\nThe XIAO nRF52840 Sense has a PDM digital output MEMS microphone. Run the below code for testing it:\n#include &lt;PDM.h&gt;\n\n// buffer to read samples into, each sample is 16-bits\nshort sampleBuffer[256];\n\n// number of samples read\nvolatile int samplesRead;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    // configure the data receive callback\n    PDM.onReceive(onPDMdata);\n\n    // optionally set the gain, defaults to 20\n    // PDM.setGain(30);\n\n    // initialize PDM with:\n    // - one channel (mono mode)\n    // - a 16 kHz sample rate\n    if (!PDM.begin(1, 16000)) {\n        Serial.println(\"Failed to start PDM!\");\n        while (1);\n    }\n}\n\nvoid loop() {\n    // wait for samples to be read\n    if (samplesRead) {\n\n        // print samples to the serial monitor or plotter\n        for (int i = 0; i &lt; samplesRead; i++) {\n            Serial.println(sampleBuffer[i]);\n            // check if the sound value is higher than 500\n            if (sampleBuffer[i]&gt;=500){\n                digitalWrite(LEDR,LOW);\n                digitalWrite(LEDG,HIGH);\n                digitalWrite(LEDB,HIGH);\n            }\n            // check if the sound value is higher than 250 and lower than 500\n            if (sampleBuffer[i]&gt;=250 && sampleBuffer[i] &lt; 500){\n                digitalWrite(LEDB,LOW);\n                digitalWrite(LEDR,HIGH);\n                digitalWrite(LEDG,HIGH);\n            }\n            //check if the sound value is higher than 0 and lower than 250\n            if (sampleBuffer[i]&gt;=0 && sampleBuffer[i] &lt; 250){\n                digitalWrite(LEDG,LOW);\n                digitalWrite(LEDR,HIGH);\n                digitalWrite(LEDB,HIGH);\n            }\n        }\n\n        // clear the read count\n        samplesRead = 0;\n    }\n}\n\nvoid onPDMdata() {\n    // query the number of bytes available\n    int bytesAvailable = PDM.available();\n\n    // read into the sample buffer\n    PDM.read(sampleBuffer, bytesAvailable);\n\n    // 16-bit, 2 bytes per sample\n    samplesRead = bytesAvailable / 2;\n}\nThe above code will continuously capture data to its buffer, displaying it in the Serial Monitor and Plotter:\n\n\nAlso, note that the RGB LED will be set up depending on the intensity of sound.\n\nThe Micrphone will not be used on this project in particular, but it is good to have it tested if it is your first time using the XIAO nRF52840 Sense.\n\n\n\n4.2.3.3 Testing the IMU\nOur tiny device also has integrated a 6-Axis IMU, the LSM6DS3TR-C, a system-in-package 3D digital accelerometer, and a 3D digital gyroscope. For testing, you should first install its library ‘Seeed Arduino LSM6DS3’.\nBefore programming the accelerometer with the Arduino IDE, you must add the necessary library for the sensor. Enter the library address 🔗 https://github.com/Seeed-Studio/Seeed_Arduino_LSM6DS3/ in the browser address bar, go to the GitHub page, click Code→Download ZIP to download the resource pack Seeed_Arduino_LSM6DS3-master.zip to the local area, as shown below.\n\n\nAdd the resource pack Seeed_Arduino_LSM6DS3-master.zip downloaded in the previous step in the menu bar’s Sketch→Include Library→Add .ZIP Library until you see a prompt that the library has been loaded successfully.\n\nRun the test code based on Harvard University’s tinymlx - Sensor Test\nNow, run the following test code based on Harvard University’s tinymlx - Sensor Test.\n#include \"LSM6DS3.h\"\n#include \"Wire.h\"\n\n//Create an instance of class LSM6DS3\nLSM6DS3 xIMU(I2C_MODE, 0x6A);    //I2C device address 0x6A\n\nchar c;\nint sign = 0;\n\nvoid setup() {\n  Serial.begin(115200);\n  while (!Serial);\n\n  // configure the IMU\n  if (xIMU.begin() != 0) {\n      Serial.println(\"Device error\");\n  } else {\n      Serial.println(\"Device OK!\");\n  }\n\n  Serial.println(\"Welcome to the IMU test for the built-in IMU on the XIAO BLE Sense\\n\");\n  Serial.println(\"Available commands:\");\n  Serial.println(\"a - display accelerometer readings in g's in x, y, and z directions\");\n  Serial.println(\"g - display gyroscope readings in deg/s in x, y, and z directions\");\n  Serial.println(\"t - display temperature readings in oC and oF\");\n}\n\nvoid loop() {\n  // Read incoming commands from serial monitor\n  \n  if (Serial.available()) {\n    c = Serial.read();\n    Serial.println(c);\n  }\n\n  if(c == 'a')sign=1;\n  else if(c == 'g')sign=2;\n  else if(c == 't')sign=3;\n  \n  float x, y, z;\n  if (sign ==1) { // testing accelerometer\n      //Accelerometer\n      x = xIMU.readFloatAccelX();\n      y = xIMU.readFloatAccelY();\n      z = xIMU.readFloatAccelZ();      \n      Serial.print(\"\\nAccelerometer:\\n\");\n      Serial.print(\"Ax:\");\n      Serial.print(x);\n      Serial.print(' ');\n      Serial.print(\"Ay:\");\n      Serial.print(y);\n      Serial.print(' ');\n      Serial.print(\"Az:\");\n      Serial.println(z);\n    }\n  else if (sign ==2) { // testing gyroscope\n      //Gyroscope\n      Serial.print(\"\\nGyroscope:\\n\");\n      x = xIMU.readFloatGyroX();\n      y = xIMU.readFloatGyroY();\n      z = xIMU.readFloatGyroZ();      \n      Serial.print(\"wx:\");\n      Serial.print(x);\n      Serial.print(' ');\n      Serial.print(\"wy:\");\n      Serial.print(y);\n      Serial.print(' ');\n      Serial.print(\"wz:\");\n      Serial.println(z);\n    }\n  else if (sign ==3) { // testing thermometer\n       //Thermometer\n      Serial.print(\"\\nThermometer:\\n\");\n      Serial.print(\" Degrees oC = \");\n      Serial.println(xIMU.readTempC(), 0);\n      Serial.print(\" Degrees oF = \");\n      Serial.println(xIMU.readTempF(), 0);\n      delay(1000);\n    }\n}\n\nGet this code online 🔗  https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/blob/main/xiao_test_IMU/xiao_test_IMU.ino\n\nOnce you run the above sketch, open the Serial Monitor:\n\n\nChoose one of the three options to test:\n\na: Accelerometer (see the result on Plotter)\ng: Gyroscope (see the result on Plotter)\nt: Temperature (see the result on Serial Monitor)\n\nThe following images show the result:"
  },
  {
    "objectID": "chapter_4-2.html#the-tinyml-motion-classification-model",
    "href": "chapter_4-2.html#the-tinyml-motion-classification-model",
    "title": "4.2 Anomaly Detection & Motion Classification",
    "section": "4.2.4 The TinyML Motion Classification Model",
    "text": "4.2.4 The TinyML Motion Classification Model\nFor our project, we will simulate mechanical stresses in transport. Our problem will be to classify four classes of movement:\n\nMaritime (pallets in boats)\nTerrestrial (palettes in a Truck or Train)\nLift (Palettes being handled by Fork-Lift)\nIdle (Palettes in Storage houses)\n\n\n\nSo, to start, we should collect data. Then, accelerometers will provide the data on the palette (or container).\n\n\n\n\nFrom the above images, we can see that primarily horizontal movements should be associated with “Terrestrial class,” Vertical movements to “Lift Class,” no activity to “Idle class,” and movent on all three axes to Maritime class.\n\n4.2.4.1 Connecting a Device to the Edge Impulse Studio\nFor data collection, we can have several options. In a real case, we can have our device, for example, connected directly to one container, and the data collected on a file (for example .CSV) and stored on an SD card (via SPI connection) or an offline repo in your computer. Data can also be sent remotely to a nearby repository, such as a mobile phone, using Bluetooth as done in this project: Sensor DataLogger. Once your dataset is collected and stored as a .CSV file, it can be uploaded to the Studio using the CSV Wizard tool.\n\nIn this video, you can learn alternative ways to send data to the Edge Impulse Studio.\n\nIn this project, we should first connect our device to the Edge Impulse Studio for data collection, which will also be used for data pre-processing, model training, testing, and deployment.\n\nFollow the instructions here to install the Node.js and Edge Impulse CLI on your computer.\n\nOnce the XIAO nRF52840 Sense is not a fully supported development board by Edge Impulse, we should use the CLI Data Forwarder to capture data from the accelerometer and send it to the Studio, as shown in this diagram:\n\n\nYour device should be connected to the computer serial and running a code to capture IMU (Accelerometer) data and “print them” on the serial. Further, the Edge Impulse Studio will “capture” them. Run the code below:\n#include \"LSM6DS3.h\"\n#include \"Wire.h\"\n\n//Create an instance of class LSM6DS3\nLSM6DS3 xIMU(I2C_MODE, 0x6A);    //I2C device address 0x6A\n\n#define CONVERT_G_TO_MS2    9.80665f\n#define FREQUENCY_HZ        50\n#define INTERVAL_MS         (1000 / (FREQUENCY_HZ + 1))\n\nstatic unsigned long last_interval_ms = 0;\n\nvoid setup() {\n    Serial.begin(115200);\n    while (!Serial);\n\n    // configure the IMU\n    if (xIMU.begin() != 0) {\n        Serial.println(\"Device error\");\n    } else {\n        Serial.println(\"Device OK!\");\n    }\n\n    Serial.println(\"Data Forwarder - Built-in IMU (Accelerometer) on the XIAO BLE Sense\\n\");\n}\n\nvoid loop() {\n    float x, y, z;\n\n    if (millis() &gt; last_interval_ms + INTERVAL_MS) {\n        last_interval_ms = millis();\n\n        x = xIMU.readFloatAccelX();\n        y = xIMU.readFloatAccelY();\n        z = xIMU.readFloatAccelZ();\n\n        Serial.print(x * CONVERT_G_TO_MS2);\n        Serial.print('\\t');\n        Serial.print(y * CONVERT_G_TO_MS2);\n        Serial.print('\\t');\n        Serial.println(z * CONVERT_G_TO_MS2);\n    }\n}\n\nGet this code online 🔗  https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/blob/main/XIAO_BLE_Sense_Accelerometer_Data_Forewarder/XIAO_BLE_Sense_Accelerometer_Data_Forewarder.ino\n\nGo to the Edge Impulse page and create a project. Next, start the CLI Data Forwarder on your terminal, entering (if it is the first time) the following command:\n\n$ edge-impulse-data-forwarder --clean\nNext, enter your EI credentials, and choose your project, variable, and device names:\n\n\n\nThe Studio can read the sampled frequency as 51Hz instead of the 50Hz previously defined in the code. It is OK.\n\nGo to the Devices section on your EI Project and verify if the device is connected (the dot should be green):\n\n\n\n\n4.2.4.2 Data Collection\nAs discussed before, we should capture data from all four Transportation Classes:\n\nlift (up-down)\nterrestrial (left-right)\nmaritime (zig-zag, etc.)\nidle\n\n\n\nBelow is one sample (10 seconds of raw data):\n\n\nYou can capture, for example, around 2 minutes (twelve samples of 10 seconds) for each of the four classes (a total of 8 minutes of data). Using the three dots menu after each one of the samples, select 2 of them, reserving them for the Test set. Alternatively, you can use the automatic Train/Test Split tool on the Danger Zone of Dashboard tab.\n\n\n\nOnce you have captured your dataset, you can explore it in more detail using the Data Explorer, a visual tool to find outliers or mislabeled data (helping to correct them). The data explorer first tries to extract meaningful features from your data (by applying signal processing and neural network embeddings) and then uses a dimensionality reduction algorithm such as PCA or t-SNE to map these features to a 2D space. This gives you a one-look overview of your complete dataset.\n\n\n\n4.2.4.3 Data Pre-Processing\nData pre-processing is extracting features from the dataset captured with the accelerometer, which involves processing and analyzing the raw data. Accelerometers measure the acceleration of an object along one or more axes (typically three, denoted as X, Y, and Z). These measurements can be used to understand various aspects of the object’s motion, such as movement patterns and vibrations.\nRaw accelerometer data can be noisy and contain errors or irrelevant information. Preprocessing steps, such as filtering and normalization, can clean and standardize the data, making it more suitable for feature extraction. In our case, we should divide the data into smaller segments or windows. This can help focus on specific events or activities within the dataset, making feature extraction more manageable and meaningful. The window size and overlap (window increase) choice depend on the application and the frequency of the events of interest. As a thumb rule, we should try to capture a couple of “cycles of data”.\n\nWith a sampling rate (SR) of 50Hz and a window size of 2 seconds, we will get 100 samples per axis, or 300 in total (3 axis x 2 seconds x 50 samples). We will slide this window every 200ms, creating a larger dataset where each instance has 300 raw features.\n\n\nOnce the data is preprocessed and segmented, you can extract features that describe the motion’s characteristics. Some typical features extracted from accelerometer data include: - Time-domain features describe the data’s statistical properties within each segment, such as mean, median, standard deviation, skewness, kurtosis, and zero-crossing rate. - Frequency-domain features are obtained by transforming the data into the frequency domain using techniques like the Fast Fourier Transform (FFT). Some typical frequency-domain features include the power spectrum, spectral energy, dominant frequencies (amplitude and frequency), and spectral entropy. - Time-frequency domain features combine the time and frequency domain information, such as the Short-Time Fourier Transform (STFT) or the Discrete Wavelet Transform (DWT). They can provide a more detailed understanding of how the signal’s frequency content changes over time.\nIn many cases, the number of extracted features can be large, which may lead to overfitting or increased computational complexity. Feature selection techniques, such as mutual information, correlation-based methods, or principal component analysis (PCA), can help identify the most relevant features for a given application and reduce the dimensionality of the dataset. The Studio can help with such feature importance calculations.\nEI Studio Spectral Features\nData preprocessing is a challenging area for embedded machine learning. Still, Edge Impulse helps overcome this with its digital signal processing (DSP) preprocessing step and, more specifically, the Spectral Features Block.\nOn the Studio, the collected raw dataset will be the input of a Spectral Analysis block, which is excellent for analyzing repetitive motion, such as data from accelerometers. This block will perform a DSP (Digital Signal Processing), extracting features such as FFT or Wavelets.\nFor our project, once the time signal is continuous, we should use FFT with, for example, a length of [32].\nThe per axis/channel Time Domain Statistical features are:\n\nRMS: 1 feature\nSkewness: 1 feature\nKurtosis: 1 feature\n\nThe per axis/channel Frequency Domain Spectral features are:\n\nSpectral Power: 16 features (FFT Length/2)\nSkewness: 1 feature\nKurtosis: 1 feature\n\nSo, for an FFT length of 32 points, the resulting output of the Spectral Analysis Block will be 21 features per axis (a total of 63 features).\n\nYou can learn more about how each feature is calculated by downloading the notebook Edge Impulse - Spectral Features Block Analysis TinyML under the hood: Spectral Analysis or opening it directly on Google CoLab.\n\nThose 63 features will be the Input Tensor of a Neural Network Classifier.\n\n\n4.2.4.4 Model Design\nOur classifier will be a Dense Neural Network (DNN) that will have 63 neurons on its input layer, two hidden layers with 20 and 10 neurons, and an output layer with four neurons (one per each class), as shown here:\n\n\n\n4.2.4.5 Impulse Design\nA complete Impulse comprises three primary building blocks: the input block - which obtains the raw data, the processing block - which extracts features, and the learning block - which classifies the data. The following image shows the interface when the three building blocks still need to be added, and our machine-learning pipeline will be implemented by adding these three blocks.\n\n\nImpulse obtains raw data through the input block, uses the processing block to extract features, and then uses the learning block to classify new data. In our continuous action recognition, the added blocks include:\n\n1. Adding the input block: Time Series Data\nClick the “Add an Input Block” button and select Time Series Data in the pop-up window as shown below to match the sensor data type we collected.\n\n\nAs shown in the figure below, set the Window Size to 2000 ms (2 seconds), the Window Increase to 80 milliseconds, and the Frequency to 51 Hz based on the calculations we made in the data preprocessing section on the Time Series Data block that appears.\n\n\n\n\n2. Adding the processing block: Spectral Analysis\nClick the “Add a Processing Block” button and select Spectral Analysis in the pop-up window as shown below to match our motion analysis task type.\n\n\nThe effect after adding the processing block is shown in the figure below.\n\n\n\n\n3. Adding the learning block: Classification\nClick the “Add Learning Block” button and select Classification in the pop-up window as shown below to match our motion analysis task type.\n\n\nThe interface of Impulse design after addition is shown in the figure below, and now the machine learning pipeline has been built.\n\n\nIn addition, we can also use a second model - K-means, which can be used for anomaly detection. If we imagine that we can treat our known classes as clusters, then any sample that does not fit into it might be an anomaly (for example, a container falling into the sea when the ship is at sea).\n\nFor this, we can use the same input tensor entering the NN classifier as the input to the K-means model:\n\nClick the “Add Learning Block” button again and select Anomaly Detection (K-means) in the pop-up window below.\n\n\nThe final Impulse design is as shown in the figure below, click the Save Impulse button on the far right.\n\n\n\n\n\n4.2.4.6 Generating features\nAt this point in our project, we have defined the pre-processing method and the model designed. Now, it is time to have the job done. First, let’s take the raw data (time-series type) and convert it to tabular data. Go to the Spectral Features tab, select Save Parameters,\n\n\nand at the top menu, select Generate Features option and Generate Features button:\n\n\nEach 2-second window data will be converted into one data point of 63 features. The Feature Explorer will show those data in 2D using UMAP.\n\nUniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction.\n\nWith the visualization, it is possible to verify that the classes present an excellent separation, which indicates that the classifier should work well.\n\nOptionally you can analyze how important each one of the features is for one class compared with other classes.\n\n\n\n4.2.4.7 Training\nOur model has four layers, as shown below:\n\nAs hyperparameters, we will use a Learning Rate of 0.005 and 20% of data for validation for 30 epochs.\n\n\n\nimage.png\n\n\nAfter training, we can see that the accuracy is 100%.\n\n\n\nimage.png\n\n\nIf a K-means block for anomaly detection has been added during model design, an additional section for Anomaly Detection will appear under the Impulse Design column on the left, as shown in the image below. Once inside the Anomaly Detection section, click [Select Suggested Axes], and the system will automatically make selections based on previously calculated important features. Then click on the [Start Training] button to begin the training. Results will be output in the Anomaly Explorer on the right after completion.\n\n\nAt this point, we have completed the basic machine learning training process.\n\n\n4.2.4.8 Testing\nUsing the 20% of data set aside during the data collection phase, we can verify the model’s performance with unknown data. As shown in the image below, click on the Model Testing section on the left side of the Edge Impulse interface. Next to the [Classify All] button, there is an icon with three dots, click on it to open the Set Confidence Thresholds popup window. Here, you can set confidence thresholds for the results of the two learning blocks. We should define an acceptable threshold for results considered as anomalies. If a result is not 100% (which is often the case) but is within the threshold range, it is still usable.\n\n\nPress the Classify All button to start the model testing. The model test results will be displayed upon completion, as shown in the image below.\n\n\n\n\n4.2.4.9 Live Classification\nOnce the model is obtained, you should use the opportunity to test the Live Classification when your device is still connected to the Edge Impulse Studio. As shown in the image below, click on the Live Classification section on the left side of the Edge Impulse interface, then click the [Start Sampling] button.\n\n\nAt this time, you can, for example, shake the XIAO, the process is the same as the sampling; wait a few seconds, and the classification results will be given. As shown in the image below, I shook the XIAO vigorously, and the model unhesitatingly inferred that the entire process was anomalous.\n\n\nTry now with the same movements used during data capture. The result should match the class used for training.\n\n⚠️ Note: Here, you will capture real data with your device and upload it to the Edge Impulse Studio, where the trained model will be used for inference (though the model is not in your device).\n\n\n\n4.2.4.10 Deployment\nNow it is time for magic˜! The Studio will package all the needed libraries, preprocessing functions, and trained models, downloading them to your computer. You should select the option Arduino Library and at the bottom, select Quantized (Int8) and Build.\n\nA Zip file will be created and downloaded to your computer.\n\n\nOn your Arduino IDE, go to Sketch tab and select the option Add .ZIP Library.\n\n\nand Choose the.zip file downloaded by the Studio:\n\n\n\n\n4.2.4.11 Inference\nNow, it is time for a real test. We will make inferences wholly disconnected from the Studio. Let’s change one of the code examples created when you deploy the Arduino Library.\nIn your Arduino IDE, go to File/Examples tab and look for your project, and on examples, select nano_ble_sense_accelerometer:\n\n\nOf course, the Arduino Nano BLE 33 differs from your board, the XIAO, but we can have the code working with only a few changes. For example, at the beginning of the code, you have the library related to Arduino Sense IMU:\n/* Includes -------------------------------------------------------------- */\n#include &lt;XIAO_BLE_Sense_-_Motion_Classification_inferencing.h&gt;\n#include &lt;Arduino_LSM9DS1.h&gt;\nChange the “includes” portion with the code related to the XIAO nRF52840 Sense IMU:\n/* Includes -------------------------------------------------------------- */\n#include &lt;XIAO_BLE_Sense_-_Motion_Classification_inferencing.h&gt;\n#include \"LSM6DS3.h\"\n#include \"Wire.h\"\n\n//Create an instance of class LSM6DS3\nLSM6DS3 xIMU(I2C_MODE, 0x6A);    //I2C device address 0x6A\nOn the setup function, initiate the IMU using the name that you stated before:\nif (xIMU.begin() != 0) {\n    ei_printf(\"Failed to initialize IMU!\\r\\n\");\n}\nelse {\n    ei_printf(\"IMU initialized\\r\\n\");\n}\nAt the loop function, the buffers: buffer[ix], buffer[ix + 1] and buffer[ix + 2] will receive the 3 axis data captured by the accelerometer. On the original code, you have the line:\nIMU.readAcceleration(buffer[ix], buffer[ix + 1], buffer[ix + 2]);\nChange it with this block of code:\nbuffer[ix]     = xIMU.readFloatAccelX();\nbuffer[ix + 1] = xIMU.readFloatAccelY();\nbuffer[ix + 2] = xIMU.readFloatAccelZ();\n\n\nGet this code online 🔗  https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/blob/main/XIAO_BLE_Sense_accelerometer/XIAO_BLE_Sense_accelerometer.ino\n\nAnd that is it! You can now upload the code to your device and proceed with the inferences.\nYou can see the result of the inference of each class on the images:\n\n\n\n\n\n\n\nPost-processing\nNow that we know the model is working since it detects the movements, we suggest that you modify the code to see the result with the XIAO completely offline (disconnected from the PC and powered by a battery, a power bank, or an independent 5V power supply).\nThe idea is that if one specific movement is detected, a particular LED could be lit. For example, if terrestrial is detected, the Green LED will light; if maritime, the Red LED will light, if it is a lift, the Blue LED will light; and if no movement is detected (idle), the LEDs will be OFF. You can also add a condition when an anomaly is detected, in this case, for example, a white color can be used (all e LEDs light simultaneously).\n\n\n4.2.4.12 Conclusion\nThe Seeed Studio XIAO nRF52840 Sense is a giant tiny device! It is powerful, trustworthy, not expensive, low power, and has suitable sensors to be used on the most common embedded machine learning applications. Even though Edge Impulse does not officially support XIAO nRF52840 Sense, we also realized that it could be easily connected with the Studio.\n\nOn the GitHub repository, you will find the last version of the codes: Seeed-XIAO-BLE-Sense.\n\nThe applications for motion classification and anomaly detection are extensive, and the XIAO is well-suited for scenarios where low power consumption and edge processing are advantageous. Its small form factor and efficiency in processing make it an ideal choice for deploying portable and remote applications where real-time processing is crucial and connectivity may be limited.\n\n\n4.2.4.13 Case Applications\nBefore we finish, consider that Movement Classification and Object Detection can be utilized in many applications across various domains. Here are some of the potential applications:\n\nIndustrial and Manufacturing\n\nPredictive Maintenance: Detecting anomalies in machinery motion to predict failures before they occur.\nQuality Control: Monitoring the motion of assembly lines or robotic arms for precision assessment and deviation detection from the standard motion pattern.\nWarehouse Logistics: Managing and tracking the movement of goods with automated systems that classify different types of motion and detect anomalies in handling.\n\n\n\nHealthcare\n\nPatient Monitoring: Detecting falls or abnormal movements in the elderly or those with mobility issues.\nRehabilitation: Monitoring the progress of patients recovering from injuries by classifying motion patterns during physical therapy sessions.\nActivity Recognition: Classifying types of physical activity for fitness applications or patient monitoring.\n\n\n\nConsumer Electronics\n\nGesture Control: Interpreting specific motions to control devices, such as turning on lights with a hand wave.\nGaming: Enhancing gaming experiences with motion-controlled inputs.\n\n\n\nTransportation and Logistics\n\nVehicle Telematics: Monitoring vehicle motion for unusual behavior such as hard braking, sharp turns, or accidents.\nCargo Monitoring: Ensuring the integrity of goods during transport by detecting unusual movements that could indicate tampering or mishandling.\n\n\n\nSmart Cities and Infrastructure\n\nStructural Health Monitoring: Detecting vibrations or movements within structures that could indicate potential failures or maintenance needs.\nTraffic Management: Analyzing the flow of pedestrians or vehicles to improve urban mobility and safety.\n\n\n\nSecurity and Surveillance\n\nIntruder Detection: Detecting motion patterns typical of unauthorized access or other security breaches.\nWildlife Monitoring: Detecting poachers or abnormal animal movements in protected areas.\n\n\n\nAgriculture\n\nEquipment Monitoring: Tracking the performance and usage of agricultural machinery.\nAnimal Behavior Analysis: Monitoring livestock movements to detect behaviors indicating health issues or stress.\n\n\n\nEnvironmental Monitoring\n\nSeismic Activity: Detecting irregular motion patterns that precede earthquakes or other geologically relevant events.\nOceanography: Studying wave patterns or marine movements for research and safety purposes."
  },
  {
    "objectID": "chapter_4-3.html#things-used-in-this-project",
    "href": "chapter_4-3.html#things-used-in-this-project",
    "title": "4.3 Sound Classification (KWS)",
    "section": "4.3.1 Things used in this project",
    "text": "4.3.1 Things used in this project\n\nHardware components\n\nSeeed Studio XIAO nRF52840 Sense × 1 \n\n\n\nSeeed Studio Seeeduino XIAO Expansion board × 1 \n\n\n\n\nSoftware apps and online services\n\nArduino IDE \n\n\n\nEdge Impulse Studio"
  },
  {
    "objectID": "chapter_4-3.html#introduction",
    "href": "chapter_4-3.html#introduction",
    "title": "4.3 Sound Classification (KWS)",
    "section": "4.3.2 Introduction",
    "text": "4.3.2 Introduction\nIn the last section, Anomaly Detection & Motion Classification, we explored Embedded Machine Learning, or simply TinyML, running on the Seeed XIAO nRF52840 Sense. Besides installing and testing the device, we explored motion classification using actual data signals from its onboard accelerometer. This new project will use the same XIAO nRF52840 Sense to classify sound, explicitly working as “Key Word Spotting” (KWS). A KWS is a typical TinyML application and an essential part of a voice assistant.\n\nBut how does a voice assistant work?\n\nTo start, it is essential to realize that Voice Assistants on the market, like Google Home or Amazon Echo-Dot, only react to humans when they are “waked up” by particular keywords such as ” Hey Google” on the first one and “Alexa” on the second.\n\n\nIn other words, recognizing voice commands is based on a multi-stage model or Cascade Detection. \nStage 1: A smaller microprocessor inside the Echo Dot or Google Home continuously listens to the sound, waiting for the keyword to be spotted. For such detection, a TinyML model at the edge is used (KWS application).\nStage 2: Only when triggered by the KWS application on Stage 1 is the data sent to the cloud and processed on a larger model.\nThe video below shows an example of a Google Assistant being programmed on a Raspberry Pi (Stage 2), with an Arduino Nano 33 BLE as the tinyML device (Stage 1): https://youtu.be/e_OPgcnsyvM\n\nTo explore the above Google Assistant project, please see the tutorial: Building an Intelligent Voice Assistant From Scratch."
  },
  {
    "objectID": "chapter_4-3.html#the-kws-project",
    "href": "chapter_4-3.html#the-kws-project",
    "title": "4.3 Sound Classification (KWS)",
    "section": "4.3.3 The KWS Project",
    "text": "4.3.3 The KWS Project\n\n\nOur KWS application will recognize three classes of sound:\n\nKeyword 1: UNIFEI\nKeyword 2: IESTI\n“SILENCE” (no keywords spoken, only background noise is present)\n\n\nOptionally, for real-world projects, it is advised to include different words than keywords 1 and 2 in the class “Silence” (or Background) or even create an extra class with such words (for example a class “others”).\n\n\n4.3.3.1 The Machine Learning Workflow\nThe main component of the KWS application is its model. So, we must train such a model with our specific keywords:\n\n\n\n\n4.3.3.2 Dataset\nThe critical component of Machine Learning Workflow is the dataset. Once we have decided on specific keywords (UNIFEI and IESTI), all datasets should be created from zero. When working with accelerometers, creating a dataset with data captured by the same type of sensor was essential. In the case of sound, it is different because of what we will classify as audio data.\n\nThe critical difference between sound and audio is the type of energy. Sound is mechanical perturbation (longitudinal sound waves) that propagate through a medium, causing variations of pressure in it. Audio is an electrical (analog or digital) signal representing sound.\n\nThe sound waves should be converted to audio data when we speak a keyword. The conversion should be done by sampling the signal generated by the microphone in 16KHz with a 16-bit depth.\n\nSo, any device that can generate audio data with this basic specification (16Khz/16bits) will work fine. As a device, we can use the proper XIAO nRF52840 Sense, a computer, or even your mobile phone.\n\n\n4.3.3.3 Capturing online Audio Data with Edge Impulse and a smartphone\nIn the TinyML Made Easy: Anomaly Detection & Motion Classification section, we learned how to install and test our device using the Arduino IDE and connect it to Edge Impulse Studio for data capturing. For that, we use the EI CLI function Data Forwarder, but according to Jan Jongboom, Edge Impulse CTO, audio goes too fast for the data forwarder to be captured. If you have PCM data already, then turning it into a WAV file and uploading it with the uploader is the easiest. With accelerometers, our sample frequency was around 50Hz, with audio being 16KHz.\nSo, we can not connect the XIAO directly to the Studio. But we can capture sound using any smartphone connected to the Studio online.\n\nWe will not explore this option here, but you can easily follow the EI documentation and tutorial.\n\n\n\n4.3.3.4 Capturing Audio Data with the XIAO nRF52840 Sense\nThe easiest way to capture audio and save it locally as a .wav file is using an expansion board for the XIAO family of devices, the Seeed Studio XIAO Expansion board.\n\n\n\n\n\n\n\n\nThis expansion board enables the building of prototypes and projects easily and quickly, using its rich peripherals such as OLED Display, SD Card interface, RTC, passive buzzer, RESET/User button, 5V servo connector, and multiple data interfaces.\nThis project will focus on classifying keywords, and the MicroSD card available on the device will be very important in helping us with data capture.\n\nSaving recorded audio from the microphone on an SD card\nConnect the XIAO nRF52840 Sense on the Expansion Board and insert an SD card into the SD card slot at the back. &gt; The SD Card should be pre-formated as FAT or exFAT.\n\n\nNext, download the Seeed_Arduino_FS Library as a zip file:\n\n\nAnd install the downloaded library: Seeed_Arduino_Mic-master.zip on your Arduino IDE: Sketch -&gt; Include Library -&gt; Add .ZIP Library...\n\n\nNext, navigate to File &gt; Examples &gt; Seeed Arduino Mic &gt; mic_Saved_OnSDcard to open the sketch: mic_Saved_OnSDcard.\nEach time you press the reset button, a 5 seconds audio sample is recorded and saved on the SD card. I changed the original file to add LEDs to help during the recording process as below:\n\nDuring the time that LED Red is ON is possible to record ==&gt; RECORD\nDuring the file writing process, LED Red is OFF ==&gt; WAIT\nWhen finished writing, LED Green is ON ==&gt; Press Reset Button once and wait for LED Red ON again, and proceed with a new sample recording\n\nI realized that sometimes at the beginning and the end of each sample, a “spike” was recorded, so I cut the initial 300ms from each 5s sample. The spike verified at the end always happened after the recording process and should be eliminated on Edge Impulse Studio before training. Also, I increased the microphone gain to 30 dB.\nThe complete file (Xiao_mic_Saved_OnSDcard.ino) can be found on the Git Hub (3_KWS): Seeed-XIAO-BLE-Sense.\nDuring the recording process, the.wav file names are shown on Serial Monitor:\n\n\nTake the SD card from the Expansion Board and insert it into your computer:\n\n\nThe files are ready to be uploaded to Edge Impulse Studio\n\n\n\n4.3.3.5 Capturing (offline) Audio Data with a smartphone or PC\nAlternatively, you can use your PC or smartphone to capture audio data with a sampling frequency 16KHz and a bit depth of 16 Bits. A good app for that is Voice Recorder Pro (IOS). Save your record as .wav files and send them to your computer.\n\n\n\nNote that any smartphone app can be used for audio recording or even your computer, for example using Audacity.\n\n\n\n4.3.3.6 Training model with Edge Impulse Studio\nWhen the raw dataset is created, you should initiate a new project at Edge Impulse Studio:\n\n\nOnce the project is created, go to the Data Acquisition section and select the Upload Existing Data tool. Choose the files to be uploaded, for example, I started uploading the samples recorded with the XIAO nRF52840 Sense:\n\n\nThe samples will now appear in the Data acquisition section:\n\n\nClick on three dots after the sample name and select Split sample. Once inside de tool, split the data into 1-second records (try to avoid start and end portions):\n\n\nThis procedure should be repeated for all samples. After that, upload other class samples (IESTI and SILENCE) captured with the XIAO and your PC or smartphone.\n\nNote: For longer audio files (minutes), first, split into 10-second segments and after that, use the tool again to get the final 1-second splits.\n\nIn the end, the dataset has around 70 1-second samples for each class:\n\n\nNow, you should split that dataset into Train/Test. You can do it manually (using the three dots menu, moving samples individually) or using Perform Train / Test Split on Dashboard - Danger Zone.\n\n\nWe can optionally check all datasets using the tab Data Explorer. The data points seem apart, which means that the classification model should work:\n\n\n\n\n4.3.3.7 Creating Impulse (Pre-Process / Model definition)\nAn impulse takes raw data, uses signal processing to extract features, and then uses a learning block to classify new data.\n\n\nFirst, we will take the data points with a 1-second window, augmenting the data, sliding that window each 500ms. Note that the option zero-point pad is set. It is important to fill with zeros samples smaller than 1 second in some cases, I reduced the 1000 ms window on the split tool to avoid noises and spikes.\nEach 1-second audio sample should be pre-processed and converted to an image (for example, 13 x 50 x 1). We will use Audio (MFCC), which extracts features from audio signals using Mel Frequency Cepstral Coefficients, which are well suited for the human voice, which is our case here.\n\n\nNext, we select the Classification block to build our model from scratch using a Convolution Neural Network (CNN).\n\n\n4.3.3.8 Pre-Processing (MFCC)\nThe next step is to create the images to be trained in the next phase:\n\n\nWe will keep the default parameter values. We do not spend much memory to pre-process data (only 17KB), but the processing time is relatively high (177 ms for a Cortex-M4 CPU as our XIAO). Save parameters and generate features:\n\n\nGoing under the hood\nTo understand better how the raw sound is preprocessed, look at the Feature Engineering for Audio Classification chapter. You can play with the MFCC features generation by downloading this notebook from GitHub or Opening it In Colab.\n\n\n4.3.3.9 Model Design and Training\nWe will use a simple Convolution Neural Network (CNN) model, tested with 1D and 2D convolutions. The basic architecture has two blocks of Convolution + MaxPooling ([8] and [16] filters, respectively) and a Dropout of [0.25] for the 1D and [0.5] for the 2D. For the last layer, after Flattening, we have [3] neurons, one for each class:\n\nAs hyper-parameters, we will have a Learning Rate of [0.005] and a model trained by [100] epochs. We will also include a data augmentation method based on SpecAugment. We trained the 1D and the 2D models with the same hyperparameters. The 1D architecture had a better overall result (91.1% accuracy) when compared with 88% of the 2D, so we will use the 1D.\n\nUsing 1D convolutions is more efficient because it requires fewer parameters than 2D convolutions, making them more suitable for resource-constrained environments.\n\n\n\n\nIf you want to understand what is happening “under the hood,” you can download the pre-processed dataset (MFCC training data) from the Dashboard tab and run this Jupyter Notebook, playing with the code or Opening it In Colab. You should adapt the notebook for your data and model. For example, you can analyze the accuracy by each epoch:\n\n\n\n\n\n4.3.3.10 Testing\nTesting the model with the data put apart before training (Test Data), we got an accuracy of 75%. Based on the small amount of data used, it is OK, but I strongly suggest increasing the number of samples.\n\n\nCollecting more data, the Test accuracy moved up around 5%, going from 75% to around 81%:\n\n\nNow, we can proceed with the project, but before deployment on our device, it is possible to perform Live Classification using a Smart Phone, confirming that the model is working with live and real data:\n\n\n\n\n4.3.3.11 Deploy and Inference\nThe Studio will package all the needed libraries, preprocessing functions, and trained models, downloading them to your computer. You should select the option Arduino Library and at the bottom, choose Quantized (Int8) and [Build].\n\n\nA Zip file will be created and downloaded to your computer:\n\nOn your Arduino IDE, go to the Sketch tab and select the option Add .ZIP Library.\n\n\nAnd Choose the.zip file downloaded by the Studio:\n\n\nNow, it is time for a real test. We will make inferences wholly disconnected from the Studio. Let’s change one of the code examples created when you deploy the Arduino Library.\nIn your Arduino IDE, go to the File/Examples tab and look for your project, and on examples, select nano_ble33_sense_microphone_continuous:\n\n\nEven though the XIAO is not the same as the Arduino, both have the same MPU and PDM microphone, so the code works as it is. Upload the sketch to XIAO and open the Serial Monitor. Start talking about one or another Keyword and confirm that the model is working correctly:\n\n\n\n\n4.3.3.12 Postprocessing\nNow that we know that the model is working by detecting our two keywords, let’s modify the code so we can see the result with the XIAO nRF52840 Sense completely offline (disconnected from the PC and powered by a battery).\nThe idea is that whenever the keyword UNIFEI is detected, the LED Red will be ON; if it is IESTI, LED Green will be ON, and if it is SILENCE (No Keyword), both LEDs will be OFF.\n\nIf you have the XIAO nRF52840 Sense installed on the Expansion Board, we can display the class label and its probability. Otherwise, use only the LEDs.\n\nLet’s go by Parts: Installing and Testing the SSD Display In your Arduino IDE, Install the u8g2 library and run the below code for testing:\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;\n#include &lt;Wire.h&gt;\n\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(PIN_WIRE_SCL, PIN_WIRE_SDA, U8X8_PIN_NONE);   \n\nvoid setup(void) {\n    u8x8.begin();\n    u8x8.setFlipMode(0);   // set number from 1 to 3, the screen word should rotate 180\n}\n\nvoid loop(void) {\n    u8x8.setFont(u8x8_font_chroma48medium8_r);\n    u8x8.setCursor(0, 0);\n    u8x8.print(\"Hello World!\");\n}\nAnd you should see the “Hello World” displayed on the SSD:\n\n\nNow, let’s create some functions that, depending on the values of pred_index and pred_value, will trigger the proper LED and display the class and probability. The code below will simulate some inference results and present them on display and LEDs:\n/* Includes ---------------------------------------------------------------- */\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;\n#include &lt;Wire.h&gt;\n\n#define NUMBER_CLASSES 3\n\n/** OLED */\nU8X8_SSD1306_128X64_NONAME_HW_I2C oled(PIN_WIRE_SCL, PIN_WIRE_SDA, U8X8_PIN_NONE);  \n\nint pred_index = 0;     \nfloat pred_value = 0; \nString lbl = \" \";\n\n\nvoid setup() {\n    pinMode(LEDR, OUTPUT);\n    pinMode(LEDG, OUTPUT);\n    pinMode(LEDB, OUTPUT);\n\n    digitalWrite(LEDR, HIGH);\n    digitalWrite(LEDG, HIGH);\n    digitalWrite(LEDB, HIGH);\n\n    oled.begin();\n    oled.setFlipMode(2);\n    oled.setFont(u8x8_font_chroma48medium8_r);\n    oled.setCursor(0, 0);\n    oled.print(\" XIAO Sense KWS\");\n}\n\n/**\n* @brief      turn_off_leds function - turn-off all RGB LEDs\n*/\nvoid turn_off_leds(){\n    digitalWrite(LEDR, HIGH);\n    digitalWrite(LEDG, HIGH);\n    digitalWrite(LEDB, HIGH);\n}\n\n/**\n* @brief      Show Inference Results on OLED Display\n*/\nvoid display_oled(int pred_index, float pred_value){\n    switch (pred_index){\n        case 0:\n            turn_off_leds();\n            digitalWrite(LEDG, LOW);\n            lbl = \"IESTI  \" ;\n            break;\n\n        case 1:\n            turn_off_leds();\n            lbl = \"SILENCE\";\n            break;\n\n        case 2:\n            turn_off_leds();\n            digitalWrite(LEDR, LOW);\n            lbl = \"UNIFEI \";\n            break;\n    }\n    oled.setCursor(0, 2);\n    oled.print(\"      \");\n    oled.setCursor(2, 4);\n    oled.print(\"Label:\");\n    oled.print(lbl);\n    oled.setCursor(2, 6);\n    oled.print(\"Prob.:\");\n    oled.print(pred_value);\n}\n\nvoid loop() {\n    for (int i = 0; i &lt; NUMBER_CLASSES; i++) { \n        pred_index = i;     \n        pred_value = 0.8;   \n        display_oled(pred_index, pred_value);\n        delay(2000);\n    }\n}\nRunning the above code, you should get the below result:\n\n\nYou should merge the above code (Initialization and functions) with the nano_ble33_sense_microphone_continuous.ino you initially used to test your model. Also, you should include the below code on loop() between the lines:\nei_printf(\": \\n\");\n...\n#if EI_CLASSIFIER_HAS_ANOMALY == 1\nAnd replacing the original function to print inference results on the Serial Monitor:\nint pred_index = 0;     // Initialize pred_index\nfloat pred_value = 0;   // Initialize pred_value\n\nfor (size_t ix = 0; ix &lt; EI_CLASSIFIER_LABEL_COUNT; ix++) {\n    ei_printf(\"    %s: %.5f\\n\", result.classification[ix].label, result.classification[ix].value);\n    if (result.classification[ix].value &gt; pred_value){\n        pred_index = ix;\n        pred_value = result.classification[ix].value;\n    }\n}\ndisplay_oled(pred_index, pred_value);\nHere you can see how the final project is: https://youtu.be/1ex88hSqqyI\n\nThe complete code can be found on the GitHub (3_KWS): Seeed-XIAO-BLE-Sense.\n\n\n\n4.3.3.13 Conclusion\nThe Seeed XIAO nRF52840 Sense is really a giant tiny device! However, it is powerful, trustworthy, not expensive, low power, and has suitable sensors to be used on the most common embedded machine learning applications such as movement and sound.\nEven though Edge Impulse does not officially support XIAO nRF52840 Sense (yet!), we also realized that it could use Studio for training and deployment.\n\nOn the GitHub repository, you will find the last version of the codes in the 3_KWS folder: Seeed-XIAO-BLE-Sense\n\nBefore we finish, consider that Sound Classification is more than just voice. For example, you can develop TinyML projects around sound in several areas as:\n\nSecurity (Broken Glass detection)\nIndustry (Anomaly Detection)\nMedical (Snore, Toss, Pulmonary diseases)\nNature (Beehive control, insect sound)"
  },
  {
    "objectID": "chapter_4-4.html#things-used-in-this-project",
    "href": "chapter_4-4.html#things-used-in-this-project",
    "title": "4.4 Image Classification",
    "section": "4.4.1 Things used in this project",
    "text": "4.4.1 Things used in this project\n\n4.4.1.1 Hardware components\n\nSeeed Studio Seeed XIAO ESP32S3 Sense x 1 \n\n\n4.4.2 Software apps and online services\n\n\nArduino IDE\n Edge Impulse Studio"
  },
  {
    "objectID": "chapter_4-4.html#introduction",
    "href": "chapter_4-4.html#introduction",
    "title": "4.4 Image Classification",
    "section": "4.4.2 Introduction",
    "text": "4.4.2 Introduction\nMore and more, we are facing an artificial intelligence (AI) revolution where, as stated by Gartner, Edge AI has a very high impact potential, and it is for now!\n\nIn the “bull-eye” of emerging technologies, radar is the Edge Computer Vision, and when we talk about Machine Learning (ML) applied to vision, the first thing that comes to mind is Image Classification, a kind of ML “Hello World”!\nSeeed Studio released a new affordable development board, the XIAO ESP32S3 Sense, which integrates a camera sensor, digital microphone, and SD card support. Combining embedded ML computing power and photography capability, this development board is a great tool to start with TinyML (intelligent voice and vision AI).\n\nXIAO ESP32S3 Sense Main Features\n\nPowerful MCU Board: Incorporate the ESP32S3 32-bit, dual-core, Xtensa processor chip operating up to 240 MHz, mounted multiple development ports, Arduino / MicroPython supported\nAdvanced Functionality: Detachable OV2640 camera sensor for 1600 * 1200 resolution, compatible with OV5640 camera sensor, integrating an additional digital microphone\nElaborate Power Design: Lithium battery charge management capability offer four power consumption model, which allows for deep sleep mode with power consumption as low as 14μA\nGreat Memory for more Possibilities: Offer 8MB PSRAM and 8MB FLASH, supporting SD card slot for external 32GB FAT memory\nOutstanding RF performance: Support 2.4GHz Wi-Fi and BLE dual wireless communication, support 100m+ remote communication when connected with U.FL antenna\nThumb-sized Compact Design: 21 x 17.5mm, adopting the classic form factor of XIAO, suitable for space-limited projects like wearable devices\n\n\nBelow is the general board pinout:\n\n\nFor more details, please refer to the Seeed Studio WiKi page:  https://wiki.seeedstudio.com/xiao_esp32s3_getting_started/"
  },
  {
    "objectID": "chapter_4-4.html#installing-the-xiao-esp32s3-sense-on-arduino-ide",
    "href": "chapter_4-4.html#installing-the-xiao-esp32s3-sense-on-arduino-ide",
    "title": "4.4 Image Classification",
    "section": "4.4.3 Installing the XIAO ESP32S3 Sense on Arduino IDE",
    "text": "4.4.3 Installing the XIAO ESP32S3 Sense on Arduino IDE\nOn Arduino IDE, navigate to File &gt; Preferences, and fill in the URL:\nhttps://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_dev_index.json\non the field ==&gt; Additional Boards Manager URLs\n\nNext, open boards manager. Go to Tools &gt; Board &gt; Boards Manager… and enter with esp32. Select and install the most updated and stable package (avoid alpha versions) :\n\n\n⚠️ Attention\nAlpha versions (for example, 3.x-alpha) do not work correctly with the XIAO and Edge Impulse. Use the last stable version (for example, 2.0.11) instead.\n\nOn Tools, select the Board (XIAO ESP32S3):\n\nLast but not least, select the Port where the ESP32S3 is connected.\nThat is it! The device should be OK. Let’s do some tests."
  },
  {
    "objectID": "chapter_4-4.html#testing-the-board-with-blink",
    "href": "chapter_4-4.html#testing-the-board-with-blink",
    "title": "4.4 Image Classification",
    "section": "4.4.4 Testing the board with BLINK",
    "text": "4.4.4 Testing the board with BLINK\nThe XIAO ESP32S3 Sense has a built-in LED that is connected to GPIO21. So, you can run the blink sketch as it (using the LED_BUILTIN Arduino constant) or by changing the Blink sketch accordantly:\n#define LED_BUILT_IN 21 \n\nvoid setup() {\n  pinMode(LED_BUILT_IN, OUTPUT); // Set the pin as output\n}\n\n// Remember that the pin work with inverted logic\n// LOW to Turn on and HIGH to turn off\nvoid loop() {\n  digitalWrite(LED_BUILT_IN, LOW); //Turn on\n  delay (1000); //Wait 1 sec\n  digitalWrite(LED_BUILT_IN, HIGH); //Turn off\n  delay (1000); //Wait 1 sec\n}\n\nNote that the pins work with inverted logic: LOW to Turn on and HIGH to turn off"
  },
  {
    "objectID": "chapter_4-4.html#connecting-sense-module-expansion-board",
    "href": "chapter_4-4.html#connecting-sense-module-expansion-board",
    "title": "4.4 Image Classification",
    "section": "4.4.5 Connecting Sense module (Expansion Board)",
    "text": "4.4.5 Connecting Sense module (Expansion Board)\nWhen purchased, the expansion board is separated from the main board, but installing the expansion board is very simple. You need to align the connector on the expansion board with the B2B connector on the XIAO ESP32S3, press it hard, and when you hear a “click,” the installation is complete.\n\nAs commented in the introduction, the expansion board, or the “sense” part of the device, has a 1600x1200 OV2640 camera, an SD card slot, and a digital microphone."
  },
  {
    "objectID": "chapter_4-4.html#microphone-test",
    "href": "chapter_4-4.html#microphone-test",
    "title": "4.4 Image Classification",
    "section": "4.4.6 Microphone Test",
    "text": "4.4.6 Microphone Test\nLet’s start with sound detection. Go to the GitHub project and download the sketch: XIAOEsp2s3_Mic_Test and run it on the Arduino IDE:\n\nWhen producing sound, you can verify it on the Serial Plotter.\nSave recorded sound (.wav audio files) to a microSD card.\nLet’s now use the onboard SD Card reader to save .wav audio files. For that, we need to habilitate the XIAO PSRAM.\n\nESP32-S3 has only a few hundred kilobytes of internal RAM on the MCU chip. It can be insufficient for some purposes so that ESP32-S3 can use up to 16 MB of external PSRAM (Psuedostatic RAM) connected in parallel with the SPI flash chip. The external memory is incorporated in the memory map and, with certain restrictions, is usable in the same way as internal data RAM.\n\nFor a start, Insert the SD Card on the XIAO as shown in the photo below (the SD Card should be formatted to FAT32).\n\n\nDownload the sketch Wav_Record, which you can find on GitHub.\nTo execute the code (Wav Record), it is necessary to use the PSRAM function of the ESP-32 chip, so turn it on before uploading.: Tools&gt;PSRAM: “OPI PSRAM”&gt;OPI PSRAM\n\n\n\nRun the code Wav_Record.ino\nThis program is executed only once after the user turns on the serial monitor, recording for 20 seconds and saving the recording file to a microSD card as “arduino_rec.wav”.\nWhen the “.” is output every 1 second in the serial monitor, the program execution is finished, and you can play the recorded sound file with the help of a card reader.\n\n\nThe sound quality is excellent!\n\nThe explanation of how the code works is beyond the scope of this tutorial, but you can find an excellent description on the wiki page."
  },
  {
    "objectID": "chapter_4-4.html#testing-the-camera",
    "href": "chapter_4-4.html#testing-the-camera",
    "title": "4.4 Image Classification",
    "section": "4.4.7 Testing the Camera",
    "text": "4.4.7 Testing the Camera\nFor testing the camera, you should download the folder take_photos_command from GitHub. The folder contains the sketch (.ino) and two .h files with camera details.\n\nRun the code: take_photos_command.ino. Open the Serial Monitor and send the command “capture” to capture and save the image on the SD Card:\n\n\nVerify that [Both NL & CR] is selected on Serial Monitor.\n\n\nHere is an example of a taken photo:"
  },
  {
    "objectID": "chapter_4-4.html#testing-wifi",
    "href": "chapter_4-4.html#testing-wifi",
    "title": "4.4 Image Classification",
    "section": "4.4.8 Testing WiFi",
    "text": "4.4.8 Testing WiFi\nOne of the differentiators of the XIAO ESP32S3 is its WiFi capability. So, let’s test its radio, scanning the wifi networks around it. You can do it by running one of the code examples on the board.\nGo to Arduino IDE Examples and look for WiFI ==&gt; WiFIScan\nOn the Serial monitor, you should see the wifi networks (SSIDs and RSSIs) in the range of your device. Here is what I got on the lab:\n\nSimple WiFi Server (Turning LED ON/OFF)\nLet’s test the device’s capability to behave as a WiFi Server. We will host a simple page on the device that sends commands to turn the XIAO built-in LED ON and OFF.\nLike before, go to GitHub to download the folder with the sketch: SimpleWiFiServer.\nBefore running the sketch, you should enter your network credentials:\nconst char* ssid     = \"Your credentials here\";\nconst char* password = \"Your credentials here\";\nYou can monitor how your server is working with the Serial Monitor.\n\nTake the IP address and enter it on your browser:\n\nYou will see a page with links that can turn ON and OFF the built-in LED of your XIAO.\nStreaming video to Web\nNow that you know that you can send commands from the webpage to your device, let’s do the reverse. Let’s take the image captured by the camera and stream it to a webpage:\nDownload from GitHub the folder that contains the code: XIAO-ESP32S3-Streeming_Video.ino.\n\nRemember that the folder contains not only the.ino file, but also a couple of.h files, necessary to handle the camera.\n\nEnter your credentials and run the sketch. On the Serial monitor, you can find the page address to enter in your browser:\n\nOpen the page on your browser (wait a few seconds to start the streaming). That’s it.\n\nStreamlining what your camera is “seen” can be important when you position it to capture a dataset for an ML project (for example, using the code “take_phots_commands.ino”.\nOf course, we can do both things simultaneously, show what the camera is seeing on the page, and send a command to capture and save the image on the SD card. For that, you can use the code Camera_HTTP_Server_STA which folder can be downloaded from GitHub.\n\nThe program will do the following tasks:\n\nSet the camera to JPEG output mode.\nCreate a web page (for example ==&gt; http://192.168.4.119//). The correct address will be displayed on the Serial Monitor.\nIf server.on (“/capture”, HTTP_GET, serverCapture), the program takes a photo and sends it to the Web.\nIt is possible to rotate the image on webPage using the button [ROTATE]\nThe command [CAPTURE] only will preview the image on the webpage, showing its size on Serial Monitor\nThe [SAVE] command will save an image on the SD Card, also showing the image on the web.\nSaved images will follow a sequential naming (image1.jpg, image2.jpg.\n\n\n\nThis program can be used for an image dataset capture with an Image Classification project.\n\nInspect the code; it will be easier to understand how the camera works. This code was developed based on the great Rui Santos Tutorial: ESP32-CAM Take Photo and Display in Web Server, which I invite all of you to visit.\nUsing the CameraWebServer\nIn File \\&gt; Examples \\&gt; ESP32 \\&gt; Camera, select CameraWebServer\nYou also should comment on all cameras’ models, except the XIAO model pins:\n#define CAMERA_MODEL_XIAO_ESP32S3 // Has PSRAM\nand do not forget the Tools to enable the PSRAM.\nEnter your wifi credentials and upload the code to the device:\n\nIf the code is executed correctly, you should see the address on the Serial Monitor:\n\n\n\nimage-20240214163034559\n\n\nCopy the address on your browser and wait for the page to be uploaded. Select the camera resolution (for example, QVGA) and select [START STREAM]. Wait for a few seconds/minutes, depending on your connection. You can save an image on your computer download area using the [Save] button.\n\nThat’s it! You can save the images directly in your computer to be used on projects."
  },
  {
    "objectID": "chapter_4-4.html#fruits-versus-veggies---a-tinyml-image-classification-project",
    "href": "chapter_4-4.html#fruits-versus-veggies---a-tinyml-image-classification-project",
    "title": "4.4 Image Classification",
    "section": "4.4.9 Fruits versus Veggies - A TinyML Image Classification Project",
    "text": "4.4.9 Fruits versus Veggies - A TinyML Image Classification Project\n\nNow that we have an embedded camera running, it is time to try image classification. For comparative motive, we will replicate the same image classification project developed to be used with an old ESP2-CAM:\nESP32-CAM: TinyML Image Classification - Fruits vs Veggies\n\nThe whole idea of our project will be to train a model and proceed with inference on the XIAO ESP32S3 Sense. For training, we should find some data (in fact, tons of data!).\nBut first of all, we need a goal! What do we want to classify?\nWith TinyML, a set of techniques associated with machine learning inference on embedded devices, we should limit the classification to three or four categories due to limitations (mainly memory). We will differentiate apples from bananas and potatoes (you can try other categories).\nSo, let’s find a specific dataset that includes images from those categories. Kaggle is a good start:\nhttps://www.kaggle.com/kritikseth/fruit-and-vegetable-image-recognition\nThis dataset contains images of the following food items:\n\nFruits - banana, apple, pear, grapes, orange, kiwi, watermelon, pomegranate, pineapple, mango.\nVegetables - cucumber, carrot, capsicum, onion, potato, lemon, tomato, radish, beetroot, cabbage, lettuce, spinach, soybean, cauliflower, bell pepper, chili pepper, turnip, corn, sweetcorn, sweet potato, paprika, jalepeño, ginger, garlic, peas, eggplant.\n\nEach category is split into the train (100 images), test (10 images), and validation (10 images).\n\nDownload the dataset from the Kaggle website to your computer.\n\n\nOptionally, you can add some fresh photos of bananas, apples, and potatoes from your home kitchen, using, for example, the codes discussed in the last section."
  },
  {
    "objectID": "chapter_4-4.html#training-the-model-with-edge-impulse-studio",
    "href": "chapter_4-4.html#training-the-model-with-edge-impulse-studio",
    "title": "4.4 Image Classification",
    "section": "4.4.10 Training the model with Edge Impulse Studio",
    "text": "4.4.10 Training the model with Edge Impulse Studio\nWe will use the Edge Impulse Studio to train our model. As you know, Edge Impulse is a leading development platform for machine learning on edge devices.\nEnter your account credentials (or create a free account) at Edge Impulse. Next, create a new project:\n\nData Acquisition\nNext, on the UPLOAD DATA section, upload from your computer the files from chosen categories:\n\nYou should now have your training dataset split in three classes of data:\n\n\nYou can upload extra data for further model testing or split the training data. I will leave it as it is to use the most data possible.\n\nImpulse Design\n\nAn impulse takes raw data (in this case, images), extracts features (resize pictures), and then uses a learning block to classify new data.\n\nClassifying images is the most common use of deep learning, but a lot of data should be used to accomplish this task. We have around 90 images for each category. Is this number enough? Not at all! We will need thousands of images to “teach or model” to differentiate an apple from a banana. But, we can solve this issue by re-training a previously trained model with thousands of images. We call this technique “Transfer Learning” (TL).\n\nWith TL, we can fine-tune a pre-trained image classification model on our data, performing well even with relatively small image datasets (our case).\nSo, starting from the raw images, we will resize them (96x96) pixels and feed them to our Transfer Learning block:\n\nPre-processing (Feature generation)\nBesides resizing the images, we can change them to Grayscale or keep the actual RGB color depth. Let’s start selecting Grayscale. Doing that, each one of our data samples will have dimension 9, 216 features (96x96x1). Keeping RGB, this dimension would be three times bigger. Working with Grayscale helps to reduce the amount of final memory needed for inference.\n\nDo not forget to [Save parameters].” This will generate the features to be used in training.\nTraining (Transfer Learning & Data Augmentation)\nIn 2007, Google introduced MobileNetV1, a family of general-purpose computer vision neural networks designed with mobile devices in mind to support classification, detection, and more. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of various use cases.\nAlthough the base MobileNet architecture is already tiny and has low latency, many times, a specific use case or application may require the model to be smaller and faster. MobileNet introduces a straightforward parameter α (alpha) called width multiplier to construct these smaller, less computationally expensive models. The role of the width multiplier α is to thin a network uniformly at each layer.\nEdge Impulse Studio has available MobileNet V1 (96x96 images) and V2 (96x96 and 160x160 images), with several different α values (from 0.05 to 1.0). For example, you will get the highest accuracy with V2, 160x160 images, and α=1.0. Of course, there is a trade-off. The higher the accuracy, the more memory (around 1.3M RAM and 2.6M ROM) will be needed to run the model, implying more latency.\nThe smaller footprint will be obtained at another extreme with MobileNet V1 and α=0.10 (around 53.2K RAM and 101K ROM).\nWhen we first published this project to be running on an ESP32-CAM, we stayed at the lower side of possibilities which guaranteed the inference with small latency but not with high accuracy. For this first pass, we will keep this model design (MobileNet V1 and α=0.10).\nAnother necessary technique to use with deep learning is data augmentation. Data augmentation is a method that can help improve the accuracy of machine learning models, creating additional artificial data. A data augmentation system makes small, random changes to your training data during the training process (such as flipping, cropping, or rotating the images).\nUnder the rood, here you can see how Edge Impulse implements a data Augmentation policy on your data:\n# Implements the data augmentation policy\ndef augment_image(image, label):\n    # Flips the image randomly\n    image = tf.image.random_flip_left_right(image)\n\n    # Increase the image size, then randomly crop it down to\n    # the original dimensions\n    resize_factor = random.uniform(1, 1.2)\n    new_height = math.floor(resize_factor * INPUT_SHAPE[0])\n    new_width = math.floor(resize_factor * INPUT_SHAPE[1])\n    image = tf.image.resize_with_crop_or_pad(image, new_height, new_width)\n    image = tf.image.random_crop(image, size=INPUT_SHAPE)\n\n    # Vary the brightness of the image\n    image = tf.image.random_brightness(image, max_delta=0.2)\n\n    return image, label\nExposure to these variations during training can help prevent your model from taking shortcuts by “memorizing” superficial clues in your training data, meaning it may better reflect the deep underlying patterns in your dataset.\nThe final layer of our model will have 16 neurons with a 10% of dropout for overfitting prevention. Here is the Training output:\n\nThe result is not great. The model reached around 77% of accuracy, but the amount of RAM expected to be used during the inference is relatively small (around 60 KBytes), which is very good.\nDeployment\nThe trained model will be deployed as a .zip Arduino library:\n\nOpen your Arduino IDE, and under Sketch, go to Include Library and add.ZIP Library. Select the file you download from Edge Impulse Studio, and that’s it!\n\nUnder the Examples tab on Arduino IDE, you should find a sketch code under your project name.\n\nOpen the Static Buffer example:\n\nYou can see that the first line of code is exactly the calling of a library with all the necessary stuff for running inference on your device.\n#include &lt;XIAO-ESP32S3-CAM-Fruits-vs-Veggies_inferencing.h&gt;\nOf course, this is a generic code (a “template”) that only gets one sample of raw data (stored on the variable: features = {} and runs the classifier, doing the inference. The result is shown on the Serial Monitor.\nWe should get the sample (image) from the camera and pre-process it (resizing to 96x96, converting to grayscale, and flatting it). This will be the input tensor of our model. The output tensor will be a vector with three values (labels), showing the probabilities of each one of the classes.\n\nReturning to your project (Tab Image), copy one of the Raw Data Sample:\n\n9, 216 features will be copied to the clipboard. This is the input tensor (a flattened image of 96x96x1), in this case, bananas. Past this Input tensor on features[] = {0xb2d77b, 0xb5d687, 0xd8e8c0, 0xeaecba, 0xc2cf67, …}\n\nEdge Impulse included the library ESP NN in its SDK, which contains optimized NN (Neural Network) functions for various Espressif chips, including the ESP32S3 (running at Arduino IDE).\nNow, when running the inference, you should get the highest score for “banana.”\n\nGreat news! Our device handles an inference, discovering that the input image is a banana. Also, note that the inference time was around 317ms, resulting in a maximum of 3 fps if you tried to classify images from a video. It is a better result than the ESP32 CAM (525ms of latency).\nNow, we should incorporate the camera and classify images in real time.\nGo to the Arduino IDE Examples and download from your project the sketch esp32_camera:\n\nYou should change lines 32 to 75, which define the camera model and pins, using the data related to our model. Copy and paste the below lines, replacing the lines 32-75:\n#define PWDN_GPIO_NUM     -1 \n#define RESET_GPIO_NUM    -1 \n#define XCLK_GPIO_NUM     10 \n#define SIOD_GPIO_NUM     40 \n#define SIOC_GPIO_NUM     39\n#define Y9_GPIO_NUM       48 \n#define Y8_GPIO_NUM       11 \n#define Y7_GPIO_NUM       12 \n#define Y6_GPIO_NUM       14 \n#define Y5_GPIO_NUM       16 \n#define Y4_GPIO_NUM       18 \n#define Y3_GPIO_NUM       17 \n#define Y2_GPIO_NUM       15 \n#define VSYNC_GPIO_NUM    38 \n#define HREF_GPIO_NUM     47 \n#define PCLK_GPIO_NUM     13\nHere you can see the resulting code:\n\nThe modified sketch can be downloaded from GitHub: xiao_esp32s3_camera.\n\nNote that you can optionally keep the pins as a .h file as we did in previous sections.\n\nUpload the code to your XIAO ESP32S3 Sense, and you should be OK to start classifying your fruits and vegetables! You can check the result on Serial Monitor."
  },
  {
    "objectID": "chapter_4-4.html#testing-the-model-inference",
    "href": "chapter_4-4.html#testing-the-model-inference",
    "title": "4.4 Image Classification",
    "section": "4.4.11 Testing the Model (Inference)",
    "text": "4.4.11 Testing the Model (Inference)\n\nGetting a photo with the camera, the classification result will appear on the Serial Monitor:\n\nOther tests:"
  },
  {
    "objectID": "chapter_4-4.html#testing-with-a-bigger-model",
    "href": "chapter_4-4.html#testing-with-a-bigger-model",
    "title": "4.4 Image Classification",
    "section": "4.4.12 Testing with a bigger model",
    "text": "4.4.12 Testing with a bigger model\nNow, let’s go to the other side of the model size. Let’s select a MobilinetV2 96x96 0.35, having as input RGB images.\n\nEven with a bigger model, the accuracy is not that good, and the amount of memory necessary to run the model increases five times, with latency increasing seven times\n\nNote that the performance here is estimated with a smaller device, the ESP-EYE. The actual inference with the ESP32S3 should be better.\n\nTo improve our model, we will need to train more images.\nEven though our model did not improve in terms of accuracy, let’s test whether the XIAO can handle such a bigger model. We will do a simple inference test with the Static Buffer sketch.\nLet’s redeploy the model. If the EON Compiler is enabled when you generate the library, the total memory needed for inference should be reduced, but it has no influence on accuracy.\n\nDoing an inference with MobilinetV2 96x96 0.35, having as input RGB images, the latency was of 219ms, what it is great for such bigger model.\n\nFor test, I trained the model again, using the smallest version of MobileNet V2, with an alpha of 0.05. Interesting that the result in accuraccy was higher.\n\n\nNote that the estimated latency for an Arduino Portenta (ou Nicla), running with a clock of 480MHz is 45ms.\n\nDeploying the model, I got an inference of only 135ms, remembering that the XIAO run with half of the clock used by the Portenta/Nicla (240MHz):"
  },
  {
    "objectID": "chapter_4-4.html#runing-inference-on-the-sensecraft-web-toolkit",
    "href": "chapter_4-4.html#runing-inference-on-the-sensecraft-web-toolkit",
    "title": "4.4 Image Classification",
    "section": "4.4.13 Runing inference on the SenseCraft-Web-Toolkit",
    "text": "4.4.13 Runing inference on the SenseCraft-Web-Toolkit\nOn big limitation of viewing inference on Arduino IDE, is that we can not see what the camera is really focusing. A good alternative for that is the SenseCraft-Web-Toolkit, a visual model deployment tool provided by SSCMA (Seeed SenseCraft Model Assistant). With this tool, you can easily deploy models to various platforms through simple operations. The tool provides a user-friendly interface and does not require any coding.\nFollow the following steps to start the SenseCraft-Web-Toolkit:\n\nOpen the SenseCraft-Web-Toolkit website.\nConnect the XIAO to your computer:\n\n\nHaving the XIAO connected, select it as below:\n\n\n\nSelect the device/Port and press [Connect]:\n\n\n\nYou can try several Computer Vision models previously uploaded by Seeed Studio. Try them and have fun!\n\nIn our case, we will use the blue button at the botton of the page: [Upload Custom AI Model].\nBut first, we will need to download from Edge Impulse Studio, our quantized .tflite model.\n\nGo to your project at Edge Impulse Studio, or clone this one:\n\n\nXIAO-ESP32S3-CAM-Fruits-vs-Veggies-v1-ESP-NN\n\n\nOn Dashboard, download the model (“block output”): Transfer learning mdodel - TensorFlow Lite (int8 quantized)\n\n\n\nOn SenseCraft-Web-Toolkit, use the blue button at the botton of the page: [Upload Custom AI Model]. A window will pop-up. Enter with the Model file that you downloaded to your computer from Edge Impulse Studio, choos a Model Name and enter with labels (ID:Object):\n\n\n\nNote that you should use the labels trained on EI Studio, entering them at alphabetic order (in our case: apple, banana, potato).\n\nAfter a few seconds (or minutes), the model will be uploaded to your device and the camera image will appear in real-time on the Preview Sector:\n\nThe Classification result will be at at the top of the image. You can also select the Confidence of your inference cursor Confidence.\nClicking in the top button (Device Log), you can open a Serial Monitor to follow the inference, same that we have done with the Arduino IDE:\n\nOn Device Log, you will get Information as:\n\n\nPreprocess time (image capture and Crop): 4ms;\nInference time (model latency): 106ms,\nPostprocess time (display of the image and inclusion of data): 0ms.\nOutput tensor (classes), for example: [[89,0]]; where 0 is Apple (and 1is banana and 2 is potato)\n\nHere are other screen shots:"
  },
  {
    "objectID": "chapter_4-4.html#conclusion",
    "href": "chapter_4-4.html#conclusion",
    "title": "4.4 Image Classification",
    "section": "4.4.14 Conclusion",
    "text": "4.4.14 Conclusion\nThe XIAO ESP32S3 Sense is a very flexible, not expensive, and easy-to-program device. The project proves the potential of TinyML. Memory is not an issue; the device can handle many post-processing tasks, including communication.\nOn the GitHub repository, you will find the last version of the codes: XIAO-ESP32S3-Sense."
  },
  {
    "objectID": "chapter_4-5.html#things-used-in-this-project",
    "href": "chapter_4-5.html#things-used-in-this-project",
    "title": "4.5 Object Detection",
    "section": "4.5.1 Things used in this project",
    "text": "4.5.1 Things used in this project\n\n4.5.1.1 Hardware components\n\nSeeed Studio Seeed XIAO ESP32S3 Sense x 1 \n\n\n4.5.2 Software apps and online services\n\n Arduino IDE\n Edge Impulse Studio"
  },
  {
    "objectID": "chapter_4-5.html#introduction",
    "href": "chapter_4-5.html#introduction",
    "title": "4.5 Object Detection",
    "section": "4.5.2 Introduction",
    "text": "4.5.2 Introduction\nIn the last section regarding Computer Vision (CV) and the XIAO ESP32S3, Image Classification, we learned how to set up and classify images with this remarkable development board. Continuing our CV journey, we will explore Object Detection on microcontrollers.\n\n4.5.2.1 Object Detection versus Image Classification\nThe main task with Image Classification models is to identify the most probable object category present on an image, for example, to classify between a cat or a dog, dominant “objects” in an image:\n\nBut what happens if there is no dominant category in the image?\n\nAn image classification model identifies the above image utterly wrong as an “ashcan,” possibly due to the color tonalities.\n\nThe model used in the previous example is the MobileNet, trained with a large dataset, the ImageNet, running on a Raspberry Pi.\n\nTo solve this issue, we need another type of model, where not only multiple categories (or labels) can be found but also where the objects are located on a given image.\nAs we can imagine, such models are much more complicated and bigger, for example, the MobileNetV2 SSD FPN-Lite 320x320, trained with the COCO dataset. This pre-trained object detection model is designed to locate up to 10 objects within an image, outputting a bounding box for each object detected. The below image is the result of such a model running on a Raspberry Pi:\n\nThose models used for object detection (such as the MobileNet SSD or YOLO) usually have several MB in size, which is OK for use with Raspberry Pi but unsuitable for use with embedded devices, where the RAM usually is lower than 1M Bytes or at least a few MB as in the case of the XIAO ESP32S3.\n\n\n4.5.2.2 An Innovative Solution for Object Detection: FOMO\nEdge Impulse launched in 2022, FOMO (Faster Objects, More Objects), a novel solution to perform object detection on embedded devices, such as the Nicla Vision and Portenta (Cortex M7), on Cortex M4F CPUs (Arduino Nano33 and OpenMV M4 series) as well the Espressif ESP32 devices (ESP-CAM, ESP-EYE and XIAO ESP32S3 Sense).\nIn this Hands-On project, we will explore Object Detection using FOMO.\n\nTo understand more about FOMO, you can go into the official FOMO announcement by Edge Impulse, where Louis Moreau and Mat Kelcey explain in detail how it works."
  },
  {
    "objectID": "chapter_4-5.html#the-object-detection-project-goal",
    "href": "chapter_4-5.html#the-object-detection-project-goal",
    "title": "4.5 Object Detection",
    "section": "4.5.3 The Object Detection Project Goal",
    "text": "4.5.3 The Object Detection Project Goal\nAll Machine Learning projects need to start with a detailed goal. Let’s assume we are in an industrial or rural facility and must sort and count oranges (fruits) and special frogs (bugs).\n\nIn other words, we should perform a multi-label classification, where each image can have three classes:\n\nBackground (No objects)\nFruit\nBug\n\nHere are some not labeled image samples that we should use to detect the objects (fruits and bugs):\n\nWe are interested in which object is in the image, its location (centroid), and how many we can find on it. The object’s size is not detected with FOMO, as with MobileNet SSD or YOLO, where the Bounding Box is one of the model outputs.\nWe will develop the project using the XIAO ESP32S3 for image capture and model inference. The ML project will be developed using the Edge Impulse Studio. But before starting the object detection project in the Studio, let’s create a raw dataset (not labeled) with images that contain the objects to be detected."
  },
  {
    "objectID": "chapter_4-5.html#data-collection",
    "href": "chapter_4-5.html#data-collection",
    "title": "4.5 Object Detection",
    "section": "4.5.4 Data Collection",
    "text": "4.5.4 Data Collection\nYou can use the XIAO, your phone, or other devices for the image capture. Here, we will use the XIAO with a code in the ESP32 library.\n\n4.5.4.1 Collecting Dataset with the XIAO ESP32S3\nOpen the Arduino IDE and select the XIAO_ESP32S3 board (and the port where it is connected). On File \\&gt; Examples \\&gt; ESP32 \\&gt; Camera, select CameraWebServer.\nOn the BOARDS MANAGER panel, confirm that you have installed the latest “stable” package.\n\n⚠️ Attention\nAlpha versions (for example, 3.x-alpha) do not work correctly with the XIAO and Edge Impulse. Use the last stable version (for example, 2.0.11) instead.\n\nYou also should comment on all cameras’ models, except the XIAO model pins:\n#define CAMERA_MODEL_XIAO_ESP32S3 // Has PSRAM\nand on Tools, enable the PSRAM. Enter your wifi credentials and upload the code to the device:\n\nIf the code is executed correctly, you should see the address on the Serial Monitor:\n\nCopy the address on your browser and wait for the page to be uploaded. Select the camera resolution (for example, QVGA) and select [START STREAM]. Wait for a few seconds/minutes, depending on your connection. You can save an image on your computer download area using the [Save] button.\n\nEdge impulse suggests that the objects should be of similar size and not overlapping for better performance. This is OK in an industrial facility, where the camera should be fixed, keeping the same distance from the objects to be detected. Despite that, we will also try using mixed sizes and positions to see the result.\n\nWe do not need to create separate folders for our images because each contains multiple labels.\n\nWe suggest around 50 images mixing the objects and varying the number of each appearing on the scene. Try to capture different angles, backgrounds, and light conditions.\n\nThe stored images use a QVGA frame size of 320x240 and RGB565 (color pixel format).\n\nAfter capturing your dataset, [Stop Stream] and move your images to a folder.\n\n\n4.5.4.2 Edge Impulse Studio\n\n4.5.4.2.1 Setup the project\nGo to Edge Impulse Studio, enter your credentials at Login (or create an account), and start a new project.\n\n\nHere, you can clone the project developed for this hands-on: XIAO-ESP32S3-Sense-Object_Detection\n\nOn your Project Dashboard, go down and on Project info and select Bounding boxes (object detection) and Espressif ESP-EYE (most similar to our board) as your Target Device:\n\n\n\n\n4.5.4.3 Uploading the unlabeled data\nOn Studio, go to the Data acquisition tab, and on the UPLOAD DATA section, upload files captured as a folder from your computer.\n\n\nYou can leave for the Studio to split your data automatically between Train and Test or do it manually. We will upload all of them as training.\n\n\nAll the not-labeled images (47) were uploaded but still need to be labeled appropriately before being used as a project dataset. The Studio has a tool for that purpose, which you can find in the link Labeling queue (47).\nThere are two ways you can use to perform AI-assisted labeling on the Edge Impulse Studio (free version):\n\nUsing yolov5\nTracking objects between frames\n\n\nEdge Impulse launched an auto-labeling feature for Enterprise customers, easing labeling tasks in object detection projects.\n\nOrdinary objects can quickly be identified and labeled using an existing library of pre-trained object detection models from YOLOv5 (trained with the COCO dataset). But since, in our case, the objects are not part of COCO datasets, we should select the option of tracking objects. With this option, once you draw bounding boxes and label the images in one frame, the objects will be tracked automatically from frame to frame, partially labeling the new ones (not all are correctly labeled).\n\nYou can use the EI uploader to import your data if you already have a labeled dataset containing bounding boxes.\n\n\n\n4.5.4.4 Labeling the Dataset\nStarting with the first image of your unlabeled data, use your mouse to drag a box around an object to add a label. Then click Save labels to advance to the next item.\n\nContinue with this process until the queue is empty. At the end, all images should have the objects labeled as those samples below:\n\nNext, review the labeled samples on the Data acquisition tab. If one of the labels is wrong, you can edit it using the three dots menu after the sample name:\n\nYou will be guided to replace the wrong label and correct the dataset.\n\n\n\n4.5.4.5 Balancing the dataset and split Train/Test\nAfter labeling all data, it was realized that the class fruit had many more samples than the bug. So, 11 new and additional bug images were collected (ending with 58 images). After labeling them, it is time to select some images and move them to the test dataset. You can do it using the three-dot menu after the image name. I selected six images, representing 13% of the total dataset."
  },
  {
    "objectID": "chapter_4-5.html#the-impulse-design",
    "href": "chapter_4-5.html#the-impulse-design",
    "title": "4.5 Object Detection",
    "section": "4.5.5 The Impulse Design",
    "text": "4.5.5 The Impulse Design\nIn this phase, you should define how to:\n\nPre-processing consists of resizing the individual images from 320 x 240 to 96 x 96 and squashing them (squared form, without cropping). Afterward, the images are converted from RGB to Grayscale.\nDesign a Model, in this case, “Object Detection.”\n\n\n\n4.5.5.1 Preprocessing all dataset\nIn this section, select Color depth as Grayscale, suitable for use with FOMO models and Save parameters.\n\nThe Studio moves automatically to the next section, Generate features, where all samples will be pre-processed, resulting in a dataset with individual 96x96x1 images or 9, 216 features.\n\nThe feature explorer shows that all samples evidence a good separation after the feature generation.\n\nSome samples seem to be in the wrong space, but clicking on them confirms that the labeling is correct."
  },
  {
    "objectID": "chapter_4-5.html#model-design-training-and-test",
    "href": "chapter_4-5.html#model-design-training-and-test",
    "title": "4.5 Object Detection",
    "section": "4.5.6 Model Design, Training, and Test",
    "text": "4.5.6 Model Design, Training, and Test\nWe will use FOMO, an object detection model based on MobileNetV2 (alpha 0.35) designed to coarsely segment an image into a grid of background vs objects of interest (here, boxes and wheels).\nFOMO is an innovative machine learning model for object detection, which can use up to 30 times less energy and memory than traditional models like Mobilenet SSD and YOLOv5. FOMO can operate on microcontrollers with less than 200 KB of RAM. The main reason this is possible is that while other models calculate the object’s size by drawing a square around it (bounding box), FOMO ignores the size of the image, providing only the information about where the object is located in the image through its centroid coordinates.\nHow FOMO works?\nFOMO takes the image in grayscale and divides it into blocks of pixels using a factor of 8. For the input of 96x96, the grid would be 12x12 (96/8=12). Next, FOMO will run a classifier through each pixel block to calculate the probability that there is a box or a wheel in each of them and, subsequently, determine the regions that have the highest probability of containing the object (If a pixel block has no objects, it will be classified as background). From the overlap of the final region, the FOMO provides the coordinates (related to the image dimensions) of the centroid of this region.\n\nFor training, we should select a pre-trained model. Let’s use the FOMO (Faster Objects, More Objects) MobileNetV2 0.35. This model uses around 250KB of RAM and 80KB of ROM (Flash), which suits well with our board.\n\nRegarding the training hyper-parameters, the model will be trained with:\n\nEpochs: 60\nBatch size: 32\nLearning Rate: 0.001.\n\nFor validation during training, 20% of the dataset (validation_dataset) will be spared. For the remaining 80% (train_dataset), we will apply Data Augmentation, which will randomly flip, change the size and brightness of the image, and crop them, artificially increasing the number of samples on the dataset for training.\nAs a result, the model ends with an overall F1 score of 85%, similar to the result when using the test data (83%).\n\nNote that FOMO automatically added a 3rd label background to the two previously defined (box and wheel).\n\n\n\nIn object detection tasks, accuracy is generally not the primary evaluation metric. Object detection involves classifying objects and providing bounding boxes around them, making it a more complex problem than simple classification. The issue is that we do not have the bounding box, only the centroids. In short, using accuracy as a metric could be misleading and may not provide a complete understanding of how well the model is performing. Because of that, we will use the F1 score.\n\n\n4.5.6.1 Test model with “Live Classification”\nOnce our model is trained, we can test it using the Live Classification tool. On the correspondent section, click on Connect a development board icon (a small MCU) and scan the QR code with your phone.\n\nOnce connected, you can use the smartphone to capture actual images to be tested by the trained model on Edge Impulse Studio.\n\nOne thing to be noted is that the model can produce false positives and negatives. This can be minimized by defining a proper Confidence Threshold (use the Three dots menu for the setup). Try with 0.8 or more."
  },
  {
    "objectID": "chapter_4-5.html#deploying-the-model",
    "href": "chapter_4-5.html#deploying-the-model",
    "title": "4.5 Object Detection",
    "section": "4.5.7 Deploying the Model",
    "text": "4.5.7 Deploying the Model\nSelect the Arduino Library and Quantized (int8) model, enable the EON Compiler on the Deploy Tab, and press [Build].\n\nOpen your Arduino IDE, and under Sketch, go to Include Library and add.ZIP Library. Select the file you download from Edge Impulse Studio, and that’s it!\n\nUnder the Examples tab on Arduino IDE, you should find a sketch code (esp32 &gt; esp32_camera) under your project name.\n\nYou should change lines 32 to 75, which define the camera model and pins, by the data related to our model. Copy and paste the below lines, replacing the lines 32-75:\n#define PWDN_GPIO_NUM     -1 \n#define RESET_GPIO_NUM    -1 \n#define XCLK_GPIO_NUM     10 \n#define SIOD_GPIO_NUM     40 \n#define SIOC_GPIO_NUM     39\n#define Y9_GPIO_NUM       48 \n#define Y8_GPIO_NUM       11 \n#define Y7_GPIO_NUM       12 \n#define Y6_GPIO_NUM       14 \n#define Y5_GPIO_NUM       16 \n#define Y4_GPIO_NUM       18 \n#define Y3_GPIO_NUM       17 \n#define Y2_GPIO_NUM       15 \n#define VSYNC_GPIO_NUM    38 \n#define HREF_GPIO_NUM     47 \n#define PCLK_GPIO_NUM     13\nHere you can see the resulting code:\n\nUpload the code to your XIAO ESP32S3 Sense, and you should be OK to start detecting fruits and bugs. You can check the result on Serial Monitor.\nBackground\n\nFruits\n\nBugs\n\nNote that the model latency is 143ms, and the frame rate per second is around 7 fps (similar to what we got with the Image Classification project). This happens because FOMO is cleverly built over a CNN model, not with an object detection model like the SSD MobileNet. For example, when running a MobileNetV2 SSD FPN-Lite 320x320 model on a Raspberry Pi 4, the latency is around five times higher (around 1.5 fps)."
  },
  {
    "objectID": "chapter_4-5.html#conclusion",
    "href": "chapter_4-5.html#conclusion",
    "title": "4.5 Object Detection",
    "section": "4.5.8 Conclusion",
    "text": "4.5.8 Conclusion\nFOMO is a significant leap in the image processing space, as Louis Moreau and Mat Kelcey put it during its launch in 2022:\n\nFOMO is a ground-breaking algorithm that brings real-time object detection, tracking, and counting to microcontrollers for the first time.\n\nMultiple possibilities exist for exploring object detection (and, more precisely, counting them) on embedded devices."
  },
  {
    "objectID": "chapter_4-6.html",
    "href": "chapter_4-6.html",
    "title": "4.6 To learn more",
    "section": "",
    "text": "This section contains links to courses, books, and projects to learn more about Machine Learning and TinyML applications.\n\nOnline Courses\n\nHarvard School of Engineering and Applied Sciences - CS249r: Tiny Machine Learning\nProfessional Certificate in Tiny Machine Learning (TinyML) – edX/Harvard\nIntroduction to Embedded Machine Learning - Coursera/Edge Impulse\nComputer Vision with Embedded Machine Learning - Coursera/Edge Impulse\nUNIFEI-IESTI01 TinyML: “Machine Learning for Embedding Devices”\n\n\n\nBooks\n\n“Python for Data Analysis by Wes McKinney”\n“Deep Learning with Python” by François Chollet - GitHub Notebooks\n“TinyML” by Pete Warden, Daniel Situnayake\n“TinyML Cookbook” by Gian Marco Iodice\n“Technical Strategy for AI Engineers, In the Era of Deep Learning” by Andrew Ng\n“AI at the Edge” book by Daniel Situnayake, Jenny Plunkett\n“MACHINE LEARNING SYSTEMS for TinyML” Collaborative effort\n\n\n\nProjects Repositories\n\nEdge Impulse Expert Network\nMRovai XIAO ESP32S3 Movement/Sound/Image"
  },
  {
    "objectID": "chapter_5.html",
    "href": "chapter_5.html",
    "title": "Chapter 5: Creative Experiments",
    "section": "",
    "text": "Since its launch, the Seeed Studio XIAO series has been widely acclaimed for its compact size, powerful performance, and versatile product range. The maker community has produced a large number of projects created with XIAO. Due to space constraints, we have selected some outstanding projects made with XIAO by our makers. These projects fully demonstrate the powerful functions and wide applications of XIAO. Let us follow the makers’ steps, stimulate creativity, and explore the endless possibilities of XIAO. We hope you can draw inspiration from these projects, use your imagination, and explore new territories with XIAO."
  },
  {
    "objectID": "chapter_5-1.html#drone-borne-salt-water-tracker-swt",
    "href": "chapter_5-1.html#drone-borne-salt-water-tracker-swt",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.1 Drone-borne Salt Water Tracker (SWT)",
    "text": "5.1.1 Drone-borne Salt Water Tracker (SWT)\nhttps://www.hackster.io/txnghia/salt-water-tracker-swt-cb68be\nAuthor: Nghia Tran\nThe ‘Salt Water Tracker’ project, using the XIAO BLE nRF52840 Sense, addresses the problem of seawater erosion in rice fields in areas like the Mekong Delta in Vietnam. The project integrates a saltwater sensor system onto a Hovergames drone, turning the drone into an efficient saltwater tracking tool. This project helps farmers monitor the salinity of rivers and large water networks in real-time to ensure water safety and guide the allocation of reservoir water. The system also features temperature, water quality, air quality sensors, and a camera function for taking pictures or videos of the water area and assisting in determining water type and conditions."
  },
  {
    "objectID": "chapter_5-1.html#sajac-project-intelligent-jacket-for-caving-adventure",
    "href": "chapter_5-1.html#sajac-project-intelligent-jacket-for-caving-adventure",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.2 SAJAC Project: Intelligent Jacket for Caving Adventure",
    "text": "5.1.2 SAJAC Project: Intelligent Jacket for Caving Adventure\nhttps://www.hackster.io/rifqiabdillah/sajac-project-smart-jacket-for-caving-0e6a19\nAuthor: Rifqi Abdillah\nCaving has become increasingly popular in recent years. However, cavers may face a variety of safety hazards, including extreme temperatures, damp air, low air pressure, poor air quality, and toxic gases. To address this, we developed the SAJAC project, an intelligent monitoring system designed to observe environmental conditions within a cave. The system uses Nicla Sense ME to measure the environmental quality around the user and sends the results to the SAJAC app on the user’s smartphone. If the cave conditions are not suitable for exploration, Nicla Sense ME or the user’s smartphone will receive notification reminders. Meanwhile, at each checkpoint within the cave, there will be a transmitter directly connected to the guard outside the cave. The user can quickly seek help via the transmitter when in danger.\nConsidering that there is no internet connection in the cave, we use a LoRa communication system based on XIAO ESP32C3 to transmit checkpoint data. When the user reaches the checkpoint, they just need to connect to the transmitter and press the “send” button. If the user encounters a situation where they cannot continue the exploration, they can decide whether to return on their own or wait for the guard’s response.\nThe main post guard will use LoRa to receive data transmitted from within the cave. There is a Wio Terminal equipped with Grove Wio E5 at the outpost to receive data from transmitters inside the cave. The Wio Terminal only needs a 5-volt power supply, suitable for places with limited power."
  },
  {
    "objectID": "chapter_5-1.html#bicycle-computer-on-spresense",
    "href": "chapter_5-1.html#bicycle-computer-on-spresense",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.3 Bicycle Computer on Spresense",
    "text": "5.1.3 Bicycle Computer on Spresense\nhttps://www.hackster.io/jens6151/bicycle-computer-on-spresense-b0e332\nAuthor: Jens\nThe goal of this project is to build a bike computer using the Sony Spresense main board, LTE expansion board, XIAO, and other peripherals. The main features include:\n\nCapture a low-resolution video stream and display it on a monitor. Option to take high-resolution photos and store them on an SD card.\nCapture mono audio, using the OPUS codec and OGG container format for high compression, to be sent or recorded to SD card via an LTE-M connection.\nTrack location via GNSS, combining the location with weather data and points of interest (POI) data received from cloud services via an LTE connection.\nConnect bike sensors (currently heart rate) via Bluetooth Low Energy, display data on the monitor, and record.\nRemote access to the camera, real-time audio stream, and various data (including location) via MQTT.\nTheft detection and notification via GNSS geofencing, accelerometer, and monitoring for nearby smartphones.\n\nThis project by Jens demonstrates the astonishing complexity of a hardcore prototype project, as can be seen from the schematic on the right."
  },
  {
    "objectID": "chapter_5-1.html#iot-ai-driven-yogurt-processing-texture-prediction-w-blynk",
    "href": "chapter_5-1.html#iot-ai-driven-yogurt-processing-texture-prediction-w-blynk",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.4 IoT AI-driven Yogurt Processing & Texture Prediction W/ Blynk",
    "text": "5.1.4 IoT AI-driven Yogurt Processing & Texture Prediction W/ Blynk\nhttps://www.instructables.com/IoT-AI-driven-Yogurt-Processing-Texture-Prediction/\nAuthor: Kutluhan Aktar\nThe aim of this project is to provide texture prediction for yogurt processing using IoT technology and AI. By using the XIAO ESP32C3 development board, along with a temperature and humidity sensor, integrated pressure sensor kit, I2C weight sensor kit, and DS18B20 waterproof temperature sensor, the project creator built an artificial neural network model and trained it with Edge Impulse to predict yogurt texture without the addition of chemical additives. Users can remotely view sensor readings and control devices through the Blynk app. Finally, the author designed a durable enclosure suitable for a dairy environment. This project has the potential to help dairy product manufacturers reduce costs and improve product quality."
  },
  {
    "objectID": "chapter_5-1.html#web-browser-operated-robot-for-gas-leak-detection",
    "href": "chapter_5-1.html#web-browser-operated-robot-for-gas-leak-detection",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.5 Web browser operated robot for gas leak detection",
    "text": "5.1.5 Web browser operated robot for gas leak detection\nhttps://www.hackster.io/ivan-arakistain/web-browser-operated-robot-for-gas-leak-detection-4cbe1b\nAuthor: Ivan Arakistain\nThis project repurposes an old hoverboard into a remote-controlled robot equipped with a hydrogen sensor for early detection of hydrogen leaks. It uses Bluetooth to connect the Seedstudio Xiao Ble Sense, MQ-8 gas sensor, and other devices, and uses Edge Impulse Studio to train a machine learning model. The robot also uses the Blues Wireless Notecard NBGL cellular connection technology to upload data to the cloud. With Remo.TV, it can be remotely operated to drive the robot and view real-time camera feeds through a browser."
  },
  {
    "objectID": "chapter_5-1.html#train-controller-with-seeed-studio-xiao-esp32c3",
    "href": "chapter_5-1.html#train-controller-with-seeed-studio-xiao-esp32c3",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.6 Train Controller With Seeed Studio XIAO ESP32C3",
    "text": "5.1.6 Train Controller With Seeed Studio XIAO ESP32C3\nhttps://www.instructables.com/Train-Controller-With-Seeed-Studio-XIAO-ESP32C3/\nAuthor: Tiago Santos\nThis project designs a train controller using the XIAO ESP32C3 module from Seeed Studio. The project is divided into a train part and a controller part. The train part uses the XIAO ESP32C3 module to connect to the train and controls the train motor through the L293D motor driver. The controller part uses the Wemos D1 Mini to receive speed and direction information and displays the actual speed on a 0.96-inch ssd1306 screen. The controller communicates with the train part through Wi-Fi and an MQTT server. The project simplifies the complexity of traditional Lego train remote control systems and improves control efficiency."
  },
  {
    "objectID": "chapter_5-1.html#rc-car-arduino-based-3d-resin-printed-rc_car_rp",
    "href": "chapter_5-1.html#rc-car-arduino-based-3d-resin-printed-rc_car_rp",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.7 RC Car (Arduino-Based 3D Resin Printed) RC_Car_RP",
    "text": "5.1.7 RC Car (Arduino-Based 3D Resin Printed) RC_Car_RP\nhttps://www.hackster.io/devinnamaky/rc-car-arduino-based-3d-resin-printed-rc-car-rp-9b4dce\nAuthor: Devin Namaky\nThis project is a 3D printed remote-controlled car based on Arduino Nano and Seeeduino XIAO, named RC_Car_RP. The project uses two standard 130 type DC motors as drive and steering, and the steering system uses gear transmission. The Seeeduino XIAO module is used to control the motor driver TB6612FNG, realizing the control of the car speed and direction. Communication between the remote control and the car is achieved through the nRF24L01 wireless module. The project is small in size, simple in design, easy to build, and can meet the remote-controlled car needs in different scenarios."
  },
  {
    "objectID": "chapter_5-1.html#pet-activity-tracker-using-xiao-ble-sense-edge-impulse",
    "href": "chapter_5-1.html#pet-activity-tracker-using-xiao-ble-sense-edge-impulse",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.8 Pet Activity Tracker using XIAO BLE Sense & Edge Impulse",
    "text": "5.1.8 Pet Activity Tracker using XIAO BLE Sense & Edge Impulse\nhttps://www.hackster.io/mithun-das/pet-activity-tracker-using-xiao-ble-sense-edge-impulse-858d73\n Author: Mithun Das\nThis project is a wearable device that tracks pet activities using XIAO BLE Sense and Edge Impulse, aimed at helping our pets stay active. The XIAO BLE Sense is a mini controller equipped with a powerful Nordic nRF52840 MCU, built-in Bluetooth 5.0 module, and designed around a 32-bit ARM® Cortex™-M4 CPU. It features a 6-axis IMU that can be used to predict activities such as rest, walking, and running.\nWith the accompanying smartphone app, users can connect to the device via Bluetooth and obtain minute-by-minute prediction data. The data is stored in the smartphone’s local storage and presented graphically to provide meaningful insights.\nThe project collects data via the EI Blue mobile app, creates machine learning models using Edge Impulse Studio, and builds an iOS app using Google Flutter. The whole system can monitor the pet’s activity status in real-time and view the data through the mobile app."
  },
  {
    "objectID": "chapter_5-1.html#h.e.d.s.-on-your-wrist-new-seeeduino-xiao-board",
    "href": "chapter_5-1.html#h.e.d.s.-on-your-wrist-new-seeeduino-xiao-board",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.9 H.E.D.S. On your wrist, New Seeeduino XIAO Board",
    "text": "5.1.9 H.E.D.S. On your wrist, New Seeeduino XIAO Board\nhttps://www.hackster.io/ihayri1/h-e-d-s-on-your-wrist-new-seeeduino-xiao-board-7d8f74 https://youtu.be/ql2wnFtSQqQ\nAuthor: Hayri Uygur\nHayri has made a Maker-style multifunctional wristwatch, H.E.D.S., using XIAO. It provides a set of small, handy tools with many functions and variations, and is equipped with a beautiful, sharp 240x240 pixel IPS display."
  },
  {
    "objectID": "chapter_5-1.html#hearbeat-monitor-with-xiao-nrf52840",
    "href": "chapter_5-1.html#hearbeat-monitor-with-xiao-nrf52840",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.10 Hearbeat Monitor With XIAO NRF52840",
    "text": "5.1.10 Hearbeat Monitor With XIAO NRF52840\nhttps://www.instructables.com/Hearbeat-Monitor-With-XIAO-NRF52840/\nAuthor: TiagoSantos This project uses a XIAO NRF52840 microcontroller, based on the Nordic nRF52840 CPU, to make a heartbeat monitor. This microcontroller supports Bluetooth 5.0 and NFC and has a super small size, making it ideal for wearable devices and other projects with limited space. The project uses another biomedical microcontroller called Bitalino to monitor the heartbeat. The XIAO NRF52840 receives information from the ECG (Electrocardiogram) sensor and then transmits it to a set of LEDs. Through this project, we can view the heart rate in real-time and observe the data of heart activity.\n\nPrepare the Bluetooth version of XIAO nRF52840. Its small size is very suitable for wearable devices.\n\n\n\n\nBitalino is a biomedical kit similar to Arduino developed by Hugo Silva in Portugal. This project will use some modules from it.  \nCircuit diagram: XIAO receives heart rate information from the ECG sensor, converts it, and sends it. The LED flashes with the heart rate, and the Arduino serial port plotter displays the graphical information of the heart rate.  \n\n\n\n\nUse a perforated board to place components and solder. First, place resistors and the female pins of XIAO, then solder the ECG sensor. Finally, cut the perforated board to the required size.\n\n\n\n\n\n\nUse Fusion 360 to design the LED shell, the main shell, and the structure of the chest part. Use Creality Slicer to transcode and send it to the 3D printer to get structural parts.\n\n\n\n\n\n\n\n\nWhen connecting the LED, use a perforated board to connect all cathodes and place a ground connector. After all connections are completed, it is necessary to check whether VCC is isolated from the ground and perform a test.\n\n\n\n\nNot everything can go as expected. During the connection check, the fixture exerted too much force, causing the perforated board to break. It had to be redone.\n\n\n\n\nFinally, it’s time to connect the battery and isolate all circuits to avoid short circuits. Usually, heat-shrink tubing would be used here, but if there is no suitable size, hot glue can also work.\n\n\n\n\nPlace all components on the 3D printed parts and perform a test, then use super glue to connect the parts. The part fixed on the chest was pasted with an elastic band. Finally, replace the LED and remove the resistor to get more noticeable light effects.\n\n\n\n\nThe final effect."
  },
  {
    "objectID": "chapter_5-1.html#multi-midi-controller-filter-router-sound-generator",
    "href": "chapter_5-1.html#multi-midi-controller-filter-router-sound-generator",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.11 Multi MIDI Controller, Filter, Router & Sound Generator",
    "text": "5.1.11 Multi MIDI Controller, Filter, Router & Sound Generator\nhttps://www.synthtopia.com/content/2022/03/29/multi-midi-controller-filter-router-sound-generator/ https://github.com/pangrus/multi\nAuthor: Pangrus\nMulti is a multifunctional MIDI controller, primarily used for audio synthesis, with a very small size. Compared with the latest generation of commercial controllers, it has a USB port and two DIN interfaces. The Multi controller is fully programmable, allowing for some functionalities in a computer-free setup. In addition, it can also be used as a sound generator as it is equipped with a 10-bit DAC converter, making it ideal for exploring digital synthesis technology. The Multi controller is powered by the robust Seeeduino XIAO, featuring 6 knobs, 2 buttons, 2 Midi DIN interfaces, and a 1/8 inch audio interface. Its MIDI input has opto-isolation to avoid ground loops, complying with the official specification."
  },
  {
    "objectID": "chapter_5-1.html#diy-eurorack-modular-synth-raspberry-pi-vco-with-seeed-xiao",
    "href": "chapter_5-1.html#diy-eurorack-modular-synth-raspberry-pi-vco-with-seeed-xiao",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.12 DIY eurorack modular synth Raspberry Pi VCO with Seeed XIAO",
    "text": "5.1.12 DIY eurorack modular synth Raspberry Pi VCO with Seeed XIAO\nhttps://www.hackster.io/hagiwo/diy-eurorack-modular-synth-rasberry-pi-vco-with-seeed-xiao-133ac0\nAuthor: HAGIWO/ハギヲ\nA maker from Japan, HAGIWO/ハギヲ, used the Seeed XIAO RP2040 development board to create a Voltage-Controlled Oscillator (VCO) module for a Eurorack modular synthesizer. This board has a Raspberry Pi RP2040 microcontroller, 4 AD converters, and is easier to use than the Raspberry Pi Pico. The VCO module has three modes: Wavefold, FM, and AM, with eight built-in waveforms, costing only about 1100 yen."
  },
  {
    "objectID": "chapter_5-1.html#xiao-cv-sequencer",
    "href": "chapter_5-1.html#xiao-cv-sequencer",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.13 Xiao CV Sequencer",
    "text": "5.1.13 Xiao CV Sequencer\nhttps://www.instructables.com/Xiao-CV-Sequencer/\nAuthor: analogsketchbook\nUsing the Seeduino Xiao microcontroller and a few parts, a decent CV synthesizer was created, mainly for modular synthesizer systems. Xiao’s role in this project is to output Control Voltage (CV) signals through its analog output pins for passing note information between modules. It also controls other features such as adjusting speed, mode switching, and sequence selection."
  },
  {
    "objectID": "chapter_5-1.html#anavi-macro-pad-10-knobs",
    "href": "chapter_5-1.html#anavi-macro-pad-10-knobs",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.14 ANAVI Macro Pad 10 & Knobs",
    "text": "5.1.14 ANAVI Macro Pad 10 & Knobs\nhttps://www.crowdsupply.com/anavi-technology/anavi-macro-pad-10\nAuthor: Crowd Supply\nA company has designed and manufactured three small, programmable, open-source mechanical input devices through crowdfunding: ANAVI Macro Pad 10 keyboard, ANAVI Knob 3, and ANAVI Knob 1. All are driven by the powerful Raspberry Pi RP2040 microcontroller inside Seeed XIAO RP2040, support USB Type-C, and run the KMK firmware based on CircuitPython. These customizable devices are suitable for video or audio editing, entertainment broadcasting, gaming, programming, etc., providing precise control and practical lighting effects. They are simple to use, and their plans and schematics can be found on GitHub."
  },
  {
    "objectID": "chapter_5-1.html#death-stranding-desk-lamp",
    "href": "chapter_5-1.html#death-stranding-desk-lamp",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.15 Death Stranding Desk Lamp",
    "text": "5.1.15 Death Stranding Desk Lamp\nhttps://www.hackster.io/wyx269263336/death-stranding-desk-lamp-ae5f71\n\nAuthor: Pinkman\nThis smart lamp, based on the multifunctional scanning device Odradek in the game Death Stranding, is made up of five separate light blades, each with three degrees of freedom, so you can adjust the desired angle at any time. It integrates the XIAO nRF52840 Sense Bluetooth main control board and WS2812 magic color light strip, and you can control its color and brightness through a mobile app."
  },
  {
    "objectID": "chapter_5-1.html#hackerbox-0077veritas",
    "href": "chapter_5-1.html#hackerbox-0077veritas",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.16 HackerBox 0077：Veritas",
    "text": "5.1.16 HackerBox 0077：Veritas\nhttps://www.instructables.com/HackerBox-0077-Veritas/\nAuthor: HackerBoxes\nThis project teaches you how to make a simple lie detector. It involves configuring the Seeeduino XIAO microcontroller module, modifying the OLED module to achieve dual display operation with a single microcontroller, assembling a Galvanic Skin Response (GSR) sensor based on an operational amplifier, and integrating a heart rate sensor. XIAO acts as the core controller in the project, realizing data collection, processing, and display."
  },
  {
    "objectID": "chapter_5-1.html#discipline---a-workout-timer",
    "href": "chapter_5-1.html#discipline---a-workout-timer",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.17 DISCIPLINE - A workout timer",
    "text": "5.1.17 DISCIPLINE - A workout timer\nhttps://www.hackster.io/rw2493/discipline-a-workout-timer-6b5614\nAuthor: Rui Wang\nDISCIPLINE: This is a homemade timer that helps you strictly control rest intervals during muscle training. The project uses the Seeeduino XIAO microcontroller, along with two buttons, a display screen, a battery, and other components to achieve a simple user interface and a portable design. XIAO is responsible for the core control function of the timer in the project, providing accurate timing services to users.\n\n\nThe design goals include:\n\nSmall, portable, and compact\nComplete timer functions\nSimple user interface design\nClear interaction flow\nCool appearance\n\nInteraction is designed to be as simple as possible to minimize operation steps.\n\n\nYellow and blue button light interaction description: After some playtests, I then use the yellow button to control the time setup, and I use the blue button to start the counting. To provide a good indication, I did several things for the LEDs. ( Y for Yellow, B for Blue) When powering it on: Y -&gt; Fade; B -&gt; ON, indicate to pick up a time period.\n\nWhen powering it on: Y -&gt; Fade; B -&gt; ON, indicate to pick up a time period.\n\nPress Y to switch timing options: 30s, 60s, 90s, 120s.\n\nPress Y to switch timing options: 30s, 60s, 90s, 120s.\n\nPress B to confirm your choice, the timer starts counting down. Y -&gt; OFF; B -&gt; OFF.\n\nPress B to confirm your choice, the timer starts counting down. Y -&gt; OFF; B -&gt; OFF.\n\nTimer ends counting, B -&gt; ON; Y -&gt; OFF forever.\n\nTimer ends counting, B -&gt; ON; Y -&gt; OFF forever.\n\n\n\nTwo finger operation: The final design choice was to allow users to hold it easily with one hand and operate it with two fingers.\n\n\n\n\nMagnetic Attachment:  After analyzing pain points, it was decided to use magnets to attach the product to places where interaction and operation are more easily realized."
  },
  {
    "objectID": "chapter_5-1.html#seeed-fusion-diy-xiao-mecha",
    "href": "chapter_5-1.html#seeed-fusion-diy-xiao-mecha",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.18 Seeed Fusion DIY XIAO Mecha",
    "text": "5.1.18 Seeed Fusion DIY XIAO Mecha\nhttps://www.seeedstudio.com/seeed-fusion-diy-xiao-mechanical-keyboard-contest.html\nXIAO 的小巧尺寸与其强悍的性能，没想到在 DIY 键盘与控制器玩家中得到认可，为此 Seeed 在2022年7月至10月，组织了一次 Fusion XIAO 机器键盘大赛，下面我们展示了此次比赛的一些获奖项目，以帮助对 DIY 键盘有兴趣的读者。\n\n1st Prize: TOTEM | a tiny splitkeyboard with splay\n(2x)19 key ergo split: 3-key thumb cluster, pinky splay, low profile. Useful repo and classy, unique case. Nicely documented and open source. And it’s a usable keyboard, which could be used as a daily driver. Other than that, Marc took a great effort to present his design aesthetically\nhttps://www.hackster.io/geist/totem-a-tiny-splitkeyboard-with-splay-cb2e43\n\nAuthor: Marc Rühl\n\n\n\n\n\n\n2nd Prize: Beyblock20 | a magnetic, modular MacroPad\nhttps://github.com/ChrisChrisLoLo/beyblock20\nAuthor: Christian Lo\n\n\n\n\n2nd Prize: Purple Owl | a 60% keyboard powered by Seeed XIAO RP2040\nhttps://www.hackster.io/sonalpinto/purple-owl-a-60-keyboard-powered-by-seeed-xiao-rp2040-f73604\n Author: Sonal Pinto\n\n\n\n\n3rd Prize: KLEIN | a wireless ergonomical keyboard\nhttps://www.hackster.io/nosnk/klein-a-wireless-ergonomical-keyboard-b4cd9a\n Author: Shashank\n\n\n\n\n3rd Prize: GRIN Quern | an ergonomic keyboard on center trackpad\nhttps://www.hackster.io/policium/grin-quern-ergonomic-keyboard-on-center-trackpad-8b58c3\n Author: policium\n\n\n\n\n\n\n\n\n3rd Prize: Kidoairaku Swallowtail | a cute butterfly-shaped keyboard\n\nAuthor: yswallow"
  },
  {
    "objectID": "about_authors.html",
    "href": "about_authors.html",
    "title": "About the authors",
    "section": "",
    "text": "Lei Feng is the leader of the technical support group and product curriculum at Seeed Studio. An experienced author in the fields of open-source hardware and edge computing, he has published several books in China, including “GameGo Beginner Programming Course for Arcade 《做游戏，玩编程——零基础开发微软 Arcade 掌机游戏》,” “Grove Beginner Kit For Arduino - Codecraft Graphical Programming Course 《Arduino 图形化编程轻松学》”, and the Chinese translation of “IoT for Beginners 《深入浅出 IoT：完整项目通关实战》” with support from Microsoft China.\nLei Feng has created numerous tutorials and open-source documentation in Chinese and English with his team. His hands-on experience developing IoT and edge computing projects gives him unique insights into simplifying complex concepts for beginners. As an engaging writer and patient teacher, Lei Feng is the ideal guide to make Arduino and TinyML approachable for newcomers worldwide.\nLinkedIn profile: https://www.linkedin.com/in/leon-feng-a029bb1/\nMarcelo Rovai is a recognized figure in engineering and technology education, holding the title of Professor Honoris Causa from the Federal University of Itajubá, Brazil. His educational background includes an Engineering degree from UNIFEI and an advanced specialization from the Polytechnic School of São Paulo University. Further enhancing his expertise, he earned an MBA from IBMEC (INSPER) and a Master’s in Data Science from the Universidad del Desarrollo in Chile.\nWith a career spanning several high-profile technology companies such as AVIBRAS Airspace, ATT, NCR, and IGT, where he served as Vice President for Latin America, he brings a wealth of industry experience to his academic endeavors. He is a prolific writer on electronics-related topics and shares his knowledge through open platforms like Hackster.io.\nIn addition to his professional pursuits, he is dedicated to educational outreach, serving as a volunteer professor at UNIFEI and engaging with the TinyML4D group as a Co-Chair, promoting TinyML education in developing countries. His work underscores a commitment to leveraging technology for societal advancement.\nLinkedIn profile: https://www.linkedin.com/in/marcelo-jose-rovai-brazil-chile/"
  }
]