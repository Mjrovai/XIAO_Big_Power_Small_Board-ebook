[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "XIAO: Big Power, Small Board",
    "section": "",
    "text": "Preface\nFrom the expansive boards of the past, Arduino has come a long way and entered the Seeed Studio XIAO series: thumb-sized yet power-packed, opening a vast horizon for innovation. “XIAO: Big Power, Small Board” dives deep into these capabilities, guiding readers from the basics of Arduino to intricate miniaturized projects. Whether readers want to illuminate an LED or delve into Embedded Machine Learning (TinyML) with XIAO boards and Edge Impulse Studio, this book covers them. Need for prior knowledge? No worries! This book takes a hands-on, project-based approach, ensuring readers grasp the concepts while implementing them. By the end, they will be adept with XIAO and inspired by many user-created projects showcasing the endless possibilities this small board offers."
  },
  {
    "objectID": "Acknowledgements.html",
    "href": "Acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "We want to express our sincere gratitude to Jiamou Yang, Yanming Wen, Mengdu Li, Chunchun Tian, Haixu Liu, Tianrui Wang, and Jianjing Huang for their invaluable technical support and manuscript revisions. This book would not have been possible without their contributions.\nWe extend our deepest gratitude to the entire TinyML4D Academic Network, comprised of distinguished professors, researchers, and professionals. Notable contributions from Marco Zennaro, Brian Plancher, José Alberto Ferreira, Jesus Lopez, Diego Mendez, Shawn Hymel, Dan Situnayake, Pete Warden, and Laurence Moroney have been instrumental in advancing our understanding of Embedded Machine Learning (TinyML).\nSpecial commendation is reserved for Professor Vijay Janapa Reddi of Harvard University. His steadfast belief in the transformative potential of open-source communities, coupled with his invaluable guidance and teachings, has served as a beacon for our efforts from the very beginning.\nAcknowledging these individuals, we pay tribute to the collective wisdom and dedication that have enriched this field and our work.\n\nIllustrative images on the e-book and chapter’s covers generated by OpenAI’s DALL-E via ChatGPT"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "The Seeed Studio XIAO series represents a groundbreaking evolution in the Arduino ecosystem, merging compactness with powerful performance. Understanding and harnessing its capabilities are essential for any enthusiast or professional in electronics and machine learning. With the rapid progression of technology and the increasing demand for smaller, more efficient devices, mastering XIAO and its integration with TinyML is crucial. It presents a new frontier for innovation, allowing the creation of sophisticated projects in spaces previously thought impossible. This topic is paramount as it aligns with the future trajectory of electronics, IoT, and machine learning, making it indispensable for those aiming to stay at the forefront of technological advancements."
  },
  {
    "objectID": "about_book.html#audience",
    "href": "about_book.html#audience",
    "title": "About this Book",
    "section": "Audience",
    "text": "Audience\nThe primary audience for “XIAO: Big Power, Small Board” encompasses hobbyists, students, educators, and professionals in electronics and machine learning who want to explore and maximize the potential of compact hardware platforms. Typically, these readers might hold positions as electronics enthusiasts, DIY project creators, electronics educators, or even junior embedded system developers. As they advance in their careers, they might be eyeing roles such as electronics design engineers, IoT developers, or machine learning hardware integrators.\nOur audience possesses a basic understanding of electronics concepts but may have yet to delve deep into Arduino programming or compact hardware design. They likely have encountered standard beginner books on Arduino or general electronics but might have yet to venture into specialized hardware or TinyML. As for skills, they have some hands-on experience with basic electronics or programming but haven’t mastered the intricacies of TinyML or advanced microcontroller functionalities."
  },
  {
    "objectID": "about_book.html#what-readers-will-learn",
    "href": "about_book.html#what-readers-will-learn",
    "title": "About this Book",
    "section": "What readers will learn",
    "text": "What readers will learn\nBy the end of this book, the reader will understand:\n\nThe fundamentals of open-source hardware, focusing on the capabilities of the Seeed Studio XIAO series.\nHow to transition from basic to advanced electronic projects, starting with simple LED controls and advancing to complex applications like telemetry and voice keyword detection.\nThe concepts behind prototype design and its practical implications in product development.\nThe intricacies of integrating various modules like the infrared receiver, ultrasonic distance sensor, and RTC clock with the XIAO platform.\nThe significance and application of Tiny Machine Learning (TinyML), emphasizing its transformative power in hardware like the XIAO nRF52840 Sense and ESP32S3 Sense.\nTechniques to utilize advanced tools such as Edge Impulse Studio for real-world applications like anomaly and object detection and video or sound classification.\n\nThe reader will be able to:\n\nSet up, program, and troubleshoot projects across all XIAO series boards, advancing from basic hardware interactions to intricate project designs.\nConvert abstract ideas into tangible electronic product prototypes, leveraging the insights from the course.\nDesign and implement intermediate-level projects such as a Smart Watch and Air Piano using specialized sensors and modules.\nHarness the power of Wi-Fi and MQTT protocols with XIAO ESP32C3 for cloud communications and data exchange.\nDeploy TinyML on different XIAO boards, executing tasks like image, motion, and sound classification besides anomaly and object detection.\nInnovate and extend project ideas, drawing inspiration from a curated collection of XIAO projects and adapting them for custom needs."
  },
  {
    "objectID": "about_book.html#software-dependencies",
    "href": "about_book.html#software-dependencies",
    "title": "About this Book",
    "section": "Software dependencies",
    "text": "Software dependencies\n\nArduino IDE: Major updates or changes to the Arduino IDE might affect content related to Arduino development and programming in the book.\nSeeed Studio XIAO Libraries: Updates to libraries specific to the XIAO series can influence the projects or example codes provided.\nEdge Impulse Studio: Significant updates or feature changes on this platform would necessitate adjustments in the TinyML chapters.\nMQTT Libraries/Protocols: Any changes related to MQTT libraries or the protocol itself could influence the content of telemetry and commands.\nESP32 Libraries: Updates to libraries used by the XIAO ESP32C3 and ESP32S3 board may impact associated projects or examples."
  },
  {
    "objectID": "about_book.html#book-outline",
    "href": "about_book.html#book-outline",
    "title": "About this Book",
    "section": "Book outline",
    "text": "Book outline\n\nChapter 1: Introduction to Hardware and Programming In this chapter, readers start with basic programming on XIAO using Arduino IDE. Through simple example programs, they will learn to control LED lights, buttons, buzzers, and other electronic components, mastering core programming concepts like digital I/O, analog I/O, tone generation, and mapping values. By manually typing out code examples line-by-line, they will develop strong coding habits and grasp programming syntax.\nChapter 2: Project Practice for Beginners - Introduction to Prototype Design In this chapter, readers will learn the basics of designing prototypes with XIAO through beginner-friendly projects. They will start from an idea and quickly create a verification prototype, focusing more on the practical application of code rather than line-by-line analysis. By leveraging Arduino libraries, community resources, and example programs, they will learn how to find and adapt code snippets to achieve desired effects efficiently. Furthermore, they will explore how to design the physical appearance of prototypes by creatively combining electronic hardware with everyday items. The key outcomes are grasping a project-based approach and developing skills to build simple interactive prototypes.\nChapter 3: Intermediate Project Practice—Complex Projects In this chapter, readers will advance their prototyping skills by creating sophisticated IoT projects with XIAO. They will implement features like Wi-Fi connectivity, MQTT telemetry, and remote control commands using the XIAO ESP32C3. Through complex builds like an intelligent remote door, smartwatch, and air piano, you will hone programming techniques for wireless communication, cloud integration, and embedded control. Optional blueprints will be provided, but readers are encouraged to explore creative enclosure designs with alternative materials. The key outcomes are mastering intermediate IoT prototyping and preparing for advanced tinyML applications.\nChapter 4: Project Practice Advanced - tinyML Application Among the XIAO series products, the Seeed Studio XIAO nRF52840 Sense has Bluetooth 5.0 wireless connectivity, low power consumption, and comes with onboard 6-axis IMU and PDM microphone sensors. The XIAO ESP32S3 Sense further integrates a camera, digital microphone, and SD card support. Those features make them powerful tools for TinyML (Embedded Machine Learning) projects. TinyML solves problems in a completely different way from traditional programming methods. This chapter will introduce readers to this cutting-edge field by walking through the entire machine-learning workflow from data collection, training, and testing to deployment and inference using the Edge Impulse Studio tool.\nChapter 5: Creative Experiments Since its launch, the Seeed Studio XIAO series has been widely acclaimed for its compact size, powerful performance, and versatile product range. The maker community has produced a large number of projects created with XIAO. Due to space constraints, we have selected some outstanding projects made with XIAO by our makers. These projects fully demonstrate the powerful functions and wide applications of XIAO. Let us follow the makers’ steps, stimulate creativity, and explore the endless possibilities of XIAO. Readers can draw inspiration from these projects, use imagination, and explore new territories with XIAO."
  },
  {
    "objectID": "chapter_1.html",
    "href": "chapter_1.html",
    "title": "Chapter 1: Introduction to Hardware and Programming",
    "section": "",
    "text": "In this unit, we will enter the world of electronics and programming and explore how to control hardware through code. Starting with the example program, Blink, we will learn how to light up an LED, turn the light on and off through a button, control the sound of a passive buzzer, and so on. In each task, we will master commonly used programming languages, such as digital input/output, analog input/output, tone and map functions, etc., and learn the primary usage of libraries. The programs in this unit are relatively simple. During the learning process, write the program code for each task by hand, develop good habits, and avoid program upload failures due to errors in symbols or unfamiliar rules."
  },
  {
    "objectID": "chapter_1-1.html#arduino-ide-text-editor",
    "href": "chapter_1-1.html#arduino-ide-text-editor",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.1 Arduino IDE Text Editor",
    "text": "1.1.1 Arduino IDE Text Editor\nWe need to program the hardware through the Arduino IDE text editor. If you have not installed the Arduino IDE, go to the download page to install it: 🔗 Software. The Arduino IDE (Integrated Development Environment) is a programming software designed explicitly for Arduino. Through it, we can write and upload different programs for Arduino hardware. When we open the Arduino IDE software, it will create a new file named Sketch, which we can rename.\n\nFor Windows Users\nThe interface of the Arduino IDE is spotless, and can be divided into four parts: menu bar, toolbar, editing area, and debug window.\n\n Menu bar: Includes files, edit, sketch, tools, and help, such as new, save, example programs, select serial port, etc.\n Horizontal toolbar: Contains several commonly used function buttons: verify, upload, debug, board selection, serial plotter, and serial monitor selection.\n Vertical toolbar: Contains shortcuts to the project folder, board manager, library manager, debug, and search.\n Code editing area: This is where you write program code, just as we usually type text in a Word window. Write the program code in this area.\n Serial monitor, output window: On the right side of the horizontal toolbar, you can open or close the serial monitor window.\n\n\nFor MAC Users\nExcept for the location of the menu bar (at the top), which is slightly different from Windows users, all other tools and experiences are the same."
  },
  {
    "objectID": "chapter_1-1.html#adding-seeed-studio-xiao-to-arduino-ide",
    "href": "chapter_1-1.html#adding-seeed-studio-xiao-to-arduino-ide",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.2 Adding Seeed Studio XIAO to Arduino IDE",
    "text": "1.1.2 Adding Seeed Studio XIAO to Arduino IDE\n\n⚠️ Attention\n Due to space limitations, all parts of this course’s program code and hardware connection are based on Seeed Studio XIAO SAMD21. Most of the code in the book can be applied to all products in the Seeed Studio XIAO series. If there are exceptions, they will be additionally marked or explained for applicable hardware. If not marked, they apply to multiple products.\n\nWe must add the Seeed Studio XIAO series products to the Arduino IDE to start our learning journey.\n\nFor Windows users, first, open your Arduino IDE, click “File→Preferences” in the top menu bar, as shown in the figure, and copy the following URL into “Additional Boards Manager URLs.”\nFor Mac users, first, open your Arduino IDE, click “Arduino IDE→Preferences” in the top menu bar, as shown in the figure, and copy the following URL into “Additional Boards Manager URLs.”\nFor Seeed Studio XIAO SAMD21, XIAO nRF52840, and XIAO nRF52840 Sense, copy the link address below: https://files.seeedstudio.com/arduino/package_seeeduino_boards_index.json\nFor Seeed Studio XIAO RP2040, copy the link address below: https://github.com/earlephilhower/arduino-pico/releases/download/global/package_rp2040_index.json\nFor Seeed Studio XIAO ESP32C3, XIAO ESP32S3, copy the link address below: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_dev_index.json\n\n\n\nIf you frequently use multiple different models of XIAO at the same time, you can click on theicon on the right side of the address bar and add all three addresses above to the board manager, as shown in the figure below.\n\n\nNext, click “Tools→Board→Board Manager,” enter the keyword Seeeduino XIAO in the search bar, find Seeed SAMD Boards in the appeared entries, and click INSTALL.\n\n\nWhen the installation starts, you will see an output pop-up window. After the installation is complete, an “INSTALLED” option will appear.\n\n⚠️ Attention\n\nEnter “RP2040” in the search bar to find the installation package for Seeed XIAO RP2040.\nEnter “XIAO nrf52840” to find two installation packages: Seeed nRF52 Boards (for low-power projects) and Seeed nRF52 mbed-enabled Boards (for higher-power TinyML projects).\nEnter “ESP32” to find the installation package for ESP32 by Espressif Systems.\n\n\n\nConnecting Seeed Studio XIAO to Arduino IDE\nConnect XIAO to the computer with a data cable, as shown in the figure below:  \nNext, click on “Tools→Board”, find “Seeeduino XIAO,” and select it, as shown in the figure below.\n\n\n\n⚠️ Attention\nIf your development board is XIAO nRF52840, please select Seeed XIAO nrf52840.  If your development board is XIAO nRF52840 Sense, please select Seeed XIAO nrf52840 Sense.  If your development board is XIAO RP2040, please select Seeed XIAO RP2040.  If your development board is XIAO ESP32C3, please select XIAO_ESP32C3.  If your development board is XIAO ESP32S3, please select XIAO_ESP32S3. \n\nCheck if the port connection is correct; if not, select it manually.\n\nThe serial port on Windows systems is displayed as “COM+number,” as shown in the figure below.\nThe serial port name on Mac or Linux systems is generally /dev/tty.usbmodem+number or /dev/cu.usbmodem+number, as shown in the figure below.\n\nNow, we can start programming XIAO through the software.\n\n⚠️ XIAO ESP32C3 may not be adequately recognized in Arduino IDE 2, and you need to specify the development board and port manually.\n\n\n\n\nWhen ESP32C3 is plugged into a PC with Arduino IDE 2, it may not be able to match the correct development board automatically. As shown in the figure below, the display is not the XIAO ESP32 development board; you need to specify manually. Select ” Other Board & Port…” from the Port drop-down menu. Enter “xiao” in the search bar of the development board, select the XIAO_ESP32C3 development board from the filtered list below, and confirm after selecting the port on the right.\n\n\n\n\nNow you can see that the development board and port are in the correct state.\n\n\n\n\n⚠️ Reset Seeed Studio XIAO\nSometimes when the program upload fails, the Seeed Studio XIAO port may disappear, and we need to perform a reset operation. The reset method will be different for different models of XIAO.\n\n\nReset of Seeed Studio XIAO SAMD21\n\nConnect XIAO SAMD21 to your computer.\nOpen “Blink” in the Arduino IDE sample program and click upload.\nWhile uploading, short circuit the RST pin in the figure once with tweezers or a short wire.\nThe reset is completed when the orange LED flashes and lights up.\n\n\nAs shown in the figure below. .\n\nReset of Seeed Studio XIAO PR2040\n\nConnect Seeed Studio XIAO RP2040 to your computer.\nPress the reset button marked with “R” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, hold down the Boot button marked with “B”, connect the board to your computer while holding down the BOOT button, and then release it to enter the bootloader mode.\n\nReset of Seeed Studio XIAO nRF52840 and Sense version\n\nConnect Seeed Studio XIAO nRF52840 or Sense version to your computer.\nPress the reset button marked with “RST” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, you can quickly click it twice to enter the bootloader mode.\n\nReset of Seeed Studio XIAO ESP32C3\n\nConnect Seeed Studio XIAO ESP32C3 to your computer.\nPress the reset button marked with “R” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, hold down the Boot button marked with “B”, connect the board to your computer while holding down the BOOT button, and then release it to enter the bootloader mode.\n\nReset of Seeed Studio XIAO ESP32S3\n\nConnect Seeed Studio XIAO ESP32S3 to your computer.\nPress the reset button marked with “R” once, the position is shown in the figure below.\n\n\n\n\nIf this does not work, hold down the Boot button marked with “B”, connect the board to your computer while holding down the BOOT button, and then release it to enter the bootloader mode.\n\n\nStructure of Arduino Programs\nNow that we have the development board, how can we write programs into it to control its functions? That’s when the Arduino IDE text editor comes in handy. We’ve already introduced the interface functions of Arduino IDE in the introduction, it’s an important tool for writing and uploading programs. Arduino programs consist of two basic functions:\nsetup()  This function is called when the program begins. Use it to initialize variables, pin modes, start using libraries, etc. setup() runs only once each time the Arduino board is powered on or reset.\nloop()  After the program in setup() is executed, the program in loop() begins to execute. The program in loop() runs repeatedly.\n\n\n\nKnowledge window:\n\nThe contents after “/* */” and “//” are comments to help you understand and manage code, the comments will not affect the normal operation of the program;\nWhen writing programs, we need to use “{}” to wrap a set of codes;\nAfter each line of code, use “;” as an end symbol to tell the Arduino editor that this line of code instruction is over.\n\n\n\n\nDigital Signals and I/O Settings\nSimply put, digital signals are signals represented in binary form of 0 and 1. In Arduino, digital signals are represented by high and low levels, high level means digital signal 1, and low level means digital signal 0. Seeed Studio XIAO has 11 digital pins, we can set these pins to perform the function of inputting or outputting digital signals.\n\n\nIn Arduino, you can use functions to set the status and function of pins. Here are the basic steps to set pins through functions:\n\nFirst, determine the pin number of the pin you want to control.\nIn the Arduino code, use the pinMode() function to set the function of the pin, such as input or output. For example, to set the pin to output mode, you can use the following code:\n\nint ledPin = 13; // The pin to be controlled\nvoid setup() {\n    pinMode(ledPin, OUTPUT); // Set the pin to output mode\n}\n\nOnce you have set the pin to output mode, you can use the digitalWrite() function to set the status of the pin, such as setting it to high or low level. For example, to set the pin to high level, you can use the following code:\n\ndigitalWrite(ledPin, HIGH); // Set the pin to high level\n\nIf you set the pin to input mode, you can use the digitalRead() function to read the status of the pin, such as detecting whether it is high or low level. For example, to read the status of the pin and save it to a variable, you can use the following code:\n\nint buttonPin = 2; // The pin to read the status from\nint buttonState = 0; // The variable to save the status\nvoid setup() {\n    pinMode(buttonPin, INPUT); // Set the pin to input mode\n}\nvoid loop() {\n    buttonState = digitalRead(buttonPin); // Read the status of the pin\n}\nBy using functions like pinMode(), digitalWrite(), and digitalRead(), you can easily set and control the status and function of pins in Arduino."
  },
  {
    "objectID": "chapter_1-1.html#task-2-complete-the-blink-example-by-connecting-an-external-led-to-seeed-xiao-esp32c3-without-led",
    "href": "chapter_1-1.html#task-2-complete-the-blink-example-by-connecting-an-external-led-to-seeed-xiao-esp32c3-without-led",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.4 Task 2: Complete the Blink example by connecting an external LED to Seeed XIAO ESP32C3 without LED",
    "text": "1.1.4 Task 2: Complete the Blink example by connecting an external LED to Seeed XIAO ESP32C3 without LED\nIf the XIAO you have on hand is Seeed XIAO ESP32C3, since it does not have an onboard LED available for users, in order to run the Blink program, you need to first connect an LED to the D10 pin of the board, as shown below:\n\n\n\n⚠️ Note  You must connect a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED to prevent the strong current from burning the LED.\n\nThen copy the following program to the Arduino IDE:\n// Define the LED pin according to the pin diagram\nint led = D10;\n\nvoid setup() {\n    // Initialize the digital pin 'led' as output\n    pinMode(led, OUTPUT);\n}\n\nvoid loop() {\n    digitalWrite(led, HIGH);   // Turn the LED on\n    delay(1000);               // Wait for a second\n    digitalWrite(led, LOW);    // Turn the LED off\n    delay(1000);               // Wait for a second\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L1_Blinks_XIAO_ESP32C3/L1_Blinks_XIAO_ESP32C3.ino\n\n\nCode Analysis \nint led = D10;\nSeeed XIAO ESP32C3 does not have an onboard LED, so we did not preset an LED corresponding pin in the Arduino core. Just now, we connected the LED to the D10 pin, so we need to declare it in the program.\npinMode(led, OUTPUT);\nWe defined led as D10, and this step is to initialize led(D10) as an output pin."
  },
  {
    "objectID": "chapter_1-1.html#extended-exercise",
    "href": "chapter_1-1.html#extended-exercise",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.5 Extended Exercise",
    "text": "1.1.5 Extended Exercise\nRewrite the Blink program: In the example program, the LED is on and off for 1 second each time, so it seems to blink evenly. Try adjusting the waiting time to give the LED different blinking effects.\nHint:\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);\n}\nvoid loop() {\n    digitalWrite(LED_BUILTIN, HIGH);   \n    delay(1000);                     \n    digitalWrite(LED_BUILTIN, LOW);   \n    delay(500);   \n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L1_ll_Blinks_1_en/L1_ll_Blinks_1_en.ino\n\nFor XIAO ESP32C3, we also need to modify the pin definition part of the program:\nint led = D10;\nvoid setup() {\n    pinMode(led, OUTPUT);\n}\nvoid loop() {\n    digitalWrite(led, HIGH);   \n    delay(1000);                     \n    digitalWrite(led, LOW);   \n    delay(500);\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L1_ll_blinks_2_en/L1_ll_blinks_2_en.ino"
  },
  {
    "objectID": "chapter_1-2.html",
    "href": "chapter_1-2.html",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "",
    "text": "In the previous section, we learned how to control an LED light to blink using only the Seeed Studio XIAO and the onboard LED light. However, there was no interaction with the external environment, such as controlling the LED light through light or sound. In this section, we will introduce a simple sensor - the button switch, to form an automatic control system of sensor-controller-actuator. Before starting the task, we need to learn some basic knowledge, like what variables are and the common program structures, so that we can better understand and run the program. ## 1.2.1 Background Knowledge In the last section, we only used the onboard LED light of the Seeed Studio XIAO without connecting other modules. It could take quite some effort for beginners to use Dupont wires to connect external sensors to a board the size of a thumb and also involve a breadboard. Is there a simpler method? ### 1.2.1.1 Seeed Studio XIAO Expansion Board The Seeed Studio XIAO Expansion Board, only half the size of Raspberry Pi 4, is powerful and can quickly and easily build prototypes and projects. The board has a variety of peripherals such as OLED, RTC, expandable memory, passive buzzer, RESET/User button, 5V servo/sensor connector, various data interfaces… You can explore the infinite possibilities of Seeed Studio XIAO. The board also supports CircuitPython. All models in the Seeed Studio XIAO series have uniform specifications and support the Seeed Studio XIAO Grove Shield and Seeed Studio XIAO Expansion Board. The series includes XIAO SAMD21, XIAO RP2040, XIAO nRF52840, XIAO nRF52840 Sense, XIAO ESP32C3 and XIAO ESP32S3. The front and back function interfaces of the XIAO expansion board are shown in the following figure:  To make it easier and quicker to build projects with Seeed Studio XIAO, we equipped it with a powerful expansion board. This board has a wealth of onboard peripherals and can quickly connect to more electronic modules to implement various functions. The expansion board brings out all the pins of XIAO, as shown in the pin diagram below:  In most cases, the XIAO expansion board is suitable for all Seeed Studio XIAO series products. When we need to use the XIAO expansion board, we need to connect the XIAO development board to the corresponding position on the expansion board, as shown in the figure below. Connect the pin headers on the XIAO main board to the position circled in yellow on the expansion board. Be sure to align it before pressing down to avoid damaging the pins. After that, we can start working on projects in combination with the expansion board.  &gt; ⚠️ Note &gt; Please first plug the Seeed Studio XIAO into the two female headers on the expansion board, and then plug in the Type-C power supply, otherwise it will damage the Seeed Studio XIAO and the expansion board.\n\n1.2.1.2 Three Basic Structures of Programs\nThe three basic structures of programs are sequential structure, selection structure, and loop structure.  #### Sequential Structure As the name suggests, the program in a sequential structure is executed in the order of the statements. It is the most basic and simple program structure. As shown in the figure below, the program will first execute the operation in the S1 box, then the operation in the S2 box, and so on.  #### Selection Structure In a program,sometimes we need to make judgments based on the situation to decide the next step. For instance, the program might need to judge the light value in the current environment. If the light value is high, indicating a bright environment, there’s no need to light up the light. If the light value is low, indicating a dim environment, then it’s necessary to turn on the light. In such cases, we use a selection structure. As shown in the following figures, the selection structure will judge whether the condition is fulfilled. If “True”, it executes S1; if “False”, it executes S2; or if “True”, it executes S1, if “False”, it exits the selection structure.  ##### The if Statement The if statement is the most common selection structure, which executes the following statement when the given expression is true. The if statement has three structural forms as shown in the following example. Simple branch structure: Execute when the condition is fulfilled.\n\nif (expression) {\n  statement;\n}\nDual branch structure: Execute statement1 when the condition is fulfilled, otherwise execute statement2.\nif (expression) {\n  statement1;\n}\nelse {\n  statement2;\n}\nMulti-branch structure: Use nested if statements to judge different situations.\nif (expression1) {\n  statement1;\n}\nelse if (expression2) {\n  statement2;\n}\nelse if (expression3) {\n  statement3;\n}\n\nswitch……case Statement\nWhen dealing with multiple selection branches, using an “if……else” structure to write a program can be quite lengthy. In this case, it’s much more convenient to use a switch statement. The switch structure compares the expression in parentheses with the constants after case. If they match, it executes the corresponding statement and exits the structure via a break statement. If none match, it runs the statement after default. It’s important to note that the expression in parentheses after switch must be of integer or character type. \nswitch (expression) {\n  case constant_expression1:\n    statement1;\n    break;\n  case constant_expression2:\n    statement2;\n    break;\n    ……\n  default:\n    statementn;\n    break;\n}\n\n\nbreak Statement\nThe break statement can only be used in a switch multi-branch selection structure and loop structures. It is used to terminate the current program structure, allowing the program to jump to subsequent statements for execution.\n\n\nLoop Structure\nA loop structure is used when a part of the program needs to be executed repeatedly, based on given judgment conditions to determine whether to continue executing a certain operation or exit the loop. There are three common types of loop statements:\n\nwhile Loop\nThe while loop is a type of “when” loop that executes the statements in the loop body when a certain condition is met. \nwhile (expression) {\n  statement;\n}\n\n\ndo……while Loop\nThis is a type of “until” loop. The statement in the loop body is executed once before the expression is evaluated. If the expression is true, the loop continues. \ndo {\n  statement;\n} while (expression);\n\n\nfor Loop\nThis includes three expressions: Expression1 for initialization, Expression2 for judgment, and Expression3 for increment. \nfor (Expression1; Expression2; Expression3) {\n  statement;\n}\nIn addition to the above loop statements, there are control statements, break and continue, in the loop structure used to prematurely end the loop or exit the loop. In this lesson, we just need to understand these program structures. In later courses, we will gradually master them through project examples. ## 1.2.2 Task 1: Control the LED on the XIAO using the button on the XIAO expansion board #### Analysis The effect we want to achieve is that when the button is pressed, the LED lights up; when the button is released, the LED goes off. The program is written in three steps:\n\nDefine pins and create variables.\nInitialize and set pin status.\nRead the button status, implement condition judgment. If the button is pressed, the light is on, otherwise, the light is off.\n\n\nVariable\nIn a program, a value that can change is called a variable. For example, defining an integer variable i as int i;. We can assign a value to the variable at the same time as we define it, such as int i =0;. Furthermore, depending on the data type, different statements are used to define variables, such as defining a floating point number, float x = 1.9;, and so on. For more details, refer to the Arduino data types and constants documentation https://www.arduino.cc/reference/en/#variables.\n\n\n\n\nWriting the Program:\nStep 1: Define pins and create variables. The on-board button switch on the XIAO expansion board is D1, so we define it as pin 1 and set a variable for the button status. Note that LED_BUILTIN will set the LED to the correct pin, so we don’t need to manually define it:\nconst int buttonPin = 1;  // The on-board button switch on the XIAO expansion board is D1, which we define as pin 1\n// If you are using XIAO RP2040, please change 1 to D1\nint buttonState = 0;  // buttonState is a variable to store the button status\nStep 2: Set pin status. Set the LED pin to output status and the button pin to input pull-up status. Use INPUT_PULLUP to enable internal pull-up resistors. When the button is not pressed, it returns 1 or HIGH (high level). When the button is pressed, it returns 0 or LOW (low level).\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);// Set the LED pin to output status\n    pinMode(buttonPin, INPUT_PULLUP);// Set the button pin to input status\n}\nStep 3: Continuously read the button status. If the button is pressed, the light is on, otherwise, the light is off. Because the on-board LED of the XIAO is negative logic, when the button is pressed and returns 0, the LED is on; when it returns 1, the LED is off.\nvoid loop() {\n    // Read the button status and store it in the buttonState variable\n    buttonState = digitalRead(buttonPin);  \n    // Check whether the button is pressed, if the button is pressed\n    if (buttonState == HIGH) {\n        // Turn on the LED:\n        digitalWrite(LED_BUILTIN, HIGH);\n    }\n    else {\n        // Turn off the LED:\n        digitalWrite(LED_BUILTIN, LOW);\n    }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L2_Button_XIAO_en/L2_Button_XIAO_en.ino\n\n\n\nUploading the Program\nWe upload the program we wrote to the hardware. First, use the data cable in the kit to connect the XIAO to the computer.  Note the position of the buttons on the XIAO extensions used for testing in the figure. Then click the verify button  to verify the program. If it is correct, click the upload button  to upload the program to the hardware. When the debugging area displays “Done uploading.”, we can press the button to see if the LED lights up.  &gt; ⚠️ Note There are two identical buttons on the expansion board. One is the RESET button near the Type-C interface, and the other is the user-defined button near the lithium battery interface. Test with the one near the lithium battery interface.\n\n\n\n1.2.3 Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3\nFor the Seeed XIAO ESP32C3, it doesn’t have an on-board LED for users to use. To run the Blink program, you need to first connect an LED to the D10 pin of the board as shown:  &gt; ⚠️ Note Be sure to add a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED to prevent overcurrent from burning out the LED.\nThen copy the following program into the Arduino IDE:\n/*\n * Button controlling external LED of XIA\n\nApologies for the confusion. It seems that there was an issue with quoting text from the document. Let's continue:\n\n#### Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3\nFor the Seeed XIAO ESP32C3, it doesn't have an on-board LED for users to use. To execute the Blink program, you first need to connect an LED to the board's `D10` pin as shown. \n\n&gt; ⚠️ Note: Make sure to add a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED and prevent overcurrent from burning out the LED.\n\nThen, copy the following program into the Arduino IDE:\n```cpp\n/*\n * Button controlling external LED of XIAO ESP32C3\n */\n\nconst int buttonPin = 1;     // The pin number of the button\nint buttonState = 0;    // Variable for reading the button status\nint led = D10;  // Pin number of the LED\n\nvoid setup() {\n  // Initialize the LED pin as an output:\n  pinMode(led, OUTPUT);\n  // Initialize the button pin as an input:\n  pinMode(buttonPin, INPUT_PULLUP);\n}\n\nvoid loop() {\n  // Read the state of the button:\n  buttonState = digitalRead(buttonPin);\n  // Check if the button is pressed. If it is, the button state is HIGH\n  if (buttonState == HIGH) {\n    // Turn the LED on:\n    digitalWrite(led, HIGH);\n  }\n  else {\n    // Turn the LED off:\n    digitalWrite(led, LOW);\n  }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L2_Button_XIAO_ESP32C3_en\n\n\nPowering XIAO with an external battery\nWhen demonstrating the effect, in addition to using a data cable to power the computer, you can also use an external lithium battery. This makes it convenient to move and do projects, as shown in the picture.   ### 1.2.4 Expanded Exercise #### Flow Chart Before writing the program, you can first draw a flow chart of the program to help organize your thoughts. The common flow chart symbols are as follows:  The button-controlled LED program we implemented in this section is represented by the following flow chart. You can try drawing it yourself."
  },
  {
    "objectID": "chapter_1-3.html#extended-exercise",
    "href": "chapter_1-3.html#extended-exercise",
    "title": "1.3 Transforming XIAO and its Expansion Board into a Morse Code Transmitter",
    "section": "1.3.4 Extended Exercise",
    "text": "1.3.4 Extended Exercise\nThe passive buzzer can emit different pitches to form a simple melody. Research how to make Arduino play notes through a search engine. You can open the extended exercise code to experience the effect of playing “Happy Birthday” with the buzzer. &gt; Get this program from Github &gt; https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L3_HappyBirthday_en"
  },
  {
    "objectID": "chapter_1-4.html",
    "href": "chapter_1-4.html",
    "title": "1.4 Monitor Knob Value Changes with Serial Monitor",
    "section": "",
    "text": "When we write a few lines of code to control the board to light up the LED, or to use a button switch to control the buzzer, we can intuitively see the working state of these external hardware. If it achieves our expected results, it is very fortunate. What if it doesn’t? The program compiles without error, where is the mistake? It would be nice if they could speak up. In this section, we will learn how to communicate with the computer through the serial monitor and check the running status and information of the program and hardware. ## 1.4.1 Background Knowledge ### 1.4.1.1 Rotary Potentiometer The rotary potentiometer, although it doesn’t seem common, has a very wide range of uses in household appliances and industrial equipment. For example, the volume knob on the sound system.  The rotary potentiometer can produce an analog output value between 0 and VCC (the voltage of the connected circuit) on its connected pins. By rotating the knob, you can change the output voltage value. The range of the knob’s angle is 300°, and the output value is 0-1023. We can use the rotary potentiometer to control the LED light to show brightness changes, or control the servo to rotate at different angles, etc.  ### 1.4.1.2 Analog I/O In the Arduino series of development boards, the pins with “A” in front of the pin number are analog input pins. We can read the analog value on these pins to achieve the effect we want. #### Analog Signal In life, analog signals are everywhere, such as the change in sound, light, temperature, etc., the frequency, amplitude, etc. of the signal can change continuously with time.  So how do we read the analog value of the pin through the development board? The analog input pin has an ADC (analog-to-digital converter), which can convert the external input analog signal into a digital signal that the development board can recognize, thereby achieving the function of reading in analog values, i.e., it can convert a 0-5V voltage signal into an integer value of 0-1023.\n\nanalogRead();\n\nRead the value from the specified analog pin. Syntax analogRead(pin); Parameters pin:The name of the analog input pin to be read.\n\nanalogWrite();\n\nCorresponding to analog input is analog output. We use the analogWrite() function to achieve this function. It should be noted that when using this function, it is only through a special way to output different voltages to achieve the effect of approximate analog values. This method is called PWM pulse width modulation, so we are writing PWM square waves to the specified pin, not the true analog value. Syntax analogWrite(pin, value); Parameters pin:The pin to output PWM, allowed data type: int. value: Duty cycle, between 0-255, allowed data type: int. &gt; ### PWM Pulse Width Modulation &gt; Pulse width modulation (PWM) is a way to achieve analog results through digital output. Simply put, you can control the charging current by adjusting the period of PWM and the duty cycle of PWM. As shown in the figure, the voltage is switched back and forth between 0V (low level) and 5V (high level). A switchback is a period. In this period, if the time of high voltage is 25% and the time of low voltage is 75%, the duty cycle is 25%, and the output voltage is 5V. &gt; When we write a few lines of code to control the lighting of LEDs on the development board, or use button switches to control the buzzer, we can directly observe the working status of these external hardware. If it achieves our expected results, we are lucky. But what if it doesn’t? The program compiles without errors, so where is the problem? It would be nice if they could talk. In this section, we will learn how to communicate with the computer, monitor the running status and information of the program and hardware through the serial monitor. &gt; \n\n1.4.1.3 Serial Communication\nWhen we want to communicate with other devices using XIAO, the most common method is serial communication. All Arduino series development boards have this functionality. As we know, computers understand binary data (like 1010). Therefore, among electronic devices, serial communication achieves its function by sending and receiving such data. The key component to implement this function is the USART (Universal Synchronous/Asynchronous Receiver Transmitter). In the Arduino IDE, we can observe the sent and received data through the Serial Monitor, and we need related serial communication functions to implement this feature. \n\n**Serial.begin()；**\n\nThis function is used to open the serial port and set the data transmission rate. Syntax Serial.begin(speed); Parameters Serial: Serial port object. speed: Baud rate, commonly set to values like 9600, 115200, etc.\n\n**Serial.println();**\n\nSyntax Serial.println(val); Parameters Serial: Serial port object. val: The value to be printed, which can be of any data type.\nFor example, to print “hello world!!!” to the Serial Monitor, we need to initialize the serial port in the setup() function and output “hello world!!!” through the serial port in the loop() function:\nvoid setup() {\n    Serial.begin(9600); // Initialize the serial port and set the data transmission rate to 9600\n}\nvoid loop() {\n    Serial.println(\"hello world!!!\"); // Output \"hello world!!!\" through the serial port\n}\nReturning to the question at the beginning of this section: when we have written the code and verified it to be correct, but the effect of running the code exceeds expectations or the hardware doesn’t respond at all, where is the problem? At this time, we can use the Serial Monitor to observe the data sent or received by the hardware to make a judgment. For instance, we can control the on-off state of an LED with a button, and we can use the Serial Monitor to check the returned value when the button is pressed to determine whether the button is working properly. Next, we will learn how to use the Serial Monitor to make the hardware “speak”. ## 1.4.2 Task 1: Use the Serial Monitor to Check if the Button is Pressed #### Analysis Remember controlling the on-off state of an LED with a button? Some of the code can be reused. We only need to read the button on-off setting and button on-off state code, and then add the initialization of the serial port and the data sent to the serial port. The program writing still follows three steps:\n\nDefine button pins and variables.\nInitialize the serial port, set the serial port baud rate, and set the status of the button on-off pin.\nRead the button state and send it to the serial port. #### Write the program Step 1: Define the button pin and variable.\n\nconst int buttonPin = 1; // Define the button switch as pin 1. If you are using XIAO RP2040/XIAO ESP32, please change 1 to D1\nint buttonState = 0; // Define buttonState as a variable to store the button status\nStep 2: Initialize the serial port, set the baud rate of the serial port, and set the button switch pin status.\nvoid setup() {\n    pinMode(buttonPin, INPUT_PULLUP);  // Set the button pin as input\n    Serial.begin(9600); // Initialize the serial port\n}\nStep 3: Read the button status and send it to the serial port\nvoid loop() {\n    buttonState = digitalRead(buttonPin);  // Read the button status and store it in the buttonState variable\n    Serial.println(buttonState); // Send the button status data to the serial port\n    delay(500);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L4_ReadButton_XIAO_en\n\n\nUpload the program:\nWe will upload the written program to the hardware. First, connect the XIAO to the computer with the data cable from the kit.  Note the position of the buttons on the XIAO extensions used for testing in the figure.\nClick  (Verify Button) in the Arduino IDE to verify the program. If the verification is correct, click (Upload Button) to upload the program to XIAO. When the debug area shows “Done uploading.”, open the serial monitor and observe the value changes printed by the serial monitor when the button is pressed and released. What did you find?\n\nWhen we press the button on the XIAO expansion board, the serial monitor shows 0, and when we release the button, the serial monitor shows 1. ## 1.4.3 Task 2: Using the Serial Monitor to View Knob Value Changes #### Analysis: In Task 1, the button switch is a digital input that sends out digital signals 0 and 1, while the knob potentiometer returns an analog signal. We need to read the rotation angle value of the knob potentiometer on pin A0 and send it to the serial port. The program also consists of three steps:\n\nDefine the knob potentiometer pin and variables.\nInitialize the serial port and set the status of the knob potentiometer pin.\nRead and calculate the rotation angle value of the knob potentiometer and send it to the serial port. #### Write the program Step 1: Define the knob potentiometer pin and variables. Here we need to define the voltage value of the ADC (Analog-to-Digital Converter) and the reference voltage of the Grove module interface, because we will calculate the voltage changes in the circuit where the knob switch is connected through these voltage values.\n\n#define ROTARY_ANGLE_SENSOR A0  // Define the rotary potentiometer interface A0\n#define ADC_REF 3 // ADC reference voltage is 3V\n#define GROVE_VCC 3 // Grove interface reference voltage is 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the knob potentiometer is 300°\nStep 2: Initialize the serial port, set the baud rate of the serial port, and set the status of the knob potentiometer pin.\nvoid setup()\n{\n    Serial.begin(9600);//Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);//Set the rotary potentiometer pin to input state\n}\nStep 3: Read and calculate the rotational angle value of the rotary potentiometer and send it to the serial port. Here, we first need to set the data type of the voltage variable, set the analog value variable of the rotary potentiometer pin, and then calculate the real-time voltage. After calculating the real-time voltage, calculate the rotational angle value of the rotary potentiometer.\nvoid loop()\n{   \n    float voltage;    //Variable voltage is of floating-point type\n    int sensorValue = analogRead(ROTARY_ANGLE_SENSOR);    //Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensorValue*ADC_REF/1023;    //Calculate real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC;    //Calculate the rotation angle of the knob\n    Serial.println(\"The angle between the mark and the starting position:\");    //Print characters at the serial port\n    Serial.println(degrees);    //Print the rotation angle value of the rotary potentiometer at the serial port\n    delay(100);\n}\n\n#define Macro Definition\n#define is a pre-processing command used for macro definitions. In Arduino, we can use #define to name constants. During the compilation of the program, all occurrences of the “macro name” will be replaced with the string in the macro definition, such as #define ledPin 5. During compilation, 5 will replace all uses of ledPin. Syntax: #define constant name constant value. The “#” symbol is mandatory, and there is no need to use the “;” symbol at the end of the sentence.\n\nThe complete code is as follows:\n/*\n * Use the serial monitor to view the knob potentiometer\n */\n#define ROTARY_ANGLE_SENSOR A0//Define the rotary potentiometer interface A0\n#define ADC_REF 3 //ADC reference voltage 3V\n#define GROVE_VCC 3 //Reference voltage 3V\n#define FULL_ANGLE 300 //The maximum rotation angle of the rotary potentiometer is 300°\n \nvoid setup()\n{\n    Serial.begin(9600);//Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);//Set the rotary potentiometer pin as an input\n}\n \nvoid loop()\n{   \n    float voltage;//Variable voltage is of floating-point type\n    int sensorValue = analogRead(ROTARY_ANGLE_SENSOR);//Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensorValue*ADC_REF/1023;//Calculate real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC;//Calculate the rotation angle of the knob\n    Serial.println(\"The angle between the mark and the starting position:\");//Print characters at the serial port\n    Serial.println(degrees);//Print the rotation angle value of the rotary potentiometer at the serial port\n    delay(100);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L4_ReadRotary_XIAO_en\n\n\n\nUpload the program:\nAfter writing the program, since external sensors are used, connect the knob module to the A0 interface using the four-color Grove cable as shown in the image below:  After connecting, connect the XIAO main control board to your computer using a data cable. In the Arduino IDE, click on the verification button  to verify the program. If it verifies correctly, click the upload button to upload the program to the hardware. When the debugging area shows “Done uploading.”, you can proceed. Open the serial monitor and rotate the knob potentiometer to observe the data changes displayed in the serial monitor. These changes represent the angle value of the knob.  ## 1.4.4 Extended Exercise While observing the angle value of the knob potentiometer in the serial monitor, we find that the value is constantly jumping and changing. Observing through the numbers alone is not very intuitive. At this time, we can use the serial plotter. With it, we can plot the data that is printed to the Arduino’s serial port in real time. Based on the second task, close the serial monitor and open the “Tools → Serial Plotter” as shown in the image below:  The serial plotter draws the data obtained from the serial port into an XY axis curve chart, where the X-axis represents the change in time and the Y-axis represents the data obtained from the serial port. Through the chart, you can more intuitively see the change in data. Please give it a try."
  },
  {
    "objectID": "chapter_1-5.html#task-1-using-a-knob-potentiometer-to-control-the-brightness-of-the-onboard-led-on-the-xiao-board",
    "href": "chapter_1-5.html#task-1-using-a-knob-potentiometer-to-control-the-brightness-of-the-onboard-led-on-the-xiao-board",
    "title": "1.5 Controlling LED and Servo with a Knob",
    "section": "1.5.2 Task 1: Using a knob potentiometer to control the brightness of the onboard LED on the XIAO board",
    "text": "1.5.2 Task 1: Using a knob potentiometer to control the brightness of the onboard LED on the XIAO board\n\nAnalysis:\nWhen using a knob potentiometer to control the LED, we need to use the map() function, because the analog value directly output by the knob potentiometer is 0-1023, this value is not the angle value of the knob rotation, we need to calculate the angle value of the knob potentiometer rotation first, then map this value to the brightness range of the LED 0-255 with the map() function. The steps to write the program are as follows:\n\nDefine the knob potentiometer, LED pin.\nInitialize the serial port, set the status of the knob potentiometer and LED pin.\nRead and calculate the rotation angle value of the knob potentiometer, and send it to the serial port.\nMap the angle value of the knob potentiometer to the LED brightness value and store it in the brightness variable, and the LED outputs this variable value. #### Writing the program: Step 1: Define the knob potentiometer, LED pin, here we need to define ADC and VCC reference voltage, in order to calculate the angle value of the knob potentiometer.\n\n#define ROTARY_ANGLE_SENSOR A0 //Define rotary potentiometer interface A0\n#define LEDPIN 13 //Define LED interface 13\n#define ADC_REF 3 //Reference voltage 3V\n#define GROVE_VCC 3 //GROVE reference voltage 3V\n#define FULL_ANGLE 300 //The maximum rotation angle of the rotary potentiometer is 300°\nStep 2: Initialize the serial port, set the status of the knob potentiometer and LED pin.\nvoid setup()\n{\n    Serial.begin(9600); //Initialize serial communication\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT); //Set the rotary potentiometer pin to input\n    pinMode(LEDPIN,OUTPUT); //Set the LED pin to output \n}\nStep 3: Read and calculate the rotation angle value of the knob potentiometer, and send it to the serial port.\nvoid loop()\n{   \n    float voltage; //Variable voltage of type float\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR); //Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value*ADC_REF/1023; //Calculate the real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC; //Calculate the angle of rotation of the knob\n    Serial.println(\"The angle between the mark and the starting position:\"); //Print character on serial monitor\n    Serial.println(degrees); //Print the rotation angle value of the rotary potentiometer on the serial monitor\n    delay(100);\nStep 4: Map the angle value of the knob potentiometer to the LED brightness value and store it in the brightness variable, and the LED outputs this variable value.\n//After Step 3\n    int brightness; //Define brightness variable\n    brightness = map(degrees, 0, FULL_ANGLE, 0, 255); //Map the rotation angle value of the rotary potentiometer to the brightness value of the LED and store it in the brightness variable\n    analogWrite(LEDPIN,brightness); //Output the variable value to the LED\n    delay(500);\n}\nThe final complete code is shown below:\n#define ROTARY_ANGLE_SENSOR A0 //Define rotary potentiometer interface A0\n#define LEDPIN 13 //Define LED interface 13\n#define ADC_REF 3 //Reference voltage 3V\n#define GROVE_VCC 3 //GROVE reference voltage 3V\n#define FULL_ANGLE 300 //The maximum rotation angle of the rotary potentiometer is 300°\n \nvoid setup()\n{\n    Serial.begin(9600); //Initialize serial communication\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT); //Set the rotary potentiometer pin to input\n    pinMode(LEDPIN,OUTPUT); //Set the LED pin to output \n}\n \nvoid loop()\n{   \n    float voltage; //Variable voltage of type float\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR); //Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value*ADC_REF/1023; //Calculate the real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC; //Calculate the angle of rotation of the knob\n    Serial.println(\"The angle between the mark and the starting position:\"); //Print character on serial monitor\n    Serial.println(degrees); //Print the rotation angle value of the rotary potentiometer on the serial monitor\n    delay(100);\n    \n    int brightness; //Define brightness variable\n    brightness = map(degrees, 0, FULL_ANGLE, 0, 255); //Map the rotation angle value of the rotary potentiometer to the brightness value of the LED and store it in the brightness variable\n    analogWrite(LEDPIN,brightness); //Output the variable value to the LED\n    delay(500);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryLed_XIAO_en\n\n\n\nUploading the Program:\nAfter writing the program, connect the rotary potentiometer to the A0 interface using a four-color Grove wire, as shown in the following figure:  Connect the XIAO main control board to your computer with a data cable. After connecting, click  (the verify button) in the Arduino IDE to check the program. If there are no errors, click  (the upload button) to upload the program to the hardware. When the debug area shows “Done uploading.”, you can open the serial monitor to observe the rotation angle and LED brightness values as you rotate the potentiometer.  &gt; ⚠️ Note The onboard LED of the XIAO board is used in this example.\nIf you need to operate offline, you can connect a lithium battery to the expansion board, as shown in the following figure.  ### Controlling an External LED with a Knob on the XIAO ESP32C3 The Seeed XIAO ESP32C3 does not have an onboard LED for users. To run this program, you need to first connect an LED to the D10 pin of the board, as shown below:  &gt; ⚠️ Note Be sure to connect a resistor (about 150Ω) in series with the LED to limit the current passing through the LED and prevent it from being damaged by overcurrent.\nNext, copy the following program into the Arduino IDE:\n#define ROTARY_ANGLE_SENSOR A0 // Define rotary potentiometer interface A0\n#define LEDPIN D10 // Define LED light interface 10\n#define ADC_REF 3 // Reference voltage 3V\n#define GROVE_VCC 3 // GROVE reference voltage 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the rotary potentiometer is 300°\n\nvoid setup()\n{\n    Serial.begin(9600); // Initialize serial communication\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT); // Set the rotary potentiometer pin to input mode\n    pinMode(LEDPIN, OUTPUT); // Set the LED light pin to output mode \n}\n\nvoid loop()\n{   \n    float voltage; // Define voltage variable as float\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR); // Read the analog value on the rotary potentiometer pin\n    voltage = (float)sensor_value*ADC_REF/1023; // Calculate real-time voltage\n    float degrees = (voltage*FULL_ANGLE)/GROVE_VCC; // Calculate the angle of rotation of the knob\n    Serial.println(\"The angle between the mark and the starting position:\"); // Print string to serial port\n    Serial.println(degrees); // Print the rotation angle value of the rotary potentiometer to the serial port\n    delay(100);\n\n    int brightness; // Define brightness variable\n    brightness = map(degrees, 0, FULL_ANGLE, 0, 255); // Map the rotary potentiometer angle value to LED light brightness value and store it in the brightness variable\n    analogWrite(LEDPIN, brightness); // Output brightness value to LED light\n    delay(500);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryLed_XIAO_ESP32C3_en"
  },
  {
    "objectID": "chapter_1-5.html#task-2-control-a-servo-motor-with-a-rotary-potentiometer",
    "href": "chapter_1-5.html#task-2-control-a-servo-motor-with-a-rotary-potentiometer",
    "title": "1.5 Controlling LED and Servo with a Knob",
    "section": "1.5.3 Task 2: Control a Servo Motor with a Rotary Potentiometer",
    "text": "1.5.3 Task 2: Control a Servo Motor with a Rotary Potentiometer\n\nAnalysis\nWhen controlling a servo motor with a rotary potentiometer, we can use the servo.h library and modify our first task slightly. The program can be divided into the following steps:\n\nDeclare the servo library, define the servo rotation angle variable, define the rotary potentiometer pin and voltage.\nInitialize the serial port, set the status of the rotary potentiometer and servo pins.\nRead and calculate the rotation angle value of the rotary potentiometer, send it to the serial port, and drive the servo to rotate according to the angle value change. #### Program Writing Step 1: Declare the servo library, define the servo rotation angle variable, define the rotary potentiometer pin and voltage.\n\n#include &lt;Servo.h&gt;// Declare the use of the servo library\n#define ROTARY_ANGLE_SENSOR A0 // Define the rotary potentiometer pin as A0\n#define ADC_REF 3 // ADC reference voltage is 3V\n#define GROVE_VCC 3 // GROVE module reference voltage is 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the rotary potentiometer is 300°\nServo myservo;  // Create a myservo object to control the servo\nint pos = 0; // Variable to store the rotation angle of the servo\nStep 2: Initialize the serial port, set the status of the rotary potentiometer and servo pins.\nvoid setup() {\n    Serial.begin(9600);// Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);// Set the rotary potentiometer pin as input\n    myservo.attach(5);  // The myservo signal is transmitted through pin 5, if you are using XIAO RP2040/XIAO ESP32, please modify 5 to D5\n}\nStep 3: Read and calculate the rotation angle value of the rotary potentiometer, send it to the serial port, and drive the servo to rotate according to the angle value change.\nvoid loop() {\n    float voltage;// Set voltage as a floating point\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR);// Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value * ADC_REF / 1023;// Real-time voltage is the read analog value multiplied by the reference voltage divided by 1023\n    float degrees = (voltage * FULL_ANGLE) / GROVE_VCC;// The rotation angle of the knob is the real-time voltage multiplied by the maximum rotation angle of the rotary potentiometer divided by the voltage value of the GROVE module interface\n    Serial.println(\"The angle between the mark and the starting position:\");// Print characters on the serial port\n    Serial.println(degrees);// Print the rotation angle value of the rotary potentiometer on the serial port\n    delay(50);\n    myservo.write(degrees); // Write the rotation angle value of the rotary potentiometer into the servo\n}\nThe final code is as follows:\n#include &lt;Servo.h&gt;// Declare the use of the servo library\n#define ROTARY_ANGLE_SENSOR A0 // Define the rotary potentiometer pin as A0\n#define ADC_REF 3 // ADC reference voltage is 3V\n#define GROVE_VCC 3 // GROVE module reference voltage is 3V\n#define FULL_ANGLE 300 // The maximum rotation angle of the rotary potentiometer is 300°\nServo myservo;  // Create a myservo object to control the servo\nint pos = 0; // Variable to store the rotation angle of the servo\n\nvoid setup() {\n    Serial.begin(9600);// Initialize the serial port\n    pinMode(ROTARY_ANGLE_SENSOR, INPUT);// Set the rotary potentiometer pin as input\n    myservo.attach(5);  // The myservo signal is transmitted through pin 5, if you are using XIAO RP2040/XIAO ESP32, please modify 5 to D5\n}\n\nvoid loop() {\n    float voltage;// Set voltage as a floating point\n    int sensor_value = analogRead(ROTARY_ANGLE_SENSOR);// Read the analog value at the rotary potentiometer pin\n    voltage = (float)sensor_value * ADC_REF / 1023;// Real-time voltage is the read analog value multiplied by the reference voltage divided by 1023\n    float degrees = (voltage * FULL_ANGLE) / GROVE_VCC;// The rotation angle of the knob is the real-time voltage multiplied by the maximum rotation angle of the rotary potentiometer divided by the voltage value of the GROVE module interface\n    Serial.println(\"The angle between the mark and the starting position:\");// Print characters on the serial port\n    Serial.println(degrees);// Print the rotation angle value of the rotary potentiometer on the serial port\n    delay(50);\n    myservo.write(degrees); // Write the rotation angle value of the rotary potentiometer into the servo\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryServo_XIAO_en\n\n\n\n\nUpload Program\nAfter writing the program, first connect the knob potentiometer and the servo to the XIAO expansion board as shown in the figure below. Then, connect the XIAO main control board to the computer with a data cable. \nAfter the connection, click (the verify button) in the Arduino IDE to verify the program. If the verification is error-free, click (the upload button) to upload the program to the hardware. When the debugging area shows “Done uploading.”, you can open the serial monitor, rotate the knob potentiometer, and observe the changes in angle value and the movement of the servo. What have you found?  &gt; ⚠️ Note: The rotation range of the servo is 0°-180°, so you will see in the serial monitor that when the angle value is greater than 180°, the servo stops rotating."
  },
  {
    "objectID": "chapter_1-5.html#extended-exercise",
    "href": "chapter_1-5.html#extended-exercise",
    "title": "1.5 Controlling LED and Servo with a Knob",
    "section": "1.5.4 Extended Exercise",
    "text": "1.5.4 Extended Exercise\nWe have been using the LED on the XIAO board. If I want to use an external LED and control it with a knob potentiometer to create a breathing light effect, what should I do? The XIAO expansion board brings out two digital-analog Grove interfaces, and there is an A7/D7 interface. We can connect the external LED to this interface, as shown in the figure:  After the connection, we can slightly modify the program from Task 1, changing #define LEDPIN 13 to #define LEDPIN 7. Upload the modified program and see if it can achieve our desired effect. &gt; Get this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L5_RotaryLed_ledmodule_en"
  },
  {
    "objectID": "chapter_1-6.html",
    "href": "chapter_1-6.html",
    "title": "1.6 Displaying “Hello World” on OLED",
    "section": "",
    "text": "In our daily life, we see displays everywhere - televisions, computers, phones, car displays, LCD billboards in shopping malls… Without a variety of screens, our lives would lose much of its fun. Of course, these screens, besides leisure and entertainment, are also indispensable tools for daily life. Common displays include LCD displays, OLED displays, etc. They all have their own strengths and weaknesses as display devices and can be applied in different fields and scenarios. The XIAO expansion board integrates an OLED display. In this lesson, we will learn how to use OLED to display text, patterns, and images. ## 1.6.1 Background Knowledge ### 1.6.1.1 OLED Display OLED, also known as Organic Light Emitting Diode, has advantages such as self-luminous, low power consumption, fast response speed, high resolution, light weight, etc. Its application field is very wide. The XIAO expansion board integrates a 0.96 inch 128x64 pixel OLED display, which can be used directly without wiring. During project production, we can display time, temperature and humidity, and other sensor return values through the OLED display, and we can also directly display letters, numbers, graphics, and even patterns, achieving visual interactive effects.  ### 1.6.1.2 How to Download and Install the U8g2_Arduino Library A library is a collection of program codes, which encapsulates some commonly used functions into a file for users to call. When we use OLED displays, temperature and humidity sensors, etc., we need to use the corresponding libraries. Where can these libraries be downloaded and how to install them? We will explain using the U8g2_Arduino library file of the OLED display as an example. Enter the website link 🔗 https://github.com/olikraus/u8g2_arduino to enter the GitHub page, click Code→Download ZIP to download the resource package to the local, as shown in the figure below.  After the download is complete, open the Arduino IDE, click Sketch→Include Library→Add .ZIP Library, and select the ZIP file you just downloaded.  If the library is installed correctly, you can see the prompt information for successful library installation in the output window. ### 1.6.1.3 U8g2 Library for OLED  U8g2 is a monochrome graphics library for embedded devices, which supports various types of OLED displays, making it easy for us to write programs to achieve the desired effects. The U8g2 library also includes the U8x8 library, and the two libraries have different functions: #### U8g2 Includes all graphic procedures (line/box/circle drawing); Supports various fonts, (almost) no restrictions on font height; Some memory in the microcontroller is needed to display. #### U8x8 Only supports text (character) output; Only allows each character to use a fixed-size font (8x8 pixels); Writes directly to the display, no buffer is needed in the microcontroller. Simply put, when we want the OLED display to display various fonts, graphics, patterns, and present visual content more flexibly, we can use the U8g2 library; when we want to display characters more directly, with no font requirements, just to display sensor values, time, etc., we can use the U8x8 library, which is more efficient. We can find many example programs in “File→Examples→U8g2”, and familiarize ourselves with the use of the library through the example programs.  Next, we will display characters and draw circles using two libraries respectively. ## 1.6.2 Task 1: Display Hello World! on the OLED of the XIAO expansion board &gt; ⚠️ Note Before starting to write a program for the OLED of the XIAO expansion board, make sure the Arduino IDE has loaded the U8g2_Arduino library file. The loading method can be referred to the description in the “How to Download and Install Arduino Library” section of this lesson.\n\nAnalysis\nIf you just want to display “Hello World!” on the OLED, you can directly write characters with the U8x8 library. The steps are as follows:\n\nDeclare the library file, set the constructor, and the constructor defines the display type, controller, RAM buffer size, and communication protocol.\nInitialize the display.\nSet the display font, set the print starting position, and output “Hello World!”. #### Write the program Step 1: Declare the library file, set the constructor, and the constructor defines the display type, controller, RAM buffer size, and communication protocol.\n\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;//Use U8x8 library file\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);\n//Set the constructor, define the display type, controller, RAM buffer size, and communication protocol, generally determine according to the used display model\nStep 2: Initialize the display. After declaring the library file in the previous step, you can use the functions in the library to set the OLED display.\nvoid setup(void) {\n    u8x8.begin();//Initialize u8x8 library\n    u8x8.setFlipMode(1);//Flip the display 180 degrees, generally numbers 0 and 1\n}\nStep 3: Set the display font (there are various fonts to choose from in the u8x8 library, we can refer to https://github.com/olikraus/u8g2/wiki/fntlist8x8 to choose), set the print starting position, and output “Hello World!”.\nvoid loop(void) {\n    u8x8.setFont(u8x8_font_chroma48medium8_r);//Define u8x8 font\n    u8x8.setCursor(0, 0);//Set the position of the drawing cursor\n    u8x8.print(\"Hello World!\");//Draw content on OLED: Hello World！\n}\nThe complete program is as follows:\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;//Use U8x8 library file\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);\n//Set the constructor, define the display type, controller, RAM buffer size, and communication protocol, generally determine according to the used display model\n\nvoid setup(void) {\n    u8x8.begin();//Initialize u8x8 library\n    u8x8.setFlipMode(1);//Flip the display 180 degrees, generally numbers 0 and 1\n}\n\nvoid loop(void) {\n    u8x8.setFont(u8x8_font_chroma48medium8_r);//Define u8x8 font\n    u8x8.setCursor(0, 0);//Set the position of the drawing cursor\n    u8x8.print(\"Hello World!\");//Draw content on OLED: Hello World！\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L6_HelloWorld_XIAO_en\n\n\n\nProgram Upload:\nAfter the program is written, we connect the XIAO main control board to the computer interface using a data cable, as shown in the image below:  Click “Upload” to transfer the program to the main control board. Once the upload is complete, check if the OLED display shows “Hello World!”.  ## 1.6.3 Task 2: Draw a Circle on the OLED Display #### Analysis To draw a circle on the OLED display, we need to use the U8g2 library. Programming involves four steps:\n\nDeclare the U8g2 library file, determine whether to use SPI or I2C protocol, and set up the constructor to connect to the OLED display.\nThe draw() function uses the u8g2.drawCircle function to draw a circle on the OLED.\nInitialize the U8g2 library.\nIn the loop() function, call related functions to draw images on the OLED. #### Program Writing Step 1: Declare the U8g2 library file, determine whether to use SPI or I2C protocol, and set up the constructor to connect to the OLED display.\n\n#include&lt;Arduino.h&gt;\n#include&lt;U8g2lib.h&gt;//Use U8g2 library\n\n// Determine whether to use SPI or I2C protocol\n#ifdef U8X8_HAVE_HW_SPI\n#include&lt;SPI.h&gt;\n#endif\n#ifdef U8X8_HAVE_HW_I2C\n#include&lt;Wire.h&gt;\n#endif\n\nU8G2_SSD1306_128X64_NONAME_F_HW_I2C u8g2(U8G2_R0, /* reset=*/ U8X8_PIN_NONE);\n// Set up the constructor, define display type, controller, RAM buffer size, and communication protocol\nStep 2: The draw()function uses the u8g2.drawCircle function to draw a circle on the OLED. The u8g2.drawCircle(x0,y0,rad,opt) function parameters are as follows:\n\nx0,y0: The position of the center of the circle.\nrad: Defines the size of the circle, with the diameter of the circle being 2*rad+1.\nopt: Choose a part or all of the circle.\n\nvoid draw(void) { \n    u8g2.drawCircle(20, 25, 10, U8G2_DRAW_ALL);// Draw a full circle with a diameter of 21 at coordinates (20, 25)\n}\nStep 3: Initialize the U8g2 library.\nvoid setup(void) {\n    u8g2.begin();// Initialize the library\n}\nStep 4: In the loop() function, call related functions to draw images on the OLED. Use the firstPage and nextPage functions to cycle through image content. They need to be used together, as shown in the program below:\nvoid loop(void) {\n    // Cycle through image display\n    u8g2.firstPage();\n    do {\n        draw();// Use draw function\n    } while( u8g2.nextPage() );\n\n    delay(1000);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L6_DrawCircle_XIAO_en\n\n\n\nUploading the Program\nAfter writing the program, connect the XIAO main control board to the computer using a data cable, as shown below:  Once connected, click on the “Upload” button to upload the program to the hardware. When the debugging area displays “Upload Successful”, check if the OLED display screen has shown a circular pattern.  ## 1.6.4 Extended Exercise Try drawing some more complex patterns."
  },
  {
    "objectID": "chapter_2.html",
    "href": "chapter_2.html",
    "title": "Chapter 2: Project Practice for Beginners - Introduction to Prototype Design",
    "section": "",
    "text": "This unit will delve into project practice with a few classic projects as case studies. We will learn how to create a quick verification prototype starting from an idea. Instead of analyzing code line by line as we’ve done previously, we will only explain critical steps in this unit. The focus will be more on the practical application of code. Arduino’s libraries and example programs are abundant, as are community resources.\nWhen working on a project, we should be adept at finding these resources, referring to example programs, and adjusting the code according to our needs to achieve the desired effects more quickly. Furthermore, this unit will begin to cover how to design appearances based on the effects achieved by the program. We will start by repurposing items around us, combining these items with electronic hardware to quickly form prototype works."
  },
  {
    "objectID": "chapter_2-1.html#enlightening-on-product-prototype-design",
    "href": "chapter_2-1.html#enlightening-on-product-prototype-design",
    "title": "2.1 Introduction to Product Prototype Design",
    "section": "2.1.2 Enlightening on Product Prototype Design",
    "text": "2.1.2 Enlightening on Product Prototype Design\n\nAuthor Introduction:  Wen Yanming, a post-90s female, graduated from the Chinese University of Hong Kong and South China University of Technology, with a master’s degree in law. She is a hardware product manager, an inventor, an entrepreneur, with over a decade of technology practice and maker experience.\n\n\n2.1.2.1 Basic Process of Product Prototype Design\nFrom idea to product prototype and then to the product, this is a process that every product must go through. A product prototype allows us to quickly verify ideas, functionality, and product feasibility in a cost-effective way, providing the basis for product testing, optimization, and iterative updates. Behind every successful product we see, there may have been countless iterations of product prototypes. Therefore, creating a good product prototype is an essential process and solid foundation for a successful product. The prototypes needed for different types of products and different stages of the product are not the same. When we mention a product prototype, it may refer to a conceptual prototype, a functional prototype, a small batch production prototype, a factory hand model, etc. It should be noted that for electronic hardware products, the discussion here is mainly about product prototypes for product concepts and functional implementation. Generally speaking, the design of a functional product prototype mainly includes the following processes:\n\n1. Identify and Clarify the Problem to be Solved\nEinstein once said: “Posing a problem is often more important than solving a problem.” Every product must exist to solve a certain problem or to provide some benefit to people. Therefore, identifying and clarifying the problem to be solved is a prerequisite for clarifying product design needs and proceeding with product design. It is important to note that just because we have identified a problem does not mean we truly understand and accurately define this problem. For example, over 100 years ago, when Henry Ford, the founder of Ford Motor Company, went around asking customers what kind of transportation they needed, almost everyone’s answer was, “I want a faster horse.” But do people really just need a faster horse? If Mr. Ford had defined the problem based on this, we might not have had faster and more comfortable cars so quickly.\n\n\n\n2. Demand Analysis and Product Definition\nOnce the problem is clearly defined, we can extract unmet needs from it. Like the example above, the problem at that time was actually how to get to the destination faster, so the corresponding need was “a faster mode of transportation,” not “a faster horse.” Therefore, we need to be good at digging deeper from the problems we discover to find the real needs. Demand analysis generally requires an analysis of the user population and use scenarios, from which to derive the functions needed to solve the problem, that is, to clarify: for whom, in what scenarios, to achieve what functions, to gain what benefits.\n\nThere are many types of needs: true user needs, superficial needs, urgent needs, ordinary needs, high-frequency needs, low-frequency needs, and so on. All of these need to be analyzed in light of the actual situation, which can then inform the correct definition of the product based on these needs. Every product ultimately needs to be commercialized to realize its maximum value. Therefore, when designing a product for the market, we also need to conduct a series of market analyses, including market size, sales expectations, profit analysis, payback period, input-output ratio analysis, and so on.\n\n\n3. Hardware Selection and Assembly\nFor the design of electronic products, once the needs are defined, we need to find hardware that can implement these functional needs. When choosing hardware, the elements that generally need to be considered include: feasibility, level of need satisfaction, cost, volume, weight, performance, lifespan, appearance, etc. One of the most important abilities of an excellent product designer is to take into account various factors based on the product definition and needs, balance these factors, and make trade-offs. Often, there is no single correct answer. Generally speaking, when we build a prototype, the first thing we should consider is creating a minimum viable product (MVP). Its function is to use the least resources to quickly verify the product and quickly improve and iterate. \n\n\n4. Software Development and Functional Implementation\nMany experienced software development engineers will draw a functional implementation flowchart before software development. They will draw a functional implementation flowchart according to the functions to be implemented. This can help clarify the software design thinking, check the function logic, facilitate the identification of leaks and deficiencies, and refer to it at any time during programming, ensuring they have a clear understanding. Therefore, regardless of the complexity of software function development, it is recommended that everyone develop a good habit of drawing a functional implementation flowchart first. It can be a simple hand-drawn sketch, or a professional software like Visio, Axure can be used to draw it.\n\nWhen developing software, try to be efficient and concise. Take full advantage of the benefits of the open-source community and learn to use existing hardware and software resources more effectively. For example, many pieces of hardware or applications already have many ready-made open-source libraries and routines. During development, you can refer to these, comply with the corresponding open-source agreements to use related resources, and avoid wasting time reinventing the wheel.\n\n\n5. Prototype Testing and Optimization\nAfter the prototype is made, we need to test it to verify its functional implementation and whether it meets the original design needs. This process should involve as many target users as possible to collect their feedback. In this way, we can better discover the defects in the product prototype, make remedial measures and improvements, update and iterate the design, and finally make a design scheme that meets user needs, laying a solid foundation for formal product design. ### 2.1.2.2 Product Prototype Practice - “One Meter Distance Alarm” Prototype  Next, let’s take the prototype manufacturing process of the “One Meter Distance Alarm” as an example to experience the product prototype design process.\n\n\n1. Identifying and Defining the Problem to be Solved\nAt the beginning of 2020, the COVID-19 pandemic broke out globally, the situation was very severe. To prevent the virus from spreading through droplets and close-range airborne contact, governments and health departments around the world urged everyone to reduce gatherings and maintain social distancing of at least one meter whenever possible. However, it is not easy for everyone to constantly remember this and maintain an accurate social distance of more than one meter. For children, they often forget to maintain distance because they are playing happily, or they have no concept of how far they should keep their distance. When going out, there are also some strangers who, due to a lack of epidemic prevention awareness, unconsciously come close to us, and we need to find a polite way to remind them. Therefore, we have derived a question from life: How can we constantly remind people to maintain a social distance of more than one meter?\n\n\n2. Needs Analysis and Product Definition\nWith the problem defined, let’s analyze the core needs that this problem triggers: an epidemic prevention reminder device for public use that sends out reminders when others enter within one meter, thus encouraging everyone to consciously maintain a one meter social distance. Thinking further about the core needs, what kind of reminder should this be? We can think of the electronic products we usually use, what kind of reminders do they have? They are nothing more than sounds, lights, vibrations, screen text prompts, etc. Considering that the reminder needs to be timely, direct, and obvious, it’s not easy to see the screen clearly at a distance of about one meter, and the volume will be larger and the cost higher after adding a screen, so we do not consider adding a screen. The remaining options are sound, light, and vibration. We can continue to balance and choose the necessary reminder method according to the cost, volume, and appearance. There is no single answer here. So, based on the needs analysis process, we tentatively define the product as: a device that emits light and vibrates to remind when it detects someone entering within a one meter distance.\n\n\n3. Hardware Selection and Assembly\nWith the product defined, we can decompose the core functional requirements: (1) Detect when a person enters within a one-meter distance (2) Alert self and others (3) Small size, easy to carry So, what kind of hardware should be used to implement these respectively? In the process of product prototype implementation, we usually choose open-source hardware with low cost, complete information, and many routines to implement hardware functions. After comprehensively considering the cost, function realization, assembly difficulty, volume, software development resources, and other elements, I have chosen the following hardware:\n\n\n\n\n\n\n\n\n\nFunctional Requirements\nHardware Product\nFunction Introduction\n\n\n\n\nMain Board\n\n\n\n\nSeeeduino XIAO（SAMD21）\nThis is a mini-main control board developed by Seed Technology based on SAMD21. The volume is very mini, only 20x17.5mm, the size of a thumb, the interface is rich, the performance is strong, very suitable for the development of various small volume devices.\n\n\n\nExpansion Board\n\n\n\n\nSeeed Studio Grove Base for XIAO\nGrove Shield for Seeed Studio XIAO is a plug-and-play Grove extension board for Seeed Studio XIAO series. With the on-board battery management chip and battery bonding pad, you could easily power your Seeed Studio XIAO with lithium battery and recharge it. 8 Grove connectors onboard includes two Grove I2C and one UART. It acts as a bridge for Seeed Studio XIAO and Seeed’s Grove system. Flash SPI bonding pad allows you add Flash to Seeed Studio XIAO to expand its memory space, providing Seeed Studio XIAO with more possibilities.\n\n\n\nDistance Detection\n\n\n\n\nGrove - Time of Flight Distance Sensor（ToF）\nThere are many sensors to detect distance, most of which measure through ultrasound, infrared, lasers, etc. Among them, the Grove Time of Flight Distance Sensor is a new generation of ToF laser ranging module based on VL53L0X, which can provide accurate distance measurement up to 2 meters. The small size and high precision of this module made it my first choice.\n\n\n\nLight Alarm\n\n\n\n\nGrove - Circular LED\nA Grove - Circular LED with a circle of LEDs can light up a white light. It is aesthetically pleasing and provides a larger, more noticeable light reminder compared to a single LED.\n\n\n\nVibration Alarm\n\n\n\n\nGrove - Vibration Motor\nA Grove module with a built-in vibration motor. It can be used plug-and-play, and it’s convenient to generate continuous or intermittent vibration reminders by controlling the digital signal.\n\n\n\nPower Supply\n\n\n\n\n3.7V lithium battery (401119)\nA mini-sized 3.7V lithium battery commonly used for Bluetooth headset power supply. The model is 401119, which represents the thickness, width, and length of the battery as 4mm, 11mm, and 19mm respectively. After welding this size lithium battery to the lithium battery pad on the Grove expansion board, it can be placed directly in the gap between the Seeeduino XIAO and the Grove expansion board, making the product more tidy and beautiful.\n\n\n\nWiring\n\n\n\n\n\n Grove universal connection cable (5cm) | The Grove universal connector is a standard connector for the Grove system. It can be used conveniently plug-and-play, without soldering and considering the line sequence. The Grove line connects various sensors and actuators to the expansion board, making the project building as simple as building blocks and saving a lot of time. The 5cm short line is very suitable for space-compact product prototypes. |\n\nThe module connection is as follows, as depicted in the image: \nThe chosen hardware modules have a great structural design, which can be directly used to build the distance alarm’s form factor, saving time in making a shell. Thus, the production method is quite simple: all that’s needed is to connect each piece of hardware to the appropriate interface, arrange their respective positions, and then bond them together with hot melt adhesive. This quickly completes the hardware connection and form factor building of a one-meter distance alarm. The completed hardware product is as follows:  \n\n\n4. Software Development and Function Implementation\nBefore officially writing the program, I planned the functions and logic that the software needs to implement and drew the following functional implementation flow chart using Visio:\n\nBecause Seeeduino XIAO supports Arduino IDE, I chose to program in the Arduino IDE. Most of the hardware provided by Seed Technology is open source, and they offer excellent documentation support for their products. Thus, during the programming process, I found the corresponding open-source hardware Wiki on the Seeedstudio official website, downloaded the relevant library files (note: library files are a collection of specific functionalities provided by developers that can be used by simply calling them, without having to rewrite the code), and referred to the example routines of the used modules. I completed the program swiftly.\nAfter the program was written and compiled successfully, I connected the Seeeduino XIAO to the computer via a Type-C connection and downloaded the written code to the Seeeduino XIAO through the Arduino IDE. Once the code was successfully uploaded, the prototype was completed.  #### 5. Prototype Testing and Optimization    After completing the prototype, it was time for testing. First, I needed to test whether the prototype implemented the basic functionality, i.e., whether it would sound and light an alarm when a person was detected within a one-meter range. Then, I had to use it in an actual scenario to see if the user experience was good enough. If it could meet the product’s requirements and definition satisfactorily, the product prototype could be deemed successful, and the next step in product development could be initiated. Of course, if issues were found during testing, adjustments and improvements were required, followed by retesting. This process is repeated until the product prototype meets the requirements, and the final scheme is determined.\nFinishing the prototype is just the first step in making a successful product. The birth of each product requires a lot of effort, continual trial and error, and adjustment to achieve the best results. The final success of a product, in addition to meeting user needs, also needs to withstand many market tests. This requires students, when beginning to learn to make products, to always maintain the spirit of a craftsman, while also keeping a keen sense for the market, and learning knowledge beyond the product itself. There is a long way to go, and I hope everyone can stick to their original intentions, keep exploring, and ultimately make successful products.\nThe source code of the program is as follows:\n#include &lt;Grove_LED_Bar.h&gt;\n#include \"Seeed_vl53l0x.h\"\n\nconst int Buzzer = 8;//Vibration motor connected to D8\nGrove_LED_Bar bar(0, 1, 0, LED_CIRCULAR_24);  //Grove-LED ring connected to D0 \nSeeed_vl53l0x VL53L0X;  //Grove-tof distance sensor connected to IIC (D4/D5)\n\n#if defined(ARDUINO_SAMD_VARIANT_COMPLIANCE) && defined(SerialUSB)\n#define SERIAL SerialUSB\n#else\n#define SERIAL Serial\n#endif\n\n\nvoid setup() {\n    bar.begin();\n\n    pinMode(Buzzer, OUTPUT);\n    digitalWrite(Buzzer, LOW);   // turn the Buzzer on (HIGH is the voltage level)\n    // Turn off all LEDs\n    bar.setBits(0x0);            \n\n    VL53L0X_Error Status = VL53L0X_ERROR_NONE;\n    SERIAL.begin(115200);\n    Status = VL53L0X.VL53L0X_common_init();\n    if (VL53L0X_ERROR_NONE != Status) {\n        SERIAL.println(\"Starting VL53L0X measurement failed!\");\n        VL53L0X.print_pal_error(Status);\n        while (1);\n    }\n\n    VL53L0X.VL53L0X_long_distance_ranging_init();\n\n    if (VL53L0X_ERROR_NONE != Status) {\n        SERIAL.println(\"Starting VL53L0X measurement failed!\");\n        VL53L0X.print_pal_error(Status);\n        while (1);\n    }\n\n}\n\nvoid loop() {\n\n    VL53L0X_RangingMeasurementData_t RangingMeasurementData;\n    VL53L0X_Error Status = VL53L0X_ERROR_NONE;\n\n    memset(&RangingMeasurementData, 0, sizeof(VL53L0X_RangingMeasurementData_t));\n    Status = VL53L0X.PerformSingleRangingMeasurement(&RangingMeasurementData);\n    if (VL53L0X_ERROR_NONE == Status) {\n        if (RangingMeasurementData.RangeMilliMeter &gt;= 2000) {\n            SERIAL.println(\"Out of range!!\");\n            digitalWrite(Buzzer, LOW);   // turn the Buzzer off (LOW is the voltage level)\n\n            // Turn off all LEDs\n            bar.setBits(0x0);\n\n        } \n        else if (RangingMeasurementData.RangeMilliMeter &lt;= 1000) {\n            digitalWrite(Buzzer, HIGH);   // turn the Buzzer on (HIGH is the voltage level)\n            // Turn on all LEDs\n            bar.setBits(0b111111111111111111111111);\n\n            SERIAL.print(\"Distance:\");\n            SERIAL.print(RangingMeasurementData.RangeMilliMeter);\n            SERIAL.println(\" mm\");\n        } \n        else {    \n            digitalWrite(Buzzer, LOW);   // turn the Buzzer off (LOW is the voltage level)\n\n            // Turn off all LEDs\n            bar.setBits(0x0);\n\n            SERIAL.print(\"Distance:\");\n            SERIAL.print(RangingMeasurementData.RangeMilliMeter);\n            SERIAL.println(\" mm\");\n        }\n\n    }\n    else {\n        SERIAL.print(\"Measurement failed!! Status code =\");\n        SERIAL.println(Status);\n        digitalWrite(Buzzer, LOW);   // turn the Buzzer off (LOW is the voltage level)\n\n        // Turn off all LEDs\n        bar.setBits(0x0);\n    }\n\n    delay(250);   \n\n}\n\nGet this program from Github\nhttps://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L7_tof_XIAO_en"
  },
  {
    "objectID": "chapter_2-2.html#task-1-reading-temperature-and-humidity-values-in-the-serial-monitor-based-on-the-dht20-model",
    "href": "chapter_2-2.html#task-1-reading-temperature-and-humidity-values-in-the-serial-monitor-based-on-the-dht20-model",
    "title": "2.2 Smart Hygrometer and Thermometer",
    "section": "2.2.2 Task 1: Reading Temperature and Humidity Values in the Serial Monitor (Based on the DHT20 model)",
    "text": "2.2.2 Task 1: Reading Temperature and Humidity Values in the Serial Monitor (Based on the DHT20 model)\n\nAdding the Grove_Temperature_And_Humidity_Sensor Library File\nBefore starting to program the Grove Temperature and Humidity Sensor with the Arduino IDE, it is necessary to add the necessary library files for the sensor. Type the library file address in the browser address bar: 🔗 https://github.com/Seeed-Studio/Grove_Temperature_And_Humidity_Sensor, enter the GitHub page, and click Code→Download ZIP to download the resource package Grove_Temperature_And_Humidity_Sensor-master.zip to your local machine, as shown in the image below.  Add the resource package Grove_Temperature_And_Humidity_Sensor-master.zip downloaded in the previous step in the menu bar’s Sketch→Include Library→Add .ZIP Library, until you see a prompt indicating the successful loading of the library.\n\n\nOpening the “DHTtester” Example\nOnce the library file has been successfully added, the DHT library can be used. The “DHTtester” example can be opened through the following path: File→Examples→Grove Temperature And Humidity Sensor→DHTtester.\n\n⚠️ Note If the DHTtester example is not found in the menu after installing the library files, it can be viewed by closing and reopening the Arduino IDE.\n\nAfter opening the example program, we can see a program like the one shown below. This program reads the temperature and relative humidity in the environment and displays real-time data in the serial monitor. Part of the example program’s code needs to be modified.\n// Example testing sketch for various DHT humidity/temperature sensors\n// Written by ladyada, public domain\n\n#include \"DHT.h\"\n\n// Uncomment whatever type you're using!\n//#define DHTTYPE DHT11   // DHT 11\n#define DHTTYPE DHT22   // DHT 22  (AM2302)\n//#define DHTTYPE DHT21   // DHT 21 (AM2301)\n//#define DHTTYPE DHT10   // DHT 10\n//#define DHTTYPE DHT20   // DHT 20\n\n/*Notice: The DHT10 and DHT20 is different from other DHT* sensor ,it uses i2c interface rather than one wire*/\n/*So it doesn't require a pin.*/\n#define DHTPIN 2     // what pin we're connected to（DHT10 and DHT20 don't need define it）\nDHT dht(DHTPIN, DHTTYPE);   //   DHT11 DHT21 DHT22\n//DHT dht(DHTTYPE);         //   DHT10 DHT20 don't need to define Pin\n\n// Connect pin 1 (on the left) of the sensor to +5V\n// Connect pin 2 of the sensor to whatever your DHTPIN is\n// Connect pin 4 (on the right) of the sensor to GROUND\n// Connect a 10K resistor from pin 2 (data) to pin 1 (power) of the sensor\n\n\n#if defined(ARDUINO_ARCH_AVR)\n    #define debug  Serial\n\n#elif defined(ARDUINO_ARCH_SAMD) ||  defined(ARDUINO_ARCH_SAM)\n    #define debug  SerialUSB\n#else\n    #define debug  Serial\n#endif\n\nvoid setup() {\n\n    debug.begin(115200);\n    debug.println(\"DHTxx test!\");\n    Wire.begin();\n\n    /*if using WIO link,must pull up the power pin.*/\n    // pinMode(PIN_GROVE_POWER, OUTPUT);\n    // digitalWrite(PIN_GROVE_POWER, 1);\n\n    dht.begin();\n}\n\nvoid loop() {\n    float temp_hum_val[2] = {0};\n    // Reading temperature or humidity takes about 250 milliseconds!\n    // Sensor readings may also be up to 2 seconds 'old' (its a very slow sensor)\n\n\n    if (!dht.readTempAndHumidity(temp_hum_val)) {\n        debug.print(\"Humidity: \");\n        debug.print(temp_hum_val[0]);\n        debug.print(\" %\\t\");\n        debug.print(\"Temperature: \");\n        debug.print(temp_hum_val[1]);\n        debug.println(\" *C\");\n    } else {\n        debug.println(\"Failed to get temprature and humidity value.\");\n    }\n\n    delay(1500);\n}\nPay attention to the document’s comments. The program above provides several types of temperature and humidity sensor models (DHT22 is set as default), but we need the DHT20. So, uncomment the part for DHT20 and delete the definitions for other unneeded sensor models. DHT10 and DHT20 do not require pin definitions, so the revised code after modification is as follows:\n#include \"DHT.h\"\n#define DHTTYPE DHT20   // DHT 20\nDHT dht(DHTTYPE); \n#if defined(ARDUINO_ARCH_AVR)\n#define debug  Serial\n\n#elif defined(ARDUINO_ARCH_SAMD) ||  defined(ARDUINO_ARCH_SAM)\n#define debug  Serial\n#else\n#define debug  Serial\n#endif\n\nvoid setup() {\n    debug.begin(115200);\n    debug.println(\"DHTxx test!\");\n    Wire.begin();\n    dht.begin();\n}\n\nvoid loop() {\n    float temp_hum_val[2] = {0};\n    if (!dht.readTempAndHumidity(temp_hum_val)) {\n        debug.print(\"Humidity: \");\n        debug.print(temp_hum_val[0]);\n        debug.print(\" %\\t\");\n        debug.print(\"Temperature: \");\n        debug.print(temp_hum_val[1]);\n        debug.println(\" *C\");\n    } else {\n        debug.println(\"Failed to get temprature and humidity value.\");\n    }\n\n    delay(1500);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_DHTtester_DHT20_XIAO_en\n\nAfter modifying the code, first connect the temperature and humidity sensor to the I2C interface of the XIAO expansion board, as shown below. Then connect the XIAO development board to your computer, upload the modified example program to XIAO in the Arduino IDE, and open the serial monitor in Arduino IDE. You will now be able to see the values of temperature and humidity. Try placing the sensor in different environments to observe if the temperature and humidity values change.   It appears the temperature and humidity sensor is functioning correctly. #### Reading Temperature and Humidity Values in the Serial Monitor (Based on the DHT11 Sensor) If you are using the Grove DHT11 Temperature and Humidity Sensor with a blue casing, parts of the program code need to be modified as follows: #define DHTPIN 0 needs to be modified according to the actual pin number the sensor is connected to. #define DHTTYPE DHT11 should be set because there are different models of temperature and humidity sensors, and you need to choose the correct one, i.e., DHT11. The example code after modification is shown below:\n#include \"DHT.h\"\n#define DHTTYPE DHT11   // DHT 11\n#define DHTPIN 0 \nDHT dht(DHTPIN, DHTTYPE); \n\n#if defined(ARDUINO_ARCH_AVR)\n    #define debug  Serial\n\n#elif defined(ARDUINO_ARCH_SAMD) ||  defined(ARDUINO_ARCH_SAM)\n    #define debug  SerialUSB\n#else\n    #define debug  Serial\n#endif\n\nvoid setup() {\n    debug.begin(115200);\n    debug.println(\"DHTxx test!\");\n    Wire.begin();\n    dht.begin();\n}\n\nvoid loop() {\n    float temp_hum_val[2] = {0};\n    if (!dht.readTempAndHumidity(temp_hum_val)) {\n        debug.print(\"Humidity: \");\n        debug.print(temp_hum_val[0]);\n        debug.print(\" %\\t\");\n        debug.print(\"Temperature: \");\n        debug.print(temp_hum_val[1]);\n        debug.println(\" *C\");\n    } else {\n        debug.println(\"Failed to get temprature and humidity value.\");\n    }\n\n    delay(1500);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_DHTtrster_DHT11_XIAO_en\n\nAfter modifying the code, first connect the temperature and humidity sensor to the A0 port of the XIAO expansion board, as shown in the figure below. Then, connect the XIAO development board to the computer, upload the modified example program to XIAO in the Arduino IDE, and open the serial monitor in the Arduino IDE to see the values of temperature and humidity. You can place the temperature and humidity sensor in different environments to see if the temperature and humidity values will change.  ## 2.2.3 Project Creation: Smart Temperature and Humidity Meter ### Project Description We are going to make a portable mini temperature and humidity detector that detects temperature and humidity values through a temperature and humidity sensor and displays the values on the OLED display of the XIAO expansion board. However, it is not rich enough to have only the display function. We can add a buzzer alarm function. When the detected temperature and humidity exceed a certain range, an alarm will be sounded as a reminder. The value range can be adjusted according to different application scenarios. For example, in a home life scenario, set a comfortable temperature and humidity range based on human feelings; or use it in plant planting places, set the temperature and humidity value range based on suitable plant growth, exceed the alarm, and remind people to adjust. ### Program Writing Referencing the example program above, one of the effects we want to achieve is to display the temperature and humidity values on the OLED display of the XIAO expansion board. The code for reading the temperature and humidity sensor detection values can be reused by just changing the display medium. In combination with Section 1.6, we have learned how to display characters on the OLED, so we just need to add an if…else condition judgment statement to judge the temperature and humidity values. The program writing idea is as follows:\n\nDeclare the DHT.h library, U8x8 library, etc., and connect the buzzer pin as a reminder to sound the device.\nInitialize the library file, define the buzzer pin state.\nDefine temperature and humidity variables to store readings and display them on the OLED screen, add logical judgment, and implement buzzer alarm.\n\nTo facilitate understanding and implementation, we divide the program implementation into two tasks:\n\nDetect temperature and humidity and display them on the OLED screen of the XIAO expansion board.\nAdd alarm function. #### Task 1: Use the Grove DHT20 sensor to detect temperature and humidity and display them on the OLED screen of the XIAO expansion board Step 1: Headers, declare the library files to be called.\n\n#include \"DHT.h\"    //Use DHT library\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;    //Use u8x8 library\n#define DHTTYPE DHT20\nDHT dht(DHTTYPE);   //DHT20 does not need to define pins\n\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);  //Setup constructor to connect to OLED screen\nStep 2: Initialize the DHT library and the u8x8 library.\nvoid setup() { \n    Wire.begin();   //Initialize wire library, and join I2C network\n    dht.begin();    //DHT starts working\n    u8x8.begin();   //u8x8 starts working\n    u8x8.setPowerSave(0);  //Turn off power saving mode, 1 is on, and nothing can be seen on the screen after power saving mode is on\n    u8x8.setFlipMode(1);\n}\nStep 3: Define temperature and humidity variables to store readings, read temperature and humidity values and display them on the OLED screen. Pay attention to the coordinate positions of temperature and humidity display.\nvoid loop() { \n    float temp, humi;   //Set the variables temp and humi to floating point type, representing temperature and humidity respectively\n    temp = dht.readTemperature();   //Read temperature value and store it in temp\n    humi = dht.readHumidity();  //Read humidity value and store it in humi\n    u8x8.setFont(u8x8_font_chroma48medium8_r);  //Set display font\n    u8x8.setCursor(0, 33);  //Set the position of the drawing cursor (0,33)\n    u8x8.print(\"Temp:\");    //Display Temp at the position (0,33)\n    u8x8.print(temp);   //Display real-time temperature value\n    u8x8.print(\"C\");    //Display the unit \"C\" of temperature\n    u8x8.setCursor(0,50);\n    u8x8.print(\"Humidity:\");\n    u8x8.print(humi);\n    u8x8.print(\"%\");\n    u8x8.refreshDisplay();\n    delay(200);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_dht20_tem_humi_XIAO_en\n\nStep 4: Connect the hardware, upload the program Connect the temperature and humidity sensor to the I2C interface of the XIAO expansion board, as shown in the figure: \nUse the data cable to connect XIAO to the computer, click the “upload” button in the Arduino IDE, and upload the program to the hardware. When the debugging area shows “upload successful”, you can observe whether the temperature and humidity values are displayed on the OLED screen, and you can hold the black part of the sensor with your palm to observe whether the values change.\n\n\nTask 2: Add an alarm function\nStep 1: Add alarm function code. The alarm function requires a buzzer to be integrated into the circuit, which can be facilitated using the on-board buzzer of the XIAO expansion board. The program needs to set the buzzer pin state, add a part for condition judgment - when the temperature exceeds a certain value or the humidity falls below a certain value, the buzzer will sound an alarm. Here, a logical expression needs to be written using the “&&” logical operator “and”. &gt; ### Boolean Operators &gt; - &&: Logical AND, represents “and”,if (expression1 && expression2), only when all expressions in the parentheses are true will it execute the statements in if {}. &gt; - ||: Logical OR, represents “or”,if (expression1 || expression2), if either of the expressions are satisfied, the entire expression is true, and the statements in if {} are executed. &gt; - !: Logical NOT, represents “not”, if (!expression1), only when the value of expression1 in the parentheses is false will it execute the statements in if {}. &gt; Usage example: &gt; When the temperature exceeds 30 or the humidity falls below 40, satisfying either condition will make the buzzer sound an alarm.\nif (temp &gt; 30 || humi &lt; 40) {\n    tone(buzzerPin, 200, 200);\n}\nThe added part of the program mainly sets the buzzer and makes decisions based on temperature and humidity, controlling the buzzer to make a sound.\n// Part of the program, will not run\nint buzzerPin = A3; // Connects the buzzer to pin A3\n\nvoid setup() {\n    pinMode(buzzerPin , OUTPUT); // Sets the buzzer pin as output\n}\n\nvoid loop() {\n    float temp, humi;\n    temp = dht.readTemperature();\n    humi = dht.readHumidity();\n    if (temp &gt; 30 || humi &lt; 40) {  // When the temperature exceeds 30 or the humidity falls below 40, satisfying either condition will make the buzzer sound an alarm.\n        tone(buzzerPin, 200, 200);\n    }\nAdd the above code to the corresponding location of the Task 1 program to realize all functions. The complete program is shown below:\n#include \"DHT.h\" // Use DHT library\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt; // Use u8x8 library\n#define DHTTYPE DHT20\nDHT dht(DHTTYPE); // DHT20 does not require pin definition\nint buzzerPin = A3;\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE); // Set constructor to connect OLED display\n\nvoid setup() { \n    pinMode(buzzerPin , OUTPUT); // Set buzzer pin to output mode\n    Wire.begin(); // Initialize Wire library and join to I2C network\n    dht.begin(); // DHT begins operation\n    u8x8.begin(); // u8x8 begins operation\n    u8x8.setPowerSave(0);  // Disable power save mode, 1 is enable. After enabling power save mode, nothing will be seen on the screen\n    u8x8.setFlipMode(1);\n}\n\nvoid loop() { \n    float temp, humi; // Set variables temp and humi to floating point type, representing temperature and humidity respectively\n    temp = dht.readTemperature(); // Read temperature value and store it in temp\n    humi = dht.readHumidity(); // Read humidity value and store it in humi\n    if (temp &gt; 30 || humi &lt; 40) {  // When the temperature is above 30 or the humidity is below 40, if either condition is met, the buzzer will sound an alarm\n        tone(buzzerPin, 200, 200);\n    }\n\n    u8x8.setFont(u8x8_font_chroma48medium8_r); // Set display font\n    u8x8.setCursor(0, 33); // Set the position of the drawing cursor (0,33)\n    u8x8.print(\"Temp:\"); // Display \"Temp:\" at the position (0,33)\n    u8x8.print(temp); // Then display the real-time temperature value\n    u8x8.print(\"C\"); // Then display the unit of temperature \"C\"\n    u8x8.setCursor(0,50);\n    u8x8.print(\"Humidity:\");\n    u8x8.print(humi);\n    u8x8.print(\"%\");\n    u8x8.refreshDisplay();\n    delay(200);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_dht20_alarm_XIAO_en\n\nStep 2: Upload the program. After writing the program, connect the XIAO main control board to the computer using a data cable, as shown in the image below:  After connection, click the “Verify” button to check the program. If the verification is successful, click the “Upload” button to upload the program to the hardware. When the debugging area shows “Upload Successful”, it is complete. To verify whether the alarm function runs smoothly, tightly grip the temperature and humidity sensor with your hand, observe the value change on the OLED display, and listen for the buzzer alarm when the temperature exceeds 30℃.  #### Task 2-2: Use Grove DHT11 sensor to display temperature and humidity on the XIAO extension board’s OLED and add an alarm function.\nFor the Grove DHT11 sensor with a blue casing, the program is shown below:\n#include \"DHT.h\"//Use DHT library\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;//Use u8x8 library\n#define DHTPIN 0 \n#define DHTTYPE DHT11//Specify using DHT11\nDHT dht(DHTPIN, DHTTYPE); \nint buzzerPin = A3;\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(/* reset=*/ U8X8_PIN_NONE);//Set constructor to connect OLED display\n\nvoid setup() { \n  pinMode(buzzerPin , OUTPUT);//Set buzzer pin to output mode\n  Wire.begin();//Initialize wire library and join to I2C network\n  dht.begin();//DHT begins operation\n  u8x8.begin();//u8x8 begins operation\n  u8x8.setPowerSave(0);  //Disable power save mode, 1 is enable. After enabling power save mode, nothing will be seen on the screen\n  u8x8.setFlipMode(1);\n}\n\nvoid loop() { \n  float temp, humi;//Set variables temp and humi to floating point type, representing temperature and humidity respectively\n  temp = dht.readTemperature();//Read temperature value and store it in temp\n  humi = dht.readHumidity();//Read humidity value and store it in humi\n  if (temp &gt; 30 || humi &lt; 40) {  //When the temperature is above 30 or the humidity is below 40, if either condition is met, the buzzer will sound an alarm\n  tone(buzzerPin, 200, 200);\n  }\n\n  u8x8.setFont(u8x8_font_chroma48medium8_r);//Set display font\n  u8x8.setCursor(0, 33);//Set the position of the drawing cursor (0,33)\n  u8x8.print(\"Temp:\");//Display \"Temp:\" at the position (0,33)\n  u8x8.print(temp);//Then display the real-time temperature value\n  u8x8.print(\"C\");//Then display the unit of temperature \"C\"\n  u8x8.setCursor(0,50);\n  u8x8.print(\"Humidity:\");\n  u8x8.print(humi);\n  u8x8.print(\"%\");\n  u8x8.refreshDisplay();\n  delay(200);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L8_dht11_alarm_XIAO_en\n\n\n\n2.2.4 Appearance Design\nStarting from this section, we will add the part of appearance design, beginning to explore the complete prototype product manufacturing. Initially, we can try to draw design sketches and make a simple modification with the materials at hand. Returning to the smart temperature and humidity meter in this section, please design the appearance of the prototype work based on the product characteristics and functions.\n\n\n\n\n\n\n\nProduct Name\nSmart Temperature and Humidity Meter\n\n\n\n\nProduct Features\nSmall, portable, high sensitivity.\n\n\nProduct Functions\nReal-time display of temperature and humidity values, and emits an alarm when temperature and humidity values exceed the comfortable range.\n\n\nProduct Appearance\n(For example, made into a pendant to hang on the backpack that is carried around, stick on the tissue storage box in the bedroom, etc.)\n\n\n\n\nCase reference"
  },
  {
    "objectID": "chapter_2-3.html",
    "href": "chapter_2-3.html",
    "title": "2.3 Surprise Gift Box Based on Light Sensor",
    "section": "",
    "text": "Are you thinking about gifting a special birthday present to your friend? Instead of buying one, you can create it with the modules we have at hand. In this section, we are going to create a surprise gift box for a good friend. What kind of surprise will appear when the gift box is opened? What kind of modules do we need to complete such a surprise gift box? Start today’s class with these questions. ## 2.3.1 Background Knowledge ### 2.3.1.1 Light Sensor Light sensors can detect the light intensity in the surrounding environment and convert the detected light energy into electrical energy. Light sensors are divided into types such as photoresistive, photodiode, and photoelectric transistor. Here, we will simply introduce two commonly used light sensors, photoresistive and photodiode. Photoresistive Type Firstly, the photoresistive type, its module will integrate a photoresistor, as shown below. The photoresistor is extremely sensitive to light, any light visible to our eyes can cause its reaction. High-intensity light will cause the resistance value to decrease, and low-intensity light will cause the resistance value to increase. By adjusting the resistance value in the circuit through the light intensity, it can control other devices, such as controlling the LED light on and off.  Photodiode Type Photodiodes, also known as photoelectric sensors or photodetectors, when a beam of light hits the diode, the electrons in the tube will quickly scatter to form electron holes, thereby causing current to flow. The stronger the light, the stronger the current. Since the current generated by the photodiode is proportional to the intensity of light, it is very beneficial for light detection that requires a rapid change in light response. The light sensor we are going to use in this lesson is of this type.  Talking about the uses of light sensors, we can build a light-controlled switch through a light sensor, such as controlling the light on and off through a light sensor, turning off the light during the day, and turning on the light at night. The main purpose of the light control device is to save energy, improve efficiency through intelligent automation, the most common in life is probably the light control light, light control desk lamp, light control street lamp, highway tunnel lighting, etc., bringing convenience to our life and also contributing to environmental protection and energy conservation. ### 2.3.1.2 RGB LED Strip  The project in this class is paired with an RGB LED strip. The strip integrates multiple color-adjustable light beads. Compared with a single LED, it can achieve more lighting effects and cool visual impacts, making it ideal for creating surprises. RGB LED strips come in various styles and models. The one we are going to use is the [Grove - WS2813 RGB LED Strip], 30-bead model. We can control the RGB LED strip to achieve a rich lighting effect through programming, and build more interesting lighting projects. ## 2.3.2 Task 1: Light up RGB LED Strip To get started with RGB LED strips, start by installing and understanding its library. #### Add the Adafruit_NeoPixel Library Before starting to program the RGB LED strip with the Arduino IDE, you need to add the necessary library files. Enter the library file address 🔗 https://github.com/adafruit/Adafruit_NeoPixel in the browser address bar, enter the GitHub page, click Code→Download ZIP to download the resource package Adafruit_NeoPixel-master.zip to your local machine.  Next, add the resource package Adafruit_NeoPixel-master.zip downloaded in the previous step via the menu bar Sketch→Include Library→Add .ZIP Library until you see the library loaded successfully. #### Open the Simple Example You can open the simple example through the following path: File → Examples → Adafruit NeoPixel → simple. Once the example program is opened, we can see the following program:\n// NeoPixel Ring simple sketch (c) 2013 Shae Erisson\n// Released under the GPLv3 license to match the rest of the\n// Adafruit NeoPixel library\n\n#include &lt;Adafruit_NeoPixel.h&gt;\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; // Required for 16 MHz Adafruit Trinket\n#endif\n\n// Which pin on the Arduino is connected to the NeoPixels?\n#define PIN        6 // On Trinket or Gemma, suggest changing this to 1\n\n// How many NeoPixels are attached to the Arduino?\n#define NUMPIXELS 16 // Popular NeoPixel ring size\n\n// When setting up the NeoPixel library, we tell it how many pixels,\n// and which pin to use to send signals. Note that for older NeoPixel\n// strips you might need to change the third parameter -- see the\n// strandtest example for more information on possible values.\nAdafruit_NeoPixel pixels(NUMPIXELS, PIN, NEO_GRB + NEO_KHZ800);\n\n#define DELAYVAL 500 // Time (in milliseconds) to pause between pixels\n\nvoid setup() {\n    // These lines are specifically to support the Adafruit Trinket 5V 16 MHz.\n    // Any other board, you can remove this part (but no harm leaving it):\n    #if defined(__AVR_ATtiny85__) && (F_CPU == 16000000)\n    clock_prescale_set(clock_div_1);\n    #endif\n    // END of Trinket-specific code.\n\n    pixels.begin(); // INITIALIZE NeoPixel strip object (REQUIRED)\n}\n\nvoid loop() {\n    pixels.clear(); // Set all pixel colors to 'off'\n\n    // The first NeoPixel in a strand is #0, second is 1, all the way up\n    // to the count of pixels minus one.\n    for(int i=0; i&lt;NUMPIXELS; i++) { // For each pixel...\n\n        // pixels.Color() takes RGB values, from 0,0,0 up to 255,255,255\n        // Here we're using a moderately bright green color:\n        pixels.setPixelColor(i, pixels.Color(0, 150, 0));\n\n        pixels.show();   // Send the updated pixel colors to the hardware.\n\n        delay(DELAYVAL); // Pause before next pass through loop\n    }\n}\nThis program allows the strip to light up 30 beads (green light) in sequence. This is a simple light strip example, and we need to modify some parameters: #define PIN 0, you need to modify the pin connected to the light strip according to the actual situation. It is connected to the A0 interface of the XIAO expansion board, so it is PIN 0. #define NUMPIXELS 30, defines the number of LEDs in the light strip. Since the light strip has different models and the number of integrated beads is different, we use a light strip with 30 beads, so it is NUMPIXELS 30.\nAfter modifying the parameters, you can remove the English comments for a clearer view of the code. It occupies a large amount of space.\n#include &lt;Adafruit_NeoPixel.h&gt; // Header file, declaring the library\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n\n#define PIN 0 // The light strip is connected to pin 0. If you are using XIAO RP2040, please change 0 to A0\n#define NUMPIXELS 30 // The number of LED lights on the light strip\nAdafruit_NeoPixel pixels(NUMPIXELS, PIN, NEO_GRB + NEO_KHZ800); // Create a new light strip object, define data mode\n#define DELAYVAL 500 // The interval time for each light to light up\n\nvoid setup() {\n    #if defined(__AVR_ATtiny85__) && (F_CPU == 16000000)\n    clock_prescale_set(clock_div_1);\n    #endif\n    pixels.begin(); // The light strip is ready to output data\n}\n\nvoid loop() {\n    pixels.clear(); // All beads on the light strip are turned off\n    for(int i=0; i&lt;NUMPIXELS; i++) { \n        pixels.setPixelColor(i, pixels.Color(0, 150, 0)); // Light up the beads in sequence, the color is green\n        pixels.show(); // Display the light strip\n        delay(DELAYVAL); \n    }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L9_NeoPixel30_simple_XIAO_en\n\nIn the code above, pixels.Color(0,150,0) is a function to set the color of the LED light strip. The numbers in the parentheses represent the three primary colors (red, green, blue) respectively. If it is (0,150,0), it means that the brightness of red is 0, the brightness of green is 150, and the brightness of blue is 0. The entire light strip will show a green effect. The larger the number, the brighter it will be, with a maximum of 255. Next, connect the light strip to the A0/D0 interface of the XIAO expansion board, as shown in the following figure:  Connect the XIAO main board to the computer with a data cable, and upload the program to the main board. After the upload is successful, observe the effect of the light strip.\nThe light strip can change color, flicker, and present various lighting effects such as breathing. We can refer to the sample program in the library: File → Example → Adafruit NeoPixel → buttoncycler. This sample program switches different lighting effects on the light strip through buttons. We can find the code for various lighting effects in it, such as flickering, rainbow lights, chasing, etc. ## 2.3.3 Project Making: Surprise Gift Box ### Project Description The program for the surprise gift box wants to realize: Use a light sensor to control the on and off of the RGB LED light strip, just like a light-controlled lamp, but the effect is opposite. When the value detected by the light sensor is less than a fixed value, that is, it is in a dim environment, the RGB LED light strip is off. When the value detected by the light sensor is greater than a fixed value, that is, in a bright environment, the RGB LED light strip lights up the rainbow light.\n\nProgram Writing\nThe program writing idea is as follows:\n\nDeclare the files to be called, create a new light strip object, define the sensor pin and the number of LEDs on the light strip.\nInitialize the light strip and set the light sensor pin mode.\nRead the light value. If the light value is greater than 100, the light strip will present a rainbow and breathing light effect. Otherwise, the light strip will turn off.\n\nThe program is completed in two tasks:\n\nTask 1: Make the Light Strip Present Rainbow and Breathing Light Effect\nStep 1: Declare the files to be called, declare the light strip object, and define the pin and the number of LEDs on the light strip.\n#include &lt;Adafruit_NeoPixel.h&gt; // Header file, declaring the library\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n\n#define PIXEL_PIN 0 // The light strip is connected to pin A0. If you are using XIAO RP2040, please change 0 to A0\n#define PIXEL_COUNT 30 // The number of LED lights on the light strip\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800);\n// Declare a new light strip object and define the data mode\nStep 2: Initialize the light strip.\nvoid setup() {\n    strip.begin(); // Initialize the light strip, the light strip is ready to output data\n}\nStep 3: The light strip presents a rainbow and breathing light effect. This part uses the for() function to present the breathing effect. For example, for( i = 0; i&lt;5; i ++ ){} means that the initial value of i is 0, when i is less than 5, the statement in the loop body {} is run, each time the loop is run, i is incremented by 1. This loop will run 5 times.\nvoid loop() {\n    strip.clear();// Turn off all the lights on the light strip\n    rainbow(10);// The light strip displays a rainbow light effect. The number in the parenthesis represents the speed of the rainbow light circulation. The smaller the number, the faster the circulation speed\n}\n// The following is the code for the rainbow light effect, presenting the breathing light effect. This code can be found in the example program buttoncycler\nvoid rainbow(int wait) {\n    for(long firstPixelHue = 0; firstPixelHue &lt; 3*65536; firstPixelHue += 256) {\n        for(int i=0; i&lt;strip.numPixels(); i++) { \n            int pixelHue = firstPixelHue + (i * 65536L / strip.numPixels());\n            strip.setPixelColor(i, strip.gamma32(strip.ColorHSV(pixelHue)));\n        }\n        strip.show(); // The light strip presents a light effect\n        delay(wait);  // Delay\n    }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L9_Rainbow_XIAO_en\n\nStep 4: Connect the hardware and upload the program. First, connect the RGB LED light strip to the A0/D0 interface of the XIAO expansion board, as shown in the figure:  Use a data cable to connect XIAO to the computer, click the “Upload” button, and upload the program to the hardware. When the debugging area shows “Upload successful”, you can observe the light effect of the light strip. \n\n\nTask 2: Adding Light Control Switch Function\nStep 1: Add code. The added function is mainly to read the light value detected by the light sensor, and use the if…else… statement to judge the light value. When it is greater than 100 (this value can be adjusted according to the actual environment), the RGB LED light strip will show a rainbow breathing light effect. Part of the program added:\n// This is an added part of the program, it cannot run directly\n#define LIGHT_PIN 7// Define the light sensor connected to A7. If you are using XIAO RP2040, please change 7 to A3. If you are using XIAO BLE, please change 7 to 5\n#define PIXEL_PIN 0// Define light strip. If you are using XIAO RP2040, please change 0 to A0\nint readValue = 0;// Define the variable readValue to store the light value\nvoid setup() { \n    pinMode(LIGHT_PIN , INPUT); // Set the pin of the light sensor as input status\n}\nvoid loop() {\n    readValue = analogRead(A7);// Read the analog value of the A7 pin light and store it in the readValue variable. If you are using XIAO RP2040, please change A7 to A3. If you are using XIAO BLE, please change A7 to A5\n    if(readValue &gt; 500){ // Condition judgment, if the light value is greater than 500, then the light strip presents a rainbow light effect, otherwise, the light strip is turned off\n        rainbow(10);\n    }else {\n        strip.clear();  \n        strip.show(); \n    }\n}\nWe add the entered statement to the corresponding position of Task 1’s program. See the complete program:\n#include &lt;Adafruit_NeoPixel.h&gt;// Header file, declare library\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n#define LIGHT_PIN 7// Define the light sensor connected to A7. If you are using XIAO RP2040, please change 7 to A3. If you are using XIAO BLE, please change 7 to 5\n#define PIXEL_PIN 0 // The light strip is connected to the A0 pin. If you are using XIAO RP2040, please change 0 to A0\n#define PIXEL_COUNT 30 // The number of LEDs on the light strip\nint readValue = 0;// Define variable readValue to store light values\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800);\n// Declare the light strip object and define the data mode\nvoid setup() {\n  strip.begin(); // Initialize the light strip and prepare the light strip to output data\n  pinMode(LIGHT_PIN , INPUT); // Set the pin of the light sensor to input state\n}\nvoid loop() {\n  strip.clear();// Turn off all the beads on the light strip\n  rainbow(10);// The light strip shows a rainbow light effect. The number in the parentheses represents the speed of the rainbow light rotation. The smaller the number, the faster the rotation speed\n  readValue = analogRead(A7);// Read the analog value of the light on the A7 pin and store it in the readValue variable. If you are using XIAO RP2040, please change A7 to A3. If you are using XIAO BLE, please change A7 to A5\n    if(readValue &gt; 500){ // Conditional judgment, if the light value is greater than 500, then the light strip presents a rainbow light effect, otherwise, the light strip is turned off\n        rainbow(10);\n    }else {\n        strip.clear();  \n        strip.show(); \n    }\n}\n// The following is the code for the rainbow light effect, presenting the breathing light effect, this code can be found in the sample program buttoncycler\nvoid rainbow(int wait) {\n  for(long firstPixelHue = 0; firstPixelHue &lt; 3*65536; firstPixelHue += 256) {\n    for(int i=0; i&lt;strip.numPixels(); i++) { \n      int pixelHue = firstPixelHue + (i * 65536L / strip.numPixels());\n      strip.setPixelColor(i, strip.gamma32(strip.ColorHSV(pixelHue)));\n    }\n    strip.show(); // The light strip presents a light effect\n    delay(wait);  // Delay\n  }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L9_StripLight_XIAO_en\n\nStep 2: Connect the hardware and upload the program. First, connect the RGB LED light strip to the A0 interface of the XIAO expansion board, and connect the light sensor to the A7 interface, as shown in the figure below: \n\n⚠️ Note If you are using XIAO BLE, please connect the light sensor to the I2C interface of the XIAO expansion board. If you are using XIAO RP2040, due to the limited number of pins exposed, you need to connect the SIG pin of the light sensor and the A3 pin of XIAO RP2040 with Dupont wires on your own.\n\nNext, connect XIAO to your computer with a data cable, click the “Upload” button in the Arduino IDE to upload the program to the hardware. When the debugging area shows “Upload successful”, you can cover the light sensor with your hand, then release the light sensor, and observe the changes in the light strip. Note that because it takes a certain amount of time for the light strip to display light effects, the light strip will not turn off immediately when you cover the light sensor.  ## 2.3.4 Exterior Design Combining the program design of the surprise gift box, when the light sensor is in a dim environment, the RGB LED light strip is off, and when the light sensor is in a bright environment, the RGB LED light strip lights up with rainbow lights. We can imagine that the electronic part is placed in a closed box, which can match the function implemented by the program and can also meet the positioning of the gift. Of course, you can also have other designs.\n\n\n\n\n\n\n\nProduct Name\nSurprise Gift Box\n\n\n\n\nProduct Features\nCool light effects, photocontrol, surprise, birthday\n\n\nProduct Functions\nControl the lighting of the RGB LED light strip with a light sensor\n\n\nProduct Appearance\n\n\n\n\n\n\nCase reference"
  },
  {
    "objectID": "chapter_2-4.html#project-production-rhythmic-dance",
    "href": "chapter_2-4.html#project-production-rhythmic-dance",
    "title": "2.4 Rhythmic Dance with a Triaxial Accelerometer",
    "section": "2.4.3 Project Production: Rhythmic Dance",
    "text": "2.4.3 Project Production: Rhythmic Dance\n\nProject Description\nWe can add an RGB LED strip in the project to achieve cool light effects changes. The three-axis accelerometer is used to detect movement, and different light effects are triggered based on different values on the X, Y, Z axes of the accelerometer. ### Program Writing To control the RGB LED strip to change the light effects via the three-axis accelerometer, follow these steps:\n\nDeclare the library files that need to be invoked, define the strip pin and LED quantity.\nInitialize the three-axis accelerometer and the strip.\nSet the light effect of the strip to red, green and blue flashing, set the conditional judgment, and control the change by different value intervals on the X, Y, Z axis of the three-axis accelerometer. ### Task: Control RGB LED Strip to Change Light Effects via Three-Axis Accelerometer Step 1: Declare the library files that need to be invoked, define the strip pin and the number of LEDs.\n\n#include \"LIS3DHTR.h\" // Declare the library file of the three-axis accelerometer\n#include &lt;Adafruit_NeoPixel.h&gt; // Declare the strip's library file\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n// Below are to initialize the module using software I2C or hardware I2C\n#ifdef SOFTWAREWIRE\n#include &lt;SoftwareWire.h&gt;\nSoftwareWire myWire(3, 2);\nLIS3DHTR&lt;SoftwareWire&gt; LIS; \n#define WIRE myWire\n#else\n#include &lt;Wire.h&gt;\nLIS3DHTR&lt;TwoWire&gt; LIS;    \n#define WIRE Wire\n#endif\n\n#define PIXEL_PIN 0 // Define the pin of the strip, if you use XIAO RP2040/XIAO ESP32, please modify 0 to A0\n#define PIXEL_COUNT 30 // Define the number of LEDs in the strip as 30\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800); // Declare the strip object, set the data type\nStep 2: Initialize the three-axis accelerometer and the strip. Here, you need to initialize the accelerometer and set the rate to 50HZ.\nvoid setup() { \n    Serial.begin(9600); // Initialize the serial monitor\n    while (!Serial) {}; // If the serial monitor isn't opened, the code will stop here, so please open the serial monitor\n    LIS.begin(WIRE, 0x19); // Initialize I2C\n    delay(100);\n    LIS.setOutputDataRate(LIS3DHTR_DATARATE_50HZ); // Set the accelerometer's output rate to 50Hz\n    strip.begin(); // Start the strip\n    strip.show(); // Display the strip\n}\nStep 3: Set the light effects to flash in red, green, and blue, respectively. Conditionals are used to change the color of the light strip according to the varying readings on the X, Y, and Z axes of the 3-axis accelerometer. These readings can be viewed via the serial monitor. By observing the change in values when the accelerometer is moved along the X, Y, and Z axes, we can determine the appropriate settings for the light strip. Since the readings may sometimes be negative, we take the absolute value of the readings. The abs() function can be used to get the absolute value, for example, abs(LIS.getAccelerationX()) would give the absolute value of the reading on the X-axis.\nvoid loop() {\n    if (!LIS) {  // Check if the 3-axis accelerometer is connected properly\n        Serial.println(\"LIS3DHTR didn't connect.\");\n        while (1);\n        return;\n    }\n\n    if ((abs(LIS.getAccelerationX()) &gt; 0.2)) {\n        theaterChase(strip.Color(127, 0, 0), 50); // The light strip turns red\n    }\n    if ((abs(LIS.getAccelerationY()) &gt; 0.2)) {\n        theaterChase(strip.Color(0, 127, 0), 50); // The light strip turns green\n    }\n    if ((abs(LIS.getAccelerationZ()) &gt; 1.0)) {\n        theaterChase(strip.Color(0, 0, 127), 50); // The light strip turns blue\n    }\n    else\n    {\n        strip.clear(); \n        strip.show();\n    }\n\n    // Read the values of the X, Y, and Z axes from the sensor and display them on the serial monitor\n    Serial.print(\"x:\"); Serial.print(LIS.getAccelerationX()); Serial.print(\"  \");\n    Serial.print(\"y:\"); Serial.print(LIS.getAccelerationY()); Serial.print(\"  \");\n    Serial.print(\"z:\"); Serial.println(LIS.getAccelerationZ());\n\n    delay(500);\n}\n// Set theaterChase for flashing light effects\nvoid theaterChase(uint32_t color, int wait) {\n    for(int a=0; a&lt;10; a++) {  \n        for(int b=0; b&lt;3; b++) { \n            strip.clear();   \n            for(int c=b; c&lt;strip.numPixels(); c += 3) {\n                strip.setPixelColor(c, color);\n            }\n            strip.show(); \n            delay(wait);\n        }\n    }\n}\nComplete program as follows:\n#include \"LIS3DHTR.h\"// Declare the library file for the 3-axis accelerometer\n#include &lt;Adafruit_NeoPixel.h&gt;// Declare the library file for the light strip\n#ifdef __AVR__\n#include &lt;avr/power.h&gt; \n#endif\n// The following is to initialize the module using software I2C or hardware I2C\n#ifdef SOFTWAREWIRE\n#include &lt;SoftwareWire.h&gt;\nSoftwareWire myWire(3, 2);\nLIS3DHTR&lt;SoftwareWire&gt; LIS; \n#define WIRE myWire\n#else\n#include &lt;Wire.h&gt;\nLIS3DHTR&lt;TwoWire&gt; LIS;    \n#define WIRE Wire\n#endif\n\n#define PIXEL_PIN 0 // Define the pin of the light strip, if you are using XIAO RP2040/XIAO ESP32, please change 0 to A0\n#define PIXEL_COUNT 30 // Define the number of LEDs on the light strip as 30\nAdafruit_NeoPixel strip(PIXEL_COUNT, PIXEL_PIN, NEO_GRB + NEO_KHZ800); // Declare the light strip object and set the data type\n\nvoid setup() { \n    Serial.begin(9600); // Initialize the serial monitor\n    while (!Serial) {};// If you do not open the serial monitor, the code will stop here, so please open the serial monitor\n    LIS.begin(WIRE, 0x19); // IIC initialization\n    delay(100);\n    LIS.setOutputDataRate(LIS3DHTR_DATARATE_50HZ); // Set the output rate of the accelerometer to 50Hz\n    strip.begin(); // The light strip starts working\n    strip.show(); // The light strip displays\n}\nvoid loop() {\n    if (!LIS) {  // Check if the 3-axis accelerometer is connected correctly\n        Serial.println(\"LIS3DHTR didn't connect.\");\n        while (1);\n        return;\n    }\n\n    if ((abs(LIS.getAccelerationX()) &gt; 0.2)) {\n        theaterChase(strip.Color(127, 0, 0), 50); // The light strip turns red\n    }\n    if ((abs(LIS.getAccelerationY()) &gt; 0.2)) {\n        theaterChase(strip.Color(0, 127, 0), 50); // The light strip turns green\n    }\n    if ((abs(LIS.getAccelerationZ()) &gt; 1.0)) {\n        theaterChase(strip.Color(0, 0, 127), 50); // The light strip turns blue\n    }\n    else\n    {\n        strip.clear(); \n        strip.show();\n    }\n\n    // Read the values of the X, Y, and Z axes from the sensor and display them on the serial monitor\n    Serial.print(\"x:\"); Serial.print(LIS.getAccelerationX()); Serial.print(\"  \");\n    Serial.print(\"y:\"); Serial.print(LIS.getAccelerationY()); Serial.print(\"  \");\n    Serial.print(\"z:\"); Serial.println(LIS.getAccelerationZ());\n\n    delay(500);\n}\n// Set theaterChase for flashing light effects\nvoid theaterChase(uint32_t color, int wait) {\n    for(int a=0; a&lt;10; a++) {  \n        for(int b=0; b&lt;3; b++) { \n            strip.clear();   \n            for(int c=b; c&lt;strip.numPixels(); c += 3) {\n                strip.setPixelColor(c, color);\n            }\n            strip.show(); \n            delay(wait);\n        }\n    }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L10_MovementRGBLED_XIAO_en\n\nStep 4: Connect the hardware and upload the program. First, connect the RGB LED light strip to the A0/D0 interface of the XIAO expansion board, and the three-axis accelerometer to the I2C interface, as shown in the figure:  Use a data cable to connect XIAO to your computer, click the “Upload” button in Arduino IDE, and upload the program to the hardware. Once the debugging area shows “Upload Successful”, you can open the serial monitor and try swinging the three-axis accelerometer left, right, up, and down to feel the light effect changes of the light strip."
  },
  {
    "objectID": "chapter_2-4.html#exterior-design",
    "href": "chapter_2-4.html#exterior-design",
    "title": "2.4 Rhythmic Dance with a Triaxial Accelerometer",
    "section": "2.4.4 Exterior Design",
    "text": "2.4.4 Exterior Design\nImagine how cool it would be if there were lights flashing with your dance steps as you passionately swing your arms. That’s where the inspiration for Rhythm Dance comes from. It can be combined with clothes or accessories to create a wearable style.\n\n\n\n\n\n\n\nProduct Name\nRhythm Dance\n\n\n\n\nProduct Features\nWearable, Cool light effects, Posture detection\n\n\nProduct Functions\nRGB LED light strip displays different light effects based on the values detected by the three-axis accelerometer\n\n\nProduct Appearance\n(For example: The waterproof layer on the outside of the RGB LED light strip can be removed, and it can be sewn together with clothes or a belt, etc.)\n\n\n\n\nReference for the case\n ###"
  },
  {
    "objectID": "chapter_3.html",
    "href": "chapter_3.html",
    "title": "Chapter 3: Intermediate Project Practice—Complex Projects",
    "section": "",
    "text": "In this unit, we will delve into more intricate and comprehensive projects, striving towards mature works in terms of program implementation and design of appearance structure. These include miniaturized smart homes, wearable electronic devices, interactive electronic instruments, Wi-Fi connectivity, and applications enabled by XIAO ESP32C3 or telemetry and command via the MQTT protocol. We will provide the laser-cut design blueprints for the first three cases for your reference. Of course, you’re not limited to these examples; you could use other, more accessible materials, such as corrugated cardboard or cardstock, for crafting. Feel free to unleash your creativity and design the work you wish to present!"
  },
  {
    "objectID": "chapter_3-1.html#task-1-reading-remote-control-key-codes",
    "href": "chapter_3-1.html#task-1-reading-remote-control-key-codes",
    "title": "3.1 Smart Remote Control Door",
    "section": "3.1.2 Task 1: Reading Remote Control Key Codes",
    "text": "3.1.2 Task 1: Reading Remote Control Key Codes\n\nAdding the[Arduino-IRremote](https://github.com/Arduino-IRremote/Arduino-IRremote)Library File\nBefore we begin programming the Grove - IR Infrared Receiver with the Arduino IDE, we need to add the necessary library files. Enter the library file address 🔗 https://github.com/Arduino-IRremote/Arduino-IRremote in your browser address bar, go to the GitHub page, and click Code→Download ZIP to download the resource package Arduino-IRremote-master.zip to your local machine, as shown in the image below:  Add the resource package Arduino-IRremote-master.zip you just downloaded through Sketch→Include Library→Add .ZIP Library in the Arduino IDE menu bar until you see a message indicating successful library loading. #### Open the Example File If you want to control other devices through the infrared remote control, such as pressing the left key on the mini infrared remote control to rotate the servo to the left, or pressing the right key to rotate the servo to the right, you first need to know what kind of code each key on the remote control will emit. This way, you can set it through the program. But how do you read the codes of different keys on the remote control? You can use the IRremote library and open the IRrecvDemo example via the following path: **File→Examples→IRremote→ReceiveDemo**. This example program can read the key codes of the remote control, but some parameters need to be modified: **int RECV_PIN = 7**, change the number according to the hardware connection pin. We have connected the infrared receiver to pin 7. Next, we select useful code. We only need to define the header file and the part that reads the remote control key codes. After reducing, the program is as follows:\n#include &lt;Arduino.h&gt;\n#include &lt;IRremote.h&gt;\n\nconst byte IR_RECEIVE_PIN=7; // The infrared receiver is connected to pin 7. If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0\n\nvoid setup() {\n    Serial.begin(115200);\n    Serial.println(F(\"Enabling IRin\"));\n    IrReceiver.begin(IR_RECEIVE_PIN,ENABLE_LED_FEEDBACK); // Start infrared decoding\n    Serial.print(F(\"Ready to receive IR signals at pin \"));\n    Serial.println(IR_RECEIVE_PIN);\n    delay(1000);\n}\n\nvoid loop() {\n    if (IrReceiver.decode()) // Decode successfully, receive a set of infrared signals\n   {\n      Serial.println(IrReceiver.decodedIRData.command, HEX); // Output infrared decoding result (hexadecimal)\n      Serial.println(IrReceiver.decodedIRData.command); // Output infrared decoding result (octal)\n      IrReceiver.resume(); // Receive the next set of values\n   }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L11_IRrecvDemo_en\n\nThe infrared receiver module is connected to the port 7, as shown in the following figure: \n\n⚠️ Note: If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0.\n\nAfter the code is uploaded, open the serial monitor, aim the remote control at the black component of the infrared receiver at a close distance, press any key, and observe the characters output by the serial monitor. The hexadecimal code appears in the first line, and the octal code appears in the second line. The two lines form one group, representing one key. Please note that if you press the key for too long, “FFFFFFFF” will appear, and this line of code and the numeric code below are invalid.  &gt; ⚠️ Note: Different remote controls may give different values."
  },
  {
    "objectID": "chapter_3-1.html#project-creation-smart-remote-door",
    "href": "chapter_3-1.html#project-creation-smart-remote-door",
    "title": "3.1 Smart Remote Control Door",
    "section": "3.1.3 Project Creation: Smart Remote Door",
    "text": "3.1.3 Project Creation: Smart Remote Door\n\nProject Description\nHow can we recreate a smart remote control door? With a remote control and an infrared receiver, the next step is to control the opening and closing of the door. Recall how the remote control doors in our life work? When the remote control is pressed, the door slowly opens. When it opens to a certain angle, it slowly closes. We can use a servo to control the rotation of the door. When closing the door, the servo rotates from 90° to 0°. When opening the door, the servo rotates from 0° to 90°. By transmitting the signals to open and close the door with a remote control, we can implement the function of a smart remote control door.\n\n\nProgram Writing\nTo control the rotation of the servo with an infrared remote control, you need to follow these steps:\n\nDeclare the IRremote library and Serve library to be called, and define variables.\nInitialize the library files, initialize the servo.\nRead the infrared decoding result and control the rotation of the servo according to the instructions to the left and right.\n\n\n\nTask 2: Control the Rotation of the Servo with an Infrared Remote Control\nStep 1: Declare the IRremote library and Serve library to be called, and define variables.\n#include &lt;IRremote.h&gt;\n#include &lt;Servo.h&gt;\n\nServo myservo; // Create a servo object myservo to control the servo\nint RECV_PIN = 7; // The infrared receiver is connected to pin 7. If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0\nIRrecv irrecv(RECV_PIN); // Define an IRrecv object to receive infrared signals\ndecode_results results; // Decoding results are placed in results\n\nint pos = 90; // Define pos as 90°\nStep 2: Initialize the library files, initialize the servo.\nvoid setup()\n{\n    Serial.begin(9600);\n    Serial.println(\"Enabling IRin\");  \n    irrecv.enableIRIn(); \n    myservo.attach(5); // Connect the servo on pin 5 to myservo. If you are using XIAO RP2040/XIAO ESP32, please change 5 to D5\n}\nStep 3: Read the infrared decoding result and control the rotation of the servo according to the instructions to the left and right. If you have questions about the program, you can refer to the comment section. &gt; ⚠️ Note: In the example, the infrared signal value of the right key 16761405, and the infrared signal value of the left key 16712445, need to be replaced by the values obtained from the “Read Remote Control Key Code” example using the remote control in your hand. Otherwise, there will be no response after pressing the key.\nvoid loop() {\n    if (irrecv.decode(&results)) {  // If decoding is successful, a set of infrared signals is received\n        if (results.value == 16761405) {  // If the received signal is 16761405 (right key)\n            for (pos; pos &lt;= 89; pos += 1) { // Then the servo is incremented from 0° to 90° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);\n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {  \n                    irrecv.resume();\n                    if (results.value == 16712445)  \n                        break;\n                }\n            }\n        }\n\n        if (results.value == 16712445) {    // If the received signal is 16712445 (left key)\n            for (pos; pos &gt;= 1; pos -= 1) { // Then the servo is decremented from 90° to 0° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);                       \n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {\n                    irrecv.resume();\n                    if (results.value == 16761405)\n                        break;\n                }\n            }\n        }\n        // Display hexadecimal and octal codes in the serial port\n        Serial.println(pos);\n        Serial.println(results.value, HEX);\n        Serial.println(results.value);\n        irrecv.resume();                    \n\n    }\n    delay(100);\n}\nComplete program details:\n#include &lt;IRremote.h&gt;\n#include &lt;Servo.h&gt;\n\nServo myservo; // Create a servo object myservo to control the servo\nint RECV_PIN = 7; // The infrared receiver is connected to pin 7. If you are using XIAO RP2040/XIAO ESP32, please change 7 to A0\nIRrecv irrecv(RECV_PIN); // Define an IRrecv object to receive infrared signals\ndecode_results results; // Decoding results are placed in results\n\nint pos = 90; // Define pos as 90°\n\nvoid setup()\n{\n    Serial.begin(9600);\n    Serial.println(\"Enabling IRin\");  \n    irrecv.enableIRIn(); \n    myservo.attach(5); // Connect the servo on pin 5 to myservo. If you are using XIAO RP2040/XIAO ESP32, please change 5 to D5\n}\n\n// Note: Left 16712445 Right 16761405, please replace with the key values read from your own remote control\nvoid loop() {\n    if (irrecv.decode(&results)) {  // If decoding is successful, a set of infrared signals is received\n        if (results.value == 16761405) {  // If the received signal is 16761405 (right key)\n            for (pos; pos &lt;= 89; pos += 1) { // Then the servo is incremented from 0° to 90° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);\n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {  \n                    irrecv.resume();\n                    if (results.value == 16712445)  \n                        break;\n                }\n            }\n        }\n\n        if (results.value == 16712445) {    // If the received signal is 16712445 (left key)\n            for (pos; pos &gt;= 1; pos -= 1) { // Then the servo is decremented from 90° to 0° in sequence\n                myservo.write(pos);              // Write the rotation angle value to the servo pin\n                delay(40);                       \n                // The following is to interrupt the above instruction and exit the loop\n                if (irrecv.decode(&results)) {\n                    irrecv.resume();\n                    if (results.value == 16761405)\n                        break;\n                }\n            }\n        }\n        // Display hexadecimal and octal codes in the serial port\n        Serial.println(pos);\n        Serial.println(results.value, HEX);\n        Serial.println(results.value);\n        irrecv.resume();                    \n\n    }\n    delay(100);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L11_IR_Servo_ino_XIAO_en\n\nStep 4: Connect the hardware and upload the program. First, connect the infrared receiving module to the 7th interface of the XIAO expansion board, and connect the servo to the I2C interface, as shown in the figure below:  &gt; ⚠️ Note: If you are using XIAO RP2040, please connect the infrared receiving module to the A0 interface.\nConnect XIAO to the computer with a data cable, click the “Upload” button, upload the program to the hardware, and when the debug area shows “Upload Successful”, open the serial monitor, aim the remote control at the infrared receiver, press the “Left” key and the “Right” key, observe the rotation of the servo, and check the encoding information output by the serial monitor. ## 3.1.4 Exterior Design In this unit, we need to implement a more complete project, combining the functions implemented by the program, the modules, and the appearance of the structure to form a prototype. Going back to the smart remote control door project, we need to control the rotation of the servo through the remote control, simulate the opening and closing of the door. When making the appearance, we need to focus on the following issues:\n\nHow to combine the servo and the door panel to make the rotation of the servo drive the rotation of the door panel.\nThe infrared receiver should be exposed in a conspicuous position, without any cover.\nWhether the main control, expansion board, and connecting wires are covered to keep the appearance neat.\nHow to make the work stand steadily.\n\nThe figure below provides an appearance case, which is laser cut from basswood, and provides cutting files for reference. If you can use drawing software, you can process and design it yourself. If you don’t have a laser cutting machine, you can also use corrugated paper, cardstock, non-woven fabric, and other handmade materials to make it, which tests your hands-on ability more. \nDownload files for use with a laser cutter 🔗 https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/dxf/XIAO_ADR.dxf."
  },
  {
    "objectID": "chapter_3-2.html#exterior-design",
    "href": "chapter_3-2.html#exterior-design",
    "title": "3.2 Smart Watch",
    "section": "3.2.4 Exterior Design",
    "text": "3.2.4 Exterior Design\nGiven its compact size, XIAO is especially suitable for creating wearable devices. The expansion board incorporates an RTC chip, a buzzer, and an OLED display screen, which means you can create a variety of applications even without adding other modules. In this section, we have made a smart watch using the on-board OLED display, RTC chip, and an external temperature and humidity sensor. When creating the appearance, we only need to consider wearability, organization of modules and connecting wires, and the exposure of the OLED display screen. As shown below, we provide a wearable watch style and the laser cutting files for it. With just a simple installation, your wearable device is ready.  Download files for laser cutting machine 🔗 https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/dxf/XIAO_X_watch.dxf.  \n\n\n\n1L12(3).jpg"
  },
  {
    "objectID": "chapter_3-3.html#task-1-reading-the-grove-ultrasonic-distance-sensor-value",
    "href": "chapter_3-3.html#task-1-reading-the-grove-ultrasonic-distance-sensor-value",
    "title": "3.3 Air Piano",
    "section": "3.3.2 Task 1: Reading the Grove Ultrasonic Distance Sensor Value",
    "text": "3.3.2 Task 1: Reading the Grove Ultrasonic Distance Sensor Value\n\nAdding the Seeed_Arduino_UltrasonicRanger Library\nBefore starting to program the Grove Ultrasonic Distance Sensor with Arduino IDE, it’s necessary to add the essential library for the sensor. Type the library address 🔗 https://github.com/Seeed-Studio/Seeed_Arduino_UltrasonicRanger into the browser address bar, enter the GitHub page, click Code→Download ZIP to download the resource package Seeed_Arduino_UltrasonicRanger-master.zip to your local drive, as shown below.  Add the downloaded resource package Seeed_Arduino_UltrasonicRanger-master.zip to the Sketch→Include Library→Add .ZIP Library from the menu bar until you see a successful library loading prompt. #### Opening the Example File After successfully installing the library, a new item Grove Ultrasonic Ranger will be added to the Arduino’s File→Examples list. Open the UltrasonicDisplayOnTerm sample program from it. This program can display the value of the ultrasonic distance sensor on the Serial Monitor. Modify Ultrasonic ultrasonic(7); in the sample program to Ultrasonic ultrasonic(0); (the ultrasonic distance sensor will be connected to the A0 port of the XIAO expansion board).  Open the modified sample file through the following path, 🔗 https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L13_UltrasonicDisplayOnTerm_XIAO_en.\n#include \"Ultrasonic.h\"//declare the library file\nUltrasonic ultrasonic(0);//define variables, connect pins. If you're using XIAO RP2040/XIAO ESP32, please change 0 to D0\nvoid setup() {\n    Serial.begin(9600);\n}\nvoid loop() {\n    long RangeInInches;//define a long integer variable named RangeInInches\n    long RangeInCentimeters;//define a long integer variable named RangeInCentimeters\n\n    Serial.println(\"The distance to obstacles in front is: \");\n    RangeInInches = ultrasonic.MeasureInInches();//read the distance value (inches) measured by the ultrasonic distance sensor and store it in the variable RangeInInches\n    Serial.print(RangeInInches);//serial print value\n    Serial.println(\" inch\");\n    delay(250);\n\n    RangeInCentimeters = ultrasonic.MeasureInCentimeters(); //read the distance value (centimeters) measured by the ultrasonic distance sensor and store it in the variable RangeInCentimeters\n    Serial.print(RangeInCentimeters);//serial print value\n    Serial.println(\" cm\");\n    delay(250);\n}\nThe ultrasonic distance sensor is connected to the A0 interface, as shown in the figure below:  After uploading the code, open the Serial Monitor. Place your hand or a card at any position in front of the ultrasonic distance sensor and observe the change in the values output by the Serial Monitor.  ## 3.3.3 Project Production: Ultrasonic Air Harp ### Project Description The working principle of the air harp is to measure the distance from the module to the palm of your hand through the ultrasonic distance sensor. Depending on the distance, the buzzer emits different musical notes. We have already learned how to measure distance and read values through the ultrasonic distance sensor with the sample program. Next, we just need to define different musical notes for the corresponding distances. As shown in the figure below: According to the width of the palm, one musical note corresponds to a unit of 2cm, and the performance starts from 4cm. “Do, Re, Mi, Fa, Sol, La, Xi, Do” respectively correspond to 4cm, 6cm, 8cm, 10cm, 12cm, 14cm, 16cm, 18cm… and so on.  ### Writing the Program\nThe implementation of the air harp program requires the following steps:\n\nDeclare the library file, define different notes and buzzer pins.\nInitialization, setting the status of the buzzer pin.\nRead the distance (cm) measured by the ultrasonic distance sensor, and make a condition judgment to set different distances to emit different notes.\n\n\nUsing the tone() Function to Play Melody\nWhen we want to control the buzzer to play notes or songs through the program, we need to set the frequency value of each note ourselves. If a song has many notes, it’s too troublesome to adjust one by one, and it tests our music theory knowledge and pitch. Is there a simpler method? Of course! When defining notes, we can refer to the tone() function written on the Arduino website 🔗 https://www.arduino.cc/en/Tutorial/BuiltInExamples/toneMelody, this function defines the corresponding frequency of different notes through pitches.h, which is convenient for us to use the tone() function to set the notes emitted by the buzzer. The code of pitches.h is shown below:\n\n/*\n* pitches.h\n*/\n\n#define NOTE_B0  31\n#define NOTE_C1  33\n#define NOTE_CS1 35\n#define NOTE_D1  37\n#define NOTE_DS1 39\n#define NOTE_E1  41\n#define NOTE_F1  44\n#define NOTE_FS1 46\n#define NOTE_G1  49\n#define NOTE_GS1 52\n#define NOTE_A1  55\n#define NOTE_AS1 58\n#define NOTE_B1  62\n#define NOTE_C2  65\n#define NOTE_CS2 69\n#define NOTE_D2  73\n#define NOTE_DS2 78\n#define NOTE_E2  82\n#define NOTE_F2  87\n#define NOTE_FS2 93\n#define NOTE_G2  98\n#define NOTE_GS2 104\n#define NOTE_A2  110\n#define NOTE_AS2 117\n#define NOTE_B2  123\n#define NOTE_C3  131\n#define NOTE_CS3 139\n#define NOTE_D3  147\n#define NOTE_DS3 156\n#define NOTE_E3  165\n#define NOTE_F3  175\n#define NOTE_FS3 185\n#define NOTE_G3  196\n#define NOTE_GS3 208\n#define NOTE_A3  220\n#define NOTE_AS3 233\n#define NOTE_B3  247\n#define NOTE_C4  262\n#define NOTE_CS4 277\n#define NOTE_D4  294\n#define NOTE_DS4 311\n#define NOTE_E4  330\n#define NOTE_F4  349\n#define NOTE_FS4 370\n#define NOTE_G4  392\n#define NOTE_GS4 415\n#define NOTE_A4  440\n#define NOTE_AS4 466\n#define NOTE_B4  494\n#define NOTE_C5  523\n#define NOTE_CS5 554\n#define NOTE_D5  587\n#define NOTE_DS5 622\n#define NOTE_E5  659\n#define NOTE_F5  698\n#define NOTE_FS5 740\n#define NOTE_G5  784\n#define NOTE_GS5 831\n#define NOTE_A5  880\n#define NOTE_AS5 932\n#define NOTE_B5  988\n#define NOTE_C6  1047\n#define NOTE_CS6 1109\n#define NOTE_D6  1175\n#define NOTE_DS6 1245\n#define NOTE_E6  1319\n#define NOTE_F6  1397\n#define NOTE_FS6 1480\n#define NOTE_G6  1568\n#define NOTE_GS6 1661\n#define NOTE_A6  1760\n#define NOTE_AS6 1865\n#define NOTE_B6  1976\n#define NOTE_C7  2093\n#define NOTE_CS7 2217\n#define NOTE_D7  2349\n#define NOTE_DS7 2489\n#define NOTE_E7  2637\n#define NOTE_F7  2794\n#define NOTE_FS7 2960\n#define NOTE_G7  3136\n#define NOTE_GS7 3322\n#define NOTE_A7  3520\n#define NOTE_AS7 3729\n#define NOTE_B7  3951\n#define NOTE_C8  4186\n#define NOTE_CS8 4435\n#define NOTE_D8  4699\n#define NOTE_DS8 4978\n\n\nTask 2: Ultrasonic Air Harp\nStep 1: Declare the library file, define different notes and buzzer pins. The main notes we use are “Do Re Mi Fa Sol La Xi Do”, corresponding to “C5 D5 E5 F5 G5 A5 B5 C6”. You can only define the notes you need to avoid the program looking too lengthy.\n#include \"Ultrasonic.h\"//declare the library file\nUltrasonic ultrasonic(0);//define the ultrasonic object and connect the ultrasonic wave to the A0 interface. If you're using XIAO RP2040, please change 0 to D0\nint buzzerPin = 3;//The buzzer is connected to the A3 interface, if you're using XIAO RP2040, please change 3 to A3\n\n#define NOTE_C5  523\n#define NOTE_CS5 554\n#define NOTE_D5  587\n#define NOTE_DS5 622\n#define NOTE_E5  659\n#define NOTE_F5  698\n#define NOTE_FS5 740\n#define NOTE_G5  784\n#define NOTE_GS5 831\n#define NOTE_A5  880\n#define NOTE_AS5 932\n#define NOTE_B5  988\n#define NOTE_C6  1047\nStep 2: Initialize the baud rate and set the buzzer pin status.\nvoid setup()\n{\n    Serial.begin(9600);\n    pinMode(buzzerPin,OUTPUT);\n}\nStep 3: Read the distance (cm) measured by the ultrasonic distance sensor and make a condition judgment to set different distances to emit different notes. Since the setting of the air harp is that different distances trigger different notes, and this distance is a long integer value, so we need to use the long() function to define the value returned by the ultrasonic wave. For example, (long)RangeInCentimeters== 4, that is, the distance value returned by the ultrasonic wave is 4. Corresponding to the buzzer emitting different notes, use the tone() function, for example, tone(3,NOTE_C5,100), that is, the buzzer on pin 3, emits NOTE_C5 (Do) note, lasts for 100 milliseconds.\nvoid loop()\n{\n    // Read the distance value detected by the ultrasonic distance sensor, in centimeters, and print it on the serial monitor\n    long RangeInCentimeters;\n    RangeInCentimeters = ultrasonic.MeasureInCentimeters(); \n    Serial.print(RangeInCentimeters);\n    Serial.println(\" cm\");\n    delay(250);\n    // Using an if statement for conditional judgment, when the distance is 4, 6, 8, 10, 12, 14, 16, 18, it corresponds to C5, D5, E5, F5, G5, A5, B5, C6\n    if (((long)RangeInCentimeters== 4)) {  //Do\n        tone(3,NOTE_C5,100);   \n    }\n    if (((long) RangeInCentimeters== 6)) { //Re\n        tone(3,NOTE_D5,100);    \n    }\n    if (((long) RangeInCentimeters== 8)) { //Mi\n        tone(3,NOTE_E5,100);  \n    }\n    if (((long) RangeInCentimeters== 10)) {  //Fa\n        tone(3,NOTE_F5,100);\n    }\n    if (((long) RangeInCentimeters== 12)) {  //Sol\n        tone(3,NOTE_G5,100);\n    }\n    if (((long) RangeInCentimeters== 14)) {  //La\n        tone(3,NOTE_A5,100);\n    }\n    if (((long) RangeInCentimeters== 16)) { //Xi\n        tone(3,NOTE_B5,100);\n    }\n    if (((long) RangeInCentimeters== 18)) {  //Do\n        tone(3,NOTE_C6,100);\n    }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L13_UltrasonicPiano_XIAO_en\n\nStep 4: Connect the hardware and upload the program. Connect the ultrasonic distance sensor to the A0 interface of the XIAO expansion board as shown below: \nUse the data cable to connect XIAO to the computer, click the “Upload” button, upload the program to the hardware, when the debugging area shows “Upload Successful”, open the serial monitor, and start playing with your palm. ## 3.3.4 Exterior Design The inspiration for the air harp comes from the piano, with a note every 2 cm also designed according to the style of the piano keys. In the process of creating the appearance, we can cut a harp surface from a basswood board, and fix the ultrasonic range sensor at the left end of the harp. We also provide laser cutting files for reference, which can be easily assembled, as shown in the picture:  Download the files suitable for the laser cutting machine 🔗 https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/dxf/XIAO_Air_Piano.dxf."
  },
  {
    "objectID": "chapter_3-4.html#task-2-ping-a-specified-website",
    "href": "chapter_3-4.html#task-2-ping-a-specified-website",
    "title": "3.4 Implementing Wi-Fi Connection and Applications with XIAO ESP32C3",
    "section": "3.4.3 Task 2: Ping a Specified Website",
    "text": "3.4.3 Task 2: Ping a Specified Website\nWith the knowledge above, we can now learn how to use the XIAO ESP32C3 to ping a specified website. Step 1. Download and install the ESP32Ping library. Enter the URL 🔗 https://github.com/marian-craciunescu/ESP32Ping to go to the GitHub page, click on Code→Download ZIP to download the resource pack to your local machine, as shown in the figure below.  After downloading, open the Arduino IDE, click on Sketch→Include Library→Add .ZIP Library, and choose the ZIP file you just downloaded.  Step 2. Copy and paste the code below into the Arduino IDE. This code sets the test website to www.seeedstudio.com. Remember to replace your-ssid in the code with your Wi-Fi network name and your-password in the code with your Wi-Fi password.\n////////////////////////////////////////////////////////////////////////////////\n// IDE:\n//   Arduino 2.0.3\n// Platform:\n//   esp32 2.0.4 - https://github.com/espressif/arduino-esp32\n// Board:\n//   XIAO_ESP32C3\n// Libraries:\n//   ESP32Ping 1.6 - https://github.com/marian-craciunescu/ESP32Ping\n\n////////////////////////////////////////////////////////////////////////////////\n// Includes\n\n#include &lt;WiFi.h&gt;\n#include &lt;ESP32Ping.h&gt;\n\nstatic constexpr unsigned long INTERVAL = 3000; // [msec.]\n\nstatic const char WIFI_SSID[] = \"your-ssid\";\nstatic const char WIFI_PASSPHRASE[] = \"your-password\";\n\nstatic const char SERVER[] = \"www.google.com\";\n\nvoid setup()\n{\n    Serial.begin(115200);\n    delay(1000);\n    Serial.println();\n    Serial.println();\n\n    Serial.println(\"WIFI: Start.\");\n    WiFi.mode(WIFI_STA);\n    if (WIFI_SSID[0] != '\\0')\n    {\n        WiFi.begin(WIFI_SSID, WIFI_PASSPHRASE);\n    }\n    else\n    {\n        WiFi.begin();\n    }\n}\n\nvoid loop()\n{\n    static int count = 0;\n\n    const bool wifiStatus = WiFi.status() == WL_CONNECTED;\n    const int wifiRssi = WiFi.RSSI();\n\n    const bool pingResult = !wifiStatus ? false : Ping.ping(SERVER, 1);\n    const float pingTime = !pingResult ? 0.f : Ping.averageTime();\n\n    Serial.print(count);\n    Serial.print('\\t');\n    Serial.print(wifiStatus ? 1 : 0);\n    Serial.print('\\t');\n    Serial.print(wifiRssi);\n    Serial.print('\\t');\n    Serial.print(pingResult ? 1 : 0);\n    Serial.print('\\t');\n    Serial.println(pingTime);\n    count++;\n\n    delay(INTERVAL);\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_Ping_XIAO_en\n\nStep 3. Upload the code and open the serial monitor to check the ping results, as shown in the figure below.  ## 3.4.4 Project Creation: Using XIAO ESP32C3 to Make HTTP GET and HTTP POST Requests ### 3.4.4.1 Introduction to HTTP Protocol HTTP stands for HyperText Transfer Protocol. It’s an application-layer protocol for distributed, collaborative, and hypermedia information systems. HTTP is the most widely used network transmission protocol on the Internet, and all WWW files must comply with this standard. HTTP is designed for communication between Web browsers and Web servers, but it can also be used for other purposes. HTTP is a protocol that uses TCP/IP to transmit data (such as HTML files, image files, query results, etc.). Despite its wide use, HTTP has significant security flaws, mainly its plain text data transmission and lack of message integrity checks. These are exactly the two most critical security aspects in emerging applications like online payment, online trading, Internet of Things, etc. Browsers like Google Chrome, Internet Explorer, and Firefox issue warnings about insecure connections when visiting websites with mixed content composed of encrypted and unencrypted content using HTTP. ### 3.4.4.2 Introduction to HTTPS Protocol HTTPS stands for HyperText Transfer Protocol Secure. It’s a protocol for secure communication over a computer network. HTTPS communicates via HTTP but uses SSL/TLS to encrypt packets. The main purpose of HTTPS is to authenticate the website server’s identity and protect the privacy and integrity of the exchanged data.\n ### 3.4.4.3 HTTP Request Methods According to the HTTP standard, HTTP requests can use multiple request methods. HTTP1.0 defined three request methods: GET, POST, and HEAD. HTTP1.1 added six new request methods: OPTIONS, PUT, PATCH, DELETE, TRACE, and CONNECT.\n\n\n\n\n\n\n\n\nNo.\nMethod\nDescription\n\n\n\n\n1\nGET\nRequests specified page information and returns the entity body.\n\n\n2\nHEAD\nSimilar to a GET request, but the response returned doesn’t contain specific content, used to obtain headers.\n\n\n3\nPOST\nSubmits data for processing to a specified resource (e.g., submits a form or uploads a file). The data is included in the request body. POST requests may result in the creation of a new resource and/or the modification of an existing resource.\n\n\n4\nPUT\nThe data sent from the client to the server replaces the content of a specified document.\n\n\n5\nDELETE\nRequests the server to delete a specified page.\n\n\n6\nCONNECT\nReserved in HTTP/1.1 for proxy servers that can switch the connection to a pipe mode.\n\n\n7\nOPTIONS\nAllows the client to view the server’s capabilities.\n\n\n8\nTRACE\nEchoes the request received by the server, mainly used for testing or diagnosis.\n\n\n9\nPATCH\nIt’s a supplement to the PUT method, used to partially update a known resource.\n\n\n\nWe’ve already learned how to connect to a Wi-Fi network using XIAO ESP32C3. Now, let’s try some more complex operations based on the network. The following sections will introduce how to use XIAO ESP32C3 to send HTTP GET and HTTP POST requests. ### 3.4.4.4 Task 3: Using XIAO ESP32C3 to Send an HTTP GET Request To send an HTTP GET request, a corresponding backend server that supports the request is required. For convenient testing, we can set up a backend server on our own PC, allowing XIAO ESP32C3 to send an HTTP GET request to the PC through the local Wi-Fi connection. There are many ways to set up a backend service. In this case, we’ll use the popular Python web framework — FastAPI to set up the backend server. To learn more about this tool, visit its official documentation. #### Setting Up a Backend Server with FastAPI Here is the Python server code.\nfrom typing import Union\nfrom pydantic import BaseModel\nfrom fastapi import FastAPI\nimport datetime\n\napp = FastAPI()\nitems = {}\n\nclass Sensor_Item(BaseModel):\n    name: str\n    value: float\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    items[\"sensor\"] = {\"name\": \"Sensor\",\"Value\":0}\n\n@app.get(\"/items/{item_id}\")\nasync def read_items(item_id: str):\n\n    return items[item_id],datetime.datetime.now()\n\n@app.post(\"/sensor/\")\nasync def update_sensor(si: Sensor_Item):\n    items[\"sensor\"][\"Value\"] = si.value\n    return si\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\nThis code snippet, implemented using the Python FastAPI framework, can return the latest information of the Sensor stored on the backend server when we use a get request on http://domain/items/sensor. When we use post to send data to http://domain/sensor/, it can modify and record the latest Sensor value. The operation steps are as follows: Step 1. Create a python file named main.py locally, copy and paste the code above into main.py. Then, on your PC, open the terminal and execute the following commands to install FastAPI.\npip install fastapi\npip install \"uvicorn[standard]\"\nStep 2. Execute the following command to start the backend service and local monitoring.\nuvicorn main:app --reload --host 0.0.0.0\n\n⚠️ Note: When running the command above, make sure the terminal is currently in the directory where main:app resides. If there is a prompt during running:\n\nERROR:    [Errno 48] Address already in use\n\nThis means the current address is already occupied and there is an address conflict. You can specify a specific port as shown in the command below.\n\nuvicorn main:app --reload --host 0.0.0.0 --port 1234\n\nIf the [Errno 48] error still appears, you can modify the port number after port.\n\nThe prompt information after the command is successfully run is as follows\nINFO:     Will watch for changes in these directories: ['']\nINFO:     Uvicorn running on http://0.0.0.0:1234 (Press CTRL+C to quit)\nINFO:     Started reloader process [53850] using WatchFiles\nINFO:     Started server process [53852]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nThe backend server for testing is now running normally. #### Using XIAO ESP32C3 to Send an HTTP GET Request Next, we’ll perform a request test on XIAO ESP32C3. The GET method should only be used for reading data, and should not be used in operations that generate “side effects”. GET requests directly issued by browsers can only be triggered by a URL. If you want to carry some parameters outside of the URL in GET, you can only rely on the querystring (query string) attached to the URL.\nStep 1: Copy and paste the following code into the Arduino IDE. This code sets the tested serverName to http://192.168.1.2/items/sensor. The 192.168.1.2 needs to be replaced with the IP address of your PC acting as the backend server. To get the IP address of your PC, Windows users can enter the ipconfig command in the command line window, and Mac users can enter the ifconfig command in the terminal window. Remember to change your-ssid in the code to your Wi-Fi network name and your-password to the corresponding Wi-Fi password.\n#include \"WiFi.h\"\n#include &lt;HTTPClient.h&gt;\n\nconst char* ssid = \"your-ssid\";\nconst char* password = \"your-password\";\nString serverName = \"http://192.168.1.2/items/sensor\";\nunsigned long lastTime = 0;\nunsigned long timerDelay = 5000;\n\nvoid setup()\n{\n    Serial.begin(115200); \n\n    WiFi.begin(ssid, password);\n    Serial.println(\"Connecting\");\n    while(WiFi.status() != WL_CONNECTED) {\n        delay(500);\n        Serial.print(\".\");\n    }\n    Serial.println(\"\");\n    Serial.print(\"Connected to WiFi network with IP Address: \");\n    Serial.println(WiFi.localIP());\n\n    Serial.println(\"Timer set to 5 seconds (timerDelay variable), it will take 5 seconds before publishing the first reading.\");\n\n    Serial.println(\"Setup done\");\n}\n\nvoid loop()\n{\n    if ((millis() - lastTime) &gt; timerDelay) {\n        //Check WiFi connection status\n        if(WiFi.status()== WL_CONNECTED){\n            HTTPClient http;\n\n            String serverPath = serverName ;\n\n            http.begin(serverPath.c_str());\n\n            int httpResponseCode = http.GET();\n\n            if (httpResponseCode&gt;0) {\n                Serial.print(\"HTTP Response code: \");\n                Serial.println(httpResponseCode);\n                String payload = http.getString();\n                Serial.println(payload);\n            }\n            else {\n                Serial.print(\"Error code: \");\n                Serial.println(httpResponseCode);\n            }\n\n            http.end();\n        }\n        else {\n            Serial.println(\"WiFi Disconnected\");\n        }\n        lastTime = millis();\n    }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_HTTPget_XIAO_en\n\n\n⚠️ Note: We need to change the serverName in the Arduino code to the IP address of the host running the backend service. The XIAO ESP32C3 needs to be on the same local area network as it. If the local area network IP of the backend server (in this example, your PC) is 192.168.1.2, then the GET request interface is http://192.168.1.2/items/sensor, and other interfaces are similar. If you specified a port when running the backend service and local monitoring, the GET request interface would be http://192.168.1.2:1234/items/sensor.\n\nStep 2: Upload the code to XIAO ESP32C3 in the Arduino IDE. After the upload is successful, open the serial monitor to check the result returned by our backend server after the GET is issued, as shown in the figure below.  The prompt HTTP Response code: 200 means the request has been successful, and our XIAO ESP32C3 has successfully gotten data from the server. ### 3.4.4.5 Task 4: Using XIAO ESP32C3 to Send an HTTP POST Request Submit data to a specified resource and request the server to process it (for example, submit a form or upload a file). The data is included in the request body. This request may create new resources or modify existing resources, or both. Each time it is submitted, the form data is encoded into the body of the HTTP request by the browser. The body of a POST request issued by a browser mainly has two formats, one is application/x-www-form-urlencoded used to transmit simple data, roughly in the format of key1=value1&key2=value2. The other is for transmitting files and will use the multipart/form-data format. The latter is adopted because the encoding method of application/x-www-form-urlencoded is very inefficient for binary data like files. Next, we will submit experimental data to the backend server built on our machine in a manner similar to submitting a form, and verify whether the backend server has received the data. Step 1: Before starting this example, make sure that the backend server built with FastAPI in the previous step is running normally. If not, please refer to the above instructions to start the server program. Step 2: Copy and paste the following code into the Arduino IDE. This code sets the tested serverName to http://192.168.1.2/sensor/. The 192.168.1.2 needs to be replaced with the IP address of your PC acting as the backend server. Remember to change your-ssid in the code to your Wi-Fi network name and your-password to the corresponding Wi-Fi password.\n#include &lt;WiFi.h&gt;\n#include &lt;HTTPClient.h&gt;\n\nconst char* ssid = \"your-ssid\";\nconst char* password = \"your-password\";\n\nconst char* serverName = \"https://192.168.1.2/sensor/\";\n\nunsigned long lastTime = 0;\nunsigned long timerDelay = 5000;\n\nvoid setup() {\n  Serial.begin(115200);\n\n  WiFi.begin(ssid, password);\n  Serial.println(\"Connecting\");\n  while(WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n  Serial.println(\"\");\n  Serial.print(\"Connected to WiFi network with IP Address: \");\n  Serial.println(WiFi.localIP());\n \n  Serial.println(\"Timer set to 5 seconds (timerDelay variable), it will take 5 seconds before publishing the first reading.\");\n}\n\nvoid loop() {\n  //Send an HTTP POST request every 10 minutes\n  if ((millis() - lastTime) &gt; timerDelay) {\n    //Check WiFi connection status\n    if(WiFi.status()== WL_CONNECTED){\n      WiFiClient client;\n      HTTPClient http;\n    \n\n      http.begin(client, serverName);\n\n      http.addHeader(\"Content-Type\", \"application/json\");\n      int httpResponseCode = http.POST(\"{\\\"name\\\":\\\"sensor\\\",\\\"value\\\":\\\"123\\\"}\");\n     \n      Serial.print(\"HTTP Response code: \");\n      Serial.println(httpResponseCode);\n        \n      // Free resources\n      http.end();\n    }\n    else {\n      Serial.println(\"WiFi Disconnected\");\n    }\n    lastTime = millis();\n  }\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L14_HTTPpost_XIAO_en\n\nStep 2: Upload the code to XIAO ESP32C3 using the Arduino IDE. After a successful upload, open the Serial Monitor to examine the result returned by our backend server in response to the GET request. The image below illustrates the process.  The message **HTTP Response code: 200** signifies a successful request. On your local PC, open a browser and navigate to **http://192.168.1.2/items/sensor** (please replace the IP address according to your actual PC’s IP address, and if a port has been set, append a colon followed by the designated port number after the IP address). You should now see the most recent data sent by the XIAO ESP32C3. Since XIAO sends data every 5 seconds, you can always view the most recent data received by the backend server by refreshing the current page (the timestamp of the data will change).  We have now successfully sent data from XIAO ESP32C3 to the local backend server."
  },
  {
    "objectID": "chapter_3-5.html#deep-dive-into-mqtt",
    "href": "chapter_3-5.html#deep-dive-into-mqtt",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.3 Deep Dive into MQTT",
    "text": "3.5.3 Deep Dive into MQTT\nTopics can have a hierarchy, and clients can use wildcards to subscribe to different levels of different hierarchies. For example: you can send temperature telemetry to the /telemetry/temperature topic, humidity data to the /telemetry/humidity topic, and then subscribe to the /telemetry/* topic in your cloud application to receive both temperature and humidity telemetry. When messages are sent, a Quality of Service (QoS) can be specified which determines the guarantee of message delivery.\n\nAt most once: The message is sent only once, and no additional steps are taken by the client and the broker to confirm delivery (Fire and Forget).\nAt least once: The message is retried by the sender until it receives an acknowledgment (Acknowledged delivery).\nExactly once: A two-level handshake is performed by the sender and receiver to ensure that only one copy of the message is received (Assured delivery). &gt; ✅ In what scenarios might you need to deliver messages on a Fire and Forget basis?\n\nAlthough MQTT (Message Queuing Telemetry Transport) has “Message Queuing” in its name (the first two letters of MQTT), it does not actually support message queues. This means that if a client disconnects and then reconnects, it will not receive messages that were sent while it was disconnected, except for those messages that it had already begun processing using the QoS process. A retain flag can be set on a message. If this flag is set, the MQTT broker will store the last message sent on a topic with this flag, and will send it to any clients who subsequently subscribe to that topic. This way, clients always receive the latest message. MQTT also supports a keep-alive feature to check if the connection is still online during long intervals between messages. MQTT connections can be public, or encrypted and protected using usernames, passwords, or certificates. &gt; 💁 MQTT communicates over TCP/IP, the same underlying network protocol as HTTP, but on a different port. You can also communicate with web applications running in a browser over MQTT on websockets, or in situations where firewalls or other network rules block standard MQTT connections."
  },
  {
    "objectID": "chapter_3-5.html#telemetry",
    "href": "chapter_3-5.html#telemetry",
    "title": "3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3",
    "section": "3.5.4 Telemetry",
    "text": "3.5.4 Telemetry\nThe word “telemetry” comes from Greek roots meaning “remote measurement”. Telemetry refers to the act of collecting data from sensors and sending it to the cloud. &gt; 💁 One of the earliest telemetry devices was invented in France in 1874, sending real-time weather and snow depth data from Mont Blanc to Paris. As there was no wireless technology at the time, it used a physical wire.\nLet’s go back to the smart thermostat example from Section 1.1.  The thermostat has temperature sensors to collect telemetry data. It likely has a built-in temperature sensor and may connect to multiple external temperature sensors via wireless protocols such as Low Energy Bluetooth (BLE). An example of the telemetry data it sends could be:\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nAC_Temperature\n18°C\nThe temperature measured by the thermostat’s built-in temperature sensor\n\n\nLiving_Room_Temperature\n19°C\nThe temperature measured by a remote temperature sensor named livingroom\n\n\n, indicating the room it is in\n\n\n\n\nBedroom_Temperature\n21°C\nThe temperature measured by a remote temperature sensor named bedroom\n\n\n, indicating the room it is in\n\n\n\n\n\nThen, the cloud service can use this telemetry data to decide what commands to send to control cooling or heating. ## 3.5.5 Task 2: Sending Telemetry Information from XIAO to MQTT Broker The next part of adding internet control to your smart hygrothermograph is sending the temperature and humidity telemetry data to the telemetry topic of the MQTT broker. Replace the XIAO of your smart hygrothermograph device from Section 2.2 with the XIAO ESP32C3, as shown in the image below.\n\nLoad the following program into the Arduino IDE to test sending telemetry data from your device to the MQTT broker. Note that in this example, we’re trying a different MQTT broker than in Task 1: broker.hivemq.com, and we’ve set XIAO_ESP32C3_Telemetry/ as the subscription name.\n////////////////////////////////////////////////////////////////////////////////\n// IDE:\n//   Arduino 2.0.0\n// Platform:\n//   esp32 2.0.5 - https://github.com/espressif/arduino-esp32\n// Board:\n//   XIAO_ESP32C3\n// Libraries:\n//   MQTT 2.5.0 - https://github.com/knolleary/pubsubclient\n//   ArduinoJson 6.19.4 - https://github.com/bblanchon/ArduinoJson\n\n////////////////////////////////////////////////////////////////////////////////\n// Includes\n\n#include &lt;WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include &lt;Wire.h&gt;\n#include \"DHT.h\"\n#define DHTTYPE DHT20   \nDHT dht(DHTTYPE); \n\nconst char* ssid = \"ssid\";\nconst char* password = \"pass\";\n\nconst char* mqtt_server = \"broker.hivemq.com\";\n\nWiFiClient espClient;\nPubSubClient client(espClient);\nlong lastMsg = 0;\nchar msg[50];\nint value = 0;\n\nfloat temperature = 0;\nfloat humidity = 0;\n\nvoid setup() {\n  Serial.begin(115200);\n  setup_wifi();\n  client.setServer(mqtt_server, 1883);\n  Wire.begin();\n  dht.begin();\n}\n\nvoid setup_wifi() {\n  delay(10);\n  // We start by connecting to a WiFi network\n  Serial.println();\n  Serial.print(\"Connecting to \");\n  Serial.println(ssid);\n\n  WiFi.begin(ssid, password);\n\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n  Serial.println(\"\");\n  Serial.println(\"WiFi connected\");\n  Serial.println(\"IP address: \");\n  Serial.println(WiFi.localIP());\n}\n\nvoid reconnect() {\n  // Loop until we're reconnected\n  while (!client.connected()) {\n    Serial.print(\"Attempting MQTT connection...\");\n    // Attempt to connect\n    if (client.connect(\"XIAO_ESP32\")) {\n      Serial.println(\"connected\");\n      // Subscribe\n      client.subscribe(\"XIAO_ESP32/LEDOUTPUT\");\n    } else {\n      Serial.print(\"failed, rc=\");\n      Serial.print(client.state());\n      Serial.println(\" try again in 5 seconds\");\n      // Wait 5 seconds before retrying\n      delay(5000);\n    }\n  }\n}\n\nvoid loop() {\n    \n  if (!client.connected()) {\n    reconnect();\n  }\n  client.loop();\n\n  long now = millis();\n  float temp_hum_val[2] = {0};\n  if (now - lastMsg &gt; 5000) {\n    lastMsg = now;\n\n    dht.readTempAndHumidity(temp_hum_val);\n    temperature = temp_hum_val[1];   \n  \n    char tempString[8];\n    dtostrf(temperature, 1, 2, tempString);\n    Serial.print(\"Temperature: \");\n    Serial.println(tempString);\n    client.publish(\"XIAO_ESP32C3_Telemetry/Temperaturedataread\", tempString);\n\n    humidity = temp_hum_val[0];\n    \n    char humString[8];\n    dtostrf(humidity, 1, 2, humString);\n    Serial.print(\"Humidity: \");\n    Serial.println(humString);\n    client.publish(\"XIAO_ESP32_Telemetry/Humiditydataread\", humString);\n  }\n\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L15_MQTTTelemetry_XIAO_en\n\nBecause this example relies on the PubSubClient.h library, if you try to compile it directly, you will encounter the error “PubSubClient.h: No such file or directory”. To resolve this issue, follow the steps below to install the library.\n\nOpen the Arduino IDE.\nGo to “Sketch” -&gt; “Include Library” -&gt; “Manage Libraries”.\nIn the Library Manager, type “PubSubClient” in the search bar.\nLook for the “PubSubClient” library by Nick O’Leary and click on it.\nClick the “Install” button to install the library.\n\nThen modify the ssid in the code to your Wi-Fi network name and pass to your Wi-Fi password corresponding to your Wi-Fi network name. After successfully uploading the program, open the serial monitor. If all goes well, you will see the device start sending temperature and humidity data, as shown in the image below. \nHow can you see the sensor data from another platform? There are many ways, such as MQTT X. After downloading and installing the software suitable for your PC system, the interface is as shown in the image below. \nClicking the + New Connection button will bring you to the connection creation window, as shown in the image below. Fill in XIAO-DHT20 in the Name box as the connection name. The Host is broker.hivemq.com that we set in the program, no other settings are needed, click Connect in the upper right corner. \nCreate a new subscription, showing all the information under XIAO_ESP32C3_Telemetry/, as shown in the image below. \nNow, we can see the telemetry data sent from XIAO ESP32C3, as shown in the image below.  ### How often should telemetry be sent? One question that needs careful consideration with telemetry is: how often should you measure and send data? The answer is — it depends on the needs of the device being monitored and the task at hand. If you measure frequently, you can indeed respond to changes in the measurements more quickly, but this would cause your device to consume more power, more bandwidth, generate more data, and require more cloud resources to handle. You need to strike a balance between measuring often enough but not too often. For a thermostat, measuring every few minutes might be enough because the temperature isn’t likely to change frequently. If you only measure once a day, then you might be heating your house for nighttime temperatures on a sunny day, and if you measure every second, you’d have thousands of unnecessary repeated temperature measurements which will eat up users’ internet speed and bandwidth (which is a problem for people with limited bandwidth plans), and also consume more power, which is a problem for devices like remote sensors that rely on battery power, and further increase the cost of cloud computing resources to process and store them. If you’re monitoring data around a machine in a factory that might cause catastrophic damage and millions in lost revenue if it fails, then measuring multiple times a second may be necessary. Wasting bandwidth is better than missing telemetry data that could signal the need to stop and repair before a machine fails. &gt; 💁 In this situation, you could consider first using an edge device to handle the telemetry data to reduce dependence on the internet.\n\nLosing connection\nInternet connections can be unreliable, and it’s common to lose signal. In this case, what should an IoT device do? Should it lose data, or should it store data until the connection is restored? Again, the answer is — it depends on the device being monitored. For a thermostat, data is likely lost once a new temperature measurement has been made. If the current temperature is 19°C, the heating system doesn’t care that the temperature 20 minutes ago was 20.5°C; it’s the current temperature that dictates whether the heat should be turned on or off. For some machines, you may want to retain this data, especially if it’s being used to look for trends. Some machine learning models can identify anomalies in data streams by looking at a defined time period (e.g., the last hour). This is often used for predictive maintenance, looking for signs that something might be about to fail so you can repair or replace it before disaster strikes. You may want every point of telemetry from a machine sent so it can be used for anomaly detection, so once an IoT device can reconnect, it will send all the telemetry data generated during the internet outage. IoT device designers should also consider whether an IoT device can operate during an internet outage or if it loses signal due to location. If a smart thermostat is unable to send telemetry data to the cloud due to an internet outage, it should be able to make some limited decisions to control heating.\n\n This Ferrari became a brick when someone tried to update it in an underground car park… but there was no cell signal there.\n\nFor MQTT handling connection interruptions, if necessary, the device and server code will need to be responsible for ensuring message delivery, for example, requiring all sent messages to be replied to by an additional message on the reply topic, and if not, to manually queue them for later resending. ## 3.5.6 Commands Commands are messages sent by the cloud to a device instructing it to do something. Most often, this involves providing some output via an actuator, but it could be an instruction to the device itself, such as to reboot, or to collect additional telemetry data and send it as a response to the command.  A thermostat could receive a command from the cloud to turn on the heat. Based on the telemetry data from all sensors, if the cloud service has decided that the heat should be turned on, then it sends the appropriate command. ## 3.5.7 Task 3: Send Commands to XIAO via MQTT Broker Having mastered telemetry, the next step is to send commands to IoT devices via an MQTT broker. In this task, we will try to use a computer with MQTT broker, often called a host computer, to send specific characters and let the Wi-Fi connected XIAO ESP32C3 control a buzzer attached to an expansion board to emit a warning sound. In the Arduino IDE, load the following program to test sending specific characters (first character is ‘0’) from the MQTT broker to activate the buzzer. We use the MQTT broker: broker.hivemq.com in this example.\n////////////////////////////////////////////////////////////////////////////////\n// IDE:\n//   Arduino 2.0.0\n// Platform:\n//   esp32 2.0.5 - https://github.com/espressif/arduino-esp32\n// Board:\n//   XIAO_ESP32C3\n// Libraries:\n//   MQTT 2.5.0 - https://github.com/knolleary/pubsubclient\n//   ArduinoJson 6.19.4 - https://github.com/bblanchon/ArduinoJson\n//  https://github.com/Seeed-Studio/Seeed_Arduino_MultiGas\n\n\n////////////////////////////////////////////////////////////////////////////////\n// Includes\n\n\n#include &lt;WiFi.h&gt;\n#include &lt;PubSubClient.h&gt;\n#include &lt;Wire.h&gt;\n\n\nconst char* ssid = \"ssid\";\nconst char* password = \"pass\";\n\n\nconst char* mqtt_server = \"broker.hivemq.com\";\n\n\nWiFiClient espClient;\nPubSubClient client(espClient);\nlong lastMsg = 0;\nchar msg[50];\nint value = 0;\n\n\nint speakerPin = A3;\n\n\nvoid setup_wifi() {\n  delay(10);\n  // We start by connecting to a WiFi network\n  Serial.println();\n  Serial.print(\"Connecting to \");\n  Serial.println(ssid);\n\n\n  WiFi.begin(ssid, password);\n\n\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.print(\".\");\n  }\n\n\n  Serial.println(\"\");\n  Serial.println(\"WiFi connected\");\n  Serial.println(\"IP address: \");\n  Serial.println(WiFi.localIP());\n}\n\n\nvoid callback(char* topic, byte* payload, unsigned int length) {\n  Serial.print(\"Message arrived [\");\n  Serial.print(topic);\n  Serial.print(\"] \");\n  for (int i=0;i&lt;length;i++) {\n    Serial.print((char)payload[i]);\n  }\n  if((char)payload[0]=='0'){\n    Serial.print(\"  RUN\");\n    digitalWrite(speakerPin, HIGH);\n    delay(2000);\n    digitalWrite(speakerPin, LOW);\n    delay(100);  \n  }\n  Serial.println();\n}\n\n\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(speakerPin, OUTPUT);\n  setup_wifi();\n  client.setServer(mqtt_server, 1883);\n  client.subscribe(\"XIAO_ESP32/Recieve\");\n  client.setCallback(callback);\n}\n\n\nvoid reconnect() {\n  // Loop until we're reconnected\n  while (!client.connected()) {\n    Serial.print(\"Attempting MQTT connection...\");\n    // Attempt to connect\n    if (client.connect(\"XIAO_ESP32\")) {\n      Serial.println(\"connected\");\n      // Subscribe\n      \n    } else {\n      Serial.print(\"failed, rc=\");\n      Serial.print(client.state());\n      Serial.println(\" try again in 5 seconds\");\n      // Wait 5 seconds before retrying\n      delay(5000);\n    }\n  }\n}\n\n\nvoid loop() {\n    \n  if (!client.connected()) {\n    reconnect();\n    client.subscribe(\"XIAO_ESP32/Recieve\");\n  }\n  client.loop();\n\n\n}\n\nGet this program from Github https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L15_MQTTCommand_XIAO_en\n\nThen modify the ssid in the code to your Wi-Fi network name, and modify the pass in the code to the Wi-Fi password corresponding to your Wi-Fi network name. The logic of the program execution is explained as follows:\nclient.setServer(mqtt_server, 1883);\nclient.subscribe(\"XIAO_ESP32/Recieve\");\nclient.setCallback(callback);\nDuring the setup stage, the connection between XIAO and the MQTT server is initialized, and the topic subscription settings and callback functions are set. Here we subscribe to the topic XIAO_ESP32/Recieve as an example. When we send a message to this topic from the host computer, the corresponding callback function callback will be executed:\nvoid callback(char* topic, byte* payload, unsigned int length) {\n  Serial.print(\"Message arrived [\");\n  Serial.print(topic);\n  Serial.print(\"] \");\n  for (int i=0;i&lt;length;i++) {\n    Serial.print((char)payload[i]);\n  }\n  if((char)payload[0]=='0'){\n    Serial.print(\"  RUN\");\n    digitalWrite(speakerPin, HIGH);\n    delay(2000);\n    digitalWrite(speakerPin, LOW);\n    delay(100);  \n  }\n  Serial.println();\n}\nHere it will first print out the received message, then extract the character at position 0. When the character at position 0, which is the first character, is0, it satisfies the condition for the if statement to perform an action. Here we connect the XIAO ESP32C3 and the expansion board together. When the condition is met, the buzzer on the expansion board will change its level briefly and beep for 2 seconds, while sending the prompt messageRUN to the serial port. In the process of development and testing by readers, you can also try to integrate the receive and send functions of MQTT, and send messages to specific topics in the callback function, so that the sender can ensure that XIAO has received the message. On the host computer, we use MQTT X to test. Open MQTT X, the interface is as shown in the following figure.  Click the + New Connection button to enter the connection creation window, as shown in the following figure. Fill in the Name box with XIAO-MQTT-Recieve as the connection name. Host is the broker.hivemq.com we set in the program, and nothing else needs to be set. Click Connect at the top right corner. The interface after successful connection is as shown in the following figure.  Now we can publish messages to the specified topic, which is the topic XIAO_ESP32/Recieve we subscribed to on XIAO. Then we enter 00 in the input box of XIAO_ESP32/Recieve at the lower right corner of the interface, and then click the send button in the lower right corner.  At this time, in the serial monitor on the PC side, you can see the prompt message received from XIAO, as shown in the following figure, and prompt RUN, the buzzer will sound for 2 seconds, indicating that the message has been received.  Now, we have successfully driven the buzzer on the expansion board connected to the Wi-Fi connected XIAO ESP32C3 through the instruction sent by the PC side. The action of the buzzer can be replaced with the control of any peripheral to achieve the desired function. ### Lost connection If a cloud service needs to send a command to an offline IoT device, what should it do? Again, the answer depends on the situation. If the latest command overwrites the previous one, the previous command may be ignored. If the cloud service sends a command to turn on the heating, and then sends another command to turn off the heating, then the turn-on command can be ignored and does not need to be resent. If the commands need to be processed in order, such as first moving the robot arm up and then closing the gripper, then they need to be sent in order once the connection is restored. &gt; ✅ How can device or server code ensure that commands are always sent and processed in order through MQTT if needed?\n\nUsing XIAO’s Bluetooth function\nXIAO nRF52840, XIAO nRF52840 Sense, XIAO ESP32C3 all support Bluetooth function, you can refer to the related Wiki documents to learn how to use the Bluetooth function. - Bluetooth Usage on Seeed Studio XIAO ESP32C3 - Bluetooth Usage (Seeed nRF52 Boards Library) - Bluetooth Usage (Seeed nrf52 mbed-enabled Boards Library)"
  },
  {
    "objectID": "chapter_4.html",
    "href": "chapter_4.html",
    "title": "Chapter 4: Project Practice Advanced - TinyML Applications",
    "section": "",
    "text": "Among the XIAO series products, the Seeed Studio XIAO nRF52840 Sense has Bluetooth 5.0 wireless connectivity, low power consumption, and onboard 6-axis IMU and PDM microphone sensors. Besides, the XIAO ESP32S3 Sense further integrates PSRAM, a camera, a digital microphone, and SD card support.\n\nThose characteristics make those devices powerful tools for TinyML (Tiny Machine Learning) projects.\n\nTinyML solves problems in a completely different way from traditional programming methods. This chapter will introduce you to this cutting-edge field by walking through the entire TinyML workflow, from data collection, pre-processing, model definition, training, testing, and deployment to allow actual inference on the physical world."
  },
  {
    "objectID": "chapter_4-1.html#introduction-to-edge-impulse-studio",
    "href": "chapter_4-1.html#introduction-to-edge-impulse-studio",
    "title": "4.1 Understanding TinyML and Edge Impulse Studio",
    "section": "4.1.4 Introduction to Edge Impulse Studio",
    "text": "4.1.4 Introduction to Edge Impulse Studio\nEdge Impulse was founded by Zach Shelby and Jan Jongboom in 2019. It is the leading edge device machine learning development platform. This platform allows developers to create and optimize solutions with real-world data, making the process of building, deploying, and scaling embedded ML applications more accessible and faster than ever before.  You can visit Edge Impulse’s official website for more information about this tool and check the official documentation for a basic explanation.\nIn the following sections, we will learn to achieve continuous motion recognition with the on-board 6-axis accelerometer of the XIAO nRF52840 Sense shown below and voice keyword wake-up functionality using the on-board PDM microphone.  Computer Vision applications such as Image Classification and Object Detection will also be implemented using the camera of the XIAO ESP32S3 Sense shown below."
  },
  {
    "objectID": "chapter_4-2.html#things-used-in-this-project",
    "href": "chapter_4-2.html#things-used-in-this-project",
    "title": "4.2 TinyML Made Easy: Anomaly Detection & Motion Classification",
    "section": "4.2.1 Things used in this project",
    "text": "4.2.1 Things used in this project\n\nHardware components\n\nSeeed Studio XIAO nRF52840 Sense × 1\n\n\n\n\nimage.png\n\n\n\n\nSoftware apps and online services\n\nArduino IDE\n\n\n\n\nimage.png\n\n\n\nEdge Impulse Studio\n\n\n\n\nimage.png"
  },
  {
    "objectID": "chapter_4-2.html#introduction",
    "href": "chapter_4-2.html#introduction",
    "title": "4.2 TinyML Made Easy: Anomaly Detection & Motion Classification",
    "section": "4.2.2 Introduction",
    "text": "4.2.2 Introduction\nAs you learned in the previous section, microcontrollers (MCUs) are very cheap electronic components, usually with just a few kilobytes of RAM, designed to use tiny amounts of energy. They can be found in almost any consumer, medical, automotive, and industrial device. Over 40 billion microcontrollers will be sold this year, and there are probably hundreds of billions in service nowadays. However, these devices get little attention because they’re often only used to replace the functionality of older electro-mechanical systems in cars, washing machines, or remote controls. More recently, with the Internet of Things (IoT) era, a significant part of those MCUs is generating “quintillions” of data that, in its majority, is not used due to the high cost and complexity (bandwidth and latency) of data transmission.\nOn the other hand, in recent decades, we have seen a lot of development in Machine Learning models trained with vast amounts of data in very powerful and power-hungry mainframes. And what is happening today is that due to those developments, it is now possible to take noisy signals like images, audio, or accelerometers and extract meaning from them by using Machine Learning algorithms such as Neural Networks.\nAnd what is more important is that we can run these algorithms on microcontrollers and sensors themselves using very little power, interpreting much more of those sensor data that we are currently ignoring. This is TinyML, a new technology that enables machine intelligence right next to the physical world.\n\nTinyML can have many exciting applications for the benefit of society at large.\n\nThis section will explore TinyML, running on a robust and tiny device, the Seed XIAO nRF52840 Sense（also called XIAO BLE Sense）."
  },
  {
    "objectID": "chapter_4-2.html#xiao-nrf52840-sense",
    "href": "chapter_4-2.html#xiao-nrf52840-sense",
    "title": "4.2 TinyML Made Easy: Anomaly Detection & Motion Classification",
    "section": "4.2.3 XIAO nRF52840 Sense",
    "text": "4.2.3 XIAO nRF52840 Sense\n #### MainFeatures\n\nBluetooth 5.0 with onboard antenna\nCPU: Nordic nRF52840, ARM® Cortex®-M4 32-bit processor with FPU, 64 MHz\nUltra-Low Power: Standby power consumption is less than 5μA\nBattery charging chip: Supports lithium battery charge and discharge management\n2 MB flash\n256 KB RAM\nPDM microphone\n6-axis LSM6DS3TR-C IMU\nUltra Small Size: 20 x 17.5mm, XIAO series classic form-factor for wearable devices\nRich interfaces: 1xUART, 1xI2C, 1xSPI, 1xNFC, 1xSWD, 11xGPIO(PWM), 6xADC\nSingle-sided components, surface mounting design ### 4.2.3.1 Connecting the XIAO nRF52840 Sense with Arduino IDE\n\nThe simple way to test and use this device is using the Arduino IDE. Once you have the IDE installed on your machine, navigate to File &gt; Preferences, and fill in “Additional Boards Manager URLs” with the URL below: https://files.seeedstudio.com/arduino/package_seeeduino_boards_index.json\n\n\n\nL17-A1.png\n\n\nNow, navigate to Tools→Board→Board Manager in the top menu, and type in the filter keyword seeed nrf52 in the search box.\nYou will see two installation packages: Seeed nRF52 Boards and Seeed nRF52 mbed-enabled Boards, the differences between these two packages are as follows:\n\nSeeed nRF52 Boards: Friendly for Bluetooth and low-power compatibility, suitable for Bluetooth and low power applications.\nSeeed nRF52 mbed-enabled Boards: Friendly for TinyML support, suitable for making TinyML or Bluetooth-related projects, but not suitable for applications with high low-power requirements.\n\nBecause we will develop a TinyML project, we chose the latest version of the Seeed nRF52 mbed-enabled Boards package. Install it and wait until you see a successful installation prompt in the output window.\n\nNow, you can access this device from your Arduino IDE by selecting the development board and serial port, as shown in the figure below.\n\n\n\nL17-企业微信20230602-092816@2x.png\n\n\nYour development board is now ready to run code on it. Let’s start with Blink - lighting up the LED. Note that the board does not have a regular LED like most Arduino boards. Instead, you will find an RGB LED that can be activated with “reverse logic” (you should apply LOW to activate each of the three separate LEDs). Test your RGB LED with the following code:\nvoid setup() {\n\n  // initialize serial.\n  Serial.begin(115200);\n  while (!Serial);\n  Serial.println(\"Serial Started\");\n  \n  // Pins for the built-in RGB LEDs on the Arduino Nano 33 BLE Sense\n  pinMode(LEDR, OUTPUT);\n  pinMode(LEDG, OUTPUT);\n  pinMode(LEDB, OUTPUT);\n\n  // Note: The RGB LEDs are ON when the pin is LOW and off when HIGH.\n  digitalWrite(LEDR, HIGH);\n  digitalWrite(LEDG, HIGH);\n  digitalWrite(LEDB, HIGH);\n  \n}\n\nvoid loop() {\n  digitalWrite(LEDR, LOW); \n  Serial.println(\"LED RED ON\");\n  delay(1000);              \n  digitalWrite(LEDR, HIGH);    \n  Serial.println(\"LED RED OFF\");\n  delay(1000);     \n\n  digitalWrite(LEDG, LOW); \n  Serial.println(\"LED GREEN ON\"); \n  delay(1000);              \n  digitalWrite(LEDG, HIGH);  \n  Serial.println(\"LED GREEN OFF\");  \n  delay(1000);  \n\n  digitalWrite(LEDB, LOW); \n  Serial.println(\"LED BLUE ON\");  \n  delay(1000);     \n  digitalWrite(LEDB, HIGH);   \n  Serial.println(\"LED BLUE OFF\");   \n  delay(1000);  \n}\n\nGet this code online 🔗 https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/tree/main/Seeed_Xiao_Sense_bilnk_RGB\n\nHere is the result:\n\n\n\nL15-rgbblink.jpg\n\n\n\n4.2.3.2 Testing the Microphone\nThe XIAO nRF52840 Sense has a PDM digital output MEMS microphone. Run the below code for testing it:\n#include &lt;PDM.h&gt;\n\n// buffer to read samples into, each sample is 16-bits\nshort sampleBuffer[256];\n\n// number of samples read\nvolatile int samplesRead;\n\nvoid setup() {\n    Serial.begin(9600);\n    while (!Serial);\n\n    // configure the data receive callback\n    PDM.onReceive(onPDMdata);\n\n    // optionally set the gain, defaults to 20\n    // PDM.setGain(30);\n\n    // initialize PDM with:\n    // - one channel (mono mode)\n    // - a 16 kHz sample rate\n    if (!PDM.begin(1, 16000)) {\n        Serial.println(\"Failed to start PDM!\");\n        while (1);\n    }\n}\n\nvoid loop() {\n    // wait for samples to be read\n    if (samplesRead) {\n\n        // print samples to the serial monitor or plotter\n        for (int i = 0; i &lt; samplesRead; i++) {\n            Serial.println(sampleBuffer[i]);\n            // check if the sound value is higher than 500\n            if (sampleBuffer[i]&gt;=500){\n                digitalWrite(LEDR,LOW);\n                digitalWrite(LEDG,HIGH);\n                digitalWrite(LEDB,HIGH);\n            }\n            // check if the sound value is higher than 250 and lower than 500\n            if (sampleBuffer[i]&gt;=250 && sampleBuffer[i] &lt; 500){\n                digitalWrite(LEDB,LOW);\n                digitalWrite(LEDR,HIGH);\n                digitalWrite(LEDG,HIGH);\n            }\n            //check if the sound value is higher than 0 and lower than 250\n            if (sampleBuffer[i]&gt;=0 && sampleBuffer[i] &lt; 250){\n                digitalWrite(LEDG,LOW);\n                digitalWrite(LEDR,HIGH);\n                digitalWrite(LEDB,HIGH);\n            }\n        }\n\n        // clear the read count\n        samplesRead = 0;\n    }\n}\n\nvoid onPDMdata() {\n    // query the number of bytes available\n    int bytesAvailable = PDM.available();\n\n    // read into the sample buffer\n    PDM.read(sampleBuffer, bytesAvailable);\n\n    // 16-bit, 2 bytes per sample\n    samplesRead = bytesAvailable / 2;\n}\nThe above code will continuously capture data to its buffer, displaying it in the Serial Monitor and Plotter:\n\n\n\nL17-A2.png\n\n\nAlso, note that the RGB LED will be set up depending on the intensity of sound.\n\nThe Micrphone will not be used on this project in particular, but it is good to have it tested if it is your first time using the XIAO nRF52840 Sense.\n\n\n\n4.2.3.3 Testing the IMU\nOur tiny device also has integrated a 6-Axis IMU, the LSM6DS3TR-C, a system-in-package 3D digital accelerometer, and a 3D digital gyroscope. For testing, you should first install its library ‘Seeed Arduino LSM6DS3’.\nBefore programming the accelerometer with the Arduino IDE, you must add the necessary library for the sensor. Enter the library address 🔗 https://github.com/Seeed-Studio/Seeed_Arduino_LSM6DS3/ in the browser address bar, go to the GitHub page, click Code→Download ZIP to download the resource pack Seeed_Arduino_LSM6DS3-master.zip to the local area, as shown below.\n\n\n\nimage.png\n\n\nAdd the resource pack Seeed_Arduino_LSM6DS3-master.zip downloaded in the previous step in the menu bar’s Sketch→Include Library→Add .ZIP Library until you see a prompt that the library has been loaded successfully.\n\nRun the test code based on Harvard University’s tinymlx - Sensor Test\nNow, run the following test code based on Harvard University’s tinymlx - Sensor Test.\n#include \"LSM6DS3.h\"\n#include \"Wire.h\"\n\n//Create an instance of class LSM6DS3\nLSM6DS3 xIMU(I2C_MODE, 0x6A);    //I2C device address 0x6A\n\nchar c;\nint sign = 0;\n\nvoid setup() {\n  Serial.begin(115200);\n  while (!Serial);\n\n  // configure the IMU\n  if (xIMU.begin() != 0) {\n      Serial.println(\"Device error\");\n  } else {\n      Serial.println(\"Device OK!\");\n  }\n\n  Serial.println(\"Welcome to the IMU test for the built-in IMU on the XIAO BLE Sense\\n\");\n  Serial.println(\"Available commands:\");\n  Serial.println(\"a - display accelerometer readings in g's in x, y, and z directions\");\n  Serial.println(\"g - display gyroscope readings in deg/s in x, y, and z directions\");\n  Serial.println(\"t - display temperature readings in oC and oF\");\n}\n\nvoid loop() {\n  // Read incoming commands from serial monitor\n  \n  if (Serial.available()) {\n    c = Serial.read();\n    Serial.println(c);\n  }\n\n  if(c == 'a')sign=1;\n  else if(c == 'g')sign=2;\n  else if(c == 't')sign=3;\n  \n  float x, y, z;\n  if (sign ==1) { // testing accelerometer\n      //Accelerometer\n      x = xIMU.readFloatAccelX();\n      y = xIMU.readFloatAccelY();\n      z = xIMU.readFloatAccelZ();      \n      Serial.print(\"\\nAccelerometer:\\n\");\n      Serial.print(\"Ax:\");\n      Serial.print(x);\n      Serial.print(' ');\n      Serial.print(\"Ay:\");\n      Serial.print(y);\n      Serial.print(' ');\n      Serial.print(\"Az:\");\n      Serial.println(z);\n    }\n  else if (sign ==2) { // testing gyroscope\n      //Gyroscope\n      Serial.print(\"\\nGyroscope:\\n\");\n      x = xIMU.readFloatGyroX();\n      y = xIMU.readFloatGyroY();\n      z = xIMU.readFloatGyroZ();      \n      Serial.print(\"wx:\");\n      Serial.print(x);\n      Serial.print(' ');\n      Serial.print(\"wy:\");\n      Serial.print(y);\n      Serial.print(' ');\n      Serial.print(\"wz:\");\n      Serial.println(z);\n    }\n  else if (sign ==3) { // testing thermometer\n       //Thermometer\n      Serial.print(\"\\nThermometer:\\n\");\n      Serial.print(\" Degrees oC = \");\n      Serial.println(xIMU.readTempC(), 0);\n      Serial.print(\" Degrees oF = \");\n      Serial.println(xIMU.readTempF(), 0);\n      delay(1000);\n    }\n}\n\nGet this code online 🔗 https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/blob/main/xiao_test_IMU/xiao_test_IMU.ino\n\nOnce you run the above sketch, open the Serial Monitor:\n\n\n\nL17-A3.png\n\n\nChoose one of the three options to test:\n\na: Accelerometer (see the result on Plotter)\ng: Gyroscope (see the result on Plotter)\nt: Temperature (see the result on Serial Monitor)\n\nThe following images show the result:\n\n\n\nL17-A4.png\n\n\n\n\n\nL17-A5.png\n\n\n\n\n\nL17-A6.png"
  },
  {
    "objectID": "chapter_4-2.html#the-tinyml-motion-classification-model",
    "href": "chapter_4-2.html#the-tinyml-motion-classification-model",
    "title": "4.2 TinyML Made Easy: Anomaly Detection & Motion Classification",
    "section": "4.2.4 The TinyML Motion Classification Model",
    "text": "4.2.4 The TinyML Motion Classification Model\nFor our project, we will simulate mechanical stresses in transport. Our problem will be to classify four classes of movement:\n\nMaritime (pallets in boats)\nTerrestrial (palettes in a Truck or Train)\nLift (Palettes being handled by Fork-Lift)\nIdle (Palettes in Storage houses)\n\nSo, to start, we should collect data. Then, accelerometers will provide the data on the palette (or container).\n  From the above images, we can see that primarily horizontal movements should be associated with “Terrestrial class,” Vertical movements to “Lift Class,” no activity to “Idle class,” and movent on all three axes to Maritime class.\n\n4.2.4.1 Connecting a Device to the Edge Impulse Studio\nFor data collection, we can have several options. In a real case, we can have our device, for example, connected directly to one container, and the data collected on a file (for example .CSV) and stored on an SD card (via SPI connection) or an offline repo in your computer. Data can also be sent remotely to a nearby repository, such as a mobile phone, using Bluetooth (as done in this project: Sensor DataLogger. Once your dataset is collected and stored as a .CSV file, it can be uploaded to the Studio using the CSV Wizard tool.\n\nIn this video, you can learn alternative ways to send data to the Edge Impulse Studio.\n\nIn this project, we should first connect our device to the Edge Impulse Studio for data collection, which will also be used for data pre-processing, model training, testing, and deployment.\n\nFollow the instructions here to install the Node.js and Edge Impulse CLI on your computer.\n\nOnce the XIAO nRF52840 Sense is not a fully supported development board by Edge Impulse, we should use the CLI Data Forwarder to capture data from the accelerometer and send it to the Studio, as shown in this diagram:  Your device should be connected to the computer serial and running a code to capture IMU (Accelerometer) data and “print them” on the serial. Further, the Edge Impulse Studio will “capture” them. Run the code below:\n#include \"LSM6DS3.h\"\n#include \"Wire.h\"\n\n//Create an instance of class LSM6DS3\nLSM6DS3 xIMU(I2C_MODE, 0x6A);    //I2C device address 0x6A\n\n#define CONVERT_G_TO_MS2    9.80665f\n#define FREQUENCY_HZ        50\n#define INTERVAL_MS         (1000 / (FREQUENCY_HZ + 1))\n\nstatic unsigned long last_interval_ms = 0;\n\nvoid setup() {\n    Serial.begin(115200);\n    while (!Serial);\n\n    // configure the IMU\n    if (xIMU.begin() != 0) {\n        Serial.println(\"Device error\");\n    } else {\n        Serial.println(\"Device OK!\");\n    }\n\n    Serial.println(\"Data Forwarder - Built-in IMU (Accelerometer) on the XIAO BLE Sense\\n\");\n}\n\nvoid loop() {\n    float x, y, z;\n\n    if (millis() &gt; last_interval_ms + INTERVAL_MS) {\n        last_interval_ms = millis();\n\n        x = xIMU.readFloatAccelX();\n        y = xIMU.readFloatAccelY();\n        z = xIMU.readFloatAccelZ();\n\n        Serial.print(x * CONVERT_G_TO_MS2);\n        Serial.print('\\t');\n        Serial.print(y * CONVERT_G_TO_MS2);\n        Serial.print('\\t');\n        Serial.println(z * CONVERT_G_TO_MS2);\n    }\n}\n\nGet this code online 🔗 https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/blob/main/XIAO_BLE_Sense_Accelerometer_Data_Forewarder/XIAO_BLE_Sense_Accelerometer_Data_Forewarder.ino\n\nGo to the Edge Impulse page and create a project. Next, start the CLI Data Forwarder on your terminal, entering (if it is the first time) the following command:\n$ edge-impulse-data-forwarder --clean\nNext, enter your EI credentials, and choose your project, variable, and device names: \n\nThe Studio can read the sampled frequency as 51Hz instead of the 50Hz previously defined in the code. It is OK.\n\nGo to the Devices section on your EI Project and verify if the device is connected (the dot should be green):\n\n\n\n4.2.4.2 Data Collection\nAs discussed before, we should capture data from all four Transportation Classes:\n\nlift (up-down)\nterrestrial (left-right)\nmaritime (zig-zag, etc.)\nidle\n\n\n\n\nimage.png\n\n\nBelow is one sample (10 seconds of raw data):\n\n\n\nimage.png\n\n\nYou can capture, for example, around 2 minutes (twelve samples of 10 seconds) for each of the four classes (a total of 8 minutes of data). Using the three dots menu after each one of the samples, select 2 of them, reserving them for the Test set. Alternatively, you can use the automatic Train/Test Split tool on the Danger Zone of Dashboard tab.\n\n\n\nimage.png\n\n\n\nOnce you have captured your dataset, you can explore it in more detail using the Data Explorer, a visual tool to find outliers or mislabeled data (helping to correct them). The data explorer first tries to extract meaningful features from your data (by applying signal processing and neural network embeddings) and then uses a dimensionality reduction algorithm such as PCA or t-SNE to map these features to a 2D space. This gives you a one-look overview of your complete dataset.\n\n\n\n4.2.4.3 Data Pre-Processing\nData pre-processing is extracting features from the dataset captured with the accelerometer, which involves processing and analyzing the raw data. Accelerometers measure the acceleration of an object along one or more axes (typically three, denoted as X, Y, and Z). These measurements can be used to understand various aspects of the object’s motion, such as movement patterns and vibrations.\nRaw accelerometer data can be noisy and contain errors or irrelevant information. Preprocessing steps, such as filtering and normalization, can clean and standardize the data, making it more suitable for feature extraction. In our case, we should divide the data into smaller segments or windows. This can help focus on specific events or activities within the dataset, making feature extraction more manageable and meaningful. The window size and overlap (window increase) choice depend on the application and the frequency of the events of interest. As a thumb rule, we should try to capture a couple of “cycles of data”.\n\nWith a sampling rate (SR) of 50Hz and a window size of 2 seconds, we will get 100 samples per axis, or 300 in total (3 axis x 2 seconds x 50 samples). We will slide this window every 200ms, creating a larger dataset where each instance has 300 raw features.\n\nOnce the data is preprocessed and segmented, you can extract features that describe the motion’s characteristics. Some typical features extracted from accelerometer data include: - Time-domain features describe the data’s statistical properties within each segment, such as mean, median, standard deviation, skewness, kurtosis, and zero-crossing rate. - Frequency-domain features are obtained by transforming the data into the frequency domain using techniques like the Fast Fourier Transform (FFT). Some typical frequency-domain features include the power spectrum, spectral energy, dominant frequencies (amplitude and frequency), and spectral entropy. - Time-frequency domain features combine the time and frequency domain information, such as the Short-Time Fourier Transform (STFT) or the Discrete Wavelet Transform (DWT). They can provide a more detailed understanding of how the signal’s frequency content changes over time.\nIn many cases, the number of extracted features can be large, which may lead to overfitting or increased computational complexity. Feature selection techniques, such as mutual information, correlation-based methods, or principal component analysis (PCA), can help identify the most relevant features for a given application and reduce the dimensionality of the dataset. The Studio can help with such feature importance calculations.\nEI Studio Spectral Features\nData preprocessing is a challenging area for embedded machine learning. Still, Edge Impulse helps overcome this with its digital signal processing (DSP) preprocessing step and, more specifically, the Spectral Features Block.\nOn the Studio, the collected raw dataset will be the input of a Spectral Analysis block, which is excellent for analyzing repetitive motion, such as data from accelerometers. This block will perform a DSP (Digital Signal Processing), extracting features such as FFT or Wavelets.\nFor our project, once the time signal is continuous, we should use FFT with, for example, a length of [32].\nThe per axis/channel Time Domain Statistical features are:\n\nRMS: 1 feature\nSkewness: 1 feature\nKurtosis: 1 feature\n\nThe per axis/channel Frequency Domain Spectral features are:\n\nSpectral Power: 16 features (FFT Length/2)\nSkewness: 1 feature\nKurtosis: 1 feature\n\nSo, for an FFT length of 32 points, the resulting output of the Spectral Analysis Block will be 21 features per axis (a total of 63 features).\n\nYou can learn more about how each feature is calculated by downloading the notebook Edge Impulse - Spectral Features Block Analysis TinyML under the hood: Spectral Analysis or opening it directly on Google CoLab.\n\nThose 63 features will be the Input Tensor of a Neural Network Classifier.\n\n\n4.2.4.4 Model Design\nOur classifier will be a Dense Neural Network (DNN) that will have 63 neurons on its input layer, two hidden layers with 20 and 10 neurons, and an output layer with four neurons (one per each class), as shown here: \n\n\n4.2.4.5 Impulse Design\nA complete Impulse comprises three primary building blocks: the input block - which obtains the raw data, the processing block - which extracts features, and the learning block - which classifies the data. The following image shows the interface when the three building blocks still need to be added, and our machine-learning pipeline will be implemented by adding these three blocks.\n\n\n\nimage.png\n\n\nImpulse obtains raw data through the input block, uses the processing block to extract features, and then uses the learning block to classify new data. In our continuous action recognition, the added blocks include:\n\n1. Adding the input block: Time Series Data\nClick the “Add an Input Block” button and select Time Series Data in the pop-up window as shown below to match the sensor data type we collected. \nAs shown in the figure below, set the Window Size to 2000 ms (2 seconds), the Window Increase to 80 milliseconds, and the Frequency to 51 Hz based on the calculations we made in the data preprocessing section on the Time Series Data block that appears.\n\n\n\n2. Adding the processing block: Spectral Analysis\nClick the “Add a Processing Block” button and select Spectral Analysis in the pop-up window as shown below to match our motion analysis task type. \nThe effect after adding the processing block is shown in the figure below.\n\n\n\nimage.png\n\n\n\n\n3. Adding the learning block: Classification\nClick the “Add Learning Block” button and select Classification in the pop-up window as shown below to match our motion analysis task type.\n\nThe interface of Impulse design after addition is shown in the figure below, and now the machine learning pipeline has been built.\n\nIn addition, we can also use a second model - K-means, which can be used for anomaly detection. If we imagine that we can treat our known classes as clusters, then any sample that does not fit into it might be an anomaly (for example, a container falling into the sea when the ship is at sea).  For this, we can use the same input tensor entering the NN classifier as the input to the K-means model:  Click the “Add Learning Block” button again and select Anomaly Detection (K-means) in the pop-up window below.\n\nThe final Impulse design is as shown in the figure below, click the Save Impulse button on the far right.\n\n\n\nimage.png\n\n\n\n\n\n4.2.4.6 Generating features\nAt this point in our project, we have defined the pre-processing method and the model designed. Now, it is time to have the job done. First, let’s take the raw data (time-series type) and convert it to tabular data. Go to the Spectral Features tab, select Save Parameters,\n\nand at the top menu, select Generate Features option and Generate Features button:\n\nEach 2-second window data will be converted into one data point of 63 features. The Feature Explorer will show those data in 2D using UMAP.\n\nUniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction.\n\nWith the visualization, it is possible to verify that the classes present an excellent separation, which indicates that the classifier should work well.\n\nOptionally you can analyze how important each one of the features is for one class compared with other classes.\n\n\n\n4.2.4.7 Training\nOur model has four layers, as shown below:\n\nAs hyperparameters, we will use a Learning Rate of 0.005 and 20% of data for validation for 30 epochs.\n\n\n\nimage.png\n\n\nAfter training, we can see that the accuracy is 100%.\n\n\n\nimage.png\n\n\nIf a K-means block for anomaly detection has been added during model design, an additional section for Anomaly Detection will appear under the Impulse Design column on the left, as shown in the image below. Once inside the Anomaly Detection section, click [Select Suggested Axes], and the system will automatically make selections based on previously calculated important features. Then click on the [Start Training] button to begin the training. Results will be output in the Anomaly Explorer on the right after completion.\n\nAt this point, we have completed the basic machine learning training process.\n\n\n4.2.4.8 Testing\nUsing the 20% of data set aside during the data collection phase, we can verify the model’s performance with unknown data. As shown in the image below, click on the Model Testing section on the left side of the Edge Impulse interface. Next to the [Classify All] button, there is an icon with three dots, click on it to open the Set Confidence Thresholds popup window. Here, you can set confidence thresholds for the results of the two learning blocks. We should define an acceptable threshold for results considered as anomalies. If a result is not 100% (which is often the case) but is within the threshold range, it is still usable.\n\nPress the [Classify All] button to start the model testing. The model test results will be displayed upon completion, as shown in the image below.\n\n\n\nimage.png\n\n\n\n\n4.2.4.9 Live Classification\nOnce the model is obtained, you should use the opportunity to test the Live Classification when your device is still connected to the Edge Impulse Studio. As shown in the image below, click on the Live Classification section on the left side of the Edge Impulse interface, then click the [Start Sampling] button.\n\nAt this time, you can, for example, shake the XIAO, the process is the same as the sampling; wait a few seconds, and the classification results will be given. As shown in the image below, I shook the XIAO vigorously, and the model unhesitatingly inferred that the entire process was anomalous.\n\nTry now with the same movements used during data capture. The result should match the class used for training.\n\n⚠️ Note: Here, you will capture real data with your device and upload it to the Edge Impulse Studio, where the trained model will be used for inference (though the model is not in your device).\n\n\n\n4.2.4.10 Deployment\nNow it is time for magic˜! The Studio will package all the needed libraries, preprocessing functions, and trained models, downloading them to your computer. You should select the option Arduino Library and at the bottom, select Quantized (Int8) and Build.\n\nA Zip file will be created and downloaded to your computer.\n\n\n\nimage.png\n\n\nOn your Arduino IDE, go to Sketch tab and select the option Add .ZIP Library.\n\n\n\nL17-企业微信20230602-154602@2x.png\n\n\nand Choose the.zip file downloaded by the Studio:\n\n\n\nL17-image_mVLE7G5k2A.png\n\n\n\n\n4.2.4.11 Inference\nNow, it is time for a real test. We will make inferences wholly disconnected from the Studio. Let’s change one of the code examples created when you deploy the Arduino Library.\nIn your Arduino IDE, go to File/Examples tab and look for your project, and on examples, select nano_ble_sense_accelerometer:\n\n\n\nL17-image_mbxNmt3Kvu.png\n\n\nOf course, the Arduino Nano BLE 33 differs from your board, the XIAO, but we can have the code working with only a few changes. For example, at the beginning of the code, you have the library related to Arduino Sense IMU:\n/* Includes -------------------------------------------------------------- */\n#include &lt;XIAO_BLE_Sense_-_Motion_Classification_inferencing.h&gt;\n#include &lt;Arduino_LSM9DS1.h&gt;\nChange the “includes” portion with the code related to the XIAO nRF52840 Sense IMU:\n/* Includes -------------------------------------------------------------- */\n#include &lt;XIAO_BLE_Sense_-_Motion_Classification_inferencing.h&gt;\n#include \"LSM6DS3.h\"\n#include \"Wire.h\"\n\n//Create an instance of class LSM6DS3\nLSM6DS3 xIMU(I2C_MODE, 0x6A);    //I2C device address 0x6A\nOn the setup function, initiate the IMU using the name that you stated before:\nif (xIMU.begin() != 0) {\n    ei_printf(\"Failed to initialize IMU!\\r\\n\");\n}\nelse {\n    ei_printf(\"IMU initialized\\r\\n\");\n}\nAt the loop function, the buffers: buffer[ix], buffer[ix + 1] and buffer[ix + 2] will receive the 3 axis data captured by the accelerometer. On the original code, you have the line:\nIMU.readAcceleration(buffer[ix], buffer[ix + 1], buffer[ix + 2]);\nChange it with this block of code:\nbuffer[ix]     = xIMU.readFloatAccelX();\nbuffer[ix + 1] = xIMU.readFloatAccelY();\nbuffer[ix + 2] = xIMU.readFloatAccelZ();\nAnd that is it! You can now upload the code to your device and proceed with the inferences. &gt; You can find the complete code on the project GitHub\nYou can see the result of the inference of each class on the images:\n\n\nGet this code online 🔗 https://github.com/Mjrovai/Seeed-XIAO-BLE-Sense/blob/main/XIAO_BLE_Sense_accelerometer/XIAO_BLE_Sense_accelerometer.ino\n\n\n\nPost-processing\nNow that we know the model is working since it detects the movements, we suggest that you modify the code to see the result with the XIAO completely offline (disconnected from the PC and powered by a battery, a power bank, or an independent 5V power supply).\nThe idea is that if one specific movement is detected, a particular LED could be lit. For example, if terrestrial is detected, the Green LED will light; if maritime, the Red LED will light, if it is a lift, the Blue LED will light; and if no movement is detected (idle), the LEDs will be OFF. You can also add a condition when an anomaly is detected, in this case, for example, a white color can be used (all e LEDs light simultaneously).\n\n\n4.2.4.12 Conclusion\nThe Seeed Studio XIAO nRF52840 Sense is a giant tiny device! It is powerful, trustworthy, not expensive, low power, and has suitable sensors to be used on the most common embedded machine learning applications. Even though Edge Impulse does not officially support XIAO nRF52840 Sense, we also realized that it could be easily connected with the Studio. &gt; On the GitHub repository, you will find the last version of the codes: Seeed-XIAO-BLE-Sense.\nThe applications for motion classification and anomaly detection are extensive, and the XIAO is well-suited for scenarios where low power consumption and edge processing are advantageous. Its small form factor and efficiency in processing make it an ideal choice for deploying portable and remote applications where real-time processing is crucial and connectivity may be limited.\n\n\n4.2.4.13 Case Applications\nBefore we finish, consider that Movement Classification and Object Detection can be utilized in many applications across various domains. Here are some of the potential applications:\n\nIndustrial and Manufacturing\n\nPredictive Maintenance: Detecting anomalies in machinery motion to predict failures before they occur.\nQuality Control: Monitoring the motion of assembly lines or robotic arms for precision assessment and deviation detection from the standard motion pattern.\nWarehouse Logistics: Managing and tracking the movement of goods with automated systems that classify different types of motion and detect anomalies in handling.\n\n\n\nHealthcare\n\nPatient Monitoring: Detecting falls or abnormal movements in the elderly or those with mobility issues.\nRehabilitation: Monitoring the progress of patients recovering from injuries by classifying motion patterns during physical therapy sessions.\nActivity Recognition: Classifying types of physical activity for fitness applications or patient monitoring.\n\n\n\nConsumer Electronics\n\nGesture Control: Interpreting specific motions to control devices, such as turning on lights with a hand wave.\nGaming: Enhancing gaming experiences with motion-controlled inputs.\n\n\n\nTransportation and Logistics\n\nVehicle Telematics: Monitoring vehicle motion for unusual behavior such as hard braking, sharp turns, or accidents.\nCargo Monitoring: Ensuring the integrity of goods during transport by detecting unusual movements that could indicate tampering or mishandling.\n\n\n\nSmart Cities and Infrastructure\n\nStructural Health Monitoring: Detecting vibrations or movements within structures that could indicate potential failures or maintenance needs.\nTraffic Management: Analyzing the flow of pedestrians or vehicles to improve urban mobility and safety.\n\n\n\nSecurity and Surveillance\n\nIntruder Detection: Detecting motion patterns typical of unauthorized access or other security breaches.\nWildlife Monitoring: Detecting poachers or abnormal animal movements in protected areas.\n\n\n\nAgriculture\n\nEquipment Monitoring: Tracking the performance and usage of agricultural machinery.\nAnimal Behavior Analysis: Monitoring livestock movements to detect behaviors indicating health issues or stress.\n\n\n\nEnvironmental Monitoring\n\nSeismic Activity: Detecting irregular motion patterns that precede earthquakes or other geologically relevant events.\nOceanography: Studying wave patterns or marine movements for research and safety purposes."
  },
  {
    "objectID": "chapter_4-3.html#things-used-in-this-project",
    "href": "chapter_4-3.html#things-used-in-this-project",
    "title": "4.3 TinyML Made Easy: Sound Classification (KWS)",
    "section": "4.3.1 Things used in this project",
    "text": "4.3.1 Things used in this project\n\nHardware components\n\nSeeed Studio XIAO nRF52840 Sense × 1 \nSeeed Studio Seeeduino XIAO Expansion board × 1\n\n\n\n\nimage.png\n\n\n\n\nSoftware apps and online services\n\nArduino IDE\n\n\n\n\nimage.png\n\n\n\nEdge Impulse Studio\n\n ## 4.3.2 Introduction In the last section, TinyML Made Easy: Anomaly Detection & Motion Classification, we explored Embedded Machine Learning, or simply TinyML, running on the Seeed XIAO nRF52840 Sense. Besides installing and testing the device, we explored motion classification using actual data signals from its onboard accelerometer. This new project will use the same XIAO nRF52840 Sense to classify sound, explicitly working as “Key Word Spotting” (KWS). A KWS is a typical TinyML application and an essential part of a voice assistant.\nBut how does a voice assistant work?\nTo start, it is essential to realize that Voice Assistants on the market, like Google Home or Amazon Echo-Dot, only react to humans when they are “waked up” by particular keywords such as ” Hey Google” on the first one and “Alexa” on the second. \nIn other words, recognizing voice commands is based on a multi-stage model or Cascade Detection. \nStage 1: A smaller microprocessor inside the Echo Dot or Google Home continuously listens to the sound, waiting for the keyword to be spotted. For such detection, a TinyML model at the edge is used (KWS application).\nStage 2: Only when triggered by the KWS application on Stage 1 is the data sent to the cloud and processed on a larger model.\nThe video below shows an example of a Google Assistant being programmed on a Raspberry Pi (Stage 2), with an Arduino Nano 33 BLE as the tinyML device (Stage 1): https://youtu.be/e_OPgcnsyvM\n\nTo explore the above Google Assistant project, please see the tutorial: Building an Intelligent Voice Assistant From Scratch."
  },
  {
    "objectID": "chapter_4-3.html#the-kws-project",
    "href": "chapter_4-3.html#the-kws-project",
    "title": "4.3 TinyML Made Easy: Sound Classification (KWS)",
    "section": "4.3.3 The KWS Project",
    "text": "4.3.3 The KWS Project\nThe diagram below will give an idea of how the final KWS application should work (during inference): \nOur KWS application will recognize three classes of sound:\n\nKeyword 1: UNIFEI\nKeyword 2: IESTI\n“SILENCE” (no keywords spoken, only background noise is present)\n\n\nOptionally, for real-world projects, it is advised to include different words than keywords 1 and 2 in the class “Silence” (or Background) or even create an extra class with such words (for example a class “others”).\n\n\n4.3.3.1 The Machine Learning Workflow\nThe main component of the KWS application is its model. So, we must train such a model with our specific keywords:\n\n\n\nL18-image_VjDpbeenv9.png\n\n\n\n\n4.3.3.2 Dataset\nThe critical component of Machine Learning Workflow is the dataset. Once we have decided on specific keywords (UNIFEI and IESTI), all datasets should be created from zero. When working with accelerometers, creating a dataset with data captured by the same type of sensor was essential. In the case of sound, it is different because of what we will classify as audio data.\n\nThe critical difference between sound and audio is the type of energy. Sound is mechanical perturbation (longitudinal sound waves) that propagate through a medium, causing variations of pressure in it. Audio is an electrical (analog or digital) signal representing sound.\n\nThe sound waves should be converted to audio data when we speak a keyword. The conversion should be done by sampling the signal generated by the microphone in 16KHz with a 16-bit depth.\n\n\n\nL18-image_RSir4IYkbj.png\n\n\nSo, any device that can generate audio data with this basic specification (16Khz/16bits) will work fine. As a device, we can use the proper XIAO nRF52840 Sense, a computer, or even your mobile phone.\n\n\n4.3.3.3 Capturing online Audio Data with Edge Impulse and a smartphone\nIn the TinyML Made Easy: Anomaly Detection & Motion Classification section, we learned how to install and test our device using the Arduino IDE and connect it to Edge Impulse Studio for data capturing. For that, we use the EI CLI function Data Forwarder, but according to Jan Jongboom, Edge Impulse CTO, audio goes too fast for the data forwarder to be captured. If you have PCM data already, then turning it into a WAV file and uploading it with the uploader is the easiest. With accelerometers, our sample frequency was around 50Hz, with audio being 16KHz.\nSo, we can not connect the XIAO directly to the Studio. But we can capture sound using any smartphone connected to the Studio online.\n\nWe will not explore this option here, but you can easily follow the EI documentation and tutorial.\n\n\n\n4.3.3.4 Capturing Audio Data with the XIAO nRF52840 Sense\nThe easiest way to capture audio and save it locally as a .wav file is using an expansion board for the XIAO family of devices, the Seeed Studio XIAO Expansion board.\n\n\n\nimage.png\n\n\n\n\n\nL18-XIAO-Expansion-2.jpeg\n\n\n\n\n\nL18-XIAO-Expansion-3.jpeg\n\n\nThis expansion board enables the building of prototypes and projects easily and quickly, using its rich peripherals such as OLED Display, SD Card interface, RTC, passive buzzer, RESET/User button, 5V servo connector, and multiple data interfaces.\nThis project will focus on classifying keywords, and the MicroSD card available on the device will be very important in helping us with data capture.\n\nSaving recorded audio from the microphone on an SD card\nConnect the XIAO nRF52840 Sense on the Expansion Board and insert an SD card into the SD card slot at the back. &gt; The SD Card should be pre-formated as FAT or exFAT.\n\nNext, download the Seeed_Arduino_FS Library as a zip file:\n\n\n\nimage.png\n\n\nAnd install the downloaded library: Seeed_Arduino_Mic-master.zip on your Arduino IDE: Sketch -&gt; Include Library -&gt; Add .ZIP Library...\n\n\n\nL17-企业微信20230602-154602@2x.png\n\n\nNext, navigate to File &gt; Examples &gt; Seeed Arduino Mic &gt; mic_Saved_OnSDcard to open the sketch: mic_Saved_OnSDcard.\nEach time you press the reset button, a 5 seconds audio sample is recorded and saved on the SD card. I changed the original file to add LEDs to help during the recording process as below:\n\nDuring the time that LED Red is ON is possible to record ==&gt; RECORD\nDuring the file writing process, LED Red is OFF ==&gt; WAIT\nWhen finished writing, LED Green is ON ==&gt; Press Reset Button once and wait for LED Red ON again, and proceed with a new sample recording\n\nI realized that sometimes at the beginning and the end of each sample, a “spike” was recorded, so I cut the initial 300ms from each 5s sample. The spike verified at the end always happened after the recording process and should be eliminated on Edge Impulse Studio before training. Also, I increased the microphone gain to 30 dB.\nThe complete file (Xiao_mic_Saved_OnSDcard.ino) can be found on the Git Hub (3_KWS): Seeed-XIAO-BLE-Sense.\nDuring the recording process, the.wav file names are shown on Serial Monitor:\n\n\n\nL18-image_I9mglC3IAw.png\n\n\nTake the SD card from the Expansion Board and insert it into your computer:\n\n\n\nL18-image_ozO8BV0wsG.png\n\n\nThe files are ready to be uploaded to Edge Impulse Studio\n\n\n\n4.3.3.5 Capturing (offline) Audio Data with a smartphone or PC\nAlternatively, you can use your PC or smartphone to capture audio data with a sampling frequency 16KHz and a bit depth of 16 Bits. A good app for that is Voice Recorder Pro (IOS). Save your record as .wav files and send them to your computer.\n\n\n\nL18-app_yaxj1pljMf.png\n\n\n\nNote that any smartphone app can be used for audio recording or even your computer, for example using Audacity.\n\n\n\n4.3.3.6 Training model with Edge Impulse Studio\nWhen the raw dataset is created, you should initiate a new project at Edge Impulse Studio:  Once the project is created, go to the Data Acquisition section and select the Upload Existing Data tool. Choose the files to be uploaded, for example, I started uploading the samples recorded with the XIAO nRF52840 Sense:  The samples will now appear in the Data acquisition section:  Click on three dots after the sample name and select Split sample. Once inside de tool, split the data into 1-second records (try to avoid start and end portions):  This procedure should be repeated for all samples. After that, upload other class samples (IESTI and SILENCE) captured with the XIAO and your PC or smartphone. &gt; Note: For longer audio files (minutes), first, split into 10-second segments and after that, use the tool again to get the final 1-second splits.\nIn the end, the dataset has around 70 1-second samples for each class:  Now, you should split that dataset into Train/Test. You can do it manually (using the three dots menu, moving samples individually) or using Perform Train / Test Split on Dashboard - Danger Zone.\n\nWe can optionally check all datasets using the tab Data Explorer. The data points seem apart, which means that the classification model should work: \n\n\n4.3.3.7 Creating Impulse (Pre-Process / Model definition)\nAn impulse takes raw data, uses signal processing to extract features, and then uses a learning block to classify new data.  First, we will take the data points with a 1-second window, augmenting the data, sliding that window each 500ms. Note that the option zero-point pad is set. It is important to fill with zeros samples smaller than 1 second (in some cases, I reduced the 1000 ms window on the split tool to avoid noises and spikes.\nEach 1-second audio sample should be pre-processed and converted to an image (for example, 13 x 50 x 1). We will use Audio (MFCC), which extracts features from audio signals using Mel Frequency Cepstral Coefficients, which are well suited for the human voice, which is our case here.\n Next, we select the Classification block to build our model from scratch using a Convolution Neural Network (CNN).\n\n\n4.3.3.8 Pre-Processing (MFCC)\nThe next step is to create the images to be trained in the next phase:  We will keep the default parameter values. We do not spend much memory to pre-process data (only 17KB), but the processing time is relatively high (177 ms for a Cortex-M4 CPU as our XIAO). Save parameters and generate features: \nGoing under the hood\nTo understand better how the raw sound is preprocessed, look at the Feature Engineering for Audio Classification chapter. You can play with the MFCC features generation by downloading this notebook from GitHub or Opening it In Colab.\n\n\n4.3.3.9 Model Design and Training\nWe will use a simple Convolution Neural Network (CNN) model, tested with 1D and 2D convolutions. The basic architecture has two blocks of Convolution + MaxPooling ([8] and [16] filters, respectively) and a Dropout of [0.25] for the 1D and [0.5] for the 2D. For the last layer, after Flattening, we have [3] neurons, one for each class:\n\nAs hyper-parameters, we will have a Learning Rate of [0.005] and a model trained by [100] epochs. We will also include a data augmentation method based on SpecAugment. We trained the 1D and the 2D models with the same hyperparameters. The 1D architecture had a better overall result (91.1% accuracy) when compared with 88% of the 2D, so we will use the 1D.\n\nUsing 1D convolutions is more efficient because it requires fewer parameters than 2D convolutions, making them more suitable for resource-constrained environments.\n\n\n\n\nimage.png\n\n\n\nIf you want to understand what is happening “under the hood,” you can download the pre-processed dataset (MFCC training data) from the Dashboard tab and run this Jupyter Notebook, playing with the code or Opening it In Colab. You should adapt the notebook for your data and model. For example, you can analyze the accuracy by each epoch:\n\n ### 4.3.3.10 Testing Testing the model with the data put apart before training (Test Data), we got an accuracy of 75%. Based on the small amount of data used, it is OK, but I strongly suggest increasing the number of samples.  Collecting more data, the Test accuracy moved up around 5%, going from 75% to around 81%: \nNow, we can proceed with the project, but before deployment on our device, it is possible to perform Live Classification using a Smart Phone, confirming that the model is working with live and real data:\n\n\n\nimage.png\n\n\n\n\n4.3.3.11 Deploy and Inference\nThe Studio will package all the needed libraries, preprocessing functions, and trained models, downloading them to your computer. You should select the option Arduino Library and at the bottom, choose Quantized (Int8) and [Build].\n\n\n\nimage.png\n\n\nA Zip file will be created and downloaded to your computer:  On your Arduino IDE, go to the Sketch tab and select the option Add .ZIP Library.\n\n\n\nL17-企业微信20230602-154602@2x.png\n\n\nAnd Choose the.zip file downloaded by the Studio:  Now, it is time for a real test. We will make inferences wholly disconnected from the Studio. Let’s change one of the code examples created when you deploy the Arduino Library.\nIn your Arduino IDE, go to the File/Examples tab and look for your project, and on examples, select nano_ble33_sense_microphone_continuous:  Even though the XIAO is not the same as the Arduino, both have the same MPU and PDM microphone, so the code works as it is. Upload the sketch to XIAO and open the Serial Monitor. Start talking about one or another Keyword and confirm that the model is working correctly: \n\n\n4.3.3.12 Postprocessing\nNow that we know that the model is working by detecting our two keywords, let’s modify the code so we can see the result with the XIAO nRF52840 Sense completely offline (disconnected from the PC and powered by a battery).\nThe idea is that whenever the keyword UNIFEI is detected, the LED Red will be ON; if it is IESTI, LED Green will be ON, and if it is SILENCE (No Keyword), both LEDs will be OFF.\n\nIf you have the XIAO nRF52840 Sense installed on the Expansion Board, we can display the class label and its probability. Otherwise, use only the LEDs.\n\nLet’s go by Parts: Installing and Testing the SSD Display In your Arduino IDE, Install the u8g2 library and run the below code for testing:\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;\n#include &lt;Wire.h&gt;\n\nU8X8_SSD1306_128X64_NONAME_HW_I2C u8x8(PIN_WIRE_SCL, PIN_WIRE_SDA, U8X8_PIN_NONE);   \n\nvoid setup(void) {\n    u8x8.begin();\n    u8x8.setFlipMode(0);   // set number from 1 to 3, the screen word should rotate 180\n}\n\nvoid loop(void) {\n    u8x8.setFont(u8x8_font_chroma48medium8_r);\n    u8x8.setCursor(0, 0);\n    u8x8.print(\"Hello World!\");\n}\nAnd you should see the “Hello World” displayed on the SSD: \nNow, let’s create some functions that, depending on the values of pred_index and pred_value, will trigger the proper LED and display the class and probability. The code below will simulate some inference results and present them on display and LEDs:\n/* Includes ---------------------------------------------------------------- */\n#include &lt;Arduino.h&gt;\n#include &lt;U8x8lib.h&gt;\n#include &lt;Wire.h&gt;\n\n#define NUMBER_CLASSES 3\n\n/** OLED */\nU8X8_SSD1306_128X64_NONAME_HW_I2C oled(PIN_WIRE_SCL, PIN_WIRE_SDA, U8X8_PIN_NONE);  \n\nint pred_index = 0;     \nfloat pred_value = 0; \nString lbl = \" \";\n\n\nvoid setup() {\n    pinMode(LEDR, OUTPUT);\n    pinMode(LEDG, OUTPUT);\n    pinMode(LEDB, OUTPUT);\n\n    digitalWrite(LEDR, HIGH);\n    digitalWrite(LEDG, HIGH);\n    digitalWrite(LEDB, HIGH);\n\n    oled.begin();\n    oled.setFlipMode(2);\n    oled.setFont(u8x8_font_chroma48medium8_r);\n    oled.setCursor(0, 0);\n    oled.print(\" XIAO Sense KWS\");\n}\n\n/**\n* @brief      turn_off_leds function - turn-off all RGB LEDs\n*/\nvoid turn_off_leds(){\n    digitalWrite(LEDR, HIGH);\n    digitalWrite(LEDG, HIGH);\n    digitalWrite(LEDB, HIGH);\n}\n\n/**\n* @brief      Show Inference Results on OLED Display\n*/\nvoid display_oled(int pred_index, float pred_value){\n    switch (pred_index){\n        case 0:\n            turn_off_leds();\n            digitalWrite(LEDG, LOW);\n            lbl = \"IESTI  \" ;\n            break;\n\n        case 1:\n            turn_off_leds();\n            lbl = \"SILENCE\";\n            break;\n\n        case 2:\n            turn_off_leds();\n            digitalWrite(LEDR, LOW);\n            lbl = \"UNIFEI \";\n            break;\n    }\n    oled.setCursor(0, 2);\n    oled.print(\"      \");\n    oled.setCursor(2, 4);\n    oled.print(\"Label:\");\n    oled.print(lbl);\n    oled.setCursor(2, 6);\n    oled.print(\"Prob.:\");\n    oled.print(pred_value);\n}\n\nvoid loop() {\n    for (int i = 0; i &lt; NUMBER_CLASSES; i++) { \n        pred_index = i;     \n        pred_value = 0.8;   \n        display_oled(pred_index, pred_value);\n        delay(2000);\n    }\n}\nRunning the above code, you should get the below result:\n\n\n\nimage.png\n\n\nYou should merge the above code (Initialization and functions) with the nano_ble33_sense_microphone_continuous.ino you initially used to test your model. Also, you should include the below code on loop() between the lines:\nei_printf(\": \\n\");\n...\n#if EI_CLASSIFIER_HAS_ANOMALY == 1\nAnd replacing the original function to print inference results on the Serial Monitor:\nint pred_index = 0;     // Initialize pred_index\nfloat pred_value = 0;   // Initialize pred_value\n\nfor (size_t ix = 0; ix &lt; EI_CLASSIFIER_LABEL_COUNT; ix++) {\n    ei_printf(\"    %s: %.5f\\n\", result.classification[ix].label, result.classification[ix].value);\n    if (result.classification[ix].value &gt; pred_value){\n        pred_index = ix;\n        pred_value = result.classification[ix].value;\n    }\n}\ndisplay_oled(pred_index, pred_value);\nHere you can see how the final project is: https://youtu.be/1ex88hSqqyI\n\nThe complete code can be found on the GitHub (3_KWS): Seeed-XIAO-BLE-Sense.\n\n\n\n4.3.3.13 Conclusion\nThe Seeed XIAO nRF52840 Sense is really a giant tiny device! However, it is powerful, trustworthy, not expensive, low power, and has suitable sensors to be used on the most common embedded machine learning applications such as movement and sound.\nEven though Edge Impulse does not officially support XIAO nRF52840 Sense (yet!), we also realized that it could use Studio for training and deployment.\n\nOn the GitHub repository, you will find the last version of the codes in the 3_KWS folder: Seeed-XIAO-BLE-Sense\n\nBefore we finish, consider that Sound Classification is more than just voice. For example, you can develop TinyML projects around sound in several areas as:\n\nSecurity (Broken Glass detection)\nIndustry (Anomaly Detection)\nMedical (Snore, Toss, Pulmonary diseases)\nNature (Beehive control, insect sound)"
  },
  {
    "objectID": "chapter_4-4.html#things-used-in-this-project",
    "href": "chapter_4-4.html#things-used-in-this-project",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.1 Things used in this project",
    "text": "4.4.1 Things used in this project\n\n4.4.1.1 Hardware components\nSeeed Studio Seeed XIAO ESP32S3 Sense x 1\n\n\n4.4.2 Software apps and online services\n\n Arduino IDE\n Edge Impulse Studio"
  },
  {
    "objectID": "chapter_4-4.html#introduction",
    "href": "chapter_4-4.html#introduction",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.2 Introduction",
    "text": "4.4.2 Introduction\nMore and more, we are facing an artificial intelligence (AI) revolution where, as stated by Gartner, Edge AI has a very high impact potential, and it is for now!\n\n\n\nimage.png\n\n\nIn the “bull-eye” of emerging technologies, radar is the Edge Computer Vision, and when we talk about Machine Learning (ML) applied to vision, the first thing that comes to mind is Image Classification, a kind of ML “Hello World”!\nSeeed Studio released a new affordable development board, the XIAO ESP32S3 Sense, which integrates a camera sensor, digital microphone, and SD card support. Combining embedded ML computing power and photography capability, this development board is a great tool to start with TinyML (intelligent voice and vision AI).\n\n\n\nimage.png\n\n\nXIAO ESP32S3 Sense Main Features\n\nPowerful MCU Board: Incorporate the ESP32S3 32-bit, dual-core, Xtensa processor chip operating up to 240 MHz, mounted multiple development ports, Arduino / MicroPython supported\nAdvanced Functionality: Detachable OV2640 camera sensor for 1600*1200 resolution, compatible with OV5640 camera sensor, integrating an additional digital microphone\nElaborate Power Design: Lithium battery charge management capability offer four power consumption model, which allows for deep sleep mode with power consumption as low as 14μA\nGreat Memory for more Possibilities: Offer 8MB PSRAM and 8MB FLASH, supporting SD card slot for external 32GB FAT memory\nOutstanding RF performance: Support 2.4GHz Wi-Fi and BLE dual wireless communication, support 100m+ remote communication when connected with U.FL antenna\nThumb-sized Compact Design: 21 x 17.5mm, adopting the classic form factor of XIAO, suitable for space-limited projects like wearable devices\n\n\n\n\nMTY4ODg1NTkyNTI4NTEyMg_561868_B55w78PjvcK7SUlF_1679553921.png\n\n\nBelow is the general board pinout:\n\n\n\nXIAO_ESP32C3_Sense_pin-out.png\n\n\n\nFor more details, please refer to Seeed Studio WiKi page: https://wiki.seeedstudio.com/xiao_esp32s3_getting_started/"
  },
  {
    "objectID": "chapter_4-4.html#installing-the-xiao-esp32s3-sense-on-arduino-ide",
    "href": "chapter_4-4.html#installing-the-xiao-esp32s3-sense-on-arduino-ide",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.3 Installing the XIAO ESP32S3 Sense on Arduino IDE",
    "text": "4.4.3 Installing the XIAO ESP32S3 Sense on Arduino IDE\nOn Arduino IDE, navigate to File &gt; Preferences, and fill in the URL:\nhttps://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_dev_index.json\non the field ==&gt; Additional Boards Manager URLs\n\n\n\nPasted Graphic.png\n\n\nNext, open boards manager. Go to Tools &gt; Board &gt; Boards Manager… and enter with esp32. Select and install the most updated and stable package (avoid alpha versions) :\n\n\n\nPasted Graphic 2.png\n\n\nOn Tools, select the Board (XIAO ESP32S3):\n\n\n\nPasted Graphic 4.png\n\n\nLast but not least, select the Port where the ESP32S3 is connected.\nThat is it! The device should be OK. Let’s do some tests."
  },
  {
    "objectID": "chapter_4-4.html#testing-the-board-with-blink",
    "href": "chapter_4-4.html#testing-the-board-with-blink",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.4 Testing the board with BLINK",
    "text": "4.4.4 Testing the board with BLINK\nThe XIAO ESP32S3 Sense has a built-in LED that is connected to GPIO21. So, you can run the blink sketch as it (using the LED_BUILTIN Arduino constant) or by changing the Blink sketch accordantly:\n#define LED_BUILT_IN 21 \n\nvoid setup() {\n  pinMode(LED_BUILT_IN, OUTPUT); // Set the pin as output\n}\n\n// Remember that the pin work with inverted logic\n// LOW to Turn on and HIGH to turn off\nvoid loop() {\n  digitalWrite(LED_BUILT_IN, LOW); //Turn on\n  delay (1000); //Wait 1 sec\n  digitalWrite(LED_BUILT_IN, HIGH); //Turn off\n  delay (1000); //Wait 1 sec\n}\n\nNote that the pins work with inverted logic: LOW to Turn on and HIGH to turn off\n\n\n\n\nblink.png"
  },
  {
    "objectID": "chapter_4-4.html#connecting-sense-module-expansion-board",
    "href": "chapter_4-4.html#connecting-sense-module-expansion-board",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.5 Connecting Sense module (Expansion Board)",
    "text": "4.4.5 Connecting Sense module (Expansion Board)\nWhen purchased, the expansion board is separated from the main board, but installing the expansion board is very simple. You need to align the connector on the expansion board with the B2B connector on the XIAO ESP32S3, press it hard, and when you hear a “click,” the installation is complete.\n\n\n\nimg\n\n\nAs commented in the introduction, the expansion board, or the “sense” part of the device, has a 1600x1200 OV2640 camera, an SD card slot, and a digital microphone."
  },
  {
    "objectID": "chapter_4-4.html#microphone-test",
    "href": "chapter_4-4.html#microphone-test",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.6 Microphone Test",
    "text": "4.4.6 Microphone Test\nLet’s start with sound detection. Go to the GitHub project and download the sketch: XIAOEsp2s3_Mic_Test and run it on the Arduino IDE:\n\n\n\nPasted Graphic 9.png\n\n\nWhen producing sound, you can verify it on the Serial Plotter.\nSave recorded sound (.wav audio files) to a microSD card.\nLet’s now use the onboard SD Card reader to save .wav audio files. For that, we need to habilitate the XIAO PSRAM.\n\nESP32-S3 has only a few hundred kilobytes of internal RAM on the MCU chip. It can be insufficient for some purposes so that ESP32-S3 can use up to 16 MB of external PSRAM (Psuedostatic RAM) connected in parallel with the SPI flash chip. The external memory is incorporated in the memory map and, with certain restrictions, is usable in the same way as internal data RAM.\n\nFor a start, Insert the SD Card on the XIAO as shown in the photo below (the SD Card should be formatted to FAT32).\n\n\n\nimage.png\n\n\n\nDownload the sketch Wav_Record, which you can find on GitHub.\nTo execute the code (Wav Record), it is necessary to use the PSRAM function of the ESP-32 chip, so turn it on before uploading.: Tools&gt;PSRAM: “OPI PSRAM”&gt;OPI PSRAM\n\n\n\n\nPasted Graphic 10.png\n\n\n\nRun the code Wav_Record.ino\nThis program is executed only once after the user turns on the serial monitor, recording for 20 seconds and saving the recording file to a microSD card as “arduino_rec.wav”.\nWhen the “.” is output every 1 second in the serial monitor, the program execution is finished, and you can play the recorded sound file with the help of a card reader.\n\n\n\n\nPasted Graphic 11.png\n\n\nThe sound quality is excellent!\n\nThe explanation of how the code works is beyond the scope of this tutorial, but you can find an excellent description on the wiki page."
  },
  {
    "objectID": "chapter_4-4.html#testing-the-camera",
    "href": "chapter_4-4.html#testing-the-camera",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.7 Testing the Camera",
    "text": "4.4.7 Testing the Camera\nFor testing the camera, you should download the folder take_photos_command from GitHub. The folder contains the sketch (.ino) and two .h files with camera details.\n\nRun the code: take_photos_command.ino. Open the Serial Monitor and send the command “capture” to capture and save the image on the SD Card:\n\n\nVerify that [Both NL & CR] is selected on Serial Monitor.\n\n\n\n\ncapture.png\n\n\nHere is an example of a taken photo:\n\n\n\nimage.png"
  },
  {
    "objectID": "chapter_4-4.html#testing-wifi",
    "href": "chapter_4-4.html#testing-wifi",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.8 Testing WiFi",
    "text": "4.4.8 Testing WiFi\nOne of the differentiators of the XIAO ESP32S3 is its WiFi capability. So, let’s test its radio, scanning the wifi networks around it. You can do it by running one of the code examples on the board.\nGo to Arduino IDE Examples and look for WiFI ==&gt; WiFIScan\nOn the Serial monitor, you should see the wifi networks (SSIDs and RSSIs) in the range of your device. Here is what I got on the lab:\n\n\n\nPasted Graphic 14.png\n\n\nSimple WiFi Server (Turning LED ON/OFF)\nLet’s test the device’s capability to behave as a WiFi Server. We will host a simple page on the device that sends commands to turn the XIAO built-in LED ON and OFF.\nLike before, go to GitHub to download the folder with the sketch: SimpleWiFiServer.\nBefore running the sketch, you should enter your network credentials:\nconst char* ssid     = \"Your credentials here\";\nconst char* password = \"Your credentials here\";\nYou can monitor how your server is working with the Serial Monitor.\n\n\n\nimage.png\n\n\nTake the IP address and enter it on your browser:\n\n\n\nPasted Graphic 18.png\n\n\nYou will see a page with links that can turn ON and OFF the built-in LED of your XIAO.\nStreaming video to Web\nNow that you know that you can send commands from the webpage to your device, let’s do the reverse. Let’s take the image captured by the camera and stream it to a webpage:\nDownload from GitHub the folder that contains the code: XIAO-ESP32S3-Streeming_Video.ino.\n\nRemember that the folder contains not only the.ino file, but also a couple of.h files, necessary to handle the camera.\n\nEnter your credentials and run the sketch. On the Serial monitor, you can find the page address to enter in your browser:\n\n\n\nPasted Graphic 21.png\n\n\nOpen the page on your browser (wait a few seconds to start the streaming). That’s it.\n\n\n\nPasted Graphic 19.png\n\n\nStreamlining what your camera is “seen” can be important when you position it to capture a dataset for an ML project (for example, using the code “take_phots_commands.ino”.\nOf course, we can do both things simultaneously, show what the camera is seeing on the page, and send a command to capture and save the image on the SD card. For that, you can use the code Camera_HTTP_Server_STA which folder can be downloaded from GitHub.\n\n\n\nPasted Graphic 29.png\n\n\nThe program will do the following tasks:\n\nSet the camera to JPEG output mode.\nCreate a web page (for example ==&gt; http://192.168.4.119//). The correct address will be displayed on the Serial Monitor.\nIf server.on (“/capture”, HTTP_GET, serverCapture), the program takes a photo and sends it to the Web.\nIt is possible to rotate the image on webPage using the button [ROTATE]\nThe command [CAPTURE] only will preview the image on the webpage, showing its size on Serial Monitor\nThe [SAVE] command will save an image on the SD Card, also showing the image on the web.\nSaved images will follow a sequential naming (image1.jpg, image2.jpg.\n\n\n\n\nPasted Graphic 32.png\n\n\n\nThis program can be used for an image dataset capture with an Image Classification project.\n\nInspect the code; it will be easier to understand how the camera works. This code was developed based on the great Rui Santos Tutorial: ESP32-CAM Take Photo and Display in Web Server, which I invite all of you to visit."
  },
  {
    "objectID": "chapter_4-4.html#fruits-versus-veggies---a-tinyml-image-classification-project",
    "href": "chapter_4-4.html#fruits-versus-veggies---a-tinyml-image-classification-project",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.9 Fruits versus Veggies - A TinyML Image Classification project",
    "text": "4.4.9 Fruits versus Veggies - A TinyML Image Classification project\n\n\n\nimg\n\n\nNow that we have an embedded camera running, it is time to try image classification. For comparative motive, we will replicate the same image classification project developed to be used with an old ESP2-CAM:\nESP32-CAM: TinyML Image Classification - Fruits vs Veggies\n\n\n\nimage.png\n\n\nThe whole idea of our project will be training a model and proceeding with inference on the XIAO ESP32S3 Sense. For training, we should find some data (in fact, tons of data!).\nBut first of all, we need a goal! What do we want to classify?\nWith TinyML, a set of technics associated with machine learning inference on embedded devices, we should limit the classification to three or four categories due to limitations (mainly memory in this situation). We will differentiate apples from bananas and potatoes (you can try other categories).\nSo, let’s find a specific dataset that includes images from those categories. Kaggle is a good start:\nhttps://www.kaggle.com/kritikseth/fruit-and-vegetable-image-recognition\nThis dataset contains images of the following food items:\n\nFruits - banana, apple, pear, grapes, orange, kiwi, watermelon, pomegranate, pineapple, mango.\nVegetables - cucumber, carrot, capsicum, onion, potato, lemon, tomato, radish, beetroot, cabbage, lettuce, spinach, soybean, cauliflower, bell pepper, chili pepper, turnip, corn, sweetcorn, sweet potato, paprika, jalepeño, ginger, garlic, peas, eggplant.\n\nEach category is split into the train (100 images), test (10 images), and validation (10 images).\n\nDownload the dataset from the Kaggle website to your computer.\n\n\nOptionally, you can add some fresh photos of bananas, apples, and potatoes from your home kitchen, using, for example, the sketch discussed in the last section."
  },
  {
    "objectID": "chapter_4-4.html#training-the-model-with-edge-impulse-studio",
    "href": "chapter_4-4.html#training-the-model-with-edge-impulse-studio",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.10 Training the model with Edge Impulse Studio",
    "text": "4.4.10 Training the model with Edge Impulse Studio\nWe will use the Edge Impulse Studio for training our model. Edge Impulse is a leading development platform for machine learning on edge devices.\nEnter your account credentials (or create a free account) at Edge Impulse. Next, create a new project:\n\n\n\nimage.png\n\n\nData Acquisition\nNext, on the UPLOAD DATA section, upload from your computer the files from chosen categories:\n\n\n\nimg\n\n\nYou should now have your training dataset, split in three classes of data:\n\n\n\nimg\n\n\n\nYou can upload extra data for further model testing or split the training data. I will leave as it, to use most data possible.\n\nImpulse Design\nAn impulse takes raw data (in this case, images), extracts features (resize pictures), and then uses a learning block to classify new data.\nAs mentioned, classifying images is the most common use of Deep Learning, but much data should be used to accomplish this task. We have around 90 images for each category. Is this number enough? Not at all! We will need thousand of images to “teach or model” to differentiate an apple from a banana. But, we can solve this issue by re-training a previously trained model with thousands of images. We called this technic “Transfer Learning” (TL).\n\n\n\nimg\n\n\nWith TL, we can fine-tune a pre-trained image classification model on our data, performing well even with relatively small image datasets (our case).\nSo, starting from the raw images, we will resize them (96x96) pixels and so, feeding them to our Transfer Learning block:\n\n\n\nimg\n\n\nPre-processing (Feature generation)\nBesides resizing the images, we should change them to Grayscale instead to keep the actual RGB color depth. Doing that, each one of our data samples will have dimension 9, 216 features (96x96x1). Keeping RGB, this dimension would be three times bigger. Working with Grayscale helps to reduce the amount of final memory needed for inference.\n\n\n\nimg\n\n\nDo not forget to “Save parameters.” This will generate the features to be used in training.\nTraining (Transfer Learning & Data Augmentation)\nIn 2007, Google introduced MobileNetV1,a family of general-purpose computer vision neural networks designed with mobile devices in mind to support classification, detection, and more. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of various use cases.\nAlthough the base MobileNet architecture is already tiny and has low latency, many times, a specific use case or application may require the model to be smaller and faster. MobileNet introduces a straightforward parameter α (alpha) called width multiplier to construct these smaller and less computationally expensive models. The role of the width multiplier α is to thin a network uniformly at each layer.\nEdge Impulse Studio has available MobileNet V1 (96x96 images) and V2 (96x96 and 160x160 images), with several different α values (from 0.05 to 1.0). For example, you will get the highest accuracy with V2, 160x160 images, and α=1.0. Of course, there is a trade-off. The highest the accuracy, the more memory (around 1.3M RAM and 2.6M ROM) will be needed to run the model and imply more latency.\nThe smaller footprint will be obtained at another extreme with MobileNet V1 and α=0.10 (around 53.2K RAM and 101K ROM).\nWhen we first published this project to be running on an ESP32-CAM, we stayed at the lower side of possibilities which guaranteed the inference with small latency but not with high accuracy. For this first pass, we will keep this model design (MobileNet V1 and α=0.10).\nAnother important technic to be used with Deep Learning is Data Augmentation. Data augmentation is a method that can help improve the accuracy of machine learning models, creating additional artificial data. A data augmentation system makes small, random changes to your training data during the training process (such as flipping, cropping, or rotating the images).\nUnder the rood, here you can see how Edge Impulse implements a data Augmentation policy on your data:\n# Implements the data augmentation policy\ndef augment_image(image, label):\n    # Flips the image randomly\n    image = tf.image.random_flip_left_right(image)\n\n    # Increase the image size, then randomly crop it down to\n    # the original dimensions\n    resize_factor = random.uniform(1, 1.2)\n    new_height = math.floor(resize_factor * INPUT_SHAPE[0])\n    new_width = math.floor(resize_factor * INPUT_SHAPE[1])\n    image = tf.image.resize_with_crop_or_pad(image, new_height, new_width)\n    image = tf.image.random_crop(image, size=INPUT_SHAPE)\n\n    # Vary the brightness of the image\n    image = tf.image.random_brightness(image, max_delta=0.2)\n\n    return image, label\nExposure to these variations during training can help prevent your model from taking shortcuts by “memorizing” superficial clues in your training data, meaning it may better reflect the deep underlying patterns in your dataset.\nThe final layer of our model will have 16 neurons with a 10% of dropout for overfitting prevention. Here is the Training output:\n\n\n\nimg\n\n\nThe result is not great. The model reached around 77% of accuracy, but the amount of RAM expected to be used during the inference is relatively small (around 60 KBytes), which is very good.\nDeployment\nThe trained model will be deployed as a.zip Arduino library:\n\n\n\nimg\n\n\nOpen your Arduino IDE, and under Sketch, go to Include Library and add.ZIP Library. Select the file you download from Edge Impulse Studio, and that’s it!\n\n\n\nimage.png\n\n\nUnder the Examples tab on Arduino IDE, you should find a sketch code under your project name.\n\n\n\nimage.png\n\n\nOpen the Static Buffer example:\n\n\n\nimage.png\n\n\nYou can see that the first line of code is exactly the calling of a library with all the necessary stuff for running inference on your device.\n#include &lt;XIAO-ESP32S3-CAM-Fruits-vs-Veggies_inferencing.h&gt;\nOf course, this is a generic code (a “template”), that only gets one sample of raw data (stored on the variable: features = {} and run the classifier, doing the inference. The result is shown on Serial Monitor.\nWe should get the sample (image) from the camera and pre-process it (resizing to 96x96, converting to grayscale, and flatting it). This will be the input tensor of our model. The output tensor will be a vector with three values (labels), showing the probabilities of each one of the classes.\n\n\n\nimage.png\n\n\nReturning to your project (Tab Image), copy one of the Raw Data Sample:\n\n\n\nimage.png\n\n\n9, 216 features will be copied to the clipboard. This is the input tensor (a flattened image of 96x96x1), in this case, bananas. Past this Input tensor on features[] = {0xb2d77b, 0xb5d687, 0xd8e8c0, 0xeaecba, 0xc2cf67, …}\n\n\n\nimage.png\n\n\nEdge Impulse included the library ESP NN in its SDK, which contains optimized NN (Neural Network) functions for various Espressif chips, including the ESP32S3 (runing at Arduino IDE).\nNow, when running the inference, you should get, as a result, the highest score for “banana”.\n\n\n\nPasted Graphic 35.png\n\n\nGreat news! Our device handles an inference, discovering that the input image is a banana. Also, note that the inference time was around 317ms, resulting in a maximum of 3 fps if you tried to classify images from a video. It is a better result than the ESP32 CAM (525ms of latency).\nNow, we should incorporate the camera and classify images in real-time.\nGo to the Arduino IDE Examples and download from your project the sketch esp32_camera:\n\n\n\nimage.png\n\n\nYou should change lines 32 to 75, which define the camera model and pins, using the data related to our model. Copy and paste the below lines, replacing the lines 32-75:\n#define PWDN_GPIO_NUM     -1 \n#define RESET_GPIO_NUM    -1 \n#define XCLK_GPIO_NUM     10 \n#define SIOD_GPIO_NUM     40 \n#define SIOC_GPIO_NUM     39\n#define Y9_GPIO_NUM       48 \n#define Y8_GPIO_NUM       11 \n#define Y7_GPIO_NUM       12 \n#define Y6_GPIO_NUM       14 \n#define Y5_GPIO_NUM       16 \n#define Y4_GPIO_NUM       18 \n#define Y3_GPIO_NUM       17 \n#define Y2_GPIO_NUM       15 \n#define VSYNC_GPIO_NUM    38 \n#define HREF_GPIO_NUM     47 \n#define PCLK_GPIO_NUM     13\nHere you can see the resulting code:\n\n\n\nimage.png\n\n\nThe modified sketch can be downloaded from GitHub: xiao_esp32s3_camera.\n\nNote that you can optionally keep the pins as a.h file as we did on previous sections.\n\nUpload the code to your XIAO ESP32S3 Sense, and you should be OK to start classifying your fruits and vegetables! You can check the result on Serial Monitor."
  },
  {
    "objectID": "chapter_4-4.html#testing-the-model-inference",
    "href": "chapter_4-4.html#testing-the-model-inference",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.11 Testing the Model (Inference)",
    "text": "4.4.11 Testing the Model (Inference)\n\n\n\ninferencia.jpg\n\n\nGetting a photo with the camera, the classification result will appear on the Serial Monitor:\n\n\n\nPasted Graphic 40.png\n\n\nOther tests:\n\n\n\ninferencia2.png"
  },
  {
    "objectID": "chapter_4-4.html#testing-with-a-bigger-model",
    "href": "chapter_4-4.html#testing-with-a-bigger-model",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.12 Testing with a bigger model",
    "text": "4.4.12 Testing with a bigger model\nNow, let’s go to the other side of the model size. Let’s select a MobilinetV2 96x96 0.35, having as input RGB images.\n\n\n\nimage.png\n\n\nEven with a bigger model, the accuracy is not good, and worst, the amount of memory necessary to run the model increases five times, with latency increasing seven times (note that the performance here is estimated with a smaller device, the ESP-EYE. So, the real inference with the ESP32S3 should be better).\n\nTo make our model better, we will probably need more images to be trained.\n\nEven though our model did not improve in terms of accuracy, let’s test whether the XIAO can handle such a bigger model. We will do a simple inference test with the Static Buffer sketch.\nLet’s redeploy the model. If the EON Compiler is enabled when you generate the library, the total memory needed for inference should be reduced, but it has no influence on accuracy.\n\n\n\nimage.png\n\n\nDoing an inference with MobilinetV2 96x96 0.35, having as input RGB images, the latency was of 219ms, what it is great for such bigger model.\n\n\n\nESPnn-infe1.png\n\n\nIn our tests, this option works with MobileNet V2 but not V1. So, I trained the model again, using the smallest version of MobileNet V2, with an alpha of 0.05. Interesting that the resultin accuraccy was higher.\n\n\n\nimage.png\n\n\n\nNote that the estimated latency for an Arduino Portenta (ou Nicla), running with a clock of 480MHz is 45ms.\n\nDeploying the model, I got an inference of only 135ms, remembering that the XIAO run with half of the clock used by the Portenta/Nicla (240MHz):\n\n\n\nimage.png"
  },
  {
    "objectID": "chapter_4-4.html#conclusion",
    "href": "chapter_4-4.html#conclusion",
    "title": "4.4 TinyML Made Easy: Image Classification",
    "section": "4.4.13 Conclusion",
    "text": "4.4.13 Conclusion\nThe XIAO ESP32S3 Sense is a very flexible, not expensive, and easy-to-program device. The project proves the potential of TinyML. Memory is not an issue; the device can handle many post-processing tasks, including communication.\nOn the GitHub repository, you will find the last version of the codes: XIAO-ESP32S3-Sense."
  },
  {
    "objectID": "chapter_4-5.html#things-used-in-this-project",
    "href": "chapter_4-5.html#things-used-in-this-project",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.1 Things used in this project",
    "text": "4.5.1 Things used in this project\n\n4.5.1.1 Hardware components\nSeeed Studio Seeed XIAO ESP32S3 Sense x 1\n\n\n4.5.2 Software apps and online services\n\n Arduino IDE\n Edge Impulse Studio"
  },
  {
    "objectID": "chapter_4-5.html#introduction",
    "href": "chapter_4-5.html#introduction",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.2 Introduction",
    "text": "4.5.2 Introduction\nIn the tutorial regarding Computer Vision (CV) and the XIAO ESP32S3, TinyML Made Easy: Image Classification, we learned how to set up and classify images with this remarkable development board, and now, continuing our CV journey, we will explore Object Detection on microcontrollers.\n\n4.5.2.1 Object Detection versus Image Classification\nThe main task with Image Classification models is to identify the most probable object category present on an image, for example, to classify between a cat or a dog, dominant “objects” in an image:\n\n\n\nimg_class.jpg\n\n\nBut what happens if there is no dominant category in the image?\n\n\n\nimg_3.png\n\n\nAn image classification model identifies the above image utterly wrong as an “ashcan,” possibly due to the color tonalities.\n\nThe model used in the previous example is the MobileNet, trained with a large dataset, the ImageNet, running on a Raspberry Pi.\n\nTo solve this issue, we need another type of model, where not only multiple categories (or labels) can be found but also where the objects are located on a given image.\nAs we can imagine, such models are much more complicated and bigger, for example, the MobileNetV2 SSD FPN-Lite 320x320, trained with the COCO dataset. This pre-trained object detection model is designed to locate up to 10 objects within an image, outputting a bounding box for each object detected. The below image is the result of such a model running on a Raspberry Pi:\n\n\n\nimg_4.png\n\n\nThose models used for object detection (such as the MobileNet SSD or YOLO) usually have several MB in size, which is OK for use with Raspberry Pi but unsuitable for use with embedded devices, where the RAM usually is lower than 1M Bytes or at least a few MB as in the case of the XIAO ESP32S3.\n\n\n4.5.2.2 An innovative solution for Object Detection: FOMO\nEdge Impulse launched in 2022,FOMO(Faster Objects, More Objects), a novel solution to perform object detection on embedded devices, such as the Nicla Vision and Portenta (Cortex M7), on Cortex M4F CPUs (Arduino Nano33 and OpenMV M4 series) as well the Espressif ESP32 devices (ESP-CAM, ESP-EYE and XIAO ESP32S3 Sense).\nIn this Hands-On project, we will explore Object Detection using FOMO.\n\nTo understand more about FOMO, you can go into the official FOMO announcementby Edge Impulse, where Louis Moreau and Mat Kelcey explain in detail how it works."
  },
  {
    "objectID": "chapter_4-5.html#the-object-detection-project-goal",
    "href": "chapter_4-5.html#the-object-detection-project-goal",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.3 The Object Detection Project Goal",
    "text": "4.5.3 The Object Detection Project Goal\nAll Machine Learning projects need to start with a detailed goal. Let’s assume we are in an industrial or rural facility and must sort and count oranges (fruits) and special frogs (bugs).\n\n\n\noranges-frogs.png\n\n\nIn other words, we should perform a multi-label classification, where each image can have three classes:\n\nBackground (No objects)\nFruit\nBug\n\nHere are some not labeled image samples that we should use to detect the objects (fruits and bugs):\n\n\n\nobjects.jpg\n\n\nWe are interested in which object is in the image, its location (centroid), and how many we can find on it. The object’s size is not detected with FOMO, as with MobileNet SSD or YOLO, where the Bounding Box is one of the model outputs.\nWe will develop the project using the XIAO ESP32S3 for image capture and model inference. The ML project will be developed using the Edge Impulse Studio. But before starting the object detection project in the Studio, let’s create a raw dataset (not labeled) with images that contain the objects to be detected."
  },
  {
    "objectID": "chapter_4-5.html#data-collection",
    "href": "chapter_4-5.html#data-collection",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.4 Data Collection",
    "text": "4.5.4 Data Collection\nYou can use the XIAO, your phone, or other devices for the image capture. Here, we will use the XIAO with a code in the ESP32 library.\n\n4.5.4.1 Collecting Dataset with the XIAO ESP32S3\nOpen the Arduino IDE and select the XIAO_ESP32S3 board (and the port where it is connected). On File &gt; Examples &gt; ESP32 &gt; Camera, select CameraWebServer. On the BOARDS MANAGER panel, confirm that you have installed the latest “stable” package.\n\nThe current alpha versions (3.0) did not work correctly with the XIAO. The 2.0.14 works fine.\n\nYou also should comment on all cameras’ models, except the XIAO model pins: #define CAMERA_MODEL_XIAO_ESP32S3 // Has PSRAM and on Tools, enable the PSRAM. Enter your wifi credentials and upload the code to the device:\nhttps://hackster.imgix.net/uploads/attachments/1654482/ide_UM8udFSg8J.jpg?auto=compress%2Cformat&w=1280&h=960&fit=max\n\n\n\nide.jpg\n\n\nIf the code is executed correctly, you should see the address on the Serial Monitor:\n\n\n\nserial_monitor.png\n\n\nCopy the address on your browser and wait for the page to be uploaded. Select the camera resolution (for example, QVGA) and select [START STREAM]. Wait for a few seconds/minutes, depending on your connection. You can save an image on your computer download area using the [Save] button.\n\n\n\nsetup-img-collection.jpg\n\n\nEdge impulse suggests that the objects should be of similar size and not overlapping for better performance. This is OK in an industrial facility, where the camera should be fixed, keeping the same distance from the objects to be detected. Despite that, we will also try using mixed sizes and positions to see the result.\n\nWe do not need to create separate folders for our images because each contains multiple labels.\n\nWe suggest around 50 images mixing the objects and varying the number of each appearing on the scene. Try to capture different angles, backgrounds, and light conditions.\n\nThe stored images use a QVGA frame size of 320x240 and RGB565 (color pixel format).\n\nAfter capturing your dataset, [Stop Stream] and move your images to a folder.\n\n\n4.5.4.2 Edge Impulse Studio\n\n4.5.4.2.1 Setup the project\nGo to Edge Impulse Studio,enter your credentials at Login (or create an account), and start a new project.\n\n\n\nimg_6.png\n\n\n\nHere, you can clone the project developed for this hands-on: XIAO-ESP32S3-Sense-Object_Detection\n\nOn your Project Dashboard, go down and on Project info and select Bounding boxes (object detection) and Espressif ESP-EYE (most similar to our board) as your Target Device:\n\n\n\nimg_7.png\n\n\n\n\n\n4.5.4.3 Uploading the unlabeled data\nOn Studio, go to the Data acquisition tab, and on the UPLOAD DATA section, upload files captured as a folder from your computer.\n\n\n\nimg_8.png\n\n\n\nYou can leave for the Studio to split your data automatically between Train and Test or do it manually. We will upload all of them as training.\n\n\n\n\nimg_9.png\n\n\nAll the not-labeled images (47) were uploaded but still need to be labeled appropriately before being used as a project dataset. The Studio has a tool for that purpose, which you can find in the link Labeling queue (47).\nThere are two ways you can use to perform AI-assisted labeling on the Edge Impulse Studio (free version):\n\nUsing yolov5\nTracking objects between frames\n\n\nEdge Impulse launched an auto-labeling featurefor Enterprise customers, easing labeling tasks in object detection projects.\n\nOrdinary objects can quickly be identified and labeled using an existing library of pre-trained object detection models from YOLOv5 (trained with the COCO dataset). But since, in our case, the objects are not part of COCO datasets, we should select the option of tracking objects. With this option, once you draw bounding boxes and label the images in one frame, the objects will be tracked automatically from frame to frame, partially labeling the new ones (not all are correctly labeled).\n\nYou can use the EI uploaderto import your data if you already have a labeled dataset containing bounding boxes.\n\n\n\n4.5.4.4 Labeling the Dataset\nStarting with the first image of your unlabeled data, use your mouse to drag a box around an object to add a label. Then click Save labels to advance to the next item.\n\n\n\nimg_10.png\n\n\nContinue with this process until the queue is empty. At the end, all images should have the objects labeled as those samples below:\n\n\n\nimg_11.jpg\n\n\nNext, review the labeled samples on the Data acquisition tab. If one of the labels is wrong, you can edit it using the three dots menu after the sample name:\n\n\n\nimg_12.png\n\n\nYou will be guided to replace the wrong label and correct the dataset.\n\n\n\nimg_13.jpg\n\n\n\n\n4.5.4.5 Balancing the dataset and split Train/Test\nAfter labeling all data, it was realized that the class fruit had many more samples than the bug. So, 11 new and additional bug images were collected (ending with 58 images). After labeling them, it is time to select some images and move them to the test dataset. You can do it using the three-dot menu after the image name. I selected six images, representing 13% of the total dataset.\n\n\n\nmove_to_test.png"
  },
  {
    "objectID": "chapter_4-5.html#the-impulse-design",
    "href": "chapter_4-5.html#the-impulse-design",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.5 The Impulse Design",
    "text": "4.5.5 The Impulse Design\nIn this phase, you should define how to:\n\nPre-processing consists of resizing the individual images from 320 x 240 to 96 x 96 and squashing them (squared form, without cropping). Afterward, the images are converted from RGB to Grayscale.\nDesign a Model, in this case, “Object Detection.”\n\n\n\n\nimg_14.png\n\n\n\n4.5.5.1 Preprocessing all dataset\nIn this section, select Color depth as Grayscale, suitable for use with FOMO models and Save parameters.\n\n\n\nimg_15.png\n\n\nThe Studio moves automatically to the next section, Generate features, where all samples will be pre-processed, resulting in a dataset with individual 96x96x1 images or 9, 216 features.\n\n\n\nimg_16.png\n\n\nThe feature explorer shows that all samples evidence a good separation after the feature generation.\n\nSome samples seem to be in the wrong space, but clicking on them confirms that the labeling is correct."
  },
  {
    "objectID": "chapter_4-5.html#model-design-training-and-test",
    "href": "chapter_4-5.html#model-design-training-and-test",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.6 Model Design, Training, and Test",
    "text": "4.5.6 Model Design, Training, and Test\nWe will use FOMO, an object detection model based on MobileNetV2 (alpha 0.35) designed to coarsely segment an image into a grid of background vs objects of interest (here, boxes and wheels).\nFOMO is an innovative machine learning model for object detection, which can use up to 30 times less energy and memory than traditional models like Mobilenet SSD and YOLOv5. FOMO can operate on microcontrollers with less than 200 KB of RAM. The main reason this is possible is that while other models calculate the object’s size by drawing a square around it (bounding box), FOMO ignores the size of the image, providing only the information about where the object is located in the image through its centroid coordinates.\nHow FOMO works?\nFOMO takes the image in grayscale and divides it into blocks of pixels using a factor of 8. For the input of 96x96, the grid would be 12x12 (96/8=12). Next, FOMO will run a classifier through each pixel block to calculate the probability that there is a box or a wheel in each of them and, subsequently, determine the regions that have the highest probability of containing the object (If a pixel block has no objects, it will be classified as background). From the overlap of the final region, the FOMO provides the coordinates (related to the image dimensions) of the centroid of this region.\n\n\n\nimg_17.png\n\n\nFor training, we should select a pre-trained model. Let’s use the FOMO (Faster Objects, More Objects) MobileNetV2 0.35`. This model uses around 250KB of RAM and 80KB of ROM (Flash), which suits well with our board.\n\n\n\nimg_18.png\n\n\nRegarding the training hyper-parameters, the model will be trained with:\n\nEpochs: 60\nBatch size: 32\nLearning Rate: 0.001.\n\nFor validation during training, 20% of the dataset (validation_dataset) will be spared. For the remaining 80% (train_dataset), we will apply Data Augmentation, which will randomly flip, change the size and brightness of the image, and crop them, artificially increasing the number of samples on the dataset for training.\nAs a result, the model ends with an overall F1 score of 85%, similar to the result when using the test data (83%).\n\nNote that FOMO automatically added a 3rd label background to the two previously defined (box and wheel).\n\n\n\n\nimg_19.png\n\n\n\nIn object detection tasks, accuracy is generally not the primary evaluation metric. Object detection involves classifying objects and providing bounding boxes around them, making it a more complex problem than simple classification. The issue is that we do not have the bounding box, only the centroids. In short, using accuracy as a metric could be misleading and may not provide a complete understanding of how well the model is performing. Because of that, we will use the F1 score.\n\n\n4.5.6.1 Test model with “Live Classification”\nOnce our model is trained, we can test it using the Live Classification tool. On the correspondent section, click on Connect a development board icon (a small MCU) and scan the QR code with your phone.\n\n\n\nimg_20.png\n\n\nOnce connected, you can use the smartphone to capture actual images to be tested by the trained model on Edge Impulse Studio.\n\n\n\nimg_21.png\n\n\nOne thing to be noted is that the model can produce false positives and negatives. This can be minimized by defining a proper Confidence Threshold (use the Three dots menu for the setup). Try with 0.8 or more."
  },
  {
    "objectID": "chapter_4-5.html#deploying-the-model",
    "href": "chapter_4-5.html#deploying-the-model",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.7 Deploying the Model",
    "text": "4.5.7 Deploying the Model\nSelect the Arduino Library and Quantized (int8) model, enable the EON Compiler on the Deploy Tab, and press [Build].\n\n\n\nimg_22.png\n\n\nOpen your Arduino IDE, and under Sketch, go to Include Library and add.ZIP Library. Select the file you download from Edge Impulse Studio, and that’s it!\n\n\n\nimg_24.png\n\n\nUnder the Examples tab on Arduino IDE, you should find a sketch code (esp32 &gt; esp32_camera) under your project name.\n\n\n\nimg_23.png\n\n\nYou should change lines 32 to 75, which define the camera model and pins, by the data related to our model. Copy and paste the below lines, replacing the lines 32-75:\n#define PWDN_GPIO_NUM     -1 \n#define RESET_GPIO_NUM    -1 \n#define XCLK_GPIO_NUM     10 \n#define SIOD_GPIO_NUM     40 \n#define SIOC_GPIO_NUM     39\n#define Y9_GPIO_NUM       48 \n#define Y8_GPIO_NUM       11 \n#define Y7_GPIO_NUM       12 \n#define Y6_GPIO_NUM       14 \n#define Y5_GPIO_NUM       16 \n#define Y4_GPIO_NUM       18 \n#define Y3_GPIO_NUM       17 \n#define Y2_GPIO_NUM       15 \n#define VSYNC_GPIO_NUM    38 \n#define HREF_GPIO_NUM     47 \n#define PCLK_GPIO_NUM     13\nHere you can see the resulting code:\n\n\n\nimg_25.png\n\n\nUpload the code to your XIAO ESP32S3 Sense, and you should be OK to start detecting fruits and bugs. You can check the result on Serial Monitor.\nBackground\n\n\n\ninference-back.png\n\n\nFruits\n\n\n\nfruits-inference.png\n\n\nBugs\n\n\n\nbugs-inference.png\n\n\nNote that the model latency is 143ms, and the frame rate per second is around 7 fps (similar to what we got with the Image Classification project). This happens because FOMO is cleverly built over a CNN model, not with an object detection model like the SSD MobileNet. For example, when running a MobileNetV2 SSD FPN-Lite 320x320 model on a Raspberry Pi 4, the latency is around five times higher (around 1.5 fps)."
  },
  {
    "objectID": "chapter_4-5.html#conclusion",
    "href": "chapter_4-5.html#conclusion",
    "title": "4.5 TinyML Made Easy: Object Detection",
    "section": "4.5.8 Conclusion",
    "text": "4.5.8 Conclusion\nFOMO is a significant leap in the image processing space, as Louis Moreau and Mat Kelcey put it during its launch in 2022:\n\nFOMO is a ground-breaking algorithm that brings real-time object detection, tracking, and counting to microcontrollers for the first time.\n\nMultiple possibilities exist for exploring object detection (and, more precisely, counting them) on embedded devices."
  },
  {
    "objectID": "chapter_5.html",
    "href": "chapter_5.html",
    "title": "Chapter 5: Creative Experiments",
    "section": "",
    "text": "Since its launch, the Seeed Studio XIAO series has been widely acclaimed for its compact size, powerful performance, and versatile product range. The maker community has produced a large number of projects created with XIAO. Due to space constraints, we have selected some outstanding projects made with XIAO by our makers. These projects fully demonstrate the powerful functions and wide applications of XIAO. Let us follow the makers’ steps, stimulate creativity, and explore the endless possibilities of XIAO. We hope you can draw inspiration from these projects, use your imagination, and explore new territories with XIAO."
  },
  {
    "objectID": "chapter_5-1.html#train-controller-with-seeed-studio-xiao-esp32c3",
    "href": "chapter_5-1.html#train-controller-with-seeed-studio-xiao-esp32c3",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.6 Train Controller With Seeed Studio XIAO ESP32C3",
    "text": "5.1.6 Train Controller With Seeed Studio XIAO ESP32C3\nhttps://www.instructables.com/Train-Controller-With-Seeed-Studio-XIAO-ESP32C3/ Author: Tiago Santos This project designs a train controller using the XIAO ESP32C3 module from Seeed Studio. The project is divided into a train part and a controller part. The train part uses the XIAO ESP32C3 module to connect to the train and controls the train motor through the L293D motor driver. The controller part uses the Wemos D1 Mini to receive speed and direction information and displays the actual speed on a 0.96-inch ssd1306 screen. The controller communicates with the train part through Wi-Fi and an MQTT server. The project simplifies the complexity of traditional Lego train remote control systems and improves control efficiency.     ## 5.1.7 RC Car (Arduino-Based 3D Resin Printed) RC_Car_RP https://www.hackster.io/devinnamaky/rc-car-arduino-based-3d-resin-printed-rc-car-rp-9b4dce Author: Devin Namaky This project is a 3D printed remote-controlled car based on Arduino Nano and Seeeduino XIAO, named RC_Car_RP. The project uses two standard 130 type DC motors as drive and steering, and the steering system uses gear transmission. The Seeeduino XIAO module is used to control the motor driver TB6612FNG, realizing the control of the car speed and direction. Communication between the remote control and the car is achieved through the nRF24L01 wireless module. The project is small in size, simple in design, easy to build, and can meet the remote-controlled car needs in different scenarios."
  },
  {
    "objectID": "chapter_5-1.html#pet-activity-tracker-using-xiao-ble-sense-edge-impulse",
    "href": "chapter_5-1.html#pet-activity-tracker-using-xiao-ble-sense-edge-impulse",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.8 Pet Activity Tracker using XIAO BLE Sense & Edge Impulse",
    "text": "5.1.8 Pet Activity Tracker using XIAO BLE Sense & Edge Impulse\nhttps://www.hackster.io/mithun-das/pet-activity-tracker-using-xiao-ble-sense-edge-impulse-858d73 Author: Mithun Das This project is a wearable device that tracks pet activities using XIAO BLE Sense and Edge Impulse, aimed at helping our pets stay active. The XIAO BLE Sense is a mini controller equipped with a powerful Nordic nRF52840 MCU, built-in Bluetooth 5.0 module, and designed around a 32-bit ARM® Cortex™-M4 CPU. It features a 6-axis IMU that can be used to predict activities such as rest, walking, and running. With the accompanying smartphone app, users can connect to the device via Bluetooth and obtain minute-by-minute prediction data. The data is stored in the smartphone’s local storage and presented graphically to provide meaningful insights. The project collects data via the EI Blue mobile app, creates machine learning models using Edge Impulse Studio, and builds an iOS app using Google Flutter. The whole system can monitor the pet’s activity status in real-time and view the data through the mobile app."
  },
  {
    "objectID": "chapter_5-1.html#h.e.d.s.-on-your-wrist-new-seeeduino-xiao-board",
    "href": "chapter_5-1.html#h.e.d.s.-on-your-wrist-new-seeeduino-xiao-board",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.9 H.E.D.S. On your wrist, New Seeeduino XIAO Board",
    "text": "5.1.9 H.E.D.S. On your wrist, New Seeeduino XIAO Board\nhttps://www.hackster.io/ihayri1/h-e-d-s-on-your-wrist-new-seeeduino-xiao-board-7d8f74 https://youtu.be/ql2wnFtSQqQ Author: Hayri Uygur Hayri has made a Maker-style multifunctional wristwatch, H.E.D.S., using XIAO. It provides a set of small, handy tools with many functions and variations, and is equipped with a beautiful, sharp 240x240 pixel IPS display."
  },
  {
    "objectID": "chapter_5-1.html#hearbeat-monitor-with-xiao-nrf52840",
    "href": "chapter_5-1.html#hearbeat-monitor-with-xiao-nrf52840",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.10 Hearbeat Monitor With XIAO NRF52840",
    "text": "5.1.10 Hearbeat Monitor With XIAO NRF52840\nhttps://www.instructables.com/Hearbeat-Monitor-With-XIAO-NRF52840/ Author: TiagoSantos This project uses a XIAO NRF52840 microcontroller, based on the Nordic nRF52840 CPU, to make a heartbeat monitor. This microcontroller supports Bluetooth 5.0 and NFC and has a super small size, making it ideal for wearable devices and other projects with limited space. The project uses another biomedical microcontroller called Bitalino to monitor the heartbeat. The XIAO NRF52840 receives information from the ECG (Electrocardiogram) sensor and then transmits it to a set of LEDs. Through this project, we can view the heart rate in real-time and observe the data of heart activity.\n\nPrepare the Bluetooth version of XIAO nRF52840. Its small size is very suitable for wearable devices. \nBitalino is a biomedical kit similar to Arduino developed by Hugo Silva in Portugal. This project will use some modules from it. \nCircuit diagram: XIAO receives heart rate information from the ECG sensor, converts it, and sends it. The LED flashes with the heart rate, and the Arduino serial port plotter displays the graphical information of the heart rate.  \nUse a perforated board to place components and solder. First, place resistors and the female pins of XIAO, then solder the ECG sensor. Finally, cut the perforated board to the required size.  \nUse Fusion 360 to design the LED shell, the main shell, and the structure of the chest part. Use Creality Slicer to transcode and send it to the 3D printer to get structural parts.   \nWhen connecting the LED, use a perforated board to connect all cathodes and place a ground connector. After all connections are completed, it is necessary to check whether VCC is isolated from the ground and perform a test. \nNot everything can go as expected. During the connection check, the fixture exerted too much force, causing the perforated board to break. It had to be redone. \nFinally, it’s time to connect the battery and isolate all circuits to avoid short circuits. Usually, heat-shrink tubing would be used here, but if there is no suitable size, hot glue can also work. \nPlace all components on the 3D printed parts and perform a test, then use super glue to connect the parts. The part fixed on the chest was pasted with an elastic band. Finally, replace the LED and remove the resistor to get more noticeable light effects. \nThe final effect."
  },
  {
    "objectID": "chapter_5-1.html#multi-midi-controller-filter-router-sound-generator",
    "href": "chapter_5-1.html#multi-midi-controller-filter-router-sound-generator",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.11 Multi MIDI Controller, Filter, Router & Sound Generator",
    "text": "5.1.11 Multi MIDI Controller, Filter, Router & Sound Generator\nhttps://www.synthtopia.com/content/2022/03/29/multi-midi-controller-filter-router-sound-generator/ https://github.com/pangrus/multi Author: Pangrus Multi is a multifunctional MIDI controller, primarily used for audio synthesis, with a very small size. Compared with the latest generation of commercial controllers, it has a USB port and two DIN interfaces. The Multi controller is fully programmable, allowing for some functionalities in a computer-free setup. In addition, it can also be used as a sound generator as it is equipped with a 10-bit DAC converter, making it ideal for exploring digital synthesis technology. The Multi controller is powered by the robust Seeeduino XIAO, featuring 6 knobs, 2 buttons, 2 Midi DIN interfaces, and a 1/8 inch audio interface. Its MIDI input has opto-isolation to avoid ground loops, complying with the official specification.   ## 5.1.12 DIY eurorack modular synth Raspberry Pi VCO with Seeed XIAO https://www.hackster.io/hagiwo/diy-eurorack-modular-synth-rasberry-pi-vco-with-seeed-xiao-133ac0 Author: HAGIWO/ハギヲ A maker from Japan, HAGIWO/ハギヲ, used the Seeed XIAO RP2040 development board to create a Voltage-Controlled Oscillator (VCO) module for a Eurorack modular synthesizer. This board has a Raspberry Pi RP2040 microcontroller, 4 AD converters, and is easier to use than the Raspberry Pi Pico. The VCO module has three modes: Wavefold, FM, and AM, with eight built-in waveforms, costing only about 1100 yen.  ## 5.1.13 Xiao CV Sequencer https://www.instructables.com/Xiao-CV-Sequencer/ Author: analogsketchbook Using the Seeduino Xiao microcontroller and a few parts, a decent CV synthesizer was created, mainly for modular synthesizer systems. Xiao’s role in this project is to output Control Voltage (CV) signals through its analog output pins for passing note information between modules. It also controls other features such as adjusting speed, mode switching, and sequence selection.    ## 5.1.14 ANAVI Macro Pad 10 & Knobs https://www.crowdsupply.com/anavi-technology/anavi-macro-pad-10 Author: Crowd Supply A company has designed and manufactured three small, programmable, open-source mechanical input devices through crowdfunding: ANAVI Macro Pad 10 keyboard, ANAVI Knob 3, and ANAVI Knob 1. All are driven by the powerful Raspberry Pi RP2040 microcontroller inside Seeed XIAO RP2040, support USB Type-C, and run the KMK firmware based on CircuitPython. These customizable devices are suitable for video or audio editing, entertainment broadcasting, gaming, programming, etc., providing precise control and practical lighting effects. They are simple to use, and their plans and schematics can be found on GitHub."
  },
  {
    "objectID": "chapter_5-1.html#death-stranding-desk-lamp",
    "href": "chapter_5-1.html#death-stranding-desk-lamp",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.15 Death Stranding Desk Lamp",
    "text": "5.1.15 Death Stranding Desk Lamp\nhttps://www.hackster.io/wyx269263336/death-stranding-desk-lamp-ae5f71\n Author: Pinkman This smart lamp, based on the multifunctional scanning device Odradek in the game Death Stranding, is made up of five separate light blades, each with three degrees of freedom, so you can adjust the desired angle at any time. It integrates the XIAO nRF52840 Sense Bluetooth main control board and WS2812 magic color light strip, and you can control its color and brightness through a mobile app."
  },
  {
    "objectID": "chapter_5-1.html#hackerbox-0077veritas",
    "href": "chapter_5-1.html#hackerbox-0077veritas",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.16 HackerBox 0077：Veritas",
    "text": "5.1.16 HackerBox 0077：Veritas\nhttps://www.instructables.com/HackerBox-0077-Veritas/ Author: HackerBoxes This project teaches you how to make a simple lie detector. It involves configuring the Seeeduino XIAO microcontroller module, modifying the OLED module to achieve dual display operation with a single microcontroller, assembling a Galvanic Skin Response (GSR) sensor based on an operational amplifier, and integrating a heart rate sensor. XIAO acts as the core controller in the project, realizing data collection, processing, and display."
  },
  {
    "objectID": "chapter_5-1.html#discipline---a-workout-timer",
    "href": "chapter_5-1.html#discipline---a-workout-timer",
    "title": "5.1 Creative and useful XIAO projects",
    "section": "5.1.17 DISCIPLINE - A workout timer",
    "text": "5.1.17 DISCIPLINE - A workout timer\nhttps://www.hackster.io/rw2493/discipline-a-workout-timer-6b5614 Author: Rui Wang DISCIPLINE: This is a homemade timer that helps you strictly control rest intervals during muscle training. The project uses the Seeeduino XIAO microcontroller, along with two buttons, a display screen, a battery, and other components to achieve a simple user interface and a portable design. XIAO is responsible for the core control function of the timer in the project, providing accurate timing services to users.  The design goals include:\n\nSmall, portable, and compact\nComplete timer functions\nSimple user interface design\nClear interaction flow\nCool appearance\n\nInteraction is designed to be as simple as possible to minimize operation steps.  Yellow and blue button light interaction description: After some playtests, I then use the yellow button to control the time setup, and I use the blue button to start the counting. To provide a good indication, I did several things for the LEDs. ( Y for Yellow, B for Blue) When powering it on: Y -&gt; Fade; B -&gt; ON, indicate to pick up a time period.\n\nWhen powering it on: Y -&gt; Fade; B -&gt; ON, indicate to pick up a time period.\n\nPress Y to switch timing options: 30s, 60s, 90s, 120s.\n\nPress Y to switch timing options: 30s, 60s, 90s, 120s.\n\nPress B to confirm your choice, the timer starts counting down. Y -&gt; OFF; B -&gt; OFF.\n\nPress B to confirm your choice, the timer starts counting down. Y -&gt; OFF; B -&gt; OFF.\n\nTimer ends counting, B -&gt; ON; Y -&gt; OFF forever.\n\nTimer ends counting, B -&gt; ON; Y -&gt; OFF forever.\n\n Two finger operation: The final design choice was to allow users to hold it easily with one hand and operate it with two fingers.  Magnetic Attachment: After analyzing pain points, it was decided to use magnets to attach the product to places where interaction and operation are more easily realized.   ## 5.1.18 Seeed Fusion DIY XIAO Mecha https://www.seeedstudio.com/seeed-fusion-diy-xiao-mechanical-keyboard-contest.html XIAO 的小巧尺寸与其强悍的性能，没想到在 DIY 键盘与控制器玩家中得到认可，为此 Seeed 在2022年7月至10月，组织了一次 Fusion XIAO 机器键盘大赛，下面我们展示了此次比赛的一些获奖项目，以帮助对 DIY 键盘有兴趣的读者。 ### 1st Prize: TOTEM | a tiny splitkeyboard with splay (2x)19 key ergo split: 3-key thumb cluster, pinky splay, low profile. Useful repo and classy, unique case. Nicely documented and open source. And it’s a usable keyboard, which could be used as a daily driver. Other than that, Marc took a great effort to present his design aesthetically https://www.hackster.io/geist/totem-a-tiny-splitkeyboard-with-splay-cb2e43  Author: Marc Rühl  \n\n2nd Prize: Beyblock20 | a magnetic, modular MacroPad\nhttps://github.com/ChrisChrisLoLo/beyblock20 Author: Christian Lo \n\n\n2nd Prize: Purple Owl | a 60% keyboard powered by Seeed XIAO RP2040\nhttps://www.hackster.io/sonalpinto/purple-owl-a-60-keyboard-powered-by-seeed-xiao-rp2040-f73604  Author: Sonal Pinto \n\n\n3rd Prize: KLEIN | a wireless ergonomical keyboard\nhttps://www.hackster.io/nosnk/klein-a-wireless-ergonomical-keyboard-b4cd9a  Author: Shashank \n\n\n3rd Prize: GRIN Quern | an ergonomic keyboard on center trackpad\nhttps://www.hackster.io/policium/grin-quern-ergonomic-keyboard-on-center-trackpad-8b58c3  Author: policium    ### 3rd Prize: Kidoairaku Swallowtail | a cute butterfly-shaped keyboard  Author: yswallow"
  },
  {
    "objectID": "references.html#to-learn-more",
    "href": "references.html#to-learn-more",
    "title": "References",
    "section": "To learn more:",
    "text": "To learn more:\n\nOnline Courses\n\nHarvard School of Engineering and Applied Sciences - CS249r: Tiny Machine Learning\nProfessional Certificate in Tiny Machine Learning (TinyML) – edX/Harvard\nIntroduction to Embedded Machine Learning - Coursera/Edge Impulse\nComputer Vision with Embedded Machine Learning - Coursera/Edge Impulse\nUNIFEI-IESTI01 TinyML: “Machine Learning for Embedding Devices”\n\n\n\nBooks\n\n“Python for Data Analysis by Wes McKinney”\n“Deep Learning with Python” by François Chollet - GitHub Notebooks\n“TinyML” by Pete Warden, Daniel Situnayake\n“TinyML Cookbook” by Gian Marco Iodice\n“Technical Strategy for AI Engineers, In the Era of Deep Learning” by Andrew Ng\n“AI at the Edge” book by Daniel Situnayake, Jenny Plunkett\n“MACHINE LEARNING SYSTEMS for TinyML” Collaborative effort\n\n\n\nProjects Repository\n\nEdge Impulse Expert Network"
  },
  {
    "objectID": "about_authors.html",
    "href": "about_authors.html",
    "title": "About the authors",
    "section": "",
    "text": "Lei Feng is the leader of the technical support group and product curriculum at Seeed Studio. An experienced author in the fields of open-source hardware and edge computing, he has published several books in China, including “GameGo Beginner Programming Course for Arcade 《做游戏，玩编程——零基础开发微软 Arcade 掌机游戏》,” “Grove Beginner Kit For Arduino - Codecraft Graphical Programming Course 《Arduino 图形化编程轻松学》”, and the Chinese translation of “IoT for Beginners 《深入浅出 IoT：完整项目通关实战》” with support from Microsoft China.\nLei Feng has created numerous tutorials and open-source documentation in Chinese and English with his team. His hands-on experience developing IoT and edge computing projects gives him unique insights into simplifying complex concepts for beginners. As an engaging writer and patient teacher, Lei Feng is the ideal guide to make Arduino and TinyML approachable for newcomers worldwide.\nLinkedIn profile: https://www.linkedin.com/in/leon-feng-a029bb1/\nMarcelo Rovai is a recognized figure in engineering and technology education, holding the title of Professor Honoris Causa from the Federal University of Itajubá, Brazil. His educational background includes an Engineering degree from UNIFEI and an advanced specialization from the Polytechnic School of São Paulo University. Further enhancing his expertise, he earned an MBA from IBMEC (INSPER) and a Master’s in Data Science from the Universidad del Desarrollo in Chile.\nWith a career spanning several high-profile technology companies such as AVIBRAS Airspace, ATT, NCR, and IGT, where he served as Vice President for Latin America, he brings a wealth of industry experience to his academic endeavors. He is a prolific writer on electronics-related topics and shares his knowledge through open platforms like Hackster.io.\nIn addition to his professional pursuits, he is dedicated to educational outreach, serving as a volunteer professor at UNIFEI and engaging with the TinyML4D group as a Co-Chair, promoting TinyML education in developing countries. His work underscores a commitment to leveraging technology for societal advancement.\nLinkedIn profile: https://www.linkedin.com/in/marcelo-jose-rovai-brazil-chile/\nTwitter handle: @mjrovai\nAuthor public speaking samples (YouTube, etc.): https://www.youtube.com/watch?v=KeXlAazzgKw"
  },
  {
    "objectID": "chapter_1-1.html#task-1-run-blink-to-make-xiaos-led-flash",
    "href": "chapter_1-1.html#task-1-run-blink-to-make-xiaos-led-flash",
    "title": "1.1 First Arduino program with Seeed Studio XIAO: Blink",
    "section": "1.1.3 Task 1: Run Blink to Make XIAO’s LED Flash",
    "text": "1.1.3 Task 1: Run Blink to Make XIAO’s LED Flash\nJust as “Hello World” is the first section in all programming languages, “Blink” is akin to “Hello World” in Arduino programming. It is the key to our journey in learning Arduino. Arduino provides many example codes to help us get started quickly, and Blink is one of them. We can select “File → Examples → 01.Basics → Blink” in the Arduino window to open the example program Blink.\n\n\nAfter opening the example program, you can see the following code, which implements the effect of LED flashing. You can see that the code has orange and green color prompts, which proves that your input is correct. Pay attention to the difference between uppercase and lowercase.\n\n\n/*\n  Blink\n\n  Turns an LED on for one second, then off for one second, repeatedly.\n\n  Most Arduinos have an on-board LED you can control. On the UNO, MEGA and ZERO\n  it is attached to digital pin 13, on MKR1000 on pin 6. LED_BUILTIN is set to\n  the correct LED pin independent of which board is used.\n  If you want to know what pin the on-board LED is connected to on your Arduino\n  model, check the Technical Specs of your board at:\n  https://www.arduino.cc/en/Main/Products\n\n  modified 8 May 2014\n  by Scott Fitzgerald\n  modified 2 Sep 2016\n  by Arturo Guadalupi\n  modified 8 Sep 2016\n  by Colby Newman\n\n  This example code is in the public domain.\n\n  https://www.arduino.cc/en/Tutorial/BuiltInExamples/Blink\n*/\n\n// the setup function runs once when you press reset or power the board\nvoid setup() {\n  // initialize digital pin LED_BUILTIN as an output.\n  pinMode(LED_BUILTIN, OUTPUT);\n}\n\n// the loop function runs over and over again forever\nvoid loop() {\n  digitalWrite(LED_BUILTIN, HIGH);  // turn the LED on (HIGH is the voltage level)\n  delay(1000);                      // wait for a second\n  digitalWrite(LED_BUILTIN, LOW);   // turn the LED off by making the voltage LOW\n  delay(1000);                      // wait for a second\n}\n\nCode Analysis\n\npinMode(LED_BUILTIN, OUTPUT);\nThe first thing the code does is to initialize LED_BUILTIN as an output pin in the setup() function. Most Arduino series boards default the onboard LED to digital pin 13. The constant LED_BUILTIN connects the onboard LED to pin 13.\n\n\n\ndigitalWrite(LED_BUILTIN, HIGH);\nIn the loop() function, we set the LED_BUILTIN pin to the “on” state, outputting 5V or 3.3V voltage to this pin, which can be represented by HIGH. However, note that all I/O pins on XIAO are 3.3V. Do not input a voltage exceeding 3.3V, or it may damage the CPU.\n\n\ndigitalWrite(LED_BUILTIN, LOW);\nWhat comes on must turn off. This statement sets the LED_BUILTIN pin to the “off” state, outputting 0V voltage to this pin, which can be represented by LOW.\n\n\ndelay(1000);\nThis is a delay statement. It means that the LED can maintain the “on” or “off” state for 1 second, because the parameter in the function is in milliseconds, so 1000 milliseconds is 1 second. After controlling the “on” and “off” statements of the LED, a delay must be added, and the waiting time should be the same to ensure that the LED flashes evenly.\n\n\n\nUpload the Program\nNext, we will learn how to upload the program. Use the data cable in the kit to connect XIAO to the computer, as shown in the figure.\n\n\nChoose the serial port of the development board from the “Tools” bar. For Windows users, it is generally COM3 or a larger number. Select it as shown in the figure below.\nIf several ports are displayed for selection, unplug the data cable, reopen the “Tools” bar, and the port that disappears is the XIAO port. Reconnect the circuit board and then select this serial port. After selecting the board and the serial port, you can see the controller model and corresponding serial port that have been set up in the lower right corner of the IDE interface.\n\n\nIn Mac or Linux systems, the serial port name is generally /dev/tty.usbmodem+number or /dev/cu.usbmodem+number, as shown in the figure below.\n\n\nNext, we can upload the program. Before uploading, we can click the (verify button) to verify whether the program is correct. If “Compilation Completed” is displayed, the program is correct.\n\n\nClick the  (upload button), the debug window will display “Compiling Project→Upload”. When “Upload Completed” is displayed, you can see the effect of the program running on XIAO, as shown in the upload successful prompt window displayed on a Mac computer.\n\n\n\n⚠️ Note\nWhen you start writing code, you will often forget the rules of uppercase and lowercase, punctuation, and make mistakes. Therefore, try to write code by yourself instead of copying and pasting. After the example program is successfully uploaded, try to create a new Sketch and start manually inputting the code."
  },
  {
    "objectID": "chapter_1-2.html#background-knowledge",
    "href": "chapter_1-2.html#background-knowledge",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.1 Background Knowledge",
    "text": "1.2.1 Background Knowledge\nIn the last section, we only used the onboard LED light of the Seeed Studio XIAO without connecting other modules. It could take quite some effort for beginners to use Dupont wires to connect external sensors to a board the size of a thumb and also involve a breadboard. Is there a simpler method?\n\n1.2.1.1 Seeed Studio XIAO Expansion Board\nThe Seeed Studio XIAO Expansion Board, only half the size of Raspberry Pi 4, is powerful and can quickly and easily build prototypes and projects. The board has a variety of peripherals such as OLED, RTC, expandable memory, passive buzzer, RESET/User button, 5V servo/sensor connector, various data interfaces… You can explore the infinite possibilities of Seeed Studio XIAO. The board also supports CircuitPython.  All models in the Seeed Studio XIAO series have uniform specifications and support the Seeed Studio XIAO Grove Shield and Seeed Studio XIAO Expansion Board. The series includes XIAO SAMD21, XIAO RP2040, XIAO nRF52840, XIAO nRF52840 Sense, XIAO ESP32C3 and XIAO ESP32S3. The front and back function interfaces of the XIAO expansion board are shown in the following figure:\n\n\nTo make it easier and quicker to build projects with Seeed Studio XIAO, we equipped it with a powerful expansion board. This board has a wealth of onboard peripherals and can quickly connect to more electronic modules to implement various functions. The expansion board brings out all the pins of XIAO, as shown in the pin diagram below:\n\nIn most cases, the XIAO expansion board is suitable for all Seeed Studio XIAO series products.  When we need to use the XIAO expansion board, we need to connect the XIAO development board to the corresponding position on the expansion board, as shown in the figure below. Connect the pin headers on the XIAO main board to the position circled in yellow on the expansion board. Be sure to align it before pressing down to avoid damaging the pins. After that, we can start working on projects in combination with the expansion board.\n\n\n\n⚠️ Note  Please first plug the Seeed Studio XIAO into the two female headers on the expansion board, and then plug in the Type-C power supply, otherwise it will damage the Seeed Studio XIAO and the expansion board.\n\n\n\n1.2.1.2 Three Basic Structures of Programs\nThe three basic structures of programs are sequential structure, selection structure, and loop structure.  \n\nSequential Structure\nAs the name suggests, the program in a sequential structure is executed in the order of the statements. It is the most basic and simple program structure. As shown in the figure below, the program will first execute the operation in the S1 box, then the operation in the S2 box, and so on.\n\n\n\n\nSelection Structure\nIn a program,sometimes we need to make judgments based on the situation to decide the next step. For instance, the program might need to judge the light value in the current environment. If the light value is high, indicating a bright environment, there’s no need to light up the light. If the light value is low, indicating a dim environment, then it’s necessary to turn on the light. In such cases, we use a selection structure.  As shown in the following figures, the selection structure will judge whether the condition is fulfilled. If “True”, it executes S1; if “False”, it executes S2; or if “True”, it executes S1, if “False”, it exits the selection structure.\n\n\n\nThe if Statement\nThe if statement is the most common selection structure, which executes the following statement when the given expression is true. The if statement has three structural forms as shown in the following example. Simple branch structure: Execute when the condition is fulfilled.\nif (expression) {\n  statement;\n}\nDual branch structure: Execute statement1 when the condition is fulfilled, otherwise execute statement2.\nif (expression) {\n  statement1;\n}\nelse {\n  statement2;\n}\nMulti-branch structure: Use nested if statements to judge different situations.\nif (expression1) {\n  statement1;\n}\nelse if (expression2) {\n  statement2;\n}\nelse if (expression3) {\n  statement3;\n}\n\n\nswitch……case Statement\n When dealing with multiple selection branches, using an “if……else” structure to write a program can be quite lengthy. In this case, it’s much more convenient to use a switch statement. The switch structure compares the expression in parentheses with the constants after case. If they match, it executes the corresponding statement and exits the structure via a break statement. If none match, it runs the statement after default. It’s important to note that the expression in parentheses after switch must be of integer or character type.\n\n\nswitch (expression) {\n  case constant_expression1:\n    statement1;\n    break;\n  case constant_expression2:\n    statement2;\n    break;\n    ……\n  default:\n    statementn;\n    break;\n}\n\n\n\nbreak Statement \nThe break statement can only be used in a switch multi-branch selection structure and loop structures. It is used to terminate the current program structure, allowing the program to jump to subsequent statements for execution.\n\n\n\nLoop Structure \nA loop structure is used when a part of the program needs to be executed repeatedly, based on given judgment conditions to determine whether to continue executing a certain operation or exit the loop. There are three common types of loop statements: \n\nwhile Loop \nThe while loop is a type of “when” loop that executes the statements in the loop body when a certain condition is met.\n\n\n\n\nwhile (expression) {\n  statement;\n}\n\n\ndo……while Loop\nThis is a type of “until” loop. The statement in the loop body is executed once before the expression is evaluated. If the expression is true, the loop continues.\n\n\n\n\ndo {\n  statement;\n} while (expression);\n\n\n\nfor Loop\nThis includes three expressions: Expression1 for initialization, Expression2 for judgment, and Expression3 for increment.\n\n\n\n\nfor (Expression1; Expression2; Expression3) {\n  statement;\n}\nIn addition to the above loop statements, there are control statements, break and continue, in the loop structure used to prematurely end the loop or exit the loop. In this lesson, we just need to understand these program structures. In later courses, we will gradually master them through project examples."
  },
  {
    "objectID": "chapter_1-2.html#task-1-control-the-led-on-the-xiao-using-the-button-on-the-xiao-expansion-board",
    "href": "chapter_1-2.html#task-1-control-the-led-on-the-xiao-using-the-button-on-the-xiao-expansion-board",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.2 Task 1: Control the LED on the XIAO using the button on the XIAO expansion board",
    "text": "1.2.2 Task 1: Control the LED on the XIAO using the button on the XIAO expansion board\n\nAnalysis\nThe effect we want to achieve is that when the button is pressed, the LED lights up; when the button is released, the LED goes off. The program is written in three steps:\n\nDefine pins and create variables.\nInitialize and set pin status.\nRead the button status, implement condition judgment. If the button is pressed, the light is on, otherwise, the light is off.\n\n\n\nVariable\n\nIn a program, a value that can change is called a variable. For example, defining an integer variable i as int i;. We can assign a value to the variable at the same time as we define it, such as int i =0;. Furthermore, depending on the data type, different statements are used to define variables, such as defining a floating point number, float x = 1.9;, and so on. For more details, refer to the Arduino data types and constants documentation https://www.arduino.cc/reference/en/#variables.\n\n\n\nWriting the Program:\nStep 1: Define pins and create variables. The on-board button switch on the XIAO expansion board is D1, so we define it as pin 1 and set a variable for the button status. Note that LED_BUILTIN will set the LED to the correct pin, so we don’t need to manually define it:\nconst int buttonPin = 1;  // The on-board button switch on the XIAO expansion board is D1, which we define as pin 1\n// If you are using XIAO RP2040, please change 1 to D1\nint buttonState = 0;  // buttonState is a variable to store the button status\nStep 2: Set pin status. Set the LED pin to output status and the button pin to input pull-up status. Use INPUT_PULLUP to enable internal pull-up resistors. When the button is not pressed, it returns 1 or HIGH (high level). When the button is pressed, it returns 0 or LOW (low level).\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);// Set the LED pin to output status\n    pinMode(buttonPin, INPUT_PULLUP);// Set the button pin to input status\n}\nStep 3: Continuously read the button status. If the button is pressed, the light is on, otherwise, the light is off. Because the on-board LED of the XIAO is negative logic, when the button is pressed and returns 0, the LED is on; when it returns 1, the LED is off.\nvoid loop() {\n    // Read the button status and store it in the buttonState variable\n    buttonState = digitalRead(buttonPin);  \n    // Check whether the button is pressed, if the button is pressed\n    if (buttonState == HIGH) {\n        // Turn on the LED:\n        digitalWrite(LED_BUILTIN, HIGH);\n    }\n    else {\n        // Turn off the LED:\n        digitalWrite(LED_BUILTIN, LOW);\n    }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/blob/main/code/L2_Button_XIAO_en/L2_Button_XIAO_en.ino\n\n\n\nUploading the Program\nWe upload the program we wrote to the hardware. First, use the data cable in the kit to connect the XIAO to the computer.\n\n\nNote the position of the buttons on the XIAO extensions used for testing in the figure.  Then click the verify button  to verify the program. If it is correct, click the upload button  to upload the program to the hardware. When the debugging area displays “Done uploading.”, we can press the button to see if the LED lights up.\n\n\n\n⚠️ Note  There are two identical buttons on the expansion board. One is the RESET button near the Type-C interface, and the other is the user-defined button near the lithium battery interface. Test with the one near the lithium battery interface."
  },
  {
    "objectID": "chapter_1-2.html#task-2-use-the-button-on-the-xiao-expansion-board-to-control-the-external-led-on-the-xiao-esp32c3",
    "href": "chapter_1-2.html#task-2-use-the-button-on-the-xiao-expansion-board-to-control-the-external-led-on-the-xiao-esp32c3",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.3 Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3",
    "text": "1.2.3 Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3\nFor the Seeed XIAO ESP32C3, it doesn’t have an on-board LED for users to use. To run the Blink program, you need to first connect an LED to the D10 pin of the board as shown:\n\n\n⚠️ Note  Be sure to add a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED to prevent overcurrent from burning out the LED.\n\nThen copy the following program into the Arduino IDE:\n/*\n * Button controlling external LED of XIA\n\nApologies for the confusion. It seems that there was an issue with quoting text from the document. Let's continue:\n\n#### Task 2: Use the button on the XIAO expansion board to control the external LED on the XIAO ESP32C3\nFor the Seeed XIAO ESP32C3, it doesn't have an on-board LED for users to use. To execute the Blink program, you first need to connect an LED to the board's `D10` pin as shown. \n\n&gt; ⚠️ Note: Make sure to add a resistor (about 150Ω) in series with the LED to limit the current flowing through the LED and prevent overcurrent from burning out the LED.\n\nThen, copy the following program into the Arduino IDE:\n```cpp\n/*\n * Button controlling external LED of XIAO ESP32C3\n */\n\nconst int buttonPin = 1;     // The pin number of the button\nint buttonState = 0;    // Variable for reading the button status\nint led = D10;  // Pin number of the LED\n\nvoid setup() {\n  // Initialize the LED pin as an output:\n  pinMode(led, OUTPUT);\n  // Initialize the button pin as an input:\n  pinMode(buttonPin, INPUT_PULLUP);\n}\n\nvoid loop() {\n  // Read the state of the button:\n  buttonState = digitalRead(buttonPin);\n  // Check if the button is pressed. If it is, the button state is HIGH\n  if (buttonState == HIGH) {\n    // Turn the LED on:\n    digitalWrite(led, HIGH);\n  }\n  else {\n    // Turn the LED off:\n    digitalWrite(led, LOW);\n  }\n}\n\nGet this program from Github  https://github.com/mouseart/XIAO-Mastering-Arduino-and-TinyML/tree/main/code/L2_Button_XIAO_ESP32C3_en\n\n\nPowering XIAO with an external battery\nWhen demonstrating the effect, in addition to using a data cable to power the computer, you can also use an external lithium battery. This makes it convenient to move and do projects, as shown in the picture."
  },
  {
    "objectID": "chapter_1-2.html#expanded-exercise",
    "href": "chapter_1-2.html#expanded-exercise",
    "title": "1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light",
    "section": "1.2.4 Expanded Exercise",
    "text": "1.2.4 Expanded Exercise\n\nFlow Chart \nBefore writing the program, you can first draw a flow chart of the program to help organize your thoughts. The common flow chart symbols are as follows:\n\n\nThe button-controlled LED program we implemented in this section is represented by the following flow chart. You can try drawing it yourself."
  }
]