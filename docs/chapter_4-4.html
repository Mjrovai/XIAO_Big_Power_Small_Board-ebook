<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>XIAO: Big Power, Small Board - 4.4 Image Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_4-5.html" rel="next">
<link href="./chapter_4-3.html" rel="prev">
<link href="./cover.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">XIAO: Big Power, Small Board</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/Mjrovai/XIAO_Big_Power_Small_Board-ebook" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_4.html">Chapter 4: Project Practice Advanced - TinyML Applications</a></li><li class="breadcrumb-item"><a href="./chapter_4-4.html">4.4 Image Classification</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgments</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about_book.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this Book</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./chapter_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Introduction to Hardware and Programming</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_1-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.1 First Arduino program with Seeed Studio XIAO: Blink</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_1-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.2 Using the Button Switch on the XIAO Expansion Board to Control an LED Light</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_1-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.3 Transforming XIAO and its Expansion Board into a Morse Code Transmitter</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_1-4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.4 Monitor Knob Value Changes with Serial Monitor</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_1-5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.5 Controlling LED and Servo with a Knob</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_1-6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.6 Displaying “Hello World” on OLED</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./chapter_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: Project Practice for Beginners - Introduction to Prototype Design</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_2-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.1 Introduction to Product Prototype Design</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_2-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.2 Smart Hygrometer and Thermometer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_2-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.3 Surprise Gift Box Based on Light Sensor</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_2-4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.4 Rhythmic Dance with a Triaxial Accelerometer</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./chapter_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Intermediate Project Practice - Complex Projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_3-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.1 Smart Remote Control Door</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_3-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.2 Smart Watch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_3-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.3 Air Piano</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_3-4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.4 Implementing Wi-Fi Connection and Applications with XIAO ESP32C3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_3-5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.5 Telemetry and Commands using the MQTT protocol with XIAO ESP32C3</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./chapter_4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Project Practice Advanced - TinyML Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_4-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.1 Understanding TinyML and Edge Impulse Studio</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_4-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.2 Anomaly Detection &amp; Motion Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_4-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.3 Sound Classification (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_4-4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">4.4 Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_4-5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.5 Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_4-6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.6 To learn more</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./chapter_5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: Creative Experiments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_5-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.1 Creative and useful XIAO projects</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about_authors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the authors</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#things-used-in-this-project" id="toc-things-used-in-this-project" class="nav-link active" data-scroll-target="#things-used-in-this-project">4.4.1 Things used in this project</a>
  <ul class="collapse">
  <li><a href="#hardware-components" id="toc-hardware-components" class="nav-link" data-scroll-target="#hardware-components">4.4.1.1 Hardware components</a></li>
  <li><a href="#software-apps-and-online-services" id="toc-software-apps-and-online-services" class="nav-link" data-scroll-target="#software-apps-and-online-services">4.4.2 Software apps and online services</a></li>
  </ul></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">4.4.2 Introduction</a></li>
  <li><a href="#installing-the-xiao-esp32s3-sense-on-arduino-ide" id="toc-installing-the-xiao-esp32s3-sense-on-arduino-ide" class="nav-link" data-scroll-target="#installing-the-xiao-esp32s3-sense-on-arduino-ide">4.4.3 Installing the XIAO ESP32S3 Sense on Arduino IDE</a></li>
  <li><a href="#testing-the-board-with-blink" id="toc-testing-the-board-with-blink" class="nav-link" data-scroll-target="#testing-the-board-with-blink">4.4.4 Testing the board with BLINK</a></li>
  <li><a href="#connecting-sense-module-expansion-board" id="toc-connecting-sense-module-expansion-board" class="nav-link" data-scroll-target="#connecting-sense-module-expansion-board">4.4.5 Connecting Sense module (Expansion Board)</a></li>
  <li><a href="#microphone-test" id="toc-microphone-test" class="nav-link" data-scroll-target="#microphone-test">4.4.6 Microphone Test</a></li>
  <li><a href="#testing-the-camera" id="toc-testing-the-camera" class="nav-link" data-scroll-target="#testing-the-camera">4.4.7 Testing the Camera</a></li>
  <li><a href="#testing-wifi" id="toc-testing-wifi" class="nav-link" data-scroll-target="#testing-wifi">4.4.8 Testing WiFi</a></li>
  <li><a href="#fruits-versus-veggies---a-tinyml-image-classification-project" id="toc-fruits-versus-veggies---a-tinyml-image-classification-project" class="nav-link" data-scroll-target="#fruits-versus-veggies---a-tinyml-image-classification-project">4.4.9 Fruits versus Veggies - A TinyML Image Classification Project</a></li>
  <li><a href="#training-the-model-with-edge-impulse-studio" id="toc-training-the-model-with-edge-impulse-studio" class="nav-link" data-scroll-target="#training-the-model-with-edge-impulse-studio">4.4.10 Training the model with Edge Impulse Studio</a></li>
  <li><a href="#testing-the-model-inference" id="toc-testing-the-model-inference" class="nav-link" data-scroll-target="#testing-the-model-inference">4.4.11 Testing the Model (Inference)</a></li>
  <li><a href="#testing-with-a-bigger-model" id="toc-testing-with-a-bigger-model" class="nav-link" data-scroll-target="#testing-with-a-bigger-model">4.4.12 Testing with a Bigger Model</a></li>
  <li><a href="#runing-inference-on-the-sensecraft-web-toolkit" id="toc-runing-inference-on-the-sensecraft-web-toolkit" class="nav-link" data-scroll-target="#runing-inference-on-the-sensecraft-web-toolkit">4.4.13 Runing inference on the SenseCraft-Web-Toolkit</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">4.4.14 Conclusion</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Mjrovai/XIAO_Big_Power_Small_Board-ebook/edit/main/chapter_4-4.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/Mjrovai/XIAO_Big_Power_Small_Board-ebook/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/Mjrovai/XIAO_Big_Power_Small_Board-ebook/blob/main/chapter_4-4.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">4.4 Image Classification</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In this section, let’s explore Computer Vision ML applications on the XIAO ESP32S3 Sense.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587471/_nOXij20mq1.blob?auto=compress%2Cformat&amp;w=900&amp;h=675&amp;fit=min" class="img-fluid"></p>
<section id="things-used-in-this-project" class="level2">
<h2 class="anchored" data-anchor-id="things-used-in-this-project">4.4.1 Things used in this project</h2>
<section id="hardware-components" class="level3">
<h3 class="anchored" data-anchor-id="hardware-components">4.4.1.1 Hardware components</h3>
<!-- ![image.png](https://cdn.nlark.com/yuque/0/2023/png/2392200/1698372025691-4acf4da8-34fb-418c-88e3-8f72474a4335.png#averageHue=%23c7c7c1&clientId=uc417d4eb-bab9-4&from=paste&height=100&id=ub288bc7f&originHeight=711&originWidth=1063&originalType=binary&ratio=2&rotation=0&showTitle=false&size=518407&status=done&style=none&taskId=u7d41cfbf-583c-4385-9c9d-a64b72bf904&title=&width=149.5) -->
<p><a href="https://www.hackster.io/seeed/products/seeed-xiao-esp32s3-sense?ref=project-cb42ae">Seeed Studio Seeed XIAO ESP32S3 Sense</a> x 1 <img src="https://files.seeedstudio.com/wiki/XIAO_Big_Power-Board-ebook-photo/chapter_4-4_1.png" width="400" height="auto"></p>
</section>
<section id="software-apps-and-online-services" class="level3">
<h3 class="anchored" data-anchor-id="software-apps-and-online-services">4.4.2 Software apps and online services</h3>
<!-- -   ![image.png](https://cdn.nlark.com/yuque/0/2022/png/2392200/1669875695345-b20a52ba-5da7-4ce2-b21b-5ecb9b9802c3.png#averageHue=%23f3f4f1&clientId=u413b5b5e-84eb-4&from=paste&height=48&id=bESIK&originHeight=96&originWidth=96&originalType=binary&ratio=1&rotation=0&showTitle=false&size=9015&status=done&style=none&taskId=u32e545f3-6819-4f99-b7ea-98db56952d2&title=&width=48)  -->
<ul>
<li><p><img src="https://files.seeedstudio.com/wiki/XIAO_Big_Power-Board-ebook-photo/chapter_4-3/chapter_4-3_4.png" class="img-fluid"><a href="https://www.hackster.io/arduino/products/arduino-ide?ref=project-958fd2">Arduino IDE</a></p></li>
<li><p><img src="https://files.seeedstudio.com/wiki/XIAO_Big_Power-Board-ebook-photo/chapter_4-3/chapter_4-3_5.png" class="img-fluid"> <a href="https://www.hackster.io/EdgeImpulse/products/edge-impulse-studio?ref=project-958fd2">Edge Impulse Studio</a></p></li>
</ul>
</section>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">4.4.2 Introduction</h2>
<p>More and more, we are facing an artificial intelligence (AI) revolution where, as stated by Gartner, <strong>Edge AI</strong> has a very high impact potential, and <strong>it is for now</strong>!</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587506/image_EZKT6sirt5.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>In the “bull-eye” of emerging technologies, radar is the <em>Edge Computer Vision</em>, and when we talk about Machine Learning (ML) applied to vision, the first thing that comes to mind is <strong>Image Classification</strong>, a kind of ML “Hello World”!</p>
<p>Seeed Studio released a new affordable development board, the <a href="https://www.seeedstudio.com/XIAO-ESP32S3-Sense-p-5639.html">XIAO ESP32S3 Sense</a>, which integrates a camera sensor, digital microphone, and SD card support. Combining embedded ML computing power and photography capability, this development board is a great tool to start with TinyML (intelligent voice and vision AI).</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587507/image_kRGbYBWevi.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p><strong>XIAO ESP32S3 Sense Main Features</strong></p>
<ul>
<li><strong>Powerful MCU Board</strong>: Incorporate the ESP32S3 32-bit, dual-core, Xtensa processor chip operating up to 240 MHz, mounted multiple development ports, Arduino / MicroPython supported</li>
<li><strong>Advanced Functionality</strong>: Detachable OV2640 camera sensor for 1600 * 1200 resolution, compatible with OV5640 camera sensor, integrating an additional digital microphone</li>
<li><strong>Elaborate Power Design</strong>: Lithium battery charge management capability offers four power consumption models, which allows for deep sleep mode with power consumption as low as 14μA</li>
<li><strong>Great Memory for more Possibilities</strong>: Offer 8MB PSRAM and 8MB FLASH, supporting SD card slot for external 32GB FAT memory</li>
<li><strong>Outstanding RF performance</strong>: Support 2.4GHz Wi-Fi and BLE dual wireless communication, support 100m+ remote communication when connected with U.FL antenna</li>
<li><strong>Thumb-sized Compact Design</strong>: 21 x 17.5mm, adopting the classic form factor of XIAO, suitable for space-limited projects like wearable devices</li>
</ul>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587508/mty4odg1ntkynti4nteymg_561868_b55w78pjvck7sulf_1679553921_9rsX6h2aAP.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Below is the general board pinout:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587509/xiao_esp32c3_sense_pin-out_z24EXaHBen.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<blockquote class="blockquote">
<p>For more details, please refer to the Seeed Studio WiKi page: <br> https://wiki.seeedstudio.com/xiao_esp32s3_getting_started/</p>
</blockquote>
</section>
<section id="installing-the-xiao-esp32s3-sense-on-arduino-ide" class="level2">
<h2 class="anchored" data-anchor-id="installing-the-xiao-esp32s3-sense-on-arduino-ide">4.4.3 Installing the XIAO ESP32S3 Sense on Arduino IDE</h2>
<p>On Arduino IDE, navigate to <strong>File &gt; Preferences</strong>, and fill in the URL:</p>
<p><a href="https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_dev_index.json"><em>https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_dev_index.json</em></a></p>
<p>on the field ==&gt; <strong>Additional Boards Manager URLs</strong></p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587510/pasted_graphic_JkHMkNOmPR.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Next, open boards manager. Go to <strong>Tools</strong> &gt; <strong>Board</strong> &gt; <strong>Boards Manager…</strong> and enter with <em>esp32.</em> Select and install the most updated and stable package (avoid <em>alpha</em> versions) :</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587511/pasted_graphic_2_OtwAIVm5cJ.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<blockquote class="blockquote">
<p>⚠️ <strong>Attention</strong></p>
<p>Alpha versions (for example, 3.x-alpha) do not work correctly with the XIAO and Edge Impulse. Use the last stable version (for example, 2.0.11) instead.</p>
</blockquote>
<p>On <strong>Tools</strong>, select the Board (<strong>XIAO ESP32S3</strong>):</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587512/pasted_graphic_4_srwnXRNO0l.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Last but not least, choose the <strong>Port</strong> where the ESP32S3 is connected.</p>
<p>That is it! The device should be OK. Let’s do some tests.</p>
</section>
<section id="testing-the-board-with-blink" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-board-with-blink">4.4.4 Testing the board with BLINK</h2>
<p>The XIAO ESP32S3 Sense has a built-in LED that is connected to GPIO21. So, you can run the blink sketch as it is (using the <code>LED_BUILTIN</code> Arduino constant) or by changing the Blink sketch accordingly:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#define LED_BUILT_IN </span><span class="dv">21</span><span class="pp"> </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> setup<span class="op">()</span> <span class="op">{</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  pinMode<span class="op">(</span>LED_BUILT_IN<span class="op">,</span> OUTPUT<span class="op">);</span> <span class="co">// Set the pin as output</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">// Remember that the pin work with inverted logic</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">// LOW to Turn on and HIGH to turn off</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> loop<span class="op">()</span> <span class="op">{</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  digitalWrite<span class="op">(</span>LED_BUILT_IN<span class="op">,</span> LOW<span class="op">);</span> <span class="co">//Turn on</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  delay <span class="op">(</span><span class="dv">1000</span><span class="op">);</span> <span class="co">//Wait 1 sec</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  digitalWrite<span class="op">(</span>LED_BUILT_IN<span class="op">,</span> HIGH<span class="op">);</span> <span class="co">//Turn off</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  delay <span class="op">(</span><span class="dv">1000</span><span class="op">);</span> <span class="co">//Wait 1 sec</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Note that the pins work with inverted logic: LOW to Turn on and HIGH to turn off.</p>
</blockquote>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587515/blink_Lg3KqJa6ln.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
</section>
<section id="connecting-sense-module-expansion-board" class="level2">
<h2 class="anchored" data-anchor-id="connecting-sense-module-expansion-board">4.4.5 Connecting Sense module (Expansion Board)</h2>
<p>When purchased, the expansion board is separated from the main board, but installing the expansion board is very simple. You need to align the connector on the expansion board with the B2B connector on the XIAO ESP32S3, press it hard, and when you hear a “click,” the installation is complete.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587516/61.gif?auto=compress%2Cformat&amp;gifq=35&amp;w=740&amp;h=555&amp;fit=max" class="img-fluid"></p>
<p>As commented in the introduction, the expansion board, or the “sense” part of the device, has a 1600x1200 OV2640 camera, an SD card slot, and a digital microphone.</p>
</section>
<section id="microphone-test" class="level2">
<h2 class="anchored" data-anchor-id="microphone-test">4.4.6 Microphone Test</h2>
<p>Let’s start with sound detection. Go to the <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense">GitHub project</a> and download the sketch: <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/Mic_Test/XiaoEsp32s3_Mic_Test">XIAOEsp2s3_Mic_Test</a> and run it on the Arduino IDE:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587517/pasted_graphic_9_g3jF00J26n.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>When producing sound, you can verify it on the Serial Plotter.</p>
<p><strong>Save recorded sound (.wav audio files) to a microSD card.</strong></p>
<p>Now, the onboard SD Card reader can save .wav audio files. For that, we need to habilitate the XIAO PSRAM.</p>
<blockquote class="blockquote">
<p>ESP32-S3 has only a few hundred kilobytes of internal RAM on the MCU chip. It can be insufficient for some purposes so that ESP32-S3 can use up to 16 MB of external PSRAM (Psuedostatic RAM) connected with the SPI flash chip. The external memory is incorporated in the memory map and, with certain restrictions, is usable in the same way as internal data RAM.</p>
</blockquote>
<p>For a start, Insert the SD Card on the XIAO as shown in the photo below (the SD Card should be formatted to <strong>FAT32</strong>).</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587521/image_Z0TlaWDD8O.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<ul>
<li>Download the sketch <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/Mic_Test/Wav_Record">Wav_Record</a>, which you can find on GitHub.</li>
<li>To execute the code (Wav Record), it is necessary to use the PSRAM function of the ESP-32 chip, so turn it on before uploading.: Tools&gt;PSRAM: “OPI PSRAM”&gt;OPI PSRAM</li>
</ul>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587522/pasted_graphic_10_VYMCMnnxD3.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<ul>
<li>Run the code <code>Wav_Record.ino</code></li>
<li>This program is executed only once after the user <strong>turns on the serial monitor</strong>, recording for 20 seconds and saving the recording file to a microSD card as “arduino_rec.wav.”</li>
<li>When the “.” is output every 1 second in the serial monitor, the program execution is finished, and you can play the recorded sound file with the help of a card reader.</li>
</ul>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587523/pasted_graphic_11_bBwAlY3SeD.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>The sound quality is excellent!</p>
<blockquote class="blockquote">
<p>The explanation of how the code works is beyond the scope of this tutorial, but you can find an excellent description on the <a href="https://wiki.seeedstudio.com/xiao_esp32s3_sense_mic#save-recorded-sound-to-microsd-card">wiki</a> page.</p>
</blockquote>
</section>
<section id="testing-the-camera" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-camera">4.4.7 Testing the Camera</h2>
<p>To test the camera, you should download the folder <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/take_photos_command">take_photos_command</a> from GitHub. The folder contains the sketch (.ino) and two .h files with camera details.</p>
<ul>
<li>Run the code: <code>take_photos_command.ino</code>. Open the Serial Monitor and send the command <code>capture</code> to capture and save the image on the SD Card:</li>
</ul>
<blockquote class="blockquote">
<p>Verify that <code>[Both NL &amp; CR]</code> is selected on Serial Monitor.</p>
</blockquote>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587526/capture_8aHAA2OzDt.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Here is an example of a taken photo:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587527/image_vCiev0aEuH.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
</section>
<section id="testing-wifi" class="level2">
<h2 class="anchored" data-anchor-id="testing-wifi">4.4.8 Testing WiFi</h2>
<p>One of the differentiators of the XIAO ESP32S3 is its WiFi capability. So, let’s test its radio, scanning the wifi networks around it. You can do it by running one of the code examples on the board.</p>
<p>Go to Arduino IDE Examples and look for <strong>WiFI ==&gt; WiFIScan</strong></p>
<p>On the Serial monitor, you should see the wifi networks (SSIDs and RSSIs) in the range of your device. Here is what I got in the lab:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587529/pasted_graphic_14_mbFXPkj0kU.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p><strong>Simple WiFi Server (Turning LED ON/OFF)</strong></p>
<p>Let’s test the device’s capability to behave as a WiFi Server. We will host a simple page on the device that sends commands to turn the XIAO built-in LED ON and OFF.</p>
<p>Like before, go to GitHub to download the folder with the sketch <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/SimpleWiFiServer">SimpleWiFiServer</a>.</p>
<p>Before running the sketch, you should enter your network credentials:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="at">const</span> <span class="dt">char</span><span class="op">*</span> ssid     <span class="op">=</span> <span class="st">"Your credentials here"</span><span class="op">;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="at">const</span> <span class="dt">char</span><span class="op">*</span> password <span class="op">=</span> <span class="st">"Your credentials here"</span><span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can monitor how your server is working with the Serial Monitor.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587531/image_l0yhot2BP2.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Take the IP address and enter it on your browser:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587532/pasted_graphic_18_Tihy6lYH9T.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>You will see a page with links that can turn the built-in LED of your XIAO ON and OFF.</p>
<p><strong>Streaming video to Web</strong></p>
<p>Now that you know that you can send commands from the webpage to your device, let’s do the reverse. Let’s take the image captured by the camera and stream it to a webpage:</p>
<p>Download from GitHub the <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/Streeming_Video">folder</a> that contains the code: XIAO-ESP32S3-Streeming_Video.ino.</p>
<blockquote class="blockquote">
<p>Remember that the folder contains the.ino file and a couple of .h files necessary to handle the camera.</p>
</blockquote>
<p>Enter your credentials and run the sketch. On the Serial monitor, you can find the page address to enter in your browser:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587533/pasted_graphic_21_s4OswByvQx.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Open the page on your browser (wait a few seconds to start the streaming). That’s it.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587534/pasted_graphic_19_xsDOsUz1vB.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Streamlining what your camera is “seen” can be important when you position it to capture a dataset for an ML project (for example, using the code “take_phots_commands.ino”.</p>
<p>Of course, we can do both things simultaneously: show what the camera sees on the page and send a command to capture and save the image on the SD card. For that, you can use the code Camera_HTTP_Server_STA, which can be downloaded from GitHub.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587535/pasted_graphic_29_Tq37VCI7wB.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>The program will do the following tasks:</p>
<ul>
<li>Set the camera to JPEG output mode.</li>
<li>Create a web page (for example ==&gt; http://192.168.4.119//). The correct address will be displayed on the Serial Monitor.</li>
<li>If server.on (“/capture”, HTTP_GET, serverCapture), the program takes a photo and sends it to the Web.</li>
<li>It is possible to rotate the image on webPage using the button [ROTATE]</li>
<li>The command [CAPTURE] only will preview the image on the webpage, showing its size on the Serial Monitor</li>
<li>The <code>[SAVE]</code> command will save an image on the SD Card and show the image on the browser.</li>
<li>Saved images will follow a sequential naming (image1.jpg, image2.jpg.</li>
</ul>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587540/pasted_graphic_32_XjZcdijNwT.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<blockquote class="blockquote">
<p>This program can be used for an image dataset capture with an Image Classification project.</p>
</blockquote>
<p>Inspect the code; it will be easier to understand how the camera works. This code was developed based on the great Rui Santos Tutorial <a href="https://randomnerdtutorials.com/esp32-cam-take-photo-display-web-server/">ESP32-CAM Take Photo and Display in Web Server</a>, which I invite all of you to visit.</p>
<p><strong>Using the CameraWebServer</strong></p>
<p>In the Arduino IDE, go to <code>File &gt; Examples &gt; ESP32 &gt; Camera</code>, and select <code>CameraWebServer</code></p>
<p>You also should comment on all cameras’ models, except the XIAO model pins:</p>
<p><code>#define CAMERA_MODEL_XIAO_ESP32S3 // Has PSRAM</code></p>
<p>And do not forget the <code>Tools</code> to enable the PSRAM.</p>
<p>Enter your wifi credentials and upload the code to the device:</p>
<p><img src="imgs_4-4/webCap1.jpg" class="img-fluid"></p>
<p>If the code is executed correctly, you should see the address on the Serial Monitor:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="imgs_4-4/serial_monitor.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image-20240214163034559</figcaption>
</figure>
</div>
<p>Copy the address on your browser and wait for the page to be uploaded. Select the camera resolution (for example, QVGA) and select <code>[START STREAM]</code>. Wait for a few seconds/minutes, depending on your connection. You can save an image on your computer download area using the [Save] button.</p>
<p><img src="imgs_4-4/img_cap.jpg" class="img-fluid"></p>
<p>That’s it! You can save the images directly on your computer to be used on projects.</p>
</section>
<section id="fruits-versus-veggies---a-tinyml-image-classification-project" class="level2">
<h2 class="anchored" data-anchor-id="fruits-versus-veggies---a-tinyml-image-classification-project">4.4.9 Fruits versus Veggies - A TinyML Image Classification Project</h2>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587486/vegetables-g3276e6aa0_1280_y8LhyxRCDB.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Now that we have an embedded camera running, it is time to try image classification. For comparative motive, we will replicate the same image classification project developed to be used with an old ESP2-CAM:</p>
<p><a href="https://www.hackster.io/mjrobot/esp32-cam-tinyml-image-classification-fruits-vs-veggies-4ab970">ESP32-CAM: TinyML Image Classification - Fruits vs Veggies</a></p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587541/image_60a57gQ8VS.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>The whole idea of our project will be to train a model and proceed with inference on the XIAO ESP32S3 Sense. For training, we should find some data <strong>(in fact, tons of data!</strong>).</p>
<p><em>But first of all, we need a goal! What do we want to classify?</em></p>
<p>With TinyML, a set of techniques associated with machine learning inference on embedded devices, we should limit the classification to three or four categories due to limitations (mainly memory). We will differentiate <strong>apples</strong> from <strong>bananas</strong> and <strong>potatoes</strong> (you can try other categories)<strong>.</strong></p>
<p>So, let’s find a specific dataset that includes images from those categories. Kaggle is a good start:</p>
<p>https://www.kaggle.com/kritikseth/fruit-and-vegetable-image-recognition</p>
<p>This dataset contains images of the following food items:</p>
<ul>
<li><strong>Fruits</strong> - <em>banana, apple</em>, pear, grapes, orange, kiwi, watermelon, pomegranate, pineapple, mango.</li>
<li><strong>Vegetables</strong> - cucumber, carrot, capsicum, onion, <em>potato,</em> lemon, tomato, radish, beetroot, cabbage, lettuce, spinach, soybean, cauliflower, bell pepper, chili pepper, turnip, corn, sweetcorn, sweet potato, paprika, jalepeño, ginger, garlic, peas, eggplant.</li>
</ul>
<p>Each category is split into the <strong>train</strong> (100 images), <strong>test</strong> (10 images), and <strong>validation</strong> (10 images).</p>
<ul>
<li>Download the dataset from the Kaggle website to your computer.</li>
</ul>
<blockquote class="blockquote">
<p>Optionally, you can add some fresh photos of bananas, apples, and potatoes from your home kitchen, using, for example, the codes discussed in the last section.</p>
</blockquote>
</section>
<section id="training-the-model-with-edge-impulse-studio" class="level2">
<h2 class="anchored" data-anchor-id="training-the-model-with-edge-impulse-studio">4.4.10 Training the model with Edge Impulse Studio</h2>
<p>We will use the Edge Impulse Studio to train our model. As you know, <a href="https://www.edgeimpulse.com/">Edge Impulse</a> is a leading development platform for machine learning on edge devices.</p>
<p>Enter your account credentials (or create a free account) at Edge Impulse. Next, create a new project:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587543/image_MDgkE355g3.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p><strong>Data Acquisition</strong></p>
<p>Next, on the UPLOAD DATA section, upload from your computer the files from chosen categories:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587488/image_brdDCN6bc5.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>It would be best if you now had your training dataset split into three classes of data:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587489/image_QyxusuY3DM.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<blockquote class="blockquote">
<p>You can upload extra data for further model testing or split the training data. I will leave it as it is to use the most data possible.</p>
</blockquote>
<p><strong>Impulse Design</strong></p>
<blockquote class="blockquote">
<p>An impulse takes raw data (in this case, images), extracts features (resize pictures), and then uses a learning block to classify new data.</p>
</blockquote>
<p>Classifying images is the most common use of deep learning, but much data should be used to accomplish this task. We have around 90 images for each category. Is this number enough? Not at all! We will need thousands of images to “teach or model” to differentiate an apple from a banana. But, we can solve this issue by re-training a previously trained model with thousands of images. We call this technique “Transfer Learning” (TL).</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587490/tl_fuVIsKd7YV.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>With TL, we can fine-tune a pre-trained image classification model on our data, performing well even with relatively small image datasets (our case).</p>
<p>So, starting from the raw images, we will resize them (96x96) pixels and feed them to our Transfer Learning block:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587491/image_QhTt0Av8u3.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p><strong>Pre-processing (Feature generation)</strong></p>
<p>Besides resizing the images, we can change them to Grayscale or keep the actual RGB color depth. Let’s start selecting <code>Grayscale</code>. Doing that, each one of our data samples will have dimension 9, 216 features (96x96x1). Keeping RGB, this dimension would be three times bigger. Working with Grayscale helps to reduce the amount of final memory needed for inference.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587492/image_eqGdUoXrMb.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Do not forget to <code>[Save parameters]</code>.” This will generate the features to be used in training.</p>
<p><strong>Training (Transfer Learning &amp; Data Augmentation)</strong></p>
<p>In 2007, Google introduced <a href="https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html">MobileNetV1,</a> a family of general-purpose computer vision neural networks designed with mobile devices in mind to support classification, detection, and more. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of various use cases.</p>
<p>Although the base MobileNet architecture is already tiny and has low latency, many times, a specific use case or application may require the model to be smaller and faster. MobileNet introduces a straightforward parameter α (alpha) called width multiplier to construct these smaller, less computationally expensive models. The role of the width multiplier α is to thin a network uniformly at each layer.</p>
<p>Edge Impulse Studio has available MobileNet V1 (96x96 images) and V2 (96x96 and 160x160 images), with several different <strong>α</strong> values (from 0.05 to 1.0). For example, you will get the highest accuracy with V2, 160x160 images, and α=1.0. Of course, there is a trade-off. The higher the accuracy, the more memory (around 1.3M RAM and 2.6M ROM) will be needed to run the model, implying more latency.</p>
<p>The smaller footprint will be obtained at another extreme with <strong>MobileNet V1</strong> and α=0.10 (around 53.2K RAM and 101K ROM).</p>
<p>When we first published this project to be running on an ESP32-CAM, we stayed at the lower side of possibilities, which guaranteed the inference with small latency but not with high accuracy. For this first pass, we will keep this model design (<strong>MobileNet V1</strong> and α=0.10).</p>
<p>Another necessary technique to use with deep learning is <strong>data augmentation</strong>. Data augmentation is a method that can help improve the accuracy of machine learning models, creating additional artificial data. A data augmentation system makes small, random changes to your training data during the training process (such as flipping, cropping, or rotating the images).</p>
<p>Under the rood, here you can see how Edge Impulse implements a data Augmentation policy on your data:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="pp"># </span><span class="er">Implements the data augmentation policy</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>def augment_image<span class="op">(</span>image<span class="op">,</span> label<span class="op">):</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">Flips the image randomly</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf<span class="op">.</span>image<span class="op">.</span>random_flip_left_right<span class="op">(</span>image<span class="op">)</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">Increase the image size, then randomly crop it down to</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">the original dimensions</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    resize_factor <span class="op">=</span> random<span class="op">.</span>uniform<span class="op">(</span><span class="dv">1</span><span class="op">,</span> <span class="fl">1.2</span><span class="op">)</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    new_height <span class="op">=</span> math<span class="op">.</span>floor<span class="op">(</span>resize_factor <span class="op">*</span> INPUT_SHAPE<span class="op">[</span><span class="dv">0</span><span class="op">])</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    new_width <span class="op">=</span> math<span class="op">.</span>floor<span class="op">(</span>resize_factor <span class="op">*</span> INPUT_SHAPE<span class="op">[</span><span class="dv">1</span><span class="op">])</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf<span class="op">.</span>image<span class="op">.</span>resize_with_crop_or_pad<span class="op">(</span>image<span class="op">,</span> new_height<span class="op">,</span> new_width<span class="op">)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf<span class="op">.</span>image<span class="op">.</span>random_crop<span class="op">(</span>image<span class="op">,</span> size<span class="op">=</span>INPUT_SHAPE<span class="op">)</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">Vary the brightness of the image</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf<span class="op">.</span>image<span class="op">.</span>random_brightness<span class="op">(</span>image<span class="op">,</span> max_delta<span class="op">=</span><span class="fl">0.2</span><span class="op">)</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> image<span class="op">,</span> label</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Exposure to these variations during training can help prevent your model from taking shortcuts by “memorizing” superficial clues in your training data, meaning it may better reflect the deep underlying patterns in your dataset.</p>
<p>The final layer of our model will have 16 neurons with a 10% of dropout for overfitting prevention. Here is the Training output:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587493/image_iqCv79Lhga.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>The result could be better. The model reached around 77% accuracy, but the amount of RAM expected to be used during the inference is relatively tiny (about 60 KBytes), which is very good.</p>
<p><strong>Deployment</strong></p>
<p>The trained model will be deployed as a .zip Arduino library:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587494/image_QqiDK41Uyp.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Open your Arduino IDE, and under <strong>Sketch,</strong> go to <strong>Include Library</strong> and <strong>add.ZIP Library.</strong> Please select the file you download from Edge Impulse Studio, and that’s it!</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587590/image_BQwzaHFlzZ.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Under the <strong>Examples</strong> tab on Arduino IDE, you should find a sketch code under your project name.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587591/image_Xglfrz0mwe.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Open the Static Buffer example:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587593/image_1ZSC9qmEuR.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>You can see that the first line of code is exactly the calling of a library with all the necessary stuff for running inference on your device.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;XIAO-ESP32S3-CAM-Fruits-vs-Veggies_inferencing.h&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Of course, this is a generic code (a “template”) that only gets one sample of raw data (stored on the variable: features = {} and runs the classifier, doing the inference. The result is shown on the Serial Monitor.</p>
<p>We should get the sample (image) from the camera and pre-process it (resizing to 96x96, converting to grayscale, and flatting it). This will be the input tensor of our model. The output tensor will be a vector with three values (labels), showing the probabilities of each one of the classes.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587596/image_vrxwEjpaAl.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Returning to your project (Tab Image), copy one of the Raw Data Sample:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587598/image_J6oBO8SFpW.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>9, 216 features will be copied to the clipboard. This is the input tensor (a flattened image of 96x96x1), in this case, bananas. Past this Input tensor on features[] = {0xb2d77b, 0xb5d687, 0xd8e8c0, 0xeaecba, 0xc2cf67, …}</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587599/image_YYAJaMDMSG.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Edge Impulse included the <a href="https://github.com/espressif/esp-nn">library ESP NN</a> in its SDK, which contains optimized NN (Neural Network) functions for various Espressif chips, including the ESP32S3 (running at Arduino IDE).</p>
<p>When running the inference, you should get the highest score for “banana.”</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587603/pasted_graphic_35_3MfEQ8f4Zg.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Great news! Our device handles an inference, discovering that the input image is a banana. Also, note that the inference time was around 317ms, resulting in a maximum of 3 fps if you tried to classify images from a video. It is a better result than the ESP32 CAM (525ms of latency).</p>
<p>Now, we should incorporate the camera and classify images in real time.</p>
<p>Go to the Arduino IDE Examples and download from your project the sketch esp32_camera:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587604/image_hjX5k8gTl8.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>You should change lines 32 to 75, which define the camera model and pins, using the data related to our model. Copy and paste the below lines, replacing the lines 32-75:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#define PWDN_GPIO_NUM     </span><span class="op">-</span><span class="dv">1</span><span class="pp"> </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#define RESET_GPIO_NUM    </span><span class="op">-</span><span class="dv">1</span><span class="pp"> </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#define XCLK_GPIO_NUM     </span><span class="dv">10</span><span class="pp"> </span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="pp">#define SIOD_GPIO_NUM     </span><span class="dv">40</span><span class="pp"> </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="pp">#define SIOC_GPIO_NUM     </span><span class="dv">39</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y9_GPIO_NUM       </span><span class="dv">48</span><span class="pp"> </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y8_GPIO_NUM       </span><span class="dv">11</span><span class="pp"> </span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y7_GPIO_NUM       </span><span class="dv">12</span><span class="pp"> </span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y6_GPIO_NUM       </span><span class="dv">14</span><span class="pp"> </span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y5_GPIO_NUM       </span><span class="dv">16</span><span class="pp"> </span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y4_GPIO_NUM       </span><span class="dv">18</span><span class="pp"> </span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y3_GPIO_NUM       </span><span class="dv">17</span><span class="pp"> </span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="pp">#define Y2_GPIO_NUM       </span><span class="dv">15</span><span class="pp"> </span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="pp">#define VSYNC_GPIO_NUM    </span><span class="dv">38</span><span class="pp"> </span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="pp">#define HREF_GPIO_NUM     </span><span class="dv">47</span><span class="pp"> </span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="pp">#define PCLK_GPIO_NUM     </span><span class="dv">13</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here you can see the resulting code:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587605/image_4VmERAOAfF.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>The modified sketch can be downloaded from GitHub: <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense/tree/main/xiao_esp32s3_camera">xiao_esp32s3_camera</a>.</p>
<blockquote class="blockquote">
<p>Note that you can optionally keep the pins as a .h file as we did in previous sections.</p>
</blockquote>
<p>Upload the code to your XIAO ESP32S3 Sense, and you should be OK to start classifying your fruits and vegetables! You can check the result on Serial Monitor.</p>
</section>
<section id="testing-the-model-inference" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-model-inference">4.4.11 Testing the Model (Inference)</h2>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587606/inferencia_FM2hfD6ETR.jpg?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Getting a photo with the camera, the classification result will appear on the Serial Monitor:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587607/pasted_graphic_40_6R61QEiLGp.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Other tests:</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587608/inferencia2_eGWjtNny2o.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
</section>
<section id="testing-with-a-bigger-model" class="level2">
<h2 class="anchored" data-anchor-id="testing-with-a-bigger-model">4.4.12 Testing with a Bigger Model</h2>
<p>Now, let’s go to the other side of the model size. Let’s select a MobilinetV2 96x96 0.35, having as input RGB images.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1587626/image_wUPCEECR3t.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Even with a bigger model, the accuracy could be better, and the amount of memory necessary to run the model increases five times, with latency increasing seven times.</p>
<blockquote class="blockquote">
<p>Note that the performance here is estimated with a smaller device, the ESP-EYE. The actual inference with the ESP32S3 should be better.</p>
</blockquote>
<p>To improve our model, we will need to train more images.</p>
<p>Even though our model did not improve accuracy, let’s test whether the XIAO can handle such a bigger model. We will do a simple inference test with the Static Buffer sketch.</p>
<p>Let’s redeploy the model. If the EON Compiler is enabled when you generate the library, the total memory needed for inference should be reduced, but it does not influence accuracy.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1591694/image_Ne6NKwD297.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>Doing an inference with MobilinetV2 96x96 0.35, having as input RGB images, the latency was of 219ms, what it is great for such bigger model.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1591700/espnn-infe1_c5bolsFLaK.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<p>For test, I trained the model again, using the smallest version of MobileNet V2, with an alpha of 0.05. Interesting that the result in accuraccy was higher.</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1591705/image_lwYLKM696A.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Note that the estimated latency for an Arduino Portenta (ou Nicla), running with a clock of 480MHz is 45ms.</p>
</blockquote>
<p>Deploying the model, I got an inference of only 135ms, remembering that the XIAO run with half of the clock used by the Portenta/Nicla (240MHz):</p>
<p><img src="https://hackster.imgix.net/uploads/attachments/1591706/image_dAfOl9Tguz.png?auto=compress%2Cformat&amp;w=1280&amp;h=960&amp;fit=max" class="img-fluid"></p>
</section>
<section id="runing-inference-on-the-sensecraft-web-toolkit" class="level2">
<h2 class="anchored" data-anchor-id="runing-inference-on-the-sensecraft-web-toolkit">4.4.13 Runing inference on the SenseCraft-Web-Toolkit</h2>
<p>One significant limitation of viewing inference on Arduino IDE is that we can not see what the camera focuses on. A good alternative is the <strong>SenseCraft-Web-Toolkit</strong>, a visual model deployment tool provided by <a href="https://sensecraftma.seeed.cc/">SSCMA</a>(Seeed SenseCraft Model Assistant). This tool allows you to deploy models to various platforms easily through simple operations. The tool provides a user-friendly interface and does not require any coding.</p>
<p>Follow the following steps to start the SenseCraft-Web-Toolkit:</p>
<ol type="1">
<li>Open the SenseCraft-Web-Toolkit <a href="https://seeed-studio.github.io/SenseCraft-Web-Toolk">website</a>.</li>
<li>Connect the XIAO to your computer:</li>
</ol>
<ul>
<li>Having the XIAO connected, select it as below:</li>
</ul>
<p><img src="imgs_4-4/senseCraft-1.jpg" class="img-fluid"></p>
<ul>
<li>Select the device/Port and press <code>[Connect]</code>:</li>
</ul>
<p><img src="imgs_4-4/senseCraft-2.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>You can try several Computer Vision models previously uploaded by Seeed Studio. Try them and have fun!</p>
</blockquote>
<p>In our case, we will use the blue button at the bottom of the page: <code>[Upload Custom AI Model]</code>.</p>
<p>But first, we will need to download from Edge Impulse Studio our <strong>quantized .tflite</strong> model.</p>
<ol start="3" type="1">
<li>Go to your project at Edge Impulse Studio, or clone this one:</li>
</ol>
<ul>
<li><a href="https://studio.edgeimpulse.com/public/228516/live">XIAO-ESP32S3-CAM-Fruits-vs-Veggies-v1-ESP-NN</a></li>
</ul>
<ol start="4" type="1">
<li>On <code>Dashboard</code>, download the model (“block output”): <code>Transfer learning mdodel - TensorFlow Lite (int8 quantized)</code></li>
</ol>
<p><img src="imgs_4-4/senseCraft-4.jpg" class="img-fluid"></p>
<ol start="5" type="1">
<li>On SenseCraft-Web-Toolkit, use the blue button at the bottom of the page: <code>[Upload Custom AI Model]</code>. A window will pop up. Enter the Model file that you downloaded to your computer from Edge Impulse Studio, choose a Model Name, and enter with labels (ID:Object):</li>
</ol>
<p><img src="imgs_4-4/senseCraft-3.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Note that you should use the labels trained on EI Studio, entering them at alphabetic order (in our case: apple, banana, potato).</p>
</blockquote>
<p>After a few seconds (or minutes), the model will be uploaded to your device and the camera image will appear in real-time on the Preview Sector:</p>
<p><img src="imgs_4-4/senseCraft-apple.jpg" class="img-fluid"></p>
<p>The Classification result will be at the top of the image. You can also select the Confidence of your inference cursor <code>Confidence</code>.</p>
<p>Clicking on the top button (Device Log), you can open a Serial Monitor to follow the inference, the same that we have done with the Arduino IDE:</p>
<p><img src="imgs_4-4/senseCraft-apple-2.jpg" class="img-fluid"></p>
<p>On Device Log, you will get Information as:</p>
<p><img src="imgs_4-4/senseCraft-log.jpg" class="img-fluid"></p>
<ul>
<li>Preprocess time (image capture and Crop): 4ms;</li>
<li>Inference time (model latency): 106ms,</li>
<li>Postprocess time (display of the image and inclusion of data): 0ms.</li>
<li>Output tensor (classes), for example: [[89,0]]; where 0 is Apple (and 1is banana and 2 is potato)</li>
</ul>
<p>Here are other screen shots:</p>
<p><img src="imgs_4-4/inference.jpg" class="img-fluid"></p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">4.4.14 Conclusion</h2>
<p>The XIAO ESP32S3 Sense is a very flexible, not expensive, and easy-to-program device. The project proves the potential of TinyML. Memory is not an issue; the device can handle many post-processing tasks, including communication.</p>
<p>On the GitHub repository, you will find the last version of the codes: <a href="https://github.com/Mjrovai/XIAO-ESP32S3-Sense">XIAO-ESP32S3-Sense.</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_4-3.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">4.3 Sound Classification (KWS)</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_4-5.html" class="pagination-link">
        <span class="nav-page-text">4.5 Object Detection</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">XIAO: Big Power, Small Board</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">This book was built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



</body></html>